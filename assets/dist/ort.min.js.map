{"version":3,"sources":["../../common/lib/backend-impl.ts","../../common/lib/backend.ts","../../common/lib/version.ts","../../common/lib/env-impl.ts","../../common/lib/env.ts","../../common/lib/tensor-conversion-impl.ts","../../common/lib/tensor-factory-impl.ts","../../common/lib/tensor-impl-type-mapping.ts","../../common/lib/tensor-utils-impl.ts","../../common/lib/tensor-impl.ts","../../common/lib/tensor.ts","../../common/lib/trace.ts","../../common/lib/inference-session-impl.ts","../../common/lib/inference-session.ts","../../common/lib/tensor-conversion.ts","../../common/lib/tensor-factory.ts","../../common/lib/onnx-model.ts","../../common/lib/onnx-value.ts","../../common/lib/index.ts","../lib/wasm/wasm-utils-env.ts","../lib/wasm/proxy-worker/main.ts","../lib/wasm/wasm-utils-import.ts","../lib/wasm/wasm-factory.ts","../lib/wasm/wasm-utils.ts","../lib/wasm/run-options.ts","../lib/wasm/session-options.ts","../lib/wasm/wasm-common.ts","../lib/wasm/wasm-utils-load-file.ts","../lib/wasm/jsep/log.ts","../lib/wasm/jsep/util.ts","../lib/wasm/jsep/tensor-view.ts","../lib/wasm/jsep/webnn/tensor-manager.ts","../lib/wasm/jsep/backend-webnn.ts","../lib/wasm/jsep/webgpu/types.ts","../lib/wasm/jsep/webgpu/gpu-data-manager.ts","../lib/wasm/jsep/webgpu/attribute-with-cache-key.ts","../lib/wasm/jsep/webgpu/ops/common.ts","../lib/wasm/jsep/webgpu/ops/transpose.ts","../lib/wasm/jsep/webgpu/ops/reduce-shared.ts","../lib/wasm/jsep/webgpu/ops/reduce.ts","../lib/wasm/jsep/webgpu/ops/argminmax.ts","../lib/wasm/jsep/webgpu/ops/attention.ts","../lib/wasm/jsep/webgpu/ops/batch-norm.ts","../lib/wasm/jsep/webgpu/ops/bias-add.ts","../lib/wasm/jsep/webgpu/ops/unary-op.ts","../lib/wasm/jsep/webgpu/ops/bias-split-gelu.ts","../lib/wasm/jsep/webgpu/ops/binary-op.ts","../lib/wasm/jsep/webgpu/ops/concat.ts","../lib/wasm/jsep/webgpu/ops/fuse-utils.ts","../lib/wasm/jsep/webgpu/ops/3rd-party/activation_util.ts","../lib/wasm/jsep/webgpu/ops/3rd-party/conv_util.ts","../lib/wasm/jsep/webgpu/ops/matmul-shaders.ts","../lib/wasm/jsep/webgpu/ops/3rd-party/matmul_packed_webgpu.ts","../lib/wasm/jsep/webgpu/ops/3rd-party/conv2d_mm_webgpu.ts","../lib/wasm/jsep/webgpu/ops/3rd-party/conv3d_naive_webgpu.ts","../lib/wasm/jsep/webgpu/ops/conv-grouped.ts","../lib/wasm/jsep/webgpu/ops/conv.ts","../lib/wasm/jsep/webgpu/ops/3rd-party/conv_backprop_webgpu.ts","../lib/wasm/jsep/webgpu/ops/conv-transpose.ts","../lib/wasm/jsep/webgpu/ops/cumsum.ts","../lib/wasm/jsep/webgpu/ops/depth-to-space.ts","../lib/wasm/jsep/webgpu/ops/einsum.ts","../lib/wasm/jsep/webgpu/ops/expand.ts","../lib/wasm/jsep/webgpu/ops/fast-gelu.ts","../lib/wasm/jsep/webgpu/ops/gather.ts","../lib/wasm/jsep/webgpu/ops/gather-nd.ts","../lib/wasm/jsep/webgpu/ops/gather-block-quantized.ts","../lib/wasm/jsep/webgpu/ops/gather-elements.ts","../lib/wasm/jsep/webgpu/ops/gemm.ts","../lib/wasm/jsep/webgpu/ops/grid-sample.ts","../lib/wasm/jsep/webgpu/ops/multihead-attention.ts","../lib/wasm/jsep/webgpu/ops/split.ts","../lib/wasm/jsep/webgpu/ops/group-query-attention.ts","../lib/wasm/jsep/webgpu/ops/instance-norm.ts","../lib/wasm/jsep/webgpu/ops/layer-norm.ts","../lib/wasm/jsep/webgpu/ops/matmul.ts","../lib/wasm/jsep/webgpu/ops/matmulnbits.ts","../lib/wasm/jsep/webgpu/ops/pad.ts","../lib/wasm/jsep/webgpu/ops/pool.ts","../lib/wasm/jsep/webgpu/ops/quantize-linear.ts","../lib/wasm/jsep/webgpu/ops/range.ts","../lib/wasm/jsep/webgpu/ops/scatter-nd.ts","../lib/wasm/jsep/webgpu/ops/resize.ts","../lib/wasm/jsep/webgpu/ops/rotary-embedding.ts","../lib/wasm/jsep/webgpu/ops/skip-layer-norm.ts","../lib/wasm/jsep/webgpu/ops/slice.ts","../lib/wasm/jsep/webgpu/ops/softmax.ts","../lib/wasm/jsep/webgpu/ops/tile.ts","../lib/wasm/jsep/webgpu/ops/where.ts","../lib/wasm/jsep/webgpu/op-resolve-rules.ts","../lib/wasm/jsep/webgpu/program-manager.ts","../lib/wasm/jsep/backend-webgpu.ts","../lib/wasm/jsep/init.ts","../lib/wasm/wasm-core-impl.ts","../lib/wasm/proxy-wrapper.ts","../lib/wasm/session-handler-inference.ts","../lib/backend-wasm.ts","../lib/index.ts","../lib/version.ts"],"names":["backends","backendsSortedByPriority","registerBackend","tryResolveAndInitializeBackend","resolveBackendAndExecutionProviders","init_backend_impl","__esmMin","name","backend","priority","currentBackend","i","backendName","backendInfo","isInitializing","e","options","eps","backendHints","backendNames","errors","availableBackendNames","resolveResult","err","filteredEps","target","prop","init_backend","version","init_version","logLevelValue","env","init_env_impl","value","init_env","tensorToDataURL","tensorToImageData","init_tensor_conversion_impl","tensor","canvas","pixels2DContext","width","height","inputformat","norm","normMean","normBias","stride","rTensorPointer","gTensorPointer","bTensorPointer","aTensorPointer","j","R","G","B","A","image","channels","step","rImagePointer","gImagePointer","bImagePointer","aImagePointer","bufferToTensor","tensorFromImage","tensorFromTexture","tensorFromGpuBuffer","tensorFromMLTensor","tensorFromPinnedBuffer","init_tensor_factory_impl","init_tensor_impl","buffer","outputformat","float32Data","Tensor","isHTMLImageEle","isImageDataEle","isImageBitmap","isString","data","bufferToTensorOptions","createCanvas","createCanvasContext","tempCanvas","resolve","reject","context","newImage","img","texture","download","dispose","dims","gpuBuffer","dataType","mlTensor","type","NUMERIC_TENSOR_TYPE_TO_TYPEDARRAY_MAP","NUMERIC_TENSOR_TYPEDARRAY_TO_TYPE_MAP","isTypedArrayChecked","checkTypedArray","init_tensor_impl_type_mapping","isBigInt64ArrayAvailable","isBigUint64ArrayAvailable","Float16Array","isFloat16ArrayAvailable","calculateSize","tensorReshape","init_tensor_utils_impl","size","dim","arg0","arg1","arg2","expectedTypedArrayConstructor","maybeDims","typedArrayConstructor","firstElementType","mappedType","releaseData","init_tensor","TRACE","TRACE_FUNC","TRACE_FUNC_BEGIN","TRACE_FUNC_END","init_trace","deviceType","label","msg","extraMsg","stack","hasTraceFunc","InferenceSession","init_inference_session_impl","_InferenceSession","handler","feeds","fetches","isFetchesEmpty","isFetches","arg1Keys","v","results","returnValue","key","result","arg3","filePathOrUint8Array","byteOffset","byteLength","optionsWithValidatedEPs","init_inference_session","init_tensor_conversion","init_tensor_factory","init_onnx_model","init_onnx_value","esm_exports","__export","init_esm","init_wasm_utils_env","main_exports","main_default","WORKER_NAME","isProxyWorker","init_main","init_wasm_core_impl","init_wasm_factory","init_wasm_utils_import","ev","message","initializeWebAssembly","initRuntime","epName","initEp","bufferData","copyFromExternalBuffer","model","createSession","sessionMetadata","releaseSession","sessionId","inputIndices","inputs","outputIndices","run","outputs","o","extractTransferableBuffers","endProfiling","urlOverride","scriptSrc","origin","getScriptSrc","inferWasmPathPrefixFromScriptSrc","isSameOrigin","normalizeUrl","fallbackUrl","preload","dynamicImportDefault","createProxyWorker","importProxyWorker","embeddedWasmModule","importWasmModule","filename","prefixOverride","baseUrl","absoluteUrl","blob","url","isMultiThreaded","wasmModuleFilename","wasmModuleUrl","needPreload","wasm","initialized","initializing","aborted","isMultiThreadSupported","isSimdSupported","getInstance","flags","timeout","numThreads","multiThreadSupported","wasmPaths","wasmPrefixOverride","mjsPathOverrideFlag","mjsPathOverride","wasmPathOverrideFlag","wasmPathOverride","wasmBinaryOverride","objectUrl","ortWasmFactory","isTimeout","tasks","config","fileName","inferredWasmPathPrefix","module","what","allocWasmString","iterateExtraOptions","checkLastError","init_wasm_utils","allocs","dataLength","dataOffset","prefix","seen","ptrSize","paramsOffset","errorCode","errorMessagePointer","errorMessage","setRunOptions","init_run_options","runOptionsHandle","runOptions","tagDataOffset","keyDataOffset","valueDataOffset","alloc","getGraphOptimzationLevel","getExecutionMode","appendDefaultOptions","appendSessionConfig","setExecutionProviders","setSessionOptions","init_session_options","graphOptimizationLevel","executionMode","session","ep","sessionOptionsHandle","executionProviders","epOptions","webgpuOptions","epNameDataOffset","epOptionsCount","keysOffset","valuesOffset","sessionOptions","logIdDataOffset","logSeverityLevel","logVerbosityLevel","optimizedModelFilePathOffset","nameOffset","tensorDataTypeStringToEnum","tensorDataTypeEnumToString","calculateTensorSizeInBytes","tensorTypeToTypedArrayConstructor","logLevelStringToEnum","isGpuBufferSupportedType","isMLTensorSupportedType","dataLocationStringToEnum","init_wasm_common","typeProto","dateType","dimsOrSize","elementSize","a","b","logLevel","location","loadFile","init_wasm_utils_load_file","file","readFile","createReadStream","stream","chunks","chunk","response","contentLengthHeader","fileSize","reader","pages","offset","done","chunkSize","logLevelPrefix","doLog","configLogLevel","debug","configureLogger","LOG","LOG_DEBUG","init_log","level","$configLogLevel","$debug","messageLevel","configLevel","args","MatMulUtil","BroadcastUtil","ShapeUtil","PoolConvUtil","GemmUtil","MIN_CLIP","MAX_CLIP","init_util","adims","bdims","isMatMul","arank","brank","crank","cdims","cShapeMatMul","aLen","bLen","max","shape","finalShape","inputRank","finalRank","_ShapeUtil","rank","newDims","axis","start","end","strides","tensorRank","axes","x","perm","pad","shape1","shape2","_PoolConvUtil","isGlobalOperator","inputDims","kernelShape","dilations","pads","isChannelLast","autoPad","outputDims","filterDims","inSize","dilation","kernel","padHeadIndex","padTailIndex","dkernel","padNeeded","leftShape","transLeft","rightShape","transRight","biasShape","M","K","N","kDim","createView","init_tensor_view","dataBuffer","convertInt64ToInt32","convertInt32ToInt64","tensorGuid","createNewTensorId","webnnDataTypeToSize","calculateByteLength","TensorWrapper","TensorIdTracker","TensorManagerImpl","createTensorManager","init_tensor_manager","returnUint8","numElements","bigInt64Array","int32Array","descriptor","shouldConvertInt64toInt32","shouldConvertInt32ToInt64","dstBuffer","int64Data","isConverted","tensorManager","wrapper","copyOld","newDataType","usage","newData","dstData","tensorId","tensorTracker","writable","readable","index","tensorWrapper","onnxDataTypeToWebnnDataType","compareMLContextOptions","WebNNBackend","init_backend_webnn","aKeys","bKeys","tensorIds","optionsOrDevice","mlContextIndex","entry","mlContext","sessionIds","onnxDataType","dimensions","webnnDataType","id","externalFilePath","builder","desc","mountedFiles","shouldConvertInt64ToInt32","filePath","fileData","bufferView","inputName","inputNames","init_types","bucketFreelist","bucketArr","calcNormalizedBufferSize","calcBucketBufferSize","guid","createNewGpuDataId","downloadGpuData","GpuDataManagerImpl","createGpuDataManager","init_gpu_data_manager","idx","sizeForBucket","originalSize","getTargetBuffer","bufferSize","gpuReadBuffer","commandEncoder","arrayBuffer","targetBuffer","srcArrayBuffer","srcOffset","srcLength","gpuDataCache","gpuBufferForUploading","sourceId","destinationId","sourceGpuDataCache","destinationGpuDataCache","previous","isStorage","isUniform","buffers","gpuData","idInput","cachedData","maxInFreeList","freelist","capturedBuffers","storage","pendingBuffers","AttributeWithCacheKeyImpl","createAttributeWithCacheKey","init_attribute_with_cache_key","attribute","WORKGROUP_SIZE","getWgslMappedType","tensorTypeToWsglStorageType","tensorTypeToWsglValueType","createTensorShapeVariables","getMaxComponents","fillVector","castToF32","sumVector","getElementAt","createIndicesHelper","inputVariable","outputVariable","atomicOutputVariable","internalVariable","ShaderHelperImpl","createShaderHelper","init_common","components","programUniforms","length","tensorType","shapeOrRank","useUniform","rankIdentity","indicesType","valueType","storageType","normalizeDim","implementationUsed","uniformPrefix","o2iSnippet","offsetToIndicesImplementation","offsetToIndices","varOffset","offsets","indicesToOffsetImplementation","indicesToOffset","varIndices","indices","init","indicesGet","indicesSet","broadcastedIndicesToOffsetImplementation","broadcastedIndicesToOffset","output","implKey","setByOffset","getByOffset","getByIndicesImplementation","getImplementation","functionParams","dimsParams","get","normalizedIndices","getByIndices","setByIndicesImplementation","setImplementation","impls","needShapeStrides","impl","indicesAndValue","normalizedDispatchGroup","limits","workgroupSize","workgroupSizeX","workgroupSizeY","workgroupSizeZ","is1DimensionDispatch","paramList","globalIdxDefinition","variable","bindingIndex","access","variables","additionalUniforms","uniformSnippets","typeTemp","uniformWgslTypeToDataType","u","dispatchGroup","validateInputs","getAdjustedPerm","getOutputShape","permFunctionBody","squeezeShape","isTransposeReshape","createTransposeProgramInfo","transpose","parseTransposeAttributes","init_transpose","inputShape","input","reverseFunc","adjustedPerm","newShape","newPerm","lastPermutedAxis","inputTensor","permAttr","inputDataType","outputShape","newInputShape","newOutputShape","transposeAsReshape","getShaderSource","shaderHelper","outputSize","channelsLast","channelsFirst","tileSize","attributes","reduceOps","reduceSharedOps","reduceInitValues","reduceOutputValues","getInnerMostAxes","computeOutAndReduceShapes","expandShapeToKeepDim","areAxesInnerMostDims","getAxesPermutation","createReduceSharedProgramInfo","reduceCommon","reduceMeanShared","reduceL1Shared","reduceL2Shared","reduceLogSumExpShared","reduceMaxShared","reduceMinShared","reduceProdShared","reduceSumShared","reduceSumSquareShared","reduceLogSumShared","init_reduce_shared","init_reduce","numInnerAxes","res","reduceShape","expandShape","shapeIdx","cacheKey","reduceType","outputDataType","reduceSize","sharedMemorySnippet","updatedAttributes","createReduceAttributesFromInputs","updatedAxes","_dim","normalizeAxes","permutedAxes","finalOutputShape","noOp","createReduceProgramInfo","runReduceProgram","reduceLogSumNaive","reduceL1Naive","reduceL2Naive","reduceLogSumExpNaive","reduceMaxNaive","reduceMeanNaive","reduceMinNaive","reduceProdNaive","reduceSumNaive","reduceSumSquareNaive","useNaiveReduceMethod","reduceMean","reduceL1","reduceL2","reduceLogSumExp","reduceMax","reduceMin","reduceProd","reduceSum","reduceSumSquare","reduceLogSum","shaderCache","reduceOp","axesInput","keepDims","noopWithEmptyAxes","reduceOnAllAxes","d","outputRank","idxCopy","ops","k","l","_output","idxZero","argMin","argMax","parseArgMinMaxAttributes","init_argminmax","argMinMaxOp","validateAttentionInputs","initVarStub","createInPlaceSoftmaxProgramInfo","createAttentionProbsProgramInfo","createVxAttentionScoreProgramInfo","applyAttention","prepare","attention","init_attention","weights","bias","maskIndex","past","attentionBias","batchSize","sequenceLength","inputHiddenSize","qHiddenSize","kHiddenSize","vHiddenSize","sz","kvSequenceLength","pastSequenceLength","totalSequenceLength","maxSequenceLength","maskType","seqLensInput","totalSequenceLengthInput","initPastSequenceLength","numHeads","seqLens","WG","totalSequenceLengthComp","elementsPerThread","f32Type","inputDependencies","inputHelper","inputHelpers","seqLensInputHelper","totalSequenceLengthInputHelper","elemValueType","uniforms","outputCount","q","pastKey","parameters","probsShape","presentKey","kvNumHeads","presentKeyShape","nReps","alpha","vectorizedHeadSize","TILE_SIZE","dispatch","feedPastKey","qInput","kInput","inputVars","pastKeyInput","seqLensInputVariable","totalSequenceLengthInputVariable","outputVars","probs","pastValue","params","repeatedVHiddenSize","presentValue","presentValueShape","feedPastValue","probsHelper","vHelper","_maskIndex","_past","attentionBiasInput","inputsK","inputsV","outputQ","outputK","outputV","weight","createBatchNormInferenceProgramInfo","parseBatchNormAttributes","batchNorm","init_batch_norm","checkShapeEqual","actual","expected","r","epsilon","spatial","format","yShape","cComponents","useShapesUniforms","scale","inputMean","inputVar","y","calcCOffset","cOffset","getInferenceModeShaderSource","helper","createBiasAddProgramInfo","biasAdd","init_bias_add","residual","createElementwiseProgramShader","createElementwiseProgramInfo","abs","acos","acosh","asin","asinh","atan","atanh","parseCastAttributes","cast","generateClipAttributesFromInputs","clip","ceil","cos","cosh","parseAlphaAttributes","elu","erfImpl","erf","exp","floor","gelu","leakyRelu","not","neg","reciprocal","relu","sigmoid","parseHardSigmoidAttributes","hardSigmoid","sin","sinh","sqrt","tan","tanhExpression","tanh","fastGeluImpl","fastGeluExpression","fastGelu","thresholdedRelu","log","quickGeluImpl","quickGeluExpression","quickgelu","init_unary_op","datasize","funcCall","additionalImplementation","additionalUniformsType","vecSize","expression","inputTensors","func","min","hasMin","hasMax","clipAttributes","varType","dType","createBiasSplitGeluProgramInfo","biasSplitGelu","init_bias_split_gelu","createBinaryOpProgramShader","createBinaryOpProgramInfo","runBinaryOp","add","div","equal","mul","pow","sub","greater","less","greaterOrEqual","lessOrEqual","init_binary_op","dimsA","dimsB","dimsOutput","vectorize","doBroadcast","sharedDimensionDivisibleBy4","typeA","typeB","typeOutput","expressionScalar","expressionVector","assignment","isAOneElement","isBOneElement","aLastDimDivisibleBy4","bLastDimDivisibleBy4","singleAssignment","resStr","typeCast","expressionA","expressionB","aDims","bDims","isBroadcast","cacheKeyAux","calculatedShape","sharedDimension","dimA","dimB","calculateInputIndexImpl","assignOutputData","createConcatProgramInfo","concat","parseConcatAttributes","init_concat","referenceIndex","referenceInput","inputType","numberOfTensors","sizeInConcatAxisStr","codeLines","returnSnippet","adjustedAxis","sizeInConcatAxis","previousSum","inputRanks","indicesAxis","sum","nonEmptyInputs","getActivationSnippet","appendActivationUniformsData","appendActivationUniforms","parseInternalActivationAttributes","init_fuse_utils","baseType","programUniform","activation","beta","clipMin","clipMax","typeSnippet","biasSnippet","init_activation_util","component","hasBias","utilFunctions","init_conv_util","strideStr","convertOutputBatchIndicesToInputBatchIndices","createNaiveMatmulProgramInfo","init_matmul_shaders","targetIndicesName","inputBatchRank","outputBatchRank","batchIndicesName","extendingInputRank","_","activationAttributes","reshapedOutputShape","isChannelsLast","squeezeOutputShapeFunction","aShape","bShape","aComponents","outputNumber","outerDims","outputShapeInShader","batchDims","applyActivation","inputVariables","processBias","biasComponents","calcResult","calcStr","writeDataToSubAVec4Snippet","calculateResultSnippet","makeMatMulPackedVec4Source","writeDataToSubASnippet","readDataFromSubASnippet","makeMatMulPackedSource","matMulReadWriteFnSource","createMatmulProgramInfo","init_matmul_packed_webgpu","transposeA","innerElementSize","workPerThread","tileInner","splitK","splitedDimInner","tileAOuter","tileBOuter","tileAWidth","tileAHight","rowPerThreadB","sequentialAccessByThreads","rowPerThreadA","colPerThreadA","matmulSnippet","batchVariable","aVariable","bVariable","outerDimsA","outerDimsB","dimAOuter","dimInner","dimBOuter","isVec4","aShapeTemp","aRank","bShapeTemp","bRank","outputShapeTemp","batchRank","declareFunctions","conv2dCommonSnippet","createConv2DMatMulProgramInfo","init_conv2d_mm_webgpu","fitAOuter","fitBOuter","fitInner","addBias","innerElementSizeX","innerElementSizeW","getXSnippet","getWSnippet","coordASnippet","coordResSnippet","xHeight","xWidth","row","col","readXSnippet","sampleX","sampleW","resType","aType","bType","inChannels","outWidth","outHeight","outChannels","dispatchX","dispatchY","workGroupSize","elementsSize","t","w","arrayProduct","parse3TupleParam","getEffectiveFilterSize","computeDefaultPad","computeOutputShape4D","get3DPadAndOutInfo","computeConv3DInfo","createConv3DNaiveProgramInfo","init_conv3d_naive_webgpu","arr","product","param","filterSize","fieldSize","effectiveFieldSize","inShape","filterShape","zeroPad","outShape","inDepth","inHeight","inWidth","strideDepth","strideHeight","strideWidth","filterDepth","filterHeight","filterWidth","padInfo","outDepth","val","padAlongDepth","padAlongHeight","padAlongWidth","front","back","top","bottom","left","right","depthwise","dataFormat","filterChannels","dilationDepth","dilationHeight","dilationWidth","effectiveFilterDepth","effectiveFilterHeight","effectiveFilterWidth","dispatchLayout","createGroupedConvProgramInfo","createGroupedConvVectorizeProgramInfo","init_conv_grouped","xShape","wShape","outputChannels","outputChannelsPerGroup","calculateResult","xNumber","calculateOutputShape","weightTransposeAttribute","getAdjustedConvAttributes","parseConvAttributes","conv2d","conv1d","conv3d","conv","init_conv","adjustPads","inputSpatialShape","spatialRank","dilatedKernelShape","dataChannel","filterInChannel","newAttributes","group","wIsConst","convInputs","transposedWeight","inputHeight","inputWidth","inputChannels","weightHeight","weightWidth","sameSize","batch","xReshaped","wReshaped","matmulOutputShape","matmulInputs","sharedDim","adjustedAttributes","convInfo","createConvTranspose2DProgramInfo","init_conv_backprop_webgpu","inputChannelsPerGroup","packInputAs4","inputChannelsPerGroupInt","inputChannelsRemainder","bComponents","effectiveFilterDims","rowDim","colDim","channelDim","dy","c","calculateRemainder","codeSnippet","computeTotalPad","distributePadding","calculateOutputShapeAndPads","getAdjustedConvTransposeAttributes","parseConvTransposeAttributes","convTranspose2d","convTranspose1d","convTranspose","init_conv_transpose","inDim","adj","outSize","totalPad","head","tail","smallPad","outputPadding","updateOutputShape","featureMaps","convTransposeInputs","createCumsumProgramInfo","cumsum","parseCumSumAttributes","init_cumsum","axisInput","axisValue","lowerLimit","upperLimit","exclusive","reverse","createDepthToSpaceProgramInfo","depthToSpace","parseDepthToSpaceAttributes","init_depth_to_space","h","blocksize","isDCRmode","reshapedInputTensor","reshapedInputRank","reshapedInput","permedOutput","shapeBeforePerm","shapeAfterPerm","symbolPattern","termPattern","termPatternOnly","lhsPattern","lhsPatternOnly","EinsumTerm","EinsumEquation","appendMax","createEinsumProgramInfo","einsum","parseEinsumAttributes","init_einsum","inputIndex","symbol","equation","lhs","rhs","inputTerm","einsumTerm","sym","info","dimValue","term","isInput","ellipsis","ellipsisDims","nextDim","indexSymbols","ellipsisDimLength","inputShapes","einsumEquation","uniformsSymbols","initProd","initSum","updateSum","reduceOpsSetIndices","reduceOpsLoopHeaders","reduceOpsLoopFooters","reduceOpCompute","isReduceOpsWithoutLoop","outputIndex","_var","programUniformsInit","acc","inputProgramUniforms","getAdjustedShape","createExpandProgramInfo","expand","init_expand","shapeIndex","inputShapeIndex","diff","isBoolOrScalar","iComponents","createFastGeluProgramInfo","init_fast_gelu","biasLength","useVec4","singleElementBias","biasGetExpression","createGatherProgramInfo","parseGatherAttributes","gather","init_gather","indicesShape","axisDimLimit","calcDataIndices","indicesRank","computeSliceOffsets","gatherND","parseGatherNDAttributes","init_gather_nd","indicesData","sizesFromSliceDimsData","numSlices","numSlicesPerBatch","inputBatchStride","numSliceDims","sliceSize","numBatches","sizesFromSliceDims","runningProduct","inputSliceOffsets","lastIndicesDimension","createGatherBlockQuantizedProgramInfo","gatherBlockQuantized","parseGatherBlockQuantizedAttributes","init_gather_block_quantized","quantizeAxis","blockSize","scales","zeroPoint","gatherAxis","outputType","isSigned","_v","_i","createGatherElementsProgramInfo","parseGatherElementsAttributes","gatherElements","init_gather_elements","inputOutputDataType","indicesDataType","createGemmProgramInfo","parseGemmAttributes","gemm","init_gemm","numTileN","numTileM","useShared","line","calculateAlpha","getShaderSourceShared","fillWorkgroupMemory","transA","transB","idxN","idxC","idxH","idxW","gsGetCubicCoeffs","gsBicubicInterpolate","gsDenormalize","gsReflect","pixelAtGrid","computePixel","createGridSampleProgramInfo","gridSample","parseGridSampleAttributes","init_grid_sample","gridShape","grid","getInput","parseMultiHeadAttentionAttributes","addBiasTranspose","maybeTransposeToBNSHAndAddBias","multiHeadAttention","init_multihead_attention","query","keyPaddingMask","hiddenSize","headSize","qkvFormat","maskDims","passPastInKv","broadcastResPosBias","qkv","biasOffset","qkvInput","biasInput","kvBNSH","Q","V","createSplitAttributesFromInputs","calculateOutputIndexImpl","writeBufferDataImpl","createSplitProgramInfo","split","parseSplitAttributes","init_split","splitSizes","numOutputs","inputSize","sizeInSplitAxis","outputsTensorInfo","outputShapes","maybeTransposeToBNSH","groupQueryAttention","init_group_query_attention","dmmhaPacking","packedQKV","hasPastKey","hasPastValue","seqlLens","splitAttributes","computeChannelScaleShift","createInstanceNormProgramInfo","createInstanceNormNHWCProgramInfo","instanceNorm","init_instance_norm","n","wgType","unitsOfWork","s","C","H","channelScaleShift","scaleShape","needTranspose","transposedXPerm","transposedX","scaleType","scaleData","num","outputHelper","createLayerNormProgramInfo","layerNorm","init_layer_norm","simplified","normCount","normSize","scaleSize","biasSize","meanInvStdDevDim","hasMeanDataOutput","hasInvStdOutput","matMul","init_matmul","batchA","batchB","reshapedA","reshapedB","createMatMulNBitsProgramInfo","createMatMulNBitsBlockSize32ProgramInfo","matMulNBits","parseMatMulNBitsAttributes","init_matmulnbits","nBlocksPerCol","blobSize","scalesShape","zeroPointsShape","expectedZeroPointsSize","blobSizeInWords","dispatchSize","inputShapeTemp","zeroPoints","qDqDataType","processOneWord","prepareScaleAndZeroPoint","prepareBData","workgroupY","workgroupX","aLengthPerTile","blocksPerTile","readA","getPadConstant","getPadReflect","getPadEdge","getPadWrap","getPadSnippet","createPadProgramInfo","createPadAttributesFromInputs","init_pad","validPads","padsLength","block","isValueFromInput","padSnippet","bigInt64Pads","updatePads","getAdjustedPoolAttributesAndOutputShape","getUniformAndPadInfo","generatePoolingCode","createShaderKeyFromAttributes","createAveragePoolShaderKeyFromAttributes","createMaxPoolShaderKeyFromAttributes","parsePoolCommonAttributes","createAveragePoolProgramInfo","parseAveragePoolAttributes","averagePool","globalPoolAttributes","parseGlobalAveragePoolAttributes","globalAveragePool","createMaxPoolProgramInfo","maxPool","parseMaxPoolAttributes","parseGlobalMaxPoolAttributes","globalMaxPool","init_pool","inputShapeAsChannelFirst","hasDilations","outputShapeAsChannelFirst","outputShapeAsChannelLast","kernelSize","kw","sw","pwStart","pwEnd","pwStartEndNotZero","phStartEndNotZero","kh","sh","phStart","phEnd","kernelStrides","hasPads","cur","outputShapeRank","op1","op2","codeW","codeH","codeHEnd","dimIdxW","dimIdxH","stridesRank","padsRank","padCode","countIncludePad","attr","averagePoolAttributes","storageOrder","maxPoolAttributes","createDequantizeLinearProgramInfo","dequantizeLinear","parseDequantizeLinearAttributes","init_quantize_linear","dI","si","isPacked","zeroPointInput","zeroPointShape","perLayerQuantization","perAxisQuantization","maxComponents","useComponents","inputComponent","validateInputsContent","createRangeProgramInfo","range","init_range","limit","delta","sameStartLimit","increasingRangeNegativeStep","decreasingRangePositiveStep","wgslType","atomicReductionSnippet","createScatterNDProgramInfo","parseScatterNDAttributes","scatterND","init_scatter_nd","reduction","ptr","floatStart","floatEnd","lastIndexDimension","numUpdatesElements","updates","validateScales","updateScales","getSafeIntegerDivision","getOriginalCoordinateFromResizedCoordinate","getNearestPixelFromOriginal","updateRoI","initOutputShape","adjustOutputShape","calculateOriginalIndicesFromOutputIndices","calculateInputIndicesFromOutputIndices","checkInputIndices","setChannelAndBatchIndices","bilinearInterpolation","bicubicInterpolation","trilinearInterpolation","createResizeProgramInfo","getOpsetVersionFromCustomDataBuffer","resize","parseResizeAttributes","init_resize","newScales","opsetVersion","sizes","roi","roiInputIndex","scalesInputIndex","sizesInputIndex","coordinateTransferMode","nearestMode","roiTmp","roiLocal","scaleInPolicy","adjustedOutputShape","scalesLength","roiLength","useExtrapolation","channelIdx","batchIdx","spacialDims","extrapolationValue","heightIdx","widthIdx","cubicCoeffA","excludeOutside","is2D","isNchw","createCubicInterpolationFunction","direction","depthIdx","scalesInput","roiInput","noScale","customDataBuffer","antialias","coordinateTransformMode","keepAspectRatioPolicy","mode","createRotaryEmbeddingProgramInfo","rotaryEmbedding","init_rotary_embedding","positionIds","cosCache","sinCache","rotaryEmbeddingDim","interleaved","batchStride","halfRotaryEmbeddingDim","globalShape","globalStrides","createSkipLayerNormProgramInfo","skipLayerNorm","init_skip_layer_norm","skip","gamma","isTraining","hasBetaInput","hasBiasInput","hasMeanOutput","hasInvStdDevOutput","hasInputSkipBiasSumOutput","uniformsArray","vecDataType","_input","_index","readInput","createSliceAttributesFromInputs","fixStartEndValues","calculateInputIndicesImpl","createSliceProgramInfo","slice","parseSliceAttributes","init_slice","starts","ends","steps","newValue","signs","array","numSteps","newEnd","newStart","outputTensorInfo","createSoftmaxProgramInfo","softmax","parseSoftmaxAttributes","init_softmax","isTransposeRequired","transposedInput","transposedInputShape","cols","rows","packedCols","maxVector","threadMaxDecl","getRepeats","createTileProgramInfo","tile","init_tile","repeatsTensorView","repeats","createWhereOpProgramShader","createWhereOpProgramInfo","where","init_where","expressionC","dimsC","WEBGPU_OP_RESOLVE_RULES","init_op_resolve_rules","ProgramManager","init_program_manager","artifact","buildArtifact","uniformBufferBinding","device","computePassEncoder","entries","bindGroup","commandInfo","programInfo","normalizedDispatchGroupSize","enableDirectives","userCode","code","shaderModule","computePipeline","z","limitPerDimension","dispatchAverage","backend_webgpu_exports","WebGpuBackend","getProgramInputTensorInfoDependencyKey","getProgramInfoUniqueKey","AdapterInfoImpl","init_backend_webgpu","inputInfos","adapterInfo","architecture","vendor","adapter","requiredFeatures","deviceDescriptor","requireFeatureIfAvailable","feature","computePassDescriptor","queryReadBuffer","mappedData","pendingKernels","pendingKernelInfo","kernelId","kernelInfo","kernelType","kernelName","programName","inputTensorViews","outputTensorViews","startTimeU64","endTimeU64","startTime","endTime","program","createKernelOutput","createIntermediateOutput","inputDatas","validatedOutputIndices","outputDatas","isTemporary","isPersistent","tensorView","persistentData","currentOffset","sizeOfElement","sizeOfVecOrMat","baseAlignment","elementPerVecOrMat","maxAlignmentOfField","uniformBufferData","uniform","actualType","actualLength","gpuDataId","src","dst","op","kernelEntry","useErrorScope","sessionInputOutputMapping","previousBuffer","bufferInfo","sessionCommandList","sessionPendingKernels","command","init_exports","TensorViewImpl","ComputeContextImpl","init_init","_TensorViewImpl","elementCount","contextDataOffset","dataIndex","inputCount","inputsOutputsMapping","mappedInputs","createTemporaryOutput","gpuAdapter","jsepInit","webGpuBackendImpl","isSourceGpu","sessionHandle","initOrt","activeSessions","getSessionInputOutputCount","prepareInputOutputTensor","loggingLevel","initJsep","powerPreference","forceFallbackAdapter","modelDataOffset","modelData","modelDataLength","ioBindingHandle","inputNamesUTF8Encoded","outputNamesUTF8Encoded","loadingPromises","path","provider","webnnOptions","gpuDevice","enableGraphCapture","outputNames","outputPreferredLocations","nameString","bindingState","buf","ioBindingState","tensorHandles","actualLocation","rawData","dataByteLength","registerBuffer","registerMLTensor","isGraphInput","tensorNameUTF8","tensorName","dataTypeEnum","createTemporaryTensor","uploadTensor","dimsOffset","outputTensors","inputOutputBound","runOptionsAllocs","inputTensorHandles","outputTensorHandles","inputOutputAllocs","beforeRunStack","inputValuesOffset","inputNamesOffset","outputValuesOffset","outputNamesOffset","handle","outputPreferredLocationsEncoded","beforeGetTensorDataStack","tensorDataOffset","keepOutputTensor","dimsLength","preferredLocation","stringData","nextOffset","maxBytesToRead","getBuffer","ensureTensor","isInt64Supported","p","profileFileName","tensors","isProxy","proxyWorker","temporaryObjectUrl","initWasmCallbacks","queuedCallbacks","enqueueCallbacks","ensureWorker","onProxyWorkerMessage","initializeWebAssemblyAndOrtRuntime","initializeOrtEp","init_proxy_wrapper","callbacks","queue","worker","transferable","serializableInputs","encodeTensorMetadata","decodeTensorMetadata","OnnxruntimeWebAssemblySessionHandler","init_session_handler_inference","getName","pathOrBuffer","inputArray","kvp","outputArray","resultMap","backend_wasm_exports","OnnxruntimeWebAssemblyBackend","initializeFlags","wasmBackend","init_backend_wasm","numCpuLogicalCores","index_exports","index_default"],"mappings":";;;;;kuBAAA,IAgBMA,GACAC,GAYOC,GAwCPC,GAwCOC,GA7GbC,GAAAC,EAAA,kBAgBMN,GAAqC,IAAI,IACzCC,GAAqC,CAAA,EAY9BC,GAAkB,CAACK,EAAcC,EAAkBC,IAA0B,CACxF,GAAID,GAAW,OAAOA,EAAQ,MAAS,YAAc,OAAOA,EAAQ,+BAAkC,WAAY,CAChH,IAAME,EAAiBV,GAAS,IAAIO,CAAI,EACxC,GAAIG,IAAmB,OACrBV,GAAS,IAAIO,EAAM,CAAE,QAAAC,EAAS,SAAAC,CAAQ,CAAE,MACnC,IAAIC,EAAe,SAAWD,EAEnC,OACK,GAAIC,EAAe,WAAaD,GACjCC,EAAe,UAAYF,EAC7B,MAAM,IAAI,MAAM,4BAA4BD,CAAI,oBAAoBE,CAAQ,EAAE,EAIlF,GAAIA,GAAY,EAAG,CACjB,IAAME,EAAIV,GAAyB,QAAQM,CAAI,EAC3CI,IAAM,IACRV,GAAyB,OAAOU,EAAG,CAAC,EAGtC,QAAS,EAAI,EAAG,EAAIV,GAAyB,OAAQ,IACnD,GAAID,GAAS,IAAIC,GAAyB,CAAC,CAAC,EAAG,UAAYQ,EAAU,CACnER,GAAyB,OAAO,EAAG,EAAGM,CAAI,EAC1C,OAGJN,GAAyB,KAAKM,CAAI,EAEpC,OAGF,MAAM,IAAI,UAAU,qBAAqB,CAC3C,EAQMJ,GAAiC,MAAOS,GAAkD,CAC9F,IAAMC,EAAcb,GAAS,IAAIY,CAAW,EAC5C,GAAI,CAACC,EACH,MAAO,qBAGT,GAAIA,EAAY,YACd,OAAOA,EAAY,QACd,GAAIA,EAAY,QACrB,OAAOA,EAAY,MACd,CACL,IAAMC,EAAiB,CAAC,CAACD,EAAY,YACrC,GAAI,CACF,OAAKC,IACHD,EAAY,YAAcA,EAAY,QAAQ,KAAKD,CAAW,GAEhE,MAAMC,EAAY,YAClBA,EAAY,YAAc,GACnBA,EAAY,cACZE,EAAG,CACV,OAAKD,IACHD,EAAY,MAAQ,GAAGE,CAAC,GACxBF,EAAY,QAAU,IAEjBA,EAAY,cAEnB,OAAOA,EAAY,aAGzB,EAWaT,GAAsC,MACjDY,GACyE,CAEzE,IAAMC,EAAMD,EAAQ,oBAAsB,CAAA,EACpCE,EAAeD,EAAI,IAAKN,GAAO,OAAOA,GAAM,SAAWA,EAAIA,EAAE,IAAK,EAClEQ,EAAeD,EAAa,SAAW,EAAIjB,GAA2BiB,EAGxEV,EACEY,EAAS,CAAA,EACTC,EAAwB,IAAI,IAClC,QAAWT,KAAeO,EAAc,CACtC,IAAMG,EAAgB,MAAMnB,GAA+BS,CAAW,EAClE,OAAOU,GAAkB,SAC3BF,EAAO,KAAK,CAAE,KAAMR,EAAa,IAAKU,CAAa,CAAE,GAEhDd,IACHA,EAAUc,GAERd,IAAYc,GACdD,EAAsB,IAAIT,CAAW,GAM3C,GAAI,CAACJ,EACH,MAAM,IAAI,MAAM,oCAAoCY,EAAO,IAAKL,GAAM,IAAIA,EAAE,IAAI,KAAKA,EAAE,GAAG,EAAE,EAAE,KAAK,IAAI,CAAC,EAAE,EAI5G,OAAW,CAAE,KAAAR,EAAM,IAAAgB,CAAG,IAAMH,EACtBF,EAAa,SAASX,CAAI,GAE5B,QAAQ,KACN,0CAA0CA,CAAI,uDAAuDgB,CAAG,EAAE,EAKhH,IAAMC,EAAcP,EAAI,OAAQN,GAAMU,EAAsB,IAAI,OAAOV,GAAM,SAAWA,EAAIA,EAAE,IAAI,CAAC,EAEnG,MAAO,CACLH,EACA,IAAI,MAAMQ,EAAS,CACjB,IAAK,CAACS,EAAQC,IACRA,IAAS,qBACJF,EAEF,QAAQ,IAAIC,EAAQC,CAAI,EAElC,EAEL,ICnKA,IAAAC,GAAArB,EAAA,kBA4DAD,OC5DA,IAMauB,GANbC,GAAAvB,EAAA,kBAMasB,GAAU,WCNvB,IAQIE,GAESC,GAVbC,GAAA1B,EAAA,kBAIAuB,KAIIC,GAAwC,UAE/BC,GAAW,CACtB,KAAM,CAAA,EACN,MAAO,CAAA,EACP,OAAQ,CAAA,EACR,SAAU,CAAE,OAAQH,EAAO,EAE3B,IAAI,SAASK,EAAmB,CAC9B,GAAIA,IAAU,OAGd,IAAI,OAAOA,GAAU,UAAY,CAAC,UAAW,OAAQ,UAAW,QAAS,OAAO,EAAE,QAAQA,CAAK,IAAM,GACnG,MAAM,IAAI,MAAM,8BAA8BA,CAAK,EAAE,EAEvDH,GAAgBG,EAClB,EACA,IAAI,UAAQ,CACV,OAAOH,EACT,GAIF,OAAO,eAAeC,GAAK,WAAY,CAAE,WAAY,EAAI,CAAE,IC/B3D,IAmSaA,EAnSbG,GAAA5B,EAAA,kBAGA0B,KAgSaD,EAAWA,KCnSxB,IASaI,GAmGAC,GA5GbC,GAAA/B,EAAA,kBASa6B,GAAkB,CAACG,EAAgBtB,IAA4C,CAC1F,IAAMuB,EAAS,OAAO,SAAa,IAAc,SAAS,cAAc,QAAQ,EAAI,IAAI,gBAAgB,EAAG,CAAC,EAC5GA,EAAO,MAAQD,EAAO,KAAK,CAAC,EAC5BC,EAAO,OAASD,EAAO,KAAK,CAAC,EAC7B,IAAME,EAAkBD,EAAO,WAAW,IAAI,EAK9C,GAAIC,GAAmB,KAAM,CAE3B,IAAIC,EACAC,EACA1B,GAAS,eAAiB,QAAaA,EAAQ,eAAiB,QAClEyB,EAAQH,EAAO,KAAK,CAAC,EACrBI,EAASJ,EAAO,KAAK,CAAC,IAGtBG,EAAQH,EAAO,KAAK,CAAC,EACrBI,EAASJ,EAAO,KAAK,CAAC,GAGxB,IAAMK,EAAc3B,GAAS,SAAW,OAAYA,EAAQ,OAAS,MAE/D4B,EAAO5B,GAAS,KAClB6B,EACAC,EACAF,IAAS,QAAaA,EAAK,OAAS,OACtCC,EAAW,CAAC,IAAK,IAAK,IAAK,GAAG,EAE1B,OAAOD,EAAK,MAAS,SACvBC,EAAW,CAACD,EAAK,KAAMA,EAAK,KAAMA,EAAK,KAAMA,EAAK,IAAI,GAEtDC,EAAW,CAACD,EAAK,KAAK,CAAC,EAAGA,EAAK,KAAK,CAAC,EAAGA,EAAK,KAAK,CAAC,EAAG,CAAC,EACnDA,EAAK,KAAK,CAAC,IAAM,SACnBC,EAAS,CAAC,EAAID,EAAK,KAAK,CAAC,IAI3BA,IAAS,QAAaA,EAAK,OAAS,OACtCE,EAAW,CAAC,EAAG,EAAG,EAAG,CAAC,EAElB,OAAOF,EAAK,MAAS,SACvBE,EAAW,CAACF,EAAK,KAAMA,EAAK,KAAMA,EAAK,KAAMA,EAAK,IAAI,GAEtDE,EAAW,CAACF,EAAK,KAAK,CAAC,EAAGA,EAAK,KAAK,CAAC,EAAGA,EAAK,KAAK,CAAC,EAAG,CAAC,EACnDA,EAAK,KAAK,CAAC,IAAM,SACnBE,EAAS,CAAC,EAAIF,EAAK,KAAK,CAAC,IAK/B,IAAMG,EAASL,EAASD,EAEpBO,EAAiB,EACnBC,EAAiBF,EACjBG,EAAiBH,EAAS,EAC1BI,EAAiB,GAGfR,IAAgB,QAClBK,EAAiB,EACjBC,EAAiBF,EACjBG,EAAiBH,EAAS,EAC1BI,EAAiBJ,EAAS,GACjBJ,IAAgB,OACzBK,EAAiB,EACjBC,EAAiBF,EACjBG,EAAiBH,EAAS,GACjBJ,IAAgB,QACzBK,EAAiB,EACjBE,EAAiBH,EACjBE,EAAiBF,EAAS,GAG5B,QAASpC,EAAI,EAAGA,EAAI+B,EAAQ/B,IAC1B,QAASyC,EAAI,EAAGA,EAAIX,EAAOW,IAAK,CAC9B,IAAMC,GAAMf,EAAO,KAAKU,GAAgB,EAAeF,EAAS,CAAC,GAAKD,EAAS,CAAC,EAC1ES,GAAMhB,EAAO,KAAKW,GAAgB,EAAeH,EAAS,CAAC,GAAKD,EAAS,CAAC,EAC1EU,GAAMjB,EAAO,KAAKY,GAAgB,EAAeJ,EAAS,CAAC,GAAKD,EAAS,CAAC,EAC1EW,EAAIL,IAAmB,GAAK,KAAQb,EAAO,KAAKa,GAAgB,EAAeL,EAAS,CAAC,GAAKD,EAAS,CAAC,EAE9GL,EAAgB,UAAY,QAAUa,EAAI,IAAMC,EAAI,IAAMC,EAAI,IAAMC,EAAI,IACxEhB,EAAgB,SAASY,EAAGzC,EAAG,EAAG,CAAC,EAGvC,GAAI,cAAe4B,EACjB,OAAOA,EAAO,UAAS,EAEvB,MAAM,IAAI,MAAM,4BAA4B,MAG9C,OAAM,IAAI,MAAM,2BAA2B,CAE/C,EAKaH,GAAoB,CAACE,EAAgBtB,IAAiD,CACjG,IAAMwB,EACJ,OAAO,SAAa,IAChB,SAAS,cAAc,QAAQ,EAAE,WAAW,IAAI,EAC/C,IAAI,gBAAgB,EAAG,CAAC,EAAE,WAAW,IAAI,EAC5CiB,EACJ,GAAIjB,GAAmB,KAAM,CAE3B,IAAIC,EACAC,EACAgB,EACA1C,GAAS,eAAiB,QAAaA,EAAQ,eAAiB,QAClEyB,EAAQH,EAAO,KAAK,CAAC,EACrBI,EAASJ,EAAO,KAAK,CAAC,EACtBoB,EAAWpB,EAAO,KAAK,CAAC,IAGxBG,EAAQH,EAAO,KAAK,CAAC,EACrBI,EAASJ,EAAO,KAAK,CAAC,EACtBoB,EAAWpB,EAAO,KAAK,CAAC,GAE1B,IAAMK,EAAc3B,IAAY,QAAaA,EAAQ,SAAW,OAAYA,EAAQ,OAAkB,MAEhG4B,EAAO5B,GAAS,KAClB6B,EACAC,EACAF,IAAS,QAAaA,EAAK,OAAS,OACtCC,EAAW,CAAC,IAAK,IAAK,IAAK,GAAG,EAE1B,OAAOD,EAAK,MAAS,SACvBC,EAAW,CAACD,EAAK,KAAMA,EAAK,KAAMA,EAAK,KAAMA,EAAK,IAAI,GAEtDC,EAAW,CAACD,EAAK,KAAK,CAAC,EAAGA,EAAK,KAAK,CAAC,EAAGA,EAAK,KAAK,CAAC,EAAG,GAAG,EACrDA,EAAK,KAAK,CAAC,IAAM,SACnBC,EAAS,CAAC,EAAID,EAAK,KAAK,CAAC,IAI3BA,IAAS,QAAaA,EAAK,OAAS,OACtCE,EAAW,CAAC,EAAG,EAAG,EAAG,CAAC,EAElB,OAAOF,EAAK,MAAS,SACvBE,EAAW,CAACF,EAAK,KAAMA,EAAK,KAAMA,EAAK,KAAMA,EAAK,IAAI,GAEtDE,EAAW,CAACF,EAAK,KAAK,CAAC,EAAGA,EAAK,KAAK,CAAC,EAAGA,EAAK,KAAK,CAAC,EAAG,CAAC,EACnDA,EAAK,KAAK,CAAC,IAAM,SACnBE,EAAS,CAAC,EAAIF,EAAK,KAAK,CAAC,IAK/B,IAAMG,EAASL,EAASD,EACxB,GAAIzB,IAAY,SAEXA,EAAQ,SAAW,QAAa0C,IAAa,GAAK1C,EAAQ,SAAW,QACrE0C,IAAa,GAAK1C,EAAQ,SAAW,OAASA,EAAQ,SAAW,OAElE,MAAM,IAAI,MAAM,+CAA+C,EAKnE,IAAM2C,EAAO,EACTC,EAAgB,EAClBC,EAAgB,EAChBC,EAAgB,EAChBC,EAAgB,EACdf,EAAiB,EACnBC,EAAiBF,EACjBG,EAAiBH,EAAS,EAC1BI,EAAiB,GAGfR,IAAgB,QAClBK,EAAiB,EACjBC,EAAiBF,EACjBG,EAAiBH,EAAS,EAC1BI,EAAiBJ,EAAS,GACjBJ,IAAgB,OACzBK,EAAiB,EACjBC,EAAiBF,EACjBG,EAAiBH,EAAS,GACjBJ,IAAgB,QACzBK,EAAiB,EACjBE,EAAiBH,EACjBE,EAAiBF,EAAS,GAG5BU,EAAQjB,EAAgB,gBAAgBC,EAAOC,CAAM,EAErD,QACM/B,EAAI,EACRA,EAAI+B,EAASD,EACbmB,GAAiBD,EAAME,GAAiBF,EAAMG,GAAiBH,EAAMI,GAAiBJ,EAAMhD,IAE5F8C,EAAM,KAAKG,CAAa,GAAMtB,EAAO,KAAKU,GAAgB,EAAeF,EAAS,CAAC,GAAKD,EAAS,CAAC,EAClGY,EAAM,KAAKI,CAAa,GAAMvB,EAAO,KAAKW,GAAgB,EAAeH,EAAS,CAAC,GAAKD,EAAS,CAAC,EAClGY,EAAM,KAAKK,CAAa,GAAMxB,EAAO,KAAKY,GAAgB,EAAeJ,EAAS,CAAC,GAAKD,EAAS,CAAC,EAClGY,EAAM,KAAKM,CAAa,EACtBZ,IAAmB,GAAK,KAAQb,EAAO,KAAKa,GAAgB,EAAeL,EAAS,CAAC,GAAKD,EAAS,CAAC,MAGxG,OAAM,IAAI,MAAM,2BAA2B,EAE7C,OAAOY,CACT,ICrNA,IAkCaO,GA8FAC,GAoKAC,GAaAC,GAWAC,GAWAC,GAvUbC,GAAAhE,EAAA,kBAiBAiE,KAiBaP,GAAiB,CAACQ,EAAuCxD,IAA0C,CAC9G,GAAIwD,IAAW,OACb,MAAM,IAAI,MAAM,8BAA8B,EAEhD,GAAIxD,EAAQ,SAAW,QAAaA,EAAQ,QAAU,OACpD,MAAM,IAAI,MAAM,wCAAwC,EAE1D,GAAIA,EAAQ,eAAiB,OAC3B,MAAM,IAAI,MAAM,yCAAyC,EAG3D,GAAM,CAAE,OAAA0B,EAAQ,MAAAD,CAAK,EAAKzB,EAEpB4B,EAAO5B,EAAQ,MAAQ,CAAE,KAAM,IAAK,KAAM,CAAC,EAC7C6B,EACAC,EAEA,OAAOF,EAAK,MAAS,SACvBC,EAAW,CAACD,EAAK,KAAMA,EAAK,KAAMA,EAAK,KAAMA,EAAK,IAAI,EAEtDC,EAAW,CAACD,EAAK,KAAM,CAAC,EAAGA,EAAK,KAAM,CAAC,EAAGA,EAAK,KAAM,CAAC,EAAGA,EAAK,KAAM,CAAC,GAAK,GAAG,EAG3E,OAAOA,EAAK,MAAS,SACvBE,EAAW,CAACF,EAAK,KAAMA,EAAK,KAAMA,EAAK,KAAMA,EAAK,IAAI,EAEtDE,EAAW,CAACF,EAAK,KAAM,CAAC,EAAGA,EAAK,KAAM,CAAC,EAAGA,EAAK,KAAM,CAAC,EAAGA,EAAK,KAAM,CAAC,GAAK,CAAC,EAG7E,IAAMD,EAAc3B,EAAQ,SAAW,OAAYA,EAAQ,OAAS,OAG9DyD,EACJzD,EAAQ,eAAiB,QAAaA,EAAQ,eAAiB,OAAYA,EAAQ,aAAwB,MACvG+B,EAASL,EAASD,EAClBiC,EAAcD,IAAiB,OAAS,IAAI,aAAa1B,EAAS,CAAC,EAAI,IAAI,aAAaA,EAAS,CAAC,EAGpGY,EAAO,EACTC,EAAgB,EAChBC,EAAgB,EAChBC,EAAgB,EAChBC,EAAgB,EACdf,EAAiB,EACnBC,EAAiBF,EACjBG,EAAiBH,EAAS,EAC1BI,EAAiB,GAGfR,IAAgB,QAClBgB,EAAO,EACPC,EAAgB,EAChBC,EAAgB,EAChBC,EAAgB,EAChBC,EAAgB,IAIdU,IAAiB,OACnBtB,EAAiBJ,EAAS,EACjB0B,IAAiB,OAC1BzB,EAAiB,EACjBE,EAAiBH,EACjBE,EAAiBF,EAAS,GACjB0B,IAAiB,QAC1BvB,EAAiB,EACjBD,EAAiBF,EACjBC,EAAiBD,EAAS,GAG5B,QACMpC,EAAI,EACRA,EAAIoC,EACJpC,IAAKiD,GAAiBD,EAAMG,GAAiBH,EAAME,GAAiBF,EAAMI,GAAiBJ,EAE3Fe,EAAY1B,GAAgB,GAAKwB,EAAOZ,CAAa,EAAId,EAAS,CAAC,GAAKD,EAAS,CAAC,EAClF6B,EAAYzB,GAAgB,GAAKuB,EAAOX,CAAa,EAAIf,EAAS,CAAC,GAAKD,EAAS,CAAC,EAClF6B,EAAYxB,GAAgB,GAAKsB,EAAOV,CAAa,EAAIhB,EAAS,CAAC,GAAKD,EAAS,CAAC,EAC9EM,IAAmB,IAAMY,IAAkB,KAC7CW,EAAYvB,GAAgB,GAAKqB,EAAOT,CAAa,EAAIjB,EAAS,CAAC,GAAKD,EAAS,CAAC,GAStF,OAHE4B,IAAiB,OACb,IAAIE,GAAO,UAAWD,EAAa,CAAC,EAAG,EAAGhC,EAAQD,CAAK,CAAC,EACxD,IAAIkC,GAAO,UAAWD,EAAa,CAAC,EAAG,EAAGhC,EAAQD,CAAK,CAAC,CAEhE,EAKawB,GAAkB,MAC7BR,EACAzC,IAKmB,CAEnB,IAAM4D,EAAiB,OAAO,iBAAqB,KAAenB,aAAiB,iBAC7EoB,EAAiB,OAAO,UAAc,KAAepB,aAAiB,UACtEqB,EAAgB,OAAO,YAAgB,KAAerB,aAAiB,YACvEsB,EAAW,OAAOtB,GAAU,SAE9BuB,EACAC,EAA+CjE,GAAW,CAAA,EAExDkE,EAAe,IAAK,CACxB,GAAI,OAAO,SAAa,IACtB,OAAO,SAAS,cAAc,QAAQ,EACjC,GAAI,OAAO,gBAAoB,IACpC,OAAO,IAAI,gBAAgB,EAAG,CAAC,EAE/B,MAAM,IAAI,MAAM,yBAAyB,CAE7C,EACMC,EAAuB5C,GACvB,OAAO,kBAAsB,KAAeA,aAAkB,mBAEvDA,aAAkB,gBADpBA,EAAO,WAAW,IAAI,EAItB,KAIX,GAAIqC,EAAgB,CAElB,IAAMrC,EAAS2C,EAAY,EAC3B3C,EAAO,MAAQkB,EAAM,MACrBlB,EAAO,OAASkB,EAAM,OACtB,IAAMjB,EAAkB2C,EAAoB5C,CAAM,EAElD,GAAIC,GAAmB,KAAM,CAC3B,IAAIE,EAASe,EAAM,OACfhB,EAAQgB,EAAM,MAMlB,GALIzC,IAAY,QAAaA,EAAQ,gBAAkB,QAAaA,EAAQ,eAAiB,SAC3F0B,EAAS1B,EAAQ,cACjByB,EAAQzB,EAAQ,cAGdA,IAAY,OAAW,CAEzB,GADAiE,EAAwBjE,EACpBA,EAAQ,eAAiB,OAC3B,MAAM,IAAI,MAAM,6DAA6D,EAE7EiE,EAAsB,aAAe,OAEvCA,EAAsB,OAASvC,EAC/BuC,EAAsB,MAAQxC,OAE9BwC,EAAsB,aAAe,OACrCA,EAAsB,OAASvC,EAC/BuC,EAAsB,MAAQxC,EAGhCD,EAAgB,UAAUiB,EAAO,EAAG,CAAC,EACrCuB,EAAOxC,EAAgB,aAAa,EAAG,EAAGC,EAAOC,CAAM,EAAE,SAEzD,OAAM,IAAI,MAAM,2BAA2B,UAEpCmC,EAAgB,CACzB,IAAInC,EACAD,EAiBJ,GAfIzB,IAAY,QAAaA,EAAQ,eAAiB,QAAaA,EAAQ,gBAAkB,QAC3F0B,EAAS1B,EAAQ,cACjByB,EAAQzB,EAAQ,eAEhB0B,EAASe,EAAM,OACfhB,EAAQgB,EAAM,OAGZzC,IAAY,SACdiE,EAAwBjE,GAE1BiE,EAAsB,OAAS,OAC/BA,EAAsB,OAASvC,EAC/BuC,EAAsB,MAAQxC,EAE1BzB,IAAY,OAAW,CACzB,IAAMoE,EAAaF,EAAY,EAE/BE,EAAW,MAAQ3C,EACnB2C,EAAW,OAAS1C,EAEpB,IAAMF,EAAkB2C,EAAoBC,CAAU,EAEtD,GAAI5C,GAAmB,KACrBA,EAAgB,aAAaiB,EAAO,EAAG,CAAC,EACxCuB,EAAOxC,EAAgB,aAAa,EAAG,EAAGC,EAAOC,CAAM,EAAE,SAEzD,OAAM,IAAI,MAAM,2BAA2B,OAG7CsC,EAAOvB,EAAM,aAENqB,EAAe,CAExB,GAAI9D,IAAY,OACd,MAAM,IAAI,MAAM,yDAAyD,EAG3E,IAAMuB,EAAS2C,EAAY,EAC3B3C,EAAO,MAAQkB,EAAM,MACrBlB,EAAO,OAASkB,EAAM,OACtB,IAAMjB,EAAkB2C,EAAoB5C,CAAM,EAElD,GAAIC,GAAmB,KAAM,CAC3B,IAAME,EAASe,EAAM,OACfhB,EAAQgB,EAAM,MACpB,OAAAjB,EAAgB,UAAUiB,EAAO,EAAG,EAAGhB,EAAOC,CAAM,EACpDsC,EAAOxC,EAAgB,aAAa,EAAG,EAAGC,EAAOC,CAAM,EAAE,KACzDuC,EAAsB,OAASvC,EAC/BuC,EAAsB,MAAQxC,EACvBuB,GAAegB,EAAMC,CAAqB,MAEjD,OAAM,IAAI,MAAM,2BAA2B,MAExC,IAAIF,EACT,OAAO,IAAI,QAAQ,CAACM,EAASC,IAAU,CACrC,IAAM/C,EAAS2C,EAAY,EACrBK,EAAUJ,EAAoB5C,CAAM,EAC1C,GAAI,CAACkB,GAAS,CAAC8B,EACb,OAAOD,EAAM,EAEf,IAAME,EAAW,IAAI,MACrBA,EAAS,YAAc,YACvBA,EAAS,IAAM/B,EACf+B,EAAS,OAAS,IAAK,CACrBjD,EAAO,MAAQiD,EAAS,MACxBjD,EAAO,OAASiD,EAAS,OACzBD,EAAQ,UAAUC,EAAU,EAAG,EAAGjD,EAAO,MAAOA,EAAO,MAAM,EAC7D,IAAMkD,EAAMF,EAAQ,aAAa,EAAG,EAAGhD,EAAO,MAAOA,EAAO,MAAM,EAElE0C,EAAsB,OAAS1C,EAAO,OACtC0C,EAAsB,MAAQ1C,EAAO,MACrC8C,EAAQrB,GAAeyB,EAAI,KAAMR,CAAqB,CAAC,CACzD,CACF,CAAC,EAED,MAAM,IAAI,MAAM,gEAAgE,EAGlF,GAAID,IAAS,OACX,OAAOhB,GAAegB,EAAMC,CAAqB,EAEjD,MAAM,IAAI,MAAM,gEAAgE,CAEpF,EAKaf,GAAoB,CAC/BwB,EACA1E,IACU,CACV,GAAM,CAAE,MAAAyB,EAAO,OAAAC,EAAQ,SAAAiD,EAAU,QAAAC,CAAO,EAAK5E,EAEvC6E,EAAO,CAAC,EAAGnD,EAAQD,EAAO,CAAC,EACjC,OAAO,IAAIkC,GAAO,CAAE,SAAU,UAAW,KAAM,UAAW,QAAAe,EAAS,KAAAG,EAAM,SAAAF,EAAU,QAAAC,CAAO,CAAE,CAC9F,EAKazB,GAAsB,CACjC2B,EACA9E,IACU,CACV,GAAM,CAAE,SAAA+E,EAAU,KAAAF,EAAM,SAAAF,EAAU,QAAAC,CAAO,EAAK5E,EAC9C,OAAO,IAAI2D,GAAO,CAAE,SAAU,aAAc,KAAMoB,GAAY,UAAW,UAAAD,EAAW,KAAAD,EAAM,SAAAF,EAAU,QAAAC,CAAO,CAAE,CAC/G,EAKaxB,GAAqB,CAChC4B,EACAhF,IACU,CACV,GAAM,CAAE,SAAA+E,EAAU,KAAAF,EAAM,SAAAF,EAAU,QAAAC,CAAO,EAAK5E,EAC9C,OAAO,IAAI2D,GAAO,CAAE,SAAU,YAAa,KAAMoB,GAAY,UAAW,SAAAC,EAAU,KAAAH,EAAM,SAAAF,EAAU,QAAAC,CAAO,CAAE,CAC7G,EAKavB,GAAyB,CACpC4B,EACAzB,EACAqB,IACW,IAAIlB,GAAO,CAAE,SAAU,aAAc,KAAAsB,EAAM,KAAMzB,EAAQ,KAAMqB,GAAQ,CAACrB,EAAO,MAAM,CAAC,CAAE,IC3UrG,IAoBa0B,GAeAC,GAcTC,GACSC,GAlDbC,GAAAhG,EAAA,kBAoBa4F,GAAwC,IAAI,IAA6C,CACpG,CAAC,UAAW,YAAY,EACxB,CAAC,QAAS,UAAU,EACpB,CAAC,OAAQ,SAAS,EAClB,CAAC,SAAU,WAAW,EACtB,CAAC,QAAS,UAAU,EACpB,CAAC,QAAS,UAAU,EACpB,CAAC,OAAQ,UAAU,EACnB,CAAC,UAAW,YAAY,EACxB,CAAC,SAAU,WAAW,EACtB,CAAC,OAAQ,UAAU,EACnB,CAAC,QAAS,UAAU,EACrB,EAGYC,GAAwC,IAAI,IAAkD,CACzG,CAAC,aAAc,SAAS,EACxB,CAAC,WAAY,OAAO,EACpB,CAAC,UAAW,MAAM,EAClB,CAAC,YAAa,QAAQ,EACtB,CAAC,WAAY,OAAO,EACpB,CAAC,WAAY,OAAO,EACpB,CAAC,aAAc,SAAS,EACxB,CAAC,YAAa,QAAQ,EACvB,EAKGC,GAAsB,GACbC,GAAkB,IAAK,CAClC,GAAI,CAACD,GAAqB,CACxBA,GAAsB,GACtB,IAAMG,EAA2B,OAAO,cAAkB,KAAe,cAAc,KACjFC,EAA4B,OAAO,eAAmB,KAAe,eAAe,KAGpFC,EAAgB,WAAmB,aACnCC,EAA0B,OAAOD,EAAiB,KAAeA,EAAa,KAEhFF,IACFL,GAAsC,IAAI,QAAS,aAAa,EAChEC,GAAsC,IAAI,cAAe,OAAO,GAE9DK,IACFN,GAAsC,IAAI,SAAU,cAAc,EAClEC,GAAsC,IAAI,eAAgB,QAAQ,GAEhEO,GACFR,GAAsC,IAAI,UAAWO,CAAY,EACjEN,GAAsC,IAAIM,EAAc,SAAS,GAGjEP,GAAsC,IAAI,UAAW,WAAW,EAGtE,IC5EA,IAgBaS,GAkBAC,GAlCbC,GAAAvG,EAAA,kBASAiE,KAOaoC,GAAiBd,GAAoC,CAChE,IAAIiB,EAAO,EACX,QAASnG,EAAI,EAAGA,EAAIkF,EAAK,OAAQlF,IAAK,CACpC,IAAMoG,EAAMlB,EAAKlF,CAAC,EAClB,GAAI,OAAOoG,GAAQ,UAAY,CAAC,OAAO,cAAcA,CAAG,EACtD,MAAM,IAAI,UAAU,QAAQpG,CAAC,8BAA8BoG,CAAG,EAAE,EAElE,GAAIA,EAAM,EACR,MAAM,IAAI,WAAW,QAAQpG,CAAC,0CAA0CoG,CAAG,EAAE,EAE/ED,GAAQC,EAEV,OAAOD,CACT,EAKaF,GAAgB,CAACtE,EAAgBuD,IAAmC,CAC/E,OAAQvD,EAAO,SAAU,CACvB,IAAK,MACH,OAAO,IAAIqC,GAAOrC,EAAO,KAAMA,EAAO,KAAMuD,CAAI,EAClD,IAAK,aACH,OAAO,IAAIlB,GAAO,CAChB,SAAU,aACV,KAAMrC,EAAO,KACb,KAAMA,EAAO,KACb,KAAAuD,EACD,EACH,IAAK,UACH,OAAO,IAAIlB,GAAO,CAChB,SAAU,UACV,QAASrC,EAAO,QAChB,KAAMA,EAAO,KACb,KAAAuD,EACD,EACH,IAAK,aACH,OAAO,IAAIlB,GAAO,CAChB,SAAU,aACV,UAAWrC,EAAO,UAClB,KAAMA,EAAO,KACb,KAAAuD,EACD,EACH,IAAK,YACH,OAAO,IAAIlB,GAAO,CAChB,SAAU,YACV,SAAUrC,EAAO,SACjB,KAAMA,EAAO,KACb,KAAAuD,EACD,EACH,QACE,MAAM,IAAI,MAAM,kCAAkCvD,EAAO,QAAQ,mBAAmB,EAE1F,ICrEA,IAiDaqC,GAjDbJ,GAAAjE,EAAA,kBAGA+B,KAEAiC,KAoBAgC,KAOAO,KAiBalC,GAAP,KAAa,CAuDjB,YACEqC,EAUAC,EACAC,EAAwB,CAGxBb,GAAe,EAEf,IAAIJ,EACAJ,EAEJ,GAAI,OAAOmB,GAAS,UAAY,aAAcA,EAO5C,OAHA,KAAK,aAAeA,EAAK,SACzBf,EAAOe,EAAK,KACZnB,EAAOmB,EAAK,KACJA,EAAK,SAAU,CACrB,IAAK,aAAc,CACjB,IAAMG,EAAgCjB,GAAsC,IAAID,CAAI,EACpF,GAAI,CAACkB,EACH,MAAM,IAAI,UAAU,qBAAqBlB,CAAI,uCAAuC,EAEtF,GAAI,EAAEe,EAAK,gBAAgBG,GACzB,MAAM,IAAI,UAAU,4BAA4BA,EAA8B,IAAI,EAAE,EAEtF,KAAK,QAAUH,EAAK,KACpB,MAEF,IAAK,UAAW,CACd,GAAIf,IAAS,UACX,MAAM,IAAI,UAAU,qBAAqBA,CAAI,iCAAiC,EAEhF,KAAK,eAAiBe,EAAK,QAC3B,KAAK,WAAaA,EAAK,SACvB,KAAK,SAAWA,EAAK,QACrB,MAEF,IAAK,aAAc,CACjB,GACEf,IAAS,WACTA,IAAS,WACTA,IAAS,SACTA,IAAS,SACTA,IAAS,UACTA,IAAS,SACTA,IAAS,QACTA,IAAS,SACTA,IAAS,OAET,MAAM,IAAI,UAAU,qBAAqBA,CAAI,oCAAoC,EAEnF,KAAK,cAAgBe,EAAK,UAC1B,KAAK,WAAaA,EAAK,SACvB,KAAK,SAAWA,EAAK,QACrB,MAEF,IAAK,YAAa,CAChB,GACEf,IAAS,WACTA,IAAS,WACTA,IAAS,SACTA,IAAS,SACTA,IAAS,UACTA,IAAS,UACTA,IAAS,QACTA,IAAS,SACTA,IAAS,QACTA,IAAS,SACTA,IAAS,OAET,MAAM,IAAI,UAAU,qBAAqBA,CAAI,kCAAkC,EAEjF,KAAK,aAAee,EAAK,SACzB,KAAK,WAAaA,EAAK,SACvB,KAAK,SAAWA,EAAK,QACrB,MAEF,QACE,MAAM,IAAI,MAAM,6CAA6C,KAAK,YAAY,GAAG,MAEhF,CAIL,IAAIhC,EACAoC,EAEJ,GAAI,OAAOJ,GAAS,SAMlB,GAFAf,EAAOe,EACPI,EAAYF,EACRF,IAAS,SAAU,CAErB,GAAI,CAAC,MAAM,QAAQC,CAAI,EACrB,MAAM,IAAI,UAAU,gDAAgD,EAItEjC,EAAOiC,MACF,CAEL,IAAMI,EAAwBnB,GAAsC,IAAIc,CAAI,EAC5E,GAAIK,IAA0B,OAC5B,MAAM,IAAI,UAAU,4BAA4BL,CAAI,GAAG,EAEzD,GAAI,MAAM,QAAQC,CAAI,EAAG,CACvB,GAAKD,IAAS,WAAaK,IAA0B,aAAgBL,IAAS,SAAWA,IAAS,OAWhG,MAAM,IAAI,UACR,cAAcA,CAAI,0DAA0DK,EAAsB,IAAI,WAAW,EAE1GL,IAAS,UAAYA,IAAS,QAYvChC,EAAQqC,EAA8B,KAAKJ,EAAM,MAAM,EAIvDjC,EAAQqC,EAA8B,KAAKJ,CAAI,UAExCA,aAAgBI,EACzBrC,EAAOiC,UACEA,aAAgB,kBACzB,GAAID,IAAS,QACXhC,EAAO,WAAW,KAAKiC,CAAI,MAE3B,OAAM,IAAI,UAAU,yDAAyD,UAEtED,IAAS,WAAaC,aAAgB,aAAeI,IAA0B,YAMxFrC,EAAO,IAAK,WAAmB,aAAaiC,EAAK,OAAQA,EAAK,WAAYA,EAAK,MAAM,MAErF,OAAM,IAAI,UAAU,KAAKhB,CAAI,kCAAkCoB,CAAqB,EAAE,UAO1FD,EAAYH,EACR,MAAM,QAAQD,CAAI,EAAG,CAEvB,GAAIA,EAAK,SAAW,EAClB,MAAM,IAAI,UAAU,qDAAqD,EAE3E,IAAMM,EAAmB,OAAON,EAAK,CAAC,EACtC,GAAIM,IAAqB,SACvBrB,EAAO,SACPjB,EAAOgC,UACEM,IAAqB,UAC9BrB,EAAO,OAIPjB,EAAO,WAAW,KAAKgC,CAAa,MAEpC,OAAM,IAAI,UAAU,uCAAuCM,CAAgB,GAAG,UAEvEN,aAAgB,kBACzBf,EAAO,QACPjB,EAAO,WAAW,KAAKgC,CAAI,MACtB,CAEL,IAAMO,EAAapB,GAAsC,IACvDa,EAAK,WAA8C,EAErD,GAAIO,IAAe,OACjB,MAAM,IAAI,UAAU,qCAAqCP,EAAK,WAAW,GAAG,EAE9Ef,EAAOsB,EACPvC,EAAOgC,EAKX,GAAII,IAAc,OAEhBA,EAAY,CAACpC,EAAK,MAAM,UACf,CAAC,MAAM,QAAQoC,CAAS,EACjC,MAAM,IAAI,UAAU,wCAAwC,EAE9DvB,EAAOuB,EAEP,KAAK,QAAUpC,EACf,KAAK,aAAe,MAItB,IAAM8B,EAAOH,GAAcd,CAAI,EAE/B,GAAI,KAAK,SAAWiB,IAAS,KAAK,QAAQ,QACnC,GAAAb,IAAS,SAAWA,IAAS,SAAW,KAAK,KAAKa,EAAO,CAAC,IAAM,KAAK,QAAQ,QAGhF,MAAM,IAAI,MAAM,iBAAiBA,CAAI,gCAAgC,KAAK,QAAQ,MAAM,IAAI,EAIhG,KAAK,KAAOb,EACZ,KAAK,KAAOJ,EACZ,KAAK,KAAOiB,CACd,CAIA,aAAa,UACXrD,EACAzC,EAIwB,CAExB,OAAOiD,GAAgBR,EAAOzC,CAAO,CACvC,CAEA,OAAO,YACL0E,EACA1E,EAAoC,CAEpC,OAAOkD,GAAkBwB,EAAS1E,CAAO,CAC3C,CAEA,OAAO,cACL8E,EACA9E,EAAsC,CAEtC,OAAOmD,GAAoB2B,EAAW9E,CAAO,CAC/C,CAEA,OAAO,aACLgF,EACAhF,EAAqC,CAErC,OAAOoD,GAAmB4B,EAAUhF,CAAO,CAC7C,CAEA,OAAO,iBACLiF,EACAzB,EACAqB,EAAwB,CAExB,OAAOxB,GAAuB4B,EAAMzB,EAAQqB,CAAI,CAClD,CAKA,UAAU7E,EAAgC,CACxC,OAAOmB,GAAgB,KAAMnB,CAAO,CACtC,CAEA,YAAYA,EAAkC,CAC5C,OAAOoB,GAAkB,KAAMpB,CAAO,CACxC,CAqDA,IAAI,MAAI,CAEN,GADA,KAAK,YAAW,EACZ,CAAC,KAAK,QACR,MAAM,IAAI,MACR,gJAC6E,EAGjF,OAAO,KAAK,OACd,CAEA,IAAI,UAAQ,CACV,OAAO,KAAK,YACd,CAEA,IAAI,SAAO,CAET,GADA,KAAK,YAAW,EACZ,CAAC,KAAK,eACR,MAAM,IAAI,MAAM,4CAA4C,EAE9D,OAAO,KAAK,cACd,CAEA,IAAI,WAAS,CAEX,GADA,KAAK,YAAW,EACZ,CAAC,KAAK,cACR,MAAM,IAAI,MAAM,4CAA4C,EAE9D,OAAO,KAAK,aACd,CAEA,IAAI,UAAQ,CAEV,GADA,KAAK,YAAW,EACZ,CAAC,KAAK,aACR,MAAM,IAAI,MAAM,6CAA6C,EAE/D,OAAO,KAAK,YACd,CAKA,MAAM,QAAQwG,EAAqB,CAEjC,OADA,KAAK,YAAW,EACR,KAAK,aAAc,CACzB,IAAK,MACL,IAAK,aACH,OAAO,KAAK,KACd,IAAK,UACL,IAAK,aACL,IAAK,YAAa,CAChB,GAAI,CAAC,KAAK,WACR,MAAM,IAAI,MAAM,qEAAqE,EAEvF,GAAI,KAAK,cACP,MAAM,IAAI,MAAM,yCAAyC,EAE3D,GAAI,CACF,KAAK,cAAgB,GACrB,IAAMxC,EAAO,MAAM,KAAK,WAAU,EAClC,YAAK,WAAa,OAClB,KAAK,aAAe,MACpB,KAAK,QAAUA,EAEXwC,GAAe,KAAK,WACtB,KAAK,SAAQ,EACb,KAAK,SAAW,QAGXxC,UAEP,KAAK,cAAgB,IAGzB,QACE,MAAM,IAAI,MAAM,kCAAkC,KAAK,YAAY,EAAE,EAE3E,CAEA,SAAO,CACL,GAAI,KAAK,cACP,MAAM,IAAI,MAAM,yCAAyC,EAGvD,KAAK,WACP,KAAK,SAAQ,EACb,KAAK,SAAW,QAElB,KAAK,QAAU,OACf,KAAK,eAAiB,OACtB,KAAK,cAAgB,OACrB,KAAK,aAAe,OACpB,KAAK,WAAa,OAClB,KAAK,cAAgB,OAErB,KAAK,aAAe,MACtB,CAKQ,aAAW,CACjB,GAAI,KAAK,eAAiB,OACxB,MAAM,IAAI,MAAM,yBAAyB,CAE7C,CAEA,QAAQa,EAAuB,CAE7B,GADA,KAAK,YAAW,EACZ,KAAK,YAAc,KAAK,SAC1B,MAAM,IAAI,MAAM,iDAAiD,EAEnE,OAAOe,GAAc,KAAMf,CAAI,CACjC,KC/iBF,IAsYalB,GAtYb8C,GAAAnH,EAAA,kBAIAiE,KAkYaI,GAASA,KCtYtB,IAQa+C,GAQPC,GAqBOC,GAUAC,GA/CbC,GAAAxH,EAAA,kBAGA0B,KAKa0F,GAAQ,CAACK,EAAoBC,IAAiB,EACrD,OAAOjG,GAAI,MAAU,IAAc,CAACA,GAAI,KAAK,MAAQ,CAACA,GAAI,QAI9D,QAAQ,UAAU,GAAGgG,CAAU,UAAUC,CAAK,EAAE,CAClD,EAEML,GAAa,CAACM,EAAaC,IAAqB,CACpD,IAAMC,EAAQ,IAAI,MAAK,EAAG,OAAO,MAAM,aAAa,GAAK,CAAA,EACrDC,EAAe,GACnB,QAASzH,EAAI,EAAGA,EAAIwH,EAAM,OAAQxH,IAAK,CACrC,GAAIyH,GAAgB,CAACD,EAAMxH,CAAC,EAAE,SAAS,YAAY,EAAG,CACpD,IAAIqH,EAAQ,QAAQC,CAAG,KAAKE,EAAMxH,CAAC,EAAE,KAAI,EAAG,MAAM,GAAG,EAAE,CAAC,CAAC,GACrDuH,IACFF,GAAS,KAAKE,CAAQ,IAExBR,GAAM,MAAOM,CAAK,EAClB,OAEEG,EAAMxH,CAAC,EAAE,SAAS,YAAY,IAChCyH,EAAe,IAGrB,EAKaR,GAAoBM,GAAqB,EAChD,OAAOnG,GAAI,MAAU,IAAc,CAACA,GAAI,KAAK,MAAQ,CAACA,GAAI,QAG9D4F,GAAW,QAASO,CAAQ,CAC9B,EAKaL,GAAkBK,GAAqB,EAC9C,OAAOnG,GAAI,MAAU,IAAc,CAACA,GAAI,KAAK,MAAQ,CAACA,GAAI,QAG9D4F,GAAW,MAAOO,CAAQ,CAC5B,ICpDA,IAgBaG,GAhBbC,GAAAhI,EAAA,kBAGAD,KAIAoH,KACAK,KAQaO,GAAP,MAAOE,CAAgB,CAC3B,YAAoBC,EAAgC,CAClD,KAAK,QAAUA,CACjB,CAGA,MAAM,IAAIC,EAAkBxB,EAAiCC,EAAiB,CAC5EU,GAAgB,EAChB,IAAMc,EAAgD,CAAA,EAClD1H,EAAsB,CAAA,EAE1B,GAAI,OAAOyH,GAAU,UAAYA,IAAU,MAAQA,aAAiB9D,IAAU,MAAM,QAAQ8D,CAAK,EAC/F,MAAM,IAAI,UACR,+FAA+F,EAInG,IAAIE,EAAiB,GAErB,GAAI,OAAO1B,GAAS,SAAU,CAC5B,GAAIA,IAAS,KACX,MAAM,IAAI,UAAU,yCAAyC,EAE/D,GAAIA,aAAgBtC,GAClB,MAAM,IAAI,UAAU,8BAA8B,EAGpD,GAAI,MAAM,QAAQsC,CAAI,EAAG,CACvB,GAAIA,EAAK,SAAW,EAClB,MAAM,IAAI,UAAU,qCAAqC,EAE3D0B,EAAiB,GAEjB,QAAWpI,KAAQ0G,EAAM,CACvB,GAAI,OAAO1G,GAAS,SAClB,MAAM,IAAI,UAAU,gDAAgD,EAEtE,GAAI,KAAK,YAAY,QAAQA,CAAI,IAAM,GACrC,MAAM,IAAI,WAAW,2CAA2CA,CAAI,GAAG,EAEzEmI,EAAQnI,CAAI,EAAI,KAGlB,GAAI,OAAO2G,GAAS,UAAYA,IAAS,KACvClG,EAAUkG,UACD,OAAOA,EAAS,IACzB,MAAM,IAAI,UAAU,8BAA8B,MAE/C,CAGL,IAAI0B,EAAY,GACVC,EAAW,OAAO,oBAAoB5B,CAAI,EAChD,QAAW1G,KAAQ,KAAK,YACtB,GAAIsI,EAAS,QAAQtI,CAAI,IAAM,GAAI,CACjC,IAAMuI,EAAK7B,EAA4D1G,CAAI,GACvEuI,IAAM,MAAQA,aAAanE,MAC7BiE,EAAY,GACZD,EAAiB,GACjBD,EAAQnI,CAAI,EAAIuI,GAKtB,GAAIF,GACF,GAAI,OAAO1B,GAAS,UAAYA,IAAS,KACvClG,EAAUkG,UACD,OAAOA,EAAS,IACzB,MAAM,IAAI,UAAU,8BAA8B,OAGpDlG,EAAUiG,WAGL,OAAOA,EAAS,IACzB,MAAM,IAAI,UAAU,yDAAyD,EAI/E,QAAW1G,KAAQ,KAAK,WACtB,GAAI,OAAOkI,EAAMlI,CAAI,EAAM,IACzB,MAAM,IAAI,MAAM,UAAUA,CAAI,0BAA0B,EAK5D,GAAIoI,EACF,QAAWpI,KAAQ,KAAK,YACtBmI,EAAQnI,CAAI,EAAI,KAMpB,IAAMwI,EAAU,MAAM,KAAK,QAAQ,IAAIN,EAAOC,EAAS1H,CAAO,EACxDgI,EAA6C,CAAA,EACnD,QAAWC,KAAOF,EAChB,GAAI,OAAO,eAAe,KAAKA,EAASE,CAAG,EAAG,CAC5C,IAAMC,EAASH,EAAQE,CAAG,EACtBC,aAAkBvE,GACpBqE,EAAYC,CAAG,EAAIC,EAEnBF,EAAYC,CAAG,EAAI,IAAItE,GAAOuE,EAAO,KAAMA,EAAO,KAAMA,EAAO,IAAI,EAIzE,OAAArB,GAAc,EACPmB,CACT,CAEA,MAAM,SAAO,CACX,OAAO,KAAK,QAAQ,QAAO,CAC7B,CAWA,aAAa,OACXhC,EACAC,EACAC,EACAiC,EAAqB,CAErBvB,GAAgB,EAEhB,IAAIwB,EACApI,EAA0B,CAAA,EAE9B,GAAI,OAAOgG,GAAS,UAElB,GADAoC,EAAuBpC,EACnB,OAAOC,GAAS,UAAYA,IAAS,KACvCjG,EAAUiG,UACD,OAAOA,EAAS,IACzB,MAAM,IAAI,UAAU,8BAA8B,UAE3CD,aAAgB,YAEzB,GADAoC,EAAuBpC,EACnB,OAAOC,GAAS,UAAYA,IAAS,KACvCjG,EAAUiG,UACD,OAAOA,EAAS,IACzB,MAAM,IAAI,UAAU,8BAA8B,UAGpDD,aAAgB,aACf,OAAO,kBAAsB,KAAeA,aAAgB,kBAC7D,CACA,IAAMxC,EAASwC,EACXqC,EAAa,EACbC,EAAatC,EAAK,WACtB,GAAI,OAAOC,GAAS,UAAYA,IAAS,KACvCjG,EAAUiG,UACD,OAAOA,GAAS,SAAU,CAEnC,GADAoC,EAAapC,EACT,CAAC,OAAO,cAAcoC,CAAU,EAClC,MAAM,IAAI,WAAW,kCAAkC,EAEzD,GAAIA,EAAa,GAAKA,GAAc7E,EAAO,WACzC,MAAM,IAAI,WAAW,oCAAoCA,EAAO,UAAU,IAAI,EAGhF,GADA8E,EAAatC,EAAK,WAAaqC,EAC3B,OAAOnC,GAAS,SAAU,CAE5B,GADAoC,EAAapC,EACT,CAAC,OAAO,cAAcoC,CAAU,EAClC,MAAM,IAAI,WAAW,kCAAkC,EAEzD,GAAIA,GAAc,GAAKD,EAAaC,EAAa9E,EAAO,WACtD,MAAM,IAAI,WAAW,oCAAoCA,EAAO,WAAa6E,CAAU,IAAI,EAE7F,GAAI,OAAOF,GAAS,UAAYA,IAAS,KACvCnI,EAAUmI,UACD,OAAOA,EAAS,IACzB,MAAM,IAAI,UAAU,8BAA8B,UAE3C,OAAOjC,EAAS,IACzB,MAAM,IAAI,UAAU,gCAAgC,UAE7C,OAAOD,EAAS,IACzB,MAAM,IAAI,UAAU,8BAA8B,EAEpDmC,EAAuB,IAAI,WAAW5E,EAAQ6E,EAAYC,CAAU,MAEpE,OAAM,IAAI,UAAU,qDAAqD,EAI3E,GAAM,CAAC9I,EAAS+I,CAAuB,EAAI,MAAMnJ,GAAoCY,CAAO,EACtFwH,EAAU,MAAMhI,EAAQ,8BAA8B4I,EAAsBG,CAAuB,EACzG,OAAA1B,GAAc,EACP,IAAIU,EAAiBC,CAAO,CACrC,CAEA,gBAAc,CACZ,KAAK,QAAQ,eAAc,CAC7B,CACA,cAAY,CACV,KAAK,QAAQ,aAAY,CAC3B,CAEA,IAAI,YAAU,CACZ,OAAO,KAAK,QAAQ,UACtB,CACA,IAAI,aAAW,CACb,OAAO,KAAK,QAAQ,WACtB,KCjOF,IA0jBaH,GA1jBbmB,GAAAlJ,EAAA,kBAGAgI,KAujBaD,GAA4CA,KC1jBzD,IAAAoB,GAAAnJ,EAAA,oBCAA,IAAAoJ,GAAApJ,EAAA,oBCAA,IAAAqJ,GAAArJ,EAAA,oBCAA,IAAAsJ,GAAAtJ,EAAA,oBCAA,IAAAuJ,GAAA,GAAAC,GAAAD,GAAA,sBAAAxB,GAAA,UAAAX,GAAA,qBAAAE,GAAA,mBAAAC,GAAA,WAAAlD,GAAA,QAAA5C,EAAA,oBAAA7B,KAAA,IAAA6J,GAAAzJ,EAAA,kBAmBAqB,KACAO,KACAsH,KACA/B,KACAgC,KACAC,KACA5B,KACA6B,KACAC,OC3BA,IAAAI,GAAA1J,EAAA,oBCAA,IAAA2J,GAAA,GAAAH,GAAAG,GAAA,aAAAC,KAAA,IAmGMC,GACAC,GA0FCF,GA9LPG,GAAA/J,EAAA,kBAsFAgK,KAUAC,KACAC,KAEML,GAAc,wBACdC,GAAgB,WAAW,MAAM,OAASD,GAE5CC,KAEF,KAAK,UAAaK,GAA2C,CAC3D,GAAM,CAAE,KAAAxE,EAAM,GAAIyE,CAAQ,EAAID,EAAG,KACjC,GAAI,CACF,OAAQxE,EAAM,CACZ,IAAK,YACH0E,GAAsBD,EAAS,IAAI,EAAE,KACnC,IAAM,CACJE,GAAYF,CAAQ,EAAE,KACpB,IAAM,CACJ,YAAY,CAAE,KAAAzE,CAAK,CAAC,CACtB,EACC1E,GAAQ,CACP,YAAY,CAAE,KAAA0E,EAAM,IAAA1E,CAAI,CAAC,CAC3B,CACF,CACF,EACCA,GAAQ,CACP,YAAY,CAAE,KAAA0E,EAAM,IAAA1E,CAAI,CAAC,CAC3B,CACF,EACA,MACF,IAAK,UAAW,CACd,GAAM,CAAE,OAAAsJ,EAAQ,IAAA9I,CAAI,EAAI2I,EACxBI,GAAO/I,EAAK8I,CAAM,EAAE,KAClB,IAAM,CACJ,YAAY,CAAE,KAAA5E,CAAK,CAAC,CACtB,EACC1E,GAAQ,CACP,YAAY,CAAE,KAAA0E,EAAM,IAAA1E,CAAI,CAAC,CAC3B,CACF,EACA,KACF,CACA,IAAK,YAAa,CAChB,GAAM,CAAE,OAAAiD,CAAO,EAAIkG,EACbK,EAAaC,GAAuBxG,CAAM,EAChD,YAAY,CAAE,KAAAyB,EAAM,IAAK8E,CAAW,CAAmB,EACvD,KACF,CACA,IAAK,SAAU,CACb,GAAM,CAAE,MAAAE,EAAO,QAAAjK,CAAQ,EAAI0J,EAC3BQ,GAAcD,EAAOjK,CAAO,EAAE,KAC3BmK,GAAoB,CACnB,YAAY,CAAE,KAAAlF,EAAM,IAAKkF,CAAgB,CAAmB,CAC9D,EACC5J,GAAQ,CACP,YAAY,CAAE,KAAA0E,EAAM,IAAA1E,CAAI,CAAC,CAC3B,CACF,EACA,KACF,CACA,IAAK,UACH6J,GAAeV,CAAQ,EACvB,YAAY,CAAE,KAAAzE,CAAK,CAAC,EACpB,MACF,IAAK,MAAO,CACV,GAAM,CAAE,UAAAoF,EAAW,aAAAC,EAAc,OAAAC,EAAQ,cAAAC,EAAe,QAAAxK,CAAQ,EAAI0J,EACpEe,GAAIJ,EAAWC,EAAcC,EAAQC,EAAe,IAAI,MAAMA,EAAc,MAAM,EAAE,KAAK,IAAI,EAAGxK,CAAO,EAAE,KACtG0K,GAAY,CACPA,EAAQ,KAAMC,GAAMA,EAAE,CAAC,IAAM,KAAK,EACpC,YAAY,CAAE,KAAA1F,EAAM,IAAK,iDAAkD,CAAC,EAE5E,YACE,CAAE,KAAAA,EAAM,IAAKyF,CAAQ,EACrBE,GAA2B,CAAC,GAAGL,EAAQ,GAAGG,CAAO,CAAiC,CACpF,CAEJ,EACCnK,GAAQ,CACP,YAAY,CAAE,KAAA0E,EAAM,IAAA1E,CAAI,CAAC,CAC3B,CACF,EACA,KACF,CACA,IAAK,gBACHsK,GAAanB,CAAQ,EACrB,YAAY,CAAE,KAAAzE,CAAK,CAAC,EACpB,MACF,QACF,CACF,OAAS1E,EAAK,CACZ,YAAY,CAAE,KAAA0E,EAAM,IAAA1E,CAAI,CAAmB,CAC7C,CACF,GAGK2I,GAAQE,GACX,KACC0B,GACC,IAAI,OAAOA,GAAeC,GAAY,CAAE,KAAqC,UAAW,KAAM5B,EAAY,CAAC,ICjMjH,IAWM6B,GAmCAC,GAiDOF,GAOAG,GAUPC,GAaAC,GAaAC,GAcAC,GAeAC,GAQAC,GAeOC,GAoBPC,GAsBOC,GAxObnC,GAAAlK,EAAA,kBAIA0J,KAOMgC,GAAmB,OAAO,SAAa,IAAc,OAAY,SAAS,OAmC1EC,GAAe,IAA0B,CAE7C,GAAI,IAkCJ,OAAO,OAAO,SAAa,IACtB,SAAS,eAAqC,IAE/C,OAAO,KAAS,IACd,KAAK,UAAU,KACf,MACR,EAOaF,GAAYE,GAAa,EAOzBC,GAAmC,IAA0B,CACxE,GAAIH,IAAa,CAACA,GAAU,WAAW,OAAO,EAC5C,OAAOA,GAAU,UAAU,EAAGA,GAAU,YAAY,GAAG,EAAI,CAAC,CAGhE,EAKMI,GAAe,CAACS,EAAkBC,IAA4B,CAClE,GAAI,CACF,IAAMC,EAAUD,GAAkBd,GAElC,OADYe,EAAU,IAAI,IAAIF,EAAUE,CAAO,EAAI,IAAI,IAAIF,CAAQ,GACxD,SAAWZ,EACxB,MAAQ,CACN,MAAO,EACT,CACF,EAKMI,GAAe,CAACQ,EAAkBC,IAA4B,CAClE,IAAMC,EAAUD,GAAkBd,GAClC,GAAI,CAEF,OADYe,EAAU,IAAI,IAAIF,EAAUE,CAAO,EAAI,IAAI,IAAIF,CAAQ,GACxD,IACb,MAAQ,CACN,MACF,CACF,EAKMP,GAAc,CAACO,EAAkBC,IAA4B,GAAGA,GAAkB,IAAI,GAAGD,CAAQ,GAcjGN,GAAU,MAAOS,GAAyC,CAE9D,IAAMC,EAAO,MADI,MAAM,MAAMD,EAAa,CAAE,YAAa,aAAc,CAAC,GAC5C,KAAK,EACjC,OAAO,IAAI,gBAAgBC,CAAI,CACjC,EAWMT,GAAuB,MAAUU,IACpC,MAAM,6BAAiCA,IAAM,QAO1CT,GAEwC,cAA+B,QAahEC,GAAoB,SAAmD,CAClF,GAAI,CAACV,GACH,MAAM,IAAI,MAAM,sEAAsE,EAIxF,GAAII,GAAaJ,EAAS,EACxB,MAAO,CAAC,OAAWS,GAAmB,CAAC,EAIzC,IAAMS,EAAM,MAAMX,GAAQP,EAAS,EACnC,MAAO,CAACkB,EAAKT,GAAmBS,CAAG,CAAC,CACtC,EAOMP,GAQA,OAcOC,GAAmB,MAC9Bb,EACAe,EACAK,IAC0E,CAC1E,GAAI,CAACpB,GAAe,CAACe,GAAkBH,IAAsBX,IAAaI,GAAaJ,EAAS,EAC9F,MAAO,CAAC,OAAWW,EAAkB,EAChC,CACL,IAAMS,EACF,kCAEEC,EAAgBtB,GAAeM,GAAae,EAAoBN,CAAc,EAW9EQ,EAAc,CAAC,IAAUH,GAAmBE,GAAiB,CAACjB,GAAaiB,EAAeP,CAAc,EACxGI,EAAMI,EACR,MAAMf,GAAQc,CAAa,EAC1BA,GAAiBf,GAAYc,EAAoBN,CAAc,EACpE,MAAO,CAACQ,EAAcJ,EAAM,OAAW,MAAMV,GAA6DU,CAAG,CAAC,CAChH,CACF,ICpQA,IAQIK,GACAC,GACAC,GACAC,GAEEC,GA0BAC,GA2BOhD,GAgIAiD,GAlMbrD,GAAAjK,EAAA,kBAMAkK,KAGI+C,GAAc,GACdC,GAAe,GACfC,GAAU,GAERC,GAAyB,IAAe,CAE5C,GAAI,OAAO,kBAAsB,IAC/B,MAAO,GAGT,GAAI,CAGF,OAAI,OAAO,eAAmB,KAC5B,IAAI,eAAe,EAAE,MAAM,YAAY,IAAI,kBAAkB,CAAC,CAAC,EAK1D,YAAY,SACjB,IAAI,WAAW,CACb,EAAG,GAAI,IAAK,IAAK,EAAG,EAAG,EAAG,EAAG,EAAG,EAAG,EAAG,GAAI,EAAG,EAAG,EAAG,EAAG,EAAG,EAAG,EAAG,EAAG,EAAG,EAAG,EAAG,EAAG,GAAI,GAAI,EAAG,EAAG,EAAG,GAAI,EAAG,IAAK,GAC3G,EAAG,EAAG,GAAI,EACZ,CAAC,CACH,CACF,MAAY,CACV,MAAO,EACT,CACF,EAEMC,GAAkB,IAAe,CACrC,GAAI,CAeF,OAAO,YAAY,SACjB,IAAI,WAAW,CACb,EAAG,GAAI,IAAK,IAAK,EAAG,EAAG,EAAG,EAAG,EAAG,EAAG,EAAG,GAAI,EAAG,EAAG,EAAG,EAAG,EAAG,EAAG,GAAI,GAAI,EAAG,GAAI,EAAG,GAAI,EAAG,IAAK,GAAI,IAAK,GAAI,EAAG,EAAG,EAC7G,EAAG,EAAG,EAAG,EAAG,EAAG,EAAG,EAAG,EAAG,EAAG,EAAG,EAAG,EAAG,EAAG,IAAK,IAAK,EAAG,GAAI,EAC1D,CAAC,CACH,CACF,MAAY,CACV,MAAO,EACT,CACF,EAEahD,GAAwB,MAAOkD,GAA+C,CACzF,GAAIN,GACF,OAAO,QAAQ,QAAQ,EAEzB,GAAIC,GACF,MAAM,IAAI,MAAM,uDAAuD,EAEzE,GAAIC,GACF,MAAM,IAAI,MAAM,oDAAoD,EAGtED,GAAe,GAGf,IAAMM,EAAUD,EAAM,YAClBE,EAAaF,EAAM,WAGvB,GAAI,CAACF,GAAgB,EACnB,MAAM,IAAI,MAAM,+DAA+D,EAIjF,IAAMK,EAAuBN,GAAuB,EAChDK,EAAa,GAAK,CAACC,IACjB,OAAO,KAAS,KAAe,CAAC,KAAK,qBAEvC,QAAQ,KACN,iCACED,EACA,uIAEJ,EAIF,QAAQ,KACN,4GACF,EAGAF,EAAM,WAAaE,EAAa,GAGlC,IAAME,EAAYJ,EAAM,UAClBK,EAAqB,OAAOD,GAAc,SAAWA,EAAY,OACjEE,EAAuBF,GAAiC,IACxDG,EAAmBD,GAA6B,MAAQA,EACxDE,EAAwBJ,GAAiC,KACzDK,EAAoBD,GAA8B,MAAQA,EAC1DE,EAAqBV,EAAM,WAE3B,CAACW,EAAWC,CAAc,EAAI,MAAM9B,GAAiByB,EAAiBF,EAAoBH,EAAa,CAAC,EAE1GW,EAAY,GAEVC,EAA8B,CAAC,EAmErC,GAhEIb,EAAU,GACZa,EAAM,KACJ,IAAI,QAAStJ,GAAY,CACvB,WAAW,IAAM,CACfqJ,EAAY,GACZrJ,EAAQ,CACV,EAAGyI,CAAO,CACZ,CAAC,CACH,EAIFa,EAAM,KACJ,IAAI,QAAQ,CAACtJ,EAASC,IAAW,CAC/B,IAAMsJ,EAAiC,CAKrC,WAAAb,CACF,EAEA,GAAIQ,EAEFK,EAAO,WAAaL,UACXD,GAAoBJ,EAI7BU,EAAO,WAAcC,GAAaP,GAAoBJ,EAAqBW,UAClET,GAAmBA,EAAgB,QAAQ,OAAO,IAAM,EAEjEQ,EAAO,WAAcC,GAAa,IAAI,IAAIA,EAAUT,CAAe,EAAE,aAC5DI,EAAW,CACpB,IAAMM,EAAyB5C,GAAiC,EAC5D4C,IAEFF,EAAO,WAAcC,GAAaC,EAAyBD,EAE/D,CAEAJ,EAAeG,CAAM,EAAE,KAEpBG,GAAW,CACVvB,GAAe,GACfD,GAAc,GACdD,GAAOyB,EACP1J,EAAQ,EACJmJ,GACF,IAAI,gBAAgBA,CAAS,CAEjC,EAECQ,GAAS,CACRxB,GAAe,GACfC,GAAU,GACVnI,EAAO0J,CAAI,CACb,CACF,CACF,CAAC,CACH,EAEA,MAAM,QAAQ,KAAKL,CAAK,EAEpBD,EACF,MAAM,IAAI,MAAM,2DAA2DZ,CAAO,IAAI,CAE1F,EAEaF,GAAc,IAAqB,CAC9C,GAAIL,IAAeD,GACjB,OAAOA,GAGT,MAAM,IAAI,MAAM,qCAAqC,CACvD,ICxMA,IAKa2B,GAeAC,GAgCAC,EApDbC,GAAA9O,EAAA,kBAGAiK,KAEa0E,GAAkB,CAACjK,EAAcqK,IAA6B,CACzE,IAAM/B,EAAOM,GAAY,EAEnB0B,EAAahC,EAAK,gBAAgBtI,CAAI,EAAI,EAC1CuK,EAAajC,EAAK,QAAQgC,CAAU,EAC1C,OAAAhC,EAAK,aAAatI,EAAMuK,EAAYD,CAAU,EAC9CD,EAAO,KAAKE,CAAU,EAEfA,CACT,EAMaL,GAAsB,CACjClO,EACAwO,EACAC,EACAjH,IACS,CACT,GAAI,OAAOxH,GAAW,UAAYA,IAAY,KAAM,CAClD,GAAIyO,EAAK,IAAIzO,CAAO,EAClB,MAAM,IAAI,MAAM,+BAA+B,EAE/CyO,EAAK,IAAIzO,CAAO,CAEpB,CAEA,OAAO,QAAQA,CAAO,EAAE,QAAQ,CAAC,CAACiI,EAAKhH,CAAK,IAAM,CAChD,IAAM1B,EAAOiP,EAASA,EAASvG,EAAMA,EACrC,GAAI,OAAOhH,GAAU,SACnBiN,GAAoBjN,EAAkC1B,EAAO,IAAKkP,EAAMjH,CAAO,UACtE,OAAOvG,GAAU,UAAY,OAAOA,GAAU,SACvDuG,EAAQjI,EAAM0B,EAAM,SAAS,CAAC,UACrB,OAAOA,GAAU,UAC1BuG,EAAQjI,EAAM0B,EAAQ,IAAM,GAAG,MAE/B,OAAM,IAAI,MAAM,mCAAmC,OAAOA,CAAK,EAAE,CAErE,CAAC,CACH,EAMakN,EAAkBzE,GAA0B,CACvD,IAAM4C,EAAOM,GAAY,EAEnBzF,EAAQmF,EAAK,UAAU,EAC7B,GAAI,CACF,IAAMoC,EAAUpC,EAAK,SACfqC,EAAerC,EAAK,WAAW,EAAIoC,CAAO,EAChDpC,EAAK,iBAAiBqC,EAAcA,EAAeD,CAAO,EAC1D,IAAME,EAAY,OAAOtC,EAAK,SAASqC,EAAcD,IAAY,EAAI,MAAQ,KAAK,CAAC,EAC7EG,EAAsBvC,EAAK,SAASqC,EAAeD,EAAS,GAAG,EAC/DI,EAAeD,EAAsBvC,EAAK,aAAauC,CAAmB,EAAI,GACpF,MAAM,IAAI,MAAM,GAAGnF,CAAO,gBAAgBkF,CAAS,oBAAoBE,CAAY,EAAE,CACvF,QAAE,CACAxC,EAAK,aAAanF,CAAK,CACzB,CACF,ICnEA,IAQa4H,GARbC,GAAA1P,EAAA,kBAKAiK,KACA6E,KAEaW,GAAiB/O,GAA6D,CACzF,IAAMsM,EAAOM,GAAY,EACrBqC,EAAmB,EACjBZ,EAAmB,CAAC,EAEpBa,EAA0ClP,GAAW,CAAC,EAE5D,GAAI,CACF,GAAIA,GAAS,mBAAqB,OAChCkP,EAAW,iBAAmB,UAE9B,OAAOlP,EAAQ,kBAAqB,UACpC,CAAC,OAAO,UAAUA,EAAQ,gBAAgB,GAC1CA,EAAQ,iBAAmB,GAC3BA,EAAQ,iBAAmB,EAE3B,MAAM,IAAI,MAAM,qCAAqCA,EAAQ,gBAAgB,EAAE,EAGjF,GAAIA,GAAS,oBAAsB,OACjCkP,EAAW,kBAAoB,UACtB,OAAOlP,EAAQ,mBAAsB,UAAY,CAAC,OAAO,UAAUA,EAAQ,iBAAiB,EACrG,MAAM,IAAI,MAAM,qCAAqCA,EAAQ,iBAAiB,EAAE,EAG9EA,GAAS,YAAc,SACzBkP,EAAW,UAAY,IAGzB,IAAIC,EAAgB,EACpB,OAAInP,GAAS,MAAQ,SACnBmP,EAAgBlB,GAAgBjO,EAAQ,IAAKqO,CAAM,GAGrDY,EAAmB3C,EAAK,qBACtB4C,EAAW,iBACXA,EAAW,kBACX,CAAC,CAACA,EAAW,UACbC,CACF,EACIF,IAAqB,GACvBd,EAAe,2BAA2B,EAGxCnO,GAAS,QAAU,QACrBkO,GAAoBlO,EAAQ,MAAO,GAAI,IAAI,QAAoC,CAACiI,EAAKhH,IAAU,CAC7F,IAAMmO,EAAgBnB,GAAgBhG,EAAKoG,CAAM,EAC3CgB,EAAkBpB,GAAgBhN,EAAOoN,CAAM,EAEjD/B,EAAK,sBAAsB2C,EAAkBG,EAAeC,CAAe,IAAM,GACnFlB,EAAe,iCAAiClG,CAAG,MAAMhH,CAAK,GAAG,CAErE,CAAC,EAGI,CAACgO,EAAkBZ,CAAM,CAClC,OAAStO,EAAG,CACV,MAAIkP,IAAqB,GACvB3C,EAAK,sBAAsB2C,CAAgB,EAE7CZ,EAAO,QAASiB,GAAUhD,EAAK,MAAMgD,CAAK,CAAC,EACrCvP,CACR,CACF,ICvEA,IAQMwP,GAeAC,GAWAC,GAsBAC,GAcAC,GA+FOC,GArKbC,GAAAvQ,EAAA,kBAKAiK,KACA6E,KAEMmB,GAA4BO,GAAqD,CACrF,OAAQA,EAAwB,CAC9B,IAAK,WACH,MAAO,GACT,IAAK,QACH,MAAO,GACT,IAAK,WACH,MAAO,GACT,IAAK,MACH,MAAO,IACT,QACE,MAAM,IAAI,MAAM,yCAAyCA,CAAsB,EAAE,CACrF,CACF,EAEMN,GAAoBO,GAAqD,CAC7E,OAAQA,EAAe,CACrB,IAAK,aACH,MAAO,GACT,IAAK,WACH,MAAO,GACT,QACE,MAAM,IAAI,MAAM,+BAA+BA,CAAa,EAAE,CAClE,CACF,EAEMN,GAAwBzP,GAAmD,CAC1EA,EAAQ,QACXA,EAAQ,MAAQ,CAAC,GAEdA,EAAQ,MAAM,UACjBA,EAAQ,MAAM,QAAU,CAAC,GAE3B,IAAMgQ,EAAUhQ,EAAQ,MAAM,QACzBgQ,EAAQ,+BAEXA,EAAQ,6BAA+B,KAKvChQ,EAAQ,oBACRA,EAAQ,mBAAmB,KAAMiQ,IAAQ,OAAOA,GAAO,SAAWA,EAAKA,EAAG,QAAU,QAAQ,IAE5FjQ,EAAQ,iBAAmB,GAE/B,EAEM0P,GAAsB,CAACQ,EAA8BjI,EAAahH,EAAeoN,IAA2B,CAChH,IAAMe,EAAgBnB,GAAgBhG,EAAKoG,CAAM,EAC3CgB,EAAkBpB,GAAgBhN,EAAOoN,CAAM,EACjDzB,GAAY,EAAE,0BAA0BsD,EAAsBd,EAAeC,CAAe,IAAM,GACpGlB,EAAe,qCAAqClG,CAAG,MAAMhH,CAAK,GAAG,CAEzE,EAQM0O,GAAwB,MAC5BO,EACAC,EACA9B,IACkB,CAClB,QAAW4B,KAAME,EAAoB,CACnC,IAAItG,EAAS,OAAOoG,GAAO,SAAWA,EAAKA,EAAG,KACxCG,EAAqC,CAAC,EAG5C,OAAQvG,EAAQ,CACd,IAAK,QAEH,GADAA,EAAS,QACL,OAAOoG,GAAO,SAAU,CAG1B,IAAMlJ,EAFekJ,GAEsD,WACvElJ,GACF2I,GAAoBQ,EAAsB,aAAcnJ,EAAYsH,CAAM,CAE9E,CACA,MACF,IAAK,SA2BD,GADAxE,EAAS,KACL,OAAOoG,GAAO,SAAU,CAC1B,IAAMI,EAAgBJ,EACtB,GAAII,GAAe,gBAAiB,CAClC,GAAIA,EAAc,kBAAoB,QAAUA,EAAc,kBAAoB,OAChF,MAAM,IAAI,MAAM,oDAAoDA,EAAc,eAAe,EAAE,EAErGX,GAAoBQ,EAAsB,kBAAmBG,EAAc,gBAAiBhC,CAAM,CACpG,CACF,CAEF,MACF,IAAK,OACL,IAAK,MACH,SACF,QACE,MAAM,IAAI,MAAM,qCAAqCxE,CAAM,EAAE,CACjE,CAEA,IAAMyG,EAAmBrC,GAAgBpE,EAAQwE,CAAM,EACjDkC,EAAiBH,EAAU,OAC7BI,EAAa,EACbC,EAAe,EACnB,GAAIF,EAAiB,EAAG,CACtBC,EAAa5D,GAAY,EAAE,QAAQ2D,EAAiB3D,GAAY,EAAE,QAAQ,EAC1EyB,EAAO,KAAKmC,CAAU,EACtBC,EAAe7D,GAAY,EAAE,QAAQ2D,EAAiB3D,GAAY,EAAE,QAAQ,EAC5EyB,EAAO,KAAKoC,CAAY,EACxB,QAAS9Q,EAAI,EAAGA,EAAI4Q,EAAgB5Q,IAClCiN,GAAY,EAAE,SAAS4D,EAAa7Q,EAAIiN,GAAY,EAAE,SAAUwD,EAAUzQ,CAAC,EAAE,CAAC,EAAG,GAAG,EACpFiN,GAAY,EAAE,SAAS6D,EAAe9Q,EAAIiN,GAAY,EAAE,SAAUwD,EAAUzQ,CAAC,EAAE,CAAC,EAAG,GAAG,CAE1F,CAEG,MAAMiN,GAAY,EAAE,4BACnBsD,EACAI,EACAE,EACAC,EACAF,CACF,IAAO,GAEPpC,EAAe,oCAAoCtE,CAAM,GAAG,CAEhE,CACF,EAEa+F,GAAoB,MAAO5P,GAA2E,CACjH,IAAMsM,EAAOM,GAAY,EACrBsD,EAAuB,EACrB7B,EAAmB,CAAC,EAEpBqC,EAAkD1Q,GAAW,CAAC,EACpEyP,GAAqBiB,CAAc,EAEnC,GAAI,CACF,IAAMZ,EAAyBP,GAAyBmB,EAAe,wBAA0B,KAAK,EAChGX,EAAgBP,GAAiBkB,EAAe,eAAiB,YAAY,EAC7EC,EACJ,OAAOD,EAAe,OAAU,SAAWzC,GAAgByC,EAAe,MAAOrC,CAAM,EAAI,EAEvFuC,EAAmBF,EAAe,kBAAoB,EAC5D,GAAI,CAAC,OAAO,UAAUE,CAAgB,GAAKA,EAAmB,GAAKA,EAAmB,EACpF,MAAM,IAAI,MAAM,qCAAqCA,CAAgB,EAAE,EAGzE,IAAMC,EAAoBH,EAAe,mBAAqB,EAC9D,GAAI,CAAC,OAAO,UAAUG,CAAiB,GAAKA,EAAoB,GAAKA,EAAoB,EACvF,MAAM,IAAI,MAAM,qCAAqCA,CAAiB,EAAE,EAG1E,IAAMC,EACJ,OAAOJ,EAAe,wBAA2B,SAC7CzC,GAAgByC,EAAe,uBAAwBrC,CAAM,EAC7D,EAsBN,GApBA6B,EAAuB5D,EAAK,yBAC1BwD,EACA,CAAC,CAACY,EAAe,kBACjB,CAAC,CAACA,EAAe,iBACjBX,EACA,CAAC,CAACW,EAAe,gBACjB,EACAC,EACAC,EACAC,EACAC,CACF,EACIZ,IAAyB,GAC3B/B,EAAe,+BAA+B,EAG5CuC,EAAe,oBACjB,MAAMf,GAAsBO,EAAsBQ,EAAe,mBAAoBrC,CAAM,EAGzFqC,EAAe,qBAAuB,OAAW,CACnD,GAAI,OAAOA,EAAe,oBAAuB,UAC/C,MAAM,IAAI,MAAM,+CAA+CA,EAAe,kBAAkB,EAAE,EAEpGhB,GACEQ,EACA,qBACAQ,EAAe,mBAAmB,SAAS,EAC3CrC,CACF,CACF,CAEA,GAAIqC,EAAe,uBACjB,OAAW,CAACnR,EAAM0B,CAAK,IAAK,OAAO,QAAQyP,EAAe,sBAAsB,EAAG,CACjF,GAAI,OAAOnR,GAAS,SAClB,MAAM,IAAI,MAAM,kDAAkDA,CAAI,EAAE,EAE1E,GAAI,OAAO0B,GAAU,UAAY,CAAC,OAAO,UAAUA,CAAK,GAAKA,EAAQ,EACnE,MAAM,IAAI,MAAM,iEAAiEA,CAAK,EAAE,EAE1F,IAAM8P,EAAa9C,GAAgB1O,EAAM8O,CAAM,EAC3C/B,EAAK,6BAA6B4D,EAAsBa,EAAY9P,CAAK,IAAM,GACjFkN,EAAe,wCAAwC5O,CAAI,MAAM0B,CAAK,GAAG,CAE7E,CAGF,OAAIyP,EAAe,QAAU,QAC3BxC,GAAoBwC,EAAe,MAAO,GAAI,IAAI,QAAoC,CAACzI,EAAKhH,IAAU,CACpGyO,GAAoBQ,EAAsBjI,EAAKhH,EAAOoN,CAAM,CAC9D,CAAC,EAGI,CAAC6B,EAAsB7B,CAAM,CACtC,OAAStO,EAAG,CACV,MAAImQ,IAAyB,GACvB5D,EAAK,0BAA0B4D,CAAoB,IAAM,GAC3D/B,EAAe,gCAAgC,EAGnDE,EAAO,QAASiB,GAAUhD,EAAK,MAAMgD,CAAK,CAAC,EACrCvP,CACR,CACF,ICjQA,IA2CaiR,GAyCAC,GA0CAC,GAqCAC,GAgDAC,GAoBAC,GAcAC,GAgBAC,GArQbC,EAAAlS,EAAA,kBA2Ca0R,GAA8B/L,GAA2B,CACpE,OAAQA,EAAM,CACZ,IAAK,OACH,MAAO,GACT,IAAK,QACH,MAAO,GACT,IAAK,OACH,MAAO,GACT,IAAK,QACH,MAAO,GACT,IAAK,SACH,MAAO,GACT,IAAK,QACH,MAAO,GACT,IAAK,SACH,MAAO,IACT,IAAK,UACH,MAAO,IACT,IAAK,UACH,MAAO,GACT,IAAK,UACH,MAAO,IACT,IAAK,SACH,MAAO,GACT,IAAK,QACH,MAAO,GACT,IAAK,SACH,MAAO,IACT,IAAK,OACH,MAAO,IACT,IAAK,QACH,MAAO,IAET,QACE,MAAM,IAAI,MAAM,0BAA0BA,CAAI,EAAE,CACpD,CACF,EAKagM,GAA8BQ,GAAqC,CAC9E,OAAQA,EAAW,CACjB,IAAK,GACH,MAAO,OACT,IAAK,GACH,MAAO,QACT,IAAK,GACH,MAAO,OACT,IAAK,GACH,MAAO,QACT,IAAK,GACH,MAAO,SACT,IAAK,GACH,MAAO,QACT,IAAK,IACH,MAAO,SACT,IAAK,IACH,MAAO,UACT,IAAK,GACH,MAAO,UACT,IAAK,IACH,MAAO,UACT,IAAK,GACH,MAAO,SACT,IAAK,GACH,MAAO,QACT,IAAK,IACH,MAAO,SACT,IAAK,IACH,MAAO,OACT,IAAK,IACH,MAAO,QAET,QACE,MAAM,IAAI,MAAM,0BAA0BA,CAAS,EAAE,CACzD,CACF,EAMaP,GAA6B,CACxCQ,EACAC,IACuB,CACvB,IAAMC,EAAc,CAClB,GACA,EACA,EACA,EACA,EACA,EACA,EACA,EACA,GACA,EACA,EACA,EACA,EACA,EACA,GACA,GACA,GACA,GACA,GACA,GACA,GACA,GACA,EACF,EAAEF,CAAQ,EAEJ5L,EAAO,OAAO6L,GAAe,SAAWA,EAAaA,EAAW,OAAO,CAACE,EAAGC,IAAMD,EAAIC,EAAG,CAAC,EAC/F,OAAOF,EAAc,EAAI,KAAK,KAAK9L,EAAO8L,CAAW,EAAI,MAC3D,EAKaT,GACXlM,GAY+B,CAC/B,OAAQA,EAAM,CACZ,IAAK,UAEH,OAAO,OAAO,aAAiB,KAAe,aAAa,KAAO,aAAe,YACnF,IAAK,UACH,OAAO,aACT,IAAK,QACH,OAAO,WACT,IAAK,OACH,OAAO,UACT,IAAK,SACH,OAAO,YACT,IAAK,QACH,OAAO,WACT,IAAK,QACH,OAAO,WACT,IAAK,OACH,OAAO,WACT,IAAK,UACH,OAAO,aACT,IAAK,SACH,OAAO,YACT,IAAK,QACH,OAAO,cACT,IAAK,SACH,OAAO,eACT,QACE,MAAM,IAAI,MAAM,qBAAqBA,CAAI,EAAE,CAC/C,CACF,EAKamM,GAAwBW,GAA0E,CAC7G,OAAQA,EAAU,CAChB,IAAK,UACH,MAAO,GACT,IAAK,OACH,MAAO,GACT,IAAK,UACH,MAAO,GACT,IAAK,QACH,MAAO,GACT,IAAK,QACH,MAAO,GACT,QACE,MAAM,IAAI,MAAM,8BAA8BA,CAAQ,EAAE,CAC5D,CACF,EAKaV,GAA4BpM,GACvCA,IAAS,WACTA,IAAS,WACTA,IAAS,SACTA,IAAS,SACTA,IAAS,UACTA,IAAS,SACTA,IAAS,QACTA,IAAS,SACTA,IAAS,OAKEqM,GAA2BrM,GACtCA,IAAS,WACTA,IAAS,WACTA,IAAS,SACTA,IAAS,SACTA,IAAS,UACTA,IAAS,UACTA,IAAS,QACTA,IAAS,SACTA,IAAS,QACTA,IAAS,SACTA,IAAS,OAKEsM,GAA4BS,GAA0C,CACjF,OAAQA,EAAU,CAChB,IAAK,OACH,MAAO,GACT,IAAK,MACH,MAAO,GACT,IAAK,aACH,MAAO,GACT,IAAK,UACH,MAAO,GACT,IAAK,aACH,MAAO,GACT,IAAK,YACH,MAAO,GACT,QACE,MAAM,IAAI,MAAM,8BAA8BA,CAAQ,EAAE,CAC5D,CACF,ICtRA,IAWaC,GAXbC,GAAA5S,EAAA,kBAGA0J,KAQaiJ,GAAW,MAAOE,GAA4E,CACzG,GAAI,OAAOA,GAAS,SAClB,GAAI,GAEF,GAAI,CACF,GAAM,CAAE,SAAAC,CAAS,EAAI,GAAQ,kBAAkB,EAC/C,OAAO,IAAI,WAAW,MAAMA,EAASD,CAAI,CAAC,CAC5C,OAASpS,EAAG,CACV,GAAIA,EAAE,OAAS,wBAAyB,CAEtC,GAAM,CAAE,iBAAAsS,CAAiB,EAAI,GAAQ,SAAS,EACxCC,EAASD,EAAiBF,CAAI,EAC9BI,EAAuB,CAAC,EAC9B,cAAiBC,KAASF,EACxBC,EAAO,KAAKC,CAAK,EAEnB,OAAO,IAAI,WAAW,OAAO,OAAOD,CAAM,CAAC,CAC7C,CACA,MAAMxS,CACR,KACK,CAEL,IAAM0S,EAAW,MAAM,MAAMN,CAAI,EACjC,GAAI,CAACM,EAAS,GACZ,MAAM,IAAI,MAAM,sCAAsCN,CAAI,EAAE,EAE9D,IAAMO,EAAsBD,EAAS,QAAQ,IAAI,gBAAgB,EAC3DE,EAAWD,EAAsB,SAASA,EAAqB,EAAE,EAAI,EAC3E,GAAIC,EAAW,WAGb,OAAO,IAAI,WAAW,MAAMF,EAAS,YAAY,CAAC,EAC7C,CAEL,GAAI,CAACA,EAAS,KACZ,MAAM,IAAI,MAAM,sCAAsCN,CAAI,qBAAqB,EAEjF,IAAMS,EAASH,EAAS,KAAK,UAAU,EAEnCjP,EACJ,GAAI,CAEFA,EAAS,IAAI,YAAYmP,CAAQ,CACnC,OAAS5S,EAAG,CACV,GAAIA,aAAa,WAAY,CAE3B,IAAM8S,EAAQ,KAAK,KAAKF,EAAW,KAAK,EACxCnP,EAAS,IAAI,YAAY,OAAO,CAAE,QAASqP,EAAO,QAASA,CAAM,CAAC,EAAE,MACtE,KACE,OAAM9S,CAEV,CAEA,IAAI+S,EAAS,EAEb,OAAa,CACX,GAAM,CAAE,KAAAC,EAAM,MAAA9R,CAAM,EAAI,MAAM2R,EAAO,KAAK,EAC1C,GAAIG,EACF,MAEF,IAAMC,EAAY/R,EAAM,WACV,IAAI,WAAWuC,EAAQsP,EAAQE,CAAS,EAChD,IAAI/R,CAAK,EACf6R,GAAUE,CACZ,CACA,OAAO,IAAI,WAAWxP,EAAQ,EAAGmP,CAAQ,CAC3C,CACF,KACK,QAAIR,aAAgB,KAClB,IAAI,WAAW,MAAMA,EAAK,YAAY,CAAC,EACrCA,aAAgB,WAClBA,EAEA,IAAI,WAAWA,CAAI,CAE9B,ICtFA,IAYMc,GAEAC,GAKFC,GACAC,GAESC,GAQAC,GAWAC,EAzCbC,GAAAlU,EAAA,kBAKAkS,IAOMyB,GAAiB,CAAC,IAAK,IAAK,IAAK,IAAK,GAAG,EAEzCC,GAAQ,CAACO,EAAe/J,IAA0B,CAEtD,QAAQ,IAAI,IAAIuJ,GAAeQ,CAAK,CAAC,IAAI,IAAI,KAAK,EAAE,YAAY,CAAC,IAAI/J,CAAO,EAAE,CAChF,EAKa2J,GAAkB,CAACK,EAA2BC,IAA0B,CACnFR,GAAiBO,EACjBN,GAAQO,CACV,EAKaL,GAAM,CAACvB,EAAoB9K,IAAuB,CAC7D,IAAM2M,EAAexC,GAAqBW,CAAQ,EAC5C8B,EAAczC,GAAqB+B,EAAc,EACnDS,GAAgBC,GAClBX,GAAMU,EAAc,OAAO3M,GAAQ,WAAaA,EAAI,EAAIA,CAAG,CAE/D,EAKasM,EAAwB,IAAIO,IAAiC,CACpEV,IACFE,GAAI,GAAGQ,CAAI,CAEf,IC7CA,IAKaC,GAYAC,GAkFAC,EA8IAC,GAsQAC,GAqDAC,GACAC,GA7iBbC,EAAAhV,EAAA,kBAKayU,GAAN,KAAiB,CAOtB,OAAO,gBAAgBlC,EAAqBC,EAAmD,CAC7F,OAAOD,EAAE,CAAC,IAAMC,EAAE,CAAC,EAAI,OAAY,CAACD,EAAE,CAAC,EAAGC,EAAE,CAAC,CAAC,CAChD,CACF,EAEakC,GAAN,KAAoB,CAQzB,OAAO,UACLO,EACAC,EACAC,EAAW,GACoB,CAC/B,IAAMC,EAAQH,EAAM,OACdI,EAAQH,EAAM,OACpB,GAAIE,IAAU,EACZ,OAAOF,EAET,GAAIG,IAAU,EACZ,OAAOJ,EAET,IAAMK,EAAQ,KAAK,IAAIL,EAAM,OAAQC,EAAM,MAAM,EAC3CK,EAAQ,IAAI,MAAcD,CAAK,EAGrC,GAAIH,EAAU,CACZ,GAAIC,EAAQ,GAAKC,EAAQ,EACvB,OAEF,IAAMG,EAAef,GAAW,gBAC9B,CAACQ,EAAMG,EAAQ,CAAC,EAAGH,EAAMG,EAAQ,CAAC,CAAC,EACnC,CAACF,EAAMG,EAAQ,CAAC,EAAGH,EAAMG,EAAQ,CAAC,CAAC,CACrC,EACA,GAAIG,IAAiB,OACnB,OAEF,CAACD,EAAMD,EAAQ,CAAC,EAAGC,EAAMD,EAAQ,CAAC,CAAC,EAAIE,CACzC,CAEA,QAASnV,EAAI8U,EAAW,EAAI,EAAG9U,GAAKiV,EAAOjV,IAAK,CAC9C,IAAMoV,EAAOL,EAAQ/U,EAAI,EAAI,EAAI4U,EAAMG,EAAQ/U,CAAC,EAC1CqV,EAAOL,EAAQhV,EAAI,EAAI,EAAI6U,EAAMG,EAAQhV,CAAC,EAEhD,GAAIoV,IAASC,GAAQD,EAAO,GAAKC,EAAO,EACtC,OAEF,IAAMC,EAAM,KAAK,IAAIF,EAAMC,CAAI,EAC/B,GAAID,GAAQC,EACVH,EAAMD,EAAQjV,CAAC,EAAI,KAAK,IAAIoV,EAAMC,CAAI,MACjC,CAEL,GAAIC,EAAM,EACR,OAEFJ,EAAMD,EAAQjV,CAAC,EAAI,CACrB,CACF,CAEA,OAAOkV,CACT,CAOA,OAAO,iBAAiBK,EAA0BC,EAAwC,CAExF,IAAMC,EAAYF,EAAM,OAClBG,EAAYF,EAAW,OAC7B,GAAIC,EAAYC,EACd,MAAO,GAET,QAAS,EAAI,EAAG,GAAKD,EAAW,IAC9B,GAAIF,EAAME,EAAY,CAAC,IAAM,GAAKF,EAAME,EAAY,CAAC,IAAMD,EAAWE,EAAY,CAAC,EACjF,MAAO,GAGX,MAAO,EACT,CACF,EAEapB,EAAN,MAAMqB,CAAU,CAIrB,OAAO,KAAKzQ,EAAiC,CAC3C,OAAOyQ,EAAU,0BAA0BzQ,EAAM,EAAGA,EAAK,MAAM,CACjE,CAKA,OAAO,aAAaA,EAAyBiB,EAAO,EAAsB,CACxE,IAAMyP,EAAO1Q,EAAK,OAClB,GAAI0Q,IAAS,EACX,MAAO,CAAC,EAEV,IAAMC,EAAU,IAAI,MAAMD,CAAI,EAC1B,EAAIA,EAAO,EACf,KAAO,GAAK,GAAG,CACb,GAAI1Q,EAAK,CAAC,EAAIiB,IAAS,EAAG,CACxB0P,EAAQ,CAAC,EAAI3Q,EAAK,CAAC,EAAIiB,EACvB,KACF,CACA,GAAIA,EAAOjB,EAAK,CAAC,IAAM,EACrB,MAAM,IAAI,MAAM,sBAAsB,EAExC2Q,EAAQ,CAAC,EAAI,EACb1P,GAAQjB,EAAK,CAAC,EACd,GACF,CACA,IAAK,IAAK,GAAK,EAAG,IAChB2Q,EAAQ,CAAC,EAAI3Q,EAAK,CAAC,EAErB,OAAO2Q,CACT,CAKA,OAAO,kBAAkB3Q,EAAyB4Q,EAAsB,CACtE,GAAIA,EAAO,GAAKA,EAAO5Q,EAAK,OAC1B,MAAM,IAAI,MAAM,wBAAwB4Q,CAAI,wCAAwC5Q,EAAK,MAAM,cAAc,EAE/G,OAAOyQ,EAAU,0BAA0BzQ,EAAM4Q,EAAM5Q,EAAK,MAAM,CACpE,CAKA,OAAO,gBAAgBA,EAAyB4Q,EAAsB,CACpE,GAAIA,EAAO,GAAKA,EAAO5Q,EAAK,OAC1B,MAAM,IAAI,MAAM,wBAAwB4Q,CAAI,sCAAsC5Q,EAAK,MAAM,cAAc,EAE7G,OAAOyQ,EAAU,0BAA0BzQ,EAAM,EAAG4Q,CAAI,CAC1D,CAKA,OAAO,0BAA0B5Q,EAAyB6Q,EAAeC,EAAqB,CAC5F,IAAI7P,EAAO,EACX,QAAS,EAAI4P,EAAO,EAAIC,EAAK,IAAK,CAGhC,GAAI9Q,EAAK,CAAC,EAAI,EACZ,MAAM,IAAI,MAER,+GACF,EAEFiB,GAAQ,OAAOjB,EAAK,CAAC,CAAC,CACxB,CACA,OAAOiB,CACT,CAEA,OAAO,eAAejB,EAA4C,CAChE,IAAM0Q,EAAO1Q,EAAK,OAClB,GAAI0Q,IAAS,EACX,MAAO,CAAC,EACH,GAAIA,IAAS,EAClB,MAAO,CAAC,CAAC,EAEX,IAAMK,EAAU,IAAI,MAAML,CAAI,EAC9BK,EAAQL,EAAO,CAAC,EAAI,EACpBK,EAAQL,EAAO,CAAC,EAAI1Q,EAAK0Q,EAAO,CAAC,EACjC,QAAS5V,EAAI4V,EAAO,EAAG5V,GAAK,EAAG,EAAEA,EAC/BiW,EAAQjW,CAAC,EAAIiW,EAAQjW,EAAI,CAAC,EAAIkF,EAAKlF,EAAI,CAAC,EAE1C,OAAOiW,CACT,CAKA,OAAO,cAAcH,EAAcI,EAA4B,CAC7D,GAAIJ,EAAO,CAACI,GAAcJ,GAAQI,EAChC,MAAM,IAAI,MAAM,sCAAsC,EAExD,OAAOJ,EAAO,EAAIA,EAAOI,EAAaJ,CACxC,CAEA,OAAO,cAAcK,EAAyBD,EAA+B,CAC3E,OAAOC,EAAK,IAAKC,GAAM,KAAK,cAAcA,EAAGF,GAAcC,EAAK,MAAM,CAAC,CACzE,CAQA,OAAO,gBAAgBjE,EAAsBmE,EAA6C,CACxF,OAAIA,EACKA,EAAK,IAAKlO,GAAM+J,EAAE/J,CAAC,CAAC,EAEpB+J,EAAE,MAAM,EAAE,QAAQ,CAE7B,CAOA,OAAO,SAAShN,EAAyBoR,EAA2C,CAClF,IAAMV,EAAO1Q,EAAK,OAClB,OAAOA,EAAK,IAAI,CAACiD,EAAG,IAAMA,EAAImO,EAAI,CAAC,EAAIA,EAAI,EAAIV,CAAI,CAAC,CACtD,CAOA,OAAO,SAASW,EAA2BC,EAAoC,CAC7E,OAAID,EAAO,SAAWC,EAAO,OACpB,GAEFD,EAAO,MAAM,CAACpO,EAAGnI,IAAMmI,IAAMqO,EAAOxW,CAAC,CAAC,CAC/C,CACF,EAEauU,GAAN,MAAMkC,CAAa,CAUxB,OAAO,qBACLC,EACAC,EACAC,EACAX,EACAY,EACAC,EACM,CACN,GAAI,CAACJ,GAAoBE,EAAY,SAAWD,EAAU,OAAS,EACjE,MAAM,IAAI,MAAM,oFAAoF,EAGtG,GAAID,EAEF,QAAStQ,EAAM,EAAGA,EAAMuQ,EAAU,OAAS,EAAGvQ,IACxCA,GAAOwQ,EAAY,OACrBA,EAAY,KAAKD,EAAUvQ,EAAM,CAAC,CAAC,EAEnCwQ,EAAYxQ,CAAG,EAAIuQ,EAAUvQ,EAAM,CAAC,EAM1C,QAASA,EAAM,EAAGA,EAAMwQ,EAAY,OAAQxQ,IAC1C,GAAIA,EAAM6P,EAAQ,QAChB,GAAIA,EAAQ7P,CAAG,EAAI,EACjB,MAAM,IAAI,MAAM,8CAA8C,OAGhE6P,EAAQ,KAAK,CAAC,EAKlB,QAAS7P,EAAM,EAAGA,EAAMwQ,EAAY,OAAQxQ,IAC1C,GAAIA,EAAMyQ,EAAU,QAClB,GAAIA,EAAUzQ,CAAG,EAAI,EACnB,MAAM,IAAI,MAAM,gDAAgD,OAGlEyQ,EAAU,KAAK,CAAC,EAKpB,QAASzQ,EAAM,EAAGA,EAAMwQ,EAAY,OAAS,EAAGxQ,IAC9C,GAAIA,EAAM0Q,EAAK,QACb,GAAIA,EAAK1Q,CAAG,EAAI,EACd,MAAM,IAAI,MAAM,0CAA0C,OAG5D0Q,EAAK,KAAK,CAAC,EAKf,QAAS1Q,EAAM,EAAGA,EAAMwQ,EAAY,OAAQxQ,IAAO,CACjD,GAAIwQ,EAAYxQ,CAAG,GAAK,EACtB,MAAM,IAAI,MAAM,yCAAyC,EAG3D,GAAI0Q,EAAK1Q,CAAG,GAAKwQ,EAAYxQ,CAAG,GAAK0Q,EAAK1Q,EAAMwQ,EAAY,MAAM,GAAKA,EAAYxQ,CAAG,EACpF,MAAM,IAAI,MAAM,oCAAoC,CAExD,CACF,CAGA,OAAO,yBACLuQ,EACAV,EACAY,EACAD,EACAE,EACAC,EACAC,EACM,CACN,GAAKA,EAIL,IAAIF,EAAK,SAAW,GAAKH,EAAU,OAAS,GAC1C,MAAM,IAAI,MAAM,8DAA8D,EAGhF,GAAIV,EAAQ,SAAWU,EAAU,OAAS,EACxC,MAAM,IAAI,MAAM,2DAA2D,EAG7E,GAAIC,EAAY,SAAWD,EAAU,OAAS,EAC5C,MAAM,IAAI,MAAM,iEAAiE,EAGnF,QAASvQ,EAAM,EAAGA,EAAMuQ,EAAU,OAAS,EAAGvQ,IAC5CqQ,EAAa,wBACXE,EAAUvQ,GAAO2Q,EAAgB,EAAI,EAAE,EACvCd,EAAQ7P,CAAG,EACXyQ,EAAUzQ,CAAG,EACbwQ,EAAYxQ,CAAG,EACf0Q,EACA1Q,EACAA,EAAMuQ,EAAU,OAAS,EACzBK,CACF,EAEJ,CAaA,OAAO,uBACLN,EACAC,EACAV,EACAY,EACAD,EACAE,EACAE,EACU,CACV,GAAIL,EAAU,QAAU,EACtB,MAAM,IAAI,MAAM,4CAA4C,EAI9D,IAAMM,EAAa,CAACN,EAAU,CAAC,EAAGA,EAAU,CAAC,CAAC,EAE9C,OAAAF,EAAa,mBACXC,EACAC,EACAM,EACAhB,EACAY,EACAD,EACAE,EACAE,CACF,EACOC,CACT,CAYA,OAAO,uBACLN,EACAO,EACAjB,EACAY,EACAD,EACAE,EACAE,EACU,CACV,GAAIL,EAAU,QAAU,GAAKO,EAAW,QAAU,EAChD,MAAM,IAAI,MAAM,yDAAyD,EAI3E,IAAMD,EAAa,CAACN,EAAU,CAAC,EAAGO,EAAW,CAAC,CAAC,EAE/C,OAAAT,EAAa,mBAAmB,GAAOE,EAAWM,EAAYhB,EAASY,EAAWD,EAAaE,EAAME,CAAO,EACrGC,CACT,CAKA,OAAe,mBACbP,EACAC,EACAM,EACAhB,EACAY,EACAD,EACAE,EACAE,EACA,CACA,GAAIN,EACF,QAAStQ,EAAM,EAAGA,EAAMuQ,EAAU,OAAS,EAAGvQ,IAC5C6Q,EAAW,KAAK,CAAC,MAGnB,SAAS7Q,EAAM,EAAGA,EAAMuQ,EAAU,OAAS,EAAGvQ,IAC5C6Q,EAAW,KACTR,EAAa,wBACXE,EAAUvQ,EAAM,CAAC,EACjB6P,EAAQ7P,CAAG,EACXyQ,EAAUzQ,CAAG,EACbwQ,EAAYxQ,CAAG,EACf0Q,EACA1Q,EACAA,EAAMuQ,EAAU,OAAS,EACzBK,CACF,CACF,CAGN,CAIA,OAAe,wBACbG,EACA/U,EACAgV,EACAC,EACAP,EACAQ,EACAC,EACAP,EACQ,CACR,IAAMQ,EAAUJ,GAAYC,EAAS,GAAK,EAC1C,GAAIL,GAAWA,IAAY,SACzB,OAAQA,EAAS,CACf,IAAK,QACH,OAAAF,EAAKQ,CAAY,EAAI,EACrBR,EAAKS,CAAY,EAAI,EACd,KAAK,OAAOJ,EAASK,GAAWpV,EAAS,CAAC,EACnD,IAAK,aACL,IAAK,aACH,GAAIgV,IAAa,EACf,MAAM,IAAI,MAAM,qDAAqD,EAChE,CAEL,IAAMK,IADoBN,EAAS/U,EAAS,GAAKA,EACX,GAAKA,EAASiV,EAASF,EAC7D,OAAAL,EAAKQ,CAAY,EAA+B,KAAK,MAAhCN,IAAY,cAA2BS,EAAY,GAAK,EAAgBA,EAAY,CAA3B,EAC9EX,EAAKS,CAAY,EAAIE,EAAYX,EAAKQ,CAAY,EAC3C,KAAK,OAAOH,EAASM,EAAYJ,GAAUjV,EAAS,CAAC,CAC9D,CACF,QACE,MAAM,IAAI,MAAM,0BAA0B,CAC9C,KAEA,QAAO,KAAK,OAAO+U,EAASL,EAAKQ,CAAY,EAAIR,EAAKS,CAAY,EAAIC,GAAWpV,EAAS,CAAC,CAE/F,CACF,EAEaoS,GAAN,KAAe,CAIpB,OAAO,qBACLkD,EACAC,EACAC,EACAC,EACAC,EACmB,CACnB,GAAIJ,EAAU,SAAW,GAAKE,EAAW,SAAW,EAClD,MAAM,IAAI,MAAM,4BAA4B,EAG9C,IAAIG,EACAC,EACAC,EAEAN,GACFI,EAAIL,EAAU,CAAC,EACfM,EAAIN,EAAU,CAAC,IAEfK,EAAIL,EAAU,CAAC,EACfM,EAAIN,EAAU,CAAC,GAGjB,IAAIQ,EAAO,GAUX,GARIL,GACFI,EAAIL,EAAW,CAAC,EAChBM,EAAO,IAEPD,EAAIL,EAAW,CAAC,EAChBM,EAAO,GAGLN,EAAWM,CAAI,IAAMF,EACvB,MAAM,IAAI,MAAM,oBAAoB,EAGtC,GAAID,GAAK,GAAKE,GAAK,GAAKD,GAAK,EAC3B,MAAM,IAAI,MAAM,yBAAyB,EAG3C,GAAIF,GAAa,CAACzD,GAAc,iBAAiByD,EAAW,CAACC,EAAGE,CAAC,CAAC,EAChE,MAAM,IAAI,MAAM,wCAAwC,EAG1D,MAAO,CAACF,EAAGE,EAAGD,CAAC,CACjB,CACF,EAEavD,GAAW,sBACXC,GAAW,uBC7iBxB,IAOayD,GAPbC,GAAAzY,EAAA,kBAKAkS,IAEasG,GAAa,CACxBE,EACA/S,IAWiB,IAAKkM,GAAkClM,CAAI,GAAG+S,CAAU,ICpB3E,IAYaC,GA6BPC,GA4DFC,GACEC,GAKAC,GAgBAC,GAWAC,GAuGAC,GA4HAC,GAsJOC,GA/fbC,GAAArZ,EAAA,kBAIAkU,KAQayE,GAAsB,CAACjU,EAAkB4U,EAAc,KAAkC,CAEpG,GAAI5U,EAAK,WAAa,IAAM,EAC1B,MAAM,IAAI,MAAM,+DAA+D,EAIjF,IAAM6U,EAAc7U,EAAK,WAAa,EAChC8U,EAAgB,IAAI,cAAc9U,EAAK,OAAQA,EAAK,WAAY6U,CAAW,EAG3EE,EAAa,IAAI,WAAWF,CAAW,EAE7C,QAAS,EAAI,EAAG,EAAIA,EAAa,IAAK,CACpC,IAAM5X,EAAQ6X,EAAc,CAAC,EAG7B,GAAI7X,EAAQ,aAAeA,EAAQ,CAAC,YAClC,MAAM,IAAI,MAAM,8DAA8D,CAAC,KAAKA,CAAK,EAAE,EAG7F8X,EAAW,CAAC,EAAI,OAAO9X,CAAK,CAC9B,CAGA,OAAO2X,EAAc,IAAI,WAAWG,EAAW,MAAM,EAAIA,CAC3D,EAGMb,GAAsB,CAAClU,EAAkB4U,EAAc,KAAqC,CAEhG,GAAI5U,EAAK,WAAa,IAAM,EAC1B,MAAM,IAAI,MAAM,8DAA8D,EAIhF,IAAM6U,EAAc7U,EAAK,WAAa,EAChC+U,EAAa,IAAI,WAAW/U,EAAK,OAAQA,EAAK,WAAY6U,CAAW,EAGrEC,EAAgB,cAAc,KAAKC,EAAY,MAAM,EAG3D,OAAOH,EAAc,IAAI,WAAWE,EAAc,MAAM,EAAIA,CAC9D,EA6CIX,GAAa,EACXC,GAAoB,IAAgBD,KAKpCE,GAAsB,IAAI,IAA+B,CAC7D,CAAC,UAAW,EAAE,EACd,CAAC,UAAW,EAAE,EACd,CAAC,QAAS,EAAE,EACZ,CAAC,SAAU,EAAE,EACb,CAAC,QAAS,EAAE,EACZ,CAAC,SAAU,EAAE,EACb,CAAC,OAAQ,CAAC,EACV,CAAC,QAAS,CAAC,EACX,CAAC,OAAQ,CAAC,EACV,CAAC,QAAS,CAAC,CACb,CAAC,EAKKC,GAAsB,CAACvT,EAA6BmQ,IAAqC,CAC7F,IAAMpP,EAAOuS,GAAoB,IAAItT,CAAQ,EAC7C,GAAI,CAACe,EACH,MAAM,IAAI,MAAM,wBAAwB,EAE1C,OAAOoP,EAAM,OAAS,EAAI,KAAK,KAAMA,EAAM,OAAO,CAACrD,EAAGC,IAAMD,EAAIC,CAAC,EAAIhM,EAAQ,CAAC,EAAI,CACpF,EAKMyS,GAAN,KAAoB,CAYlB,YAAYS,EAOT,CAfH,KAAO,0BAA4B,GACnC,KAAO,wBAA0B,GAe/B,GAAM,CAAE,UAAA3O,EAAW,QAAA9F,EAAS,OAAAjD,EAAQ,SAAAyD,EAAU,MAAAmQ,EAAO,0BAAA+D,EAA4B,EAAM,EAAID,EAC3F,KAAK,UAAY3O,EACjB,KAAK,UAAY9F,EACjB,KAAK,SAAWjD,EAChB,KAAK,SAAWyD,EAChB,KAAK,YAAcmQ,EACnB,KAAK,0BAA4B+D,CACnC,CAEA,IAAW,QAAmB,CAC5B,OAAO,KAAK,QACd,CAEA,IAAW,MAA0B,CACnC,OAAO,KAAK,QACd,CAEA,IAAW,OAA2B,CACpC,OAAO,KAAK,WACd,CAEA,IAAW,YAAqB,CAC9B,OAAOX,GAAoB,KAAK,SAAU,KAAK,WAAW,CAC5D,CAEO,SAAgB,CACrB/E,EAAU,UAAW,IAAM,+BAA+B,EAC1D,KAAK,SAAS,QAAQ,CACxB,CAEO,MAAMvP,EAAwB,CACnC,KAAK,UAAU,YAAY,KAAK,SAAUA,CAAI,CAChD,CAOA,MAAa,KACXkV,EACAC,EACkC,CAClC,GAAID,EAA2B,CAE7B,IAAMlV,EAAO,MAAM,KAAK,UAAU,WAAW,KAAK,QAAQ,EACpDoV,EAAYlB,GAAoB,IAAI,WAAWlU,CAAI,CAAC,EAE1D,GAAImV,EAAW,EAEXA,aAAqB,YACjB,IAAI,WAAWA,CAAS,EACxB,IAAI,WAAWA,EAAU,OAAQA,EAAU,WAAYA,EAAU,UAAU,GACpE,IAAIC,CAAS,EAC1B,MACF,KACE,QAAOA,EAAU,MAErB,KACE,QAAOD,EAAY,KAAK,UAAU,WAAW,KAAK,SAAUA,CAAS,EAAI,KAAK,UAAU,WAAW,KAAK,QAAQ,CAEpH,CAEO,eAAe5U,EAAoBQ,EAA6BmQ,EAAmC,CACxG,OACE,KAAK,YAAc3Q,GACnB,KAAK,WAAaQ,GAClB,KAAK,YAAY,SAAWmQ,EAAM,QAClC,KAAK,YAAY,MAAM,CAACpN,EAAG,IAAMA,IAAMoN,EAAM,CAAC,CAAC,CAEnD,CAEO,2BAA2BmE,EAA4B,CAC5D,KAAK,wBAA0BA,CACjC,CACF,EAQMb,GAAN,KAAsB,CAGpB,YACUc,EACAC,EACR,CAFQ,mBAAAD,EACA,aAAAC,CACP,CAEH,IAAW,eAA2C,CACpD,OAAO,KAAK,OACd,CAEO,eAAsB,CACvB,KAAK,gBACP,KAAK,cAAc,cAAc,KAAK,aAAa,EACnD,KAAK,QAAU,OAEnB,CAEA,MAAa,aACXlP,EACAtF,EACAmQ,EACAsE,EACmB,CACnB,IAAIC,EAAc1U,EACZR,EAAU,KAAK,cAAc,aAAa8F,CAAS,EAEnD4O,EACJQ,IAAgB,SAAW,CAAClV,EAAQ,gBAAgB,EAAE,MAAM,UAAU,SAAS,OAAO,EAMxF,GALI0U,IACFQ,EAAc,QACdlG,EAAU,UAAW,IAAM,4EAA4E,GAGrG,KAAK,QAAS,CAChB,GAAI,KAAK,QAAQ,eAAehP,EAASkV,EAAavE,CAAK,EACzD,OAAO,KAAK,QAAQ,OAEpB,GAAIsE,EAAS,CACX,GAAI,KAAK,QAAQ,aAAelB,GAAoBmB,EAAavE,CAAK,EACpE,MAAM,IAAI,MAAM,oDAAoD,EAEtE,KAAK,aAAe,IAAI,WAAW,MAAM,KAAK,QAAQ,KAAK,CAAC,CAC9D,CACA,KAAK,cAAc,cAAc,KAAK,OAAO,CAEjD,CAGA,IAAMwE,EAAQ,OAAO,cAAiB,IAAc,OAAY,cAAc,KAAO,cAAc,MACnG,YAAK,QAAU,MAAM,KAAK,cAAc,gBACtCrP,EACAoP,EACAvE,EACAwE,EACA,GACA,GACAT,CACF,EAEIO,GAAW,KAAK,eAGlB,KAAK,QAAQ,MAAM,KAAK,YAAY,EACpC,KAAK,aAAe,QAGf,KAAK,QAAQ,MACtB,CAEO,OAAOxV,EAAwB,CACpC,IAAI2V,EAAU3V,EACd,GAAI,KAAK,QAMP,GALI,KAAK,QAAQ,4BAEf2V,EAAU1B,GAAoBjU,EAAM,EAAI,EACxC,KAAK,QAAQ,2BAA2B,EAAI,GAE1C2V,EAAQ,aAAe,KAAK,QAAQ,WAAY,CAClD,KAAK,QAAQ,MAAMA,CAAO,EAC1B,MACF,MACEpG,EAAU,UAAW,IAAM,yDAAyD,EACpF,KAAK,cAAc,EAInB,KAAK,aACP,KAAK,aAAa,IAAIoG,CAAO,EAE7B,KAAK,aAAe,IAAI,WAAWA,CAAO,CAE9C,CAEA,MAAa,SAASR,EAA6E,CACjG,GAAI,KAAK,aAAc,CAErB,IAAMS,EAAU,KAAK,SAAS,wBACzB1B,GAAoB,KAAK,YAAY,EACtC,KAAK,aAET,GAAIiB,EAAW,CACTA,aAAqB,YACvB,IAAI,WAAWA,CAAS,EAAE,IAAIS,CAAO,EAErC,IAAI,WAAWT,EAAU,OAAQA,EAAU,WAAYA,EAAU,UAAU,EAAE,IAAIS,CAAO,EAE1F,MACF,KACE,QAAOA,EAAQ,MAEnB,CACA,GAAI,CAAC,KAAK,QACR,MAAM,IAAI,MAAM,8BAA8B,EAGhD,OAAKT,EAGE,KAAK,QAAQ,KAAK,KAAK,SAAS,0BAA2BA,CAAS,EAFlE,KAAK,QAAQ,KAAK,KAAK,SAAS,yBAAyB,CAGpE,CACF,EAEMV,GAAN,KAAiD,CAK/C,YAAoBjZ,EAAuB,CAAvB,aAAAA,EAJpB,KAAQ,mBAAqD,IAAI,IACjE,KAAQ,YAA+B,CAAC,EACxC,KAAQ,gBAAsC,IAAI,GAEN,CAErC,aAAa6K,EAA8B,CAChD,IAAM9F,EAAU,KAAK,QAAQ,aAAa8F,CAAS,EACnD,GAAI,CAAC9F,EACH,MAAM,IAAI,MAAM,kCAAkC,EAEpD,OAAOA,CACT,CAEO,iBAA4B,CACjC,IAAMsV,EAAWzB,GAAkB,EACnC,YAAK,mBAAmB,IAAIyB,EAAU,IAAIrB,GAAgB,IAAI,CAAC,EACxDqB,CACT,CAEO,gBAAgBA,EAA0B,CAC/C,IAAMC,EAAgB,KAAK,mBAAmB,IAAID,CAAQ,EACrDC,IAGL,KAAK,mBAAmB,OAAOD,CAAQ,EACnCC,EAAc,eAChB,KAAK,cAAcA,EAAc,aAAa,EAElD,CAEA,MAAa,aACXzP,EACAwP,EACA9U,EACAmQ,EACAsE,EACmB,CACnBjG,EACE,UACA,IACE,iDAAiDsG,CAAQ,eACvD9U,CACF,YAAYmQ,CAAK,cAAcsE,CAAO,GAC1C,EACA,IAAMlY,EAAS,KAAK,mBAAmB,IAAIuY,CAAQ,EACnD,GAAI,CAACvY,EACH,MAAM,IAAI,MAAM,mBAAmB,EAErC,OAAOA,EAAO,aAAa+I,EAAWtF,EAAUmQ,EAAOsE,CAAO,CAChE,CAEO,OAAOK,EAAoB7V,EAAwB,CACxD,IAAM1C,EAAS,KAAK,mBAAmB,IAAIuY,CAAQ,EACnD,GAAI,CAACvY,EACH,MAAM,IAAI,MAAM,mBAAmB,EAErCA,EAAO,OAAO0C,CAAI,CACpB,CAIA,MAAM,SAAS6V,EAAoBV,EAA6E,CAC9G5F,EACE,UACA,IAAM,6CAA6CsG,CAAQ,gBAAgBV,GAAW,UAAU,GAClG,EACA,IAAMW,EAAgB,KAAK,mBAAmB,IAAID,CAAQ,EAC1D,GAAI,CAACC,EACH,MAAM,IAAI,MAAM,mBAAmB,EAErC,OAAOA,EAAc,SAASX,CAAS,CACzC,CAEO,yBAAyB9O,EAAyB,CACvD,QAAW/I,KAAU,KAAK,YACpBA,EAAO,YAAc+I,GACvB/I,EAAO,QAAQ,EAGnB,KAAK,YAAc,KAAK,YAAY,OAAQA,GAAWA,EAAO,YAAc+I,CAAS,CACvF,CAEO,eACLA,EACArF,EACAD,EACAmQ,EACU,CACV,IAAM3Q,EAAU,KAAK,aAAa8F,CAAS,EACrCwP,EAAWzB,GAAkB,EAG7BmB,EAAU,IAAIhB,GAAc,CAChC,UAAAlO,EACA,QAAA9F,EACA,OAAQS,EACR,SAAAD,EACA,MAAAmQ,CACF,CAAC,EACD,YAAK,mBAAmB,IAAI2E,EAAU,IAAIrB,GAAgB,KAAMe,CAAO,CAAC,EACxE,KAAK,gBAAgB,IAAIA,CAAO,EACzBM,CACT,CAKA,MAAa,gBACXxP,EACAtF,EACAmQ,EACAwE,EACAK,EACAC,EACAf,EAA4B,GACJ,CACxB,IAAM1U,EAAU,KAAK,aAAa8F,CAAS,EAC3C,OAAW,CAAC4P,EAAO3Y,CAAM,IAAK,KAAK,YAAY,QAAQ,EACrD,GAAIA,EAAO,eAAeiD,EAASQ,EAAUmQ,CAAK,EAAG,CACnD3B,EAAU,UAAW,IAAM,qCAAqCxO,CAAQ,YAAYmQ,CAAK,GAAG,EAC5F,IAAMqE,EAAU,KAAK,YAAY,OAAOU,EAAO,CAAC,EAAE,CAAC,EACnD,OAAAV,EAAQ,UAAYlP,EACbkP,CACT,CAEFhG,EAAU,UAAW,IAAM,6CAA6CxO,CAAQ,YAAYmQ,CAAK,GAAG,EACpG,IAAM5T,EAAS,MAAMiD,EAAQ,aAAa,CACxC,SAAAQ,EACA,MAAAmQ,EACA,WAAYA,EACZ,MAAAwE,EACA,SAAAK,EACA,SAAAC,CACF,CAAC,EACD,OAAO,IAAIzB,GAAc,CAAE,UAAAlO,EAAW,QAAA9F,EAAS,OAAAjD,EAAQ,SAAAyD,EAAU,MAAAmQ,EAAO,0BAAA+D,CAA0B,CAAC,CACrG,CAKO,cAAciB,EAA8B,CAC7C,KAAK,gBAAgB,IAAIA,CAAa,GACxC,KAAK,gBAAgB,OAAOA,CAAa,EAE3C,KAAK,YAAY,KAAKA,CAAa,CACrC,CACF,EAEaxB,GAAsB,IAAI5E,IACrC,IAAI2E,GAAkB,GAAG3E,CAAI,IChgB/B,IAoBMqG,GAoBAC,GAgBOC,GAxDbC,GAAAhb,EAAA,kBAUAkS,IACAjI,KAEAwO,KACAY,KACAnF,KAKM2G,GAA8B,IAAI,IAAiC,CACvE,GAAiB,SAAS,EAC1B,IAAmB,SAAS,EAC5B,GAAiB,OAAO,EACxB,IAAkB,QAAQ,EAC1B,GAAiB,OAAO,EACxB,IAAkB,QAAQ,EAC1B,IAAgB,MAAM,EACtB,IAAiB,OAAO,EACxB,GAAgB,MAAM,EACtB,GAAiB,OAAO,EACxB,GAAgB,OAAO,CACzB,CAAC,EAQKC,GAA0B,CAACvI,EAAsBC,IAAkC,CACvF,GAAID,IAAMC,EACR,MAAO,GAET,GAAID,IAAM,QAAaC,IAAM,OAC3B,MAAO,GAET,IAAMyI,EAAQ,OAAO,KAAK1I,CAAC,EAAE,KAAK,EAC5B2I,EAAQ,OAAO,KAAK1I,CAAC,EAAE,KAAK,EAClC,OAAOyI,EAAM,SAAWC,EAAM,QAAUD,EAAM,MAAM,CAACtS,EAAKgS,IAAUhS,IAAQuS,EAAMP,CAAK,GAAKpI,EAAE5J,CAAG,IAAM6J,EAAE7J,CAAG,CAAC,CAC/G,EAMaoS,GAAN,KAAmB,CAmCxB,YAAYtZ,EAAU,CA/BtB,KAAQ,cAAgB2X,GAAoB,IAAI,EAIhD,KAAQ,qBAAuB,IAAI,IAInC,KAAQ,sBAAwB,IAAI,IAIpC,KAAQ,eAAmC,CAAC,EAQ5C,KAAQ,mBAA4C,IAAI,IAKxD,KAAQ,qBAAiC,CAAC,EAI1C,KAAQ,0BAAqD,IAAI,IAG/DrF,GAAgBtS,EAAI,SAAW,CAAC,CAACA,EAAI,KAAK,CAC5C,CAEA,IAAW,kBAA2B,CACpC,GAAI,KAAK,kBAAoB,OAC3B,MAAM,IAAI,MAAM,mBAAmB,EAErC,OAAO,KAAK,eACd,CAEO,WAAWsJ,EAAyB,CACzCkJ,EAAU,UAAW,IAAM,kCAAkClJ,CAAS,GAAG,EACzE,KAAK,gBAAkBA,CACzB,CAEO,SAASA,EAAyB,CACvCkJ,EAAU,UAAW,IAAM,gCAAgClJ,CAAS,GAAG,EACvE,IAAMoQ,EAAY,KAAK,0BAA0B,IAAIpQ,CAAS,EAC9D,GAAKoQ,EAGL,SAAWZ,KAAYY,EACrBlH,EAAU,UAAW,IAAM,iDAAiDsG,CAAQ,GAAG,EACvF,KAAK,cAAc,gBAAgBA,CAAQ,EAE7C,KAAK,0BAA0B,OAAOxP,CAAS,EAC/C,KAAK,gBAAkB,OACzB,CAEA,MAAa,gBAAgBqQ,EAAoE,CAC/F,GAAIA,aAA2B,UAAW,CACxC,IAAMC,EAAiB,KAAK,eAAe,UAAWC,GAAUA,EAAM,YAAcF,CAAe,EACnG,GAAIC,IAAmB,GACrB,OAAO,KAAK,eAAeA,CAAc,EAAE,UACtC,CACL,IAAME,EAAY,MAAM,UAAU,GAAG,cAAcH,CAAe,EAClE,YAAK,eAAe,KAAK,CAAE,UAAWA,EAAiB,UAAAG,CAAU,CAAC,EAC3DA,CACT,CACF,SAAWH,IAAoB,OAAW,CACxC,IAAMC,EAAiB,KAAK,eAAe,UACxCC,GAAUA,EAAM,UAAY,QAAaA,EAAM,YAAc,MAChE,EACA,GAAID,IAAmB,GACrB,OAAO,KAAK,eAAeA,CAAc,EAAE,UACtC,CACL,IAAME,EAAY,MAAM,UAAU,GAAG,cAAc,EACnD,YAAK,eAAe,KAAK,CAAE,UAAAA,CAAU,CAAC,EAC/BA,CACT,CACF,CAEA,IAAMF,EAAiB,KAAK,eAAe,UAAWC,GACpDR,GAAwBQ,EAAM,QAASF,CAAe,CACxD,EACA,GAAIC,IAAmB,GACrB,OAAO,KAAK,eAAeA,CAAc,EAAE,UACtC,CACL,IAAME,EAAY,MAAM,UAAU,GAAG,cAAcH,CAAe,EAClE,YAAK,eAAe,KAAK,CAAE,QAASA,EAAiB,UAAAG,CAAU,CAAC,EACzDA,CACT,CACF,CAEO,kBAAkBxQ,EAAmBwQ,EAA4B,CACtE,KAAK,qBAAqB,IAAIxQ,EAAWwQ,CAAS,EAClD,IAAIC,EAAa,KAAK,sBAAsB,IAAID,CAAS,EACpDC,IACHA,EAAa,IAAI,IACjB,KAAK,sBAAsB,IAAID,EAAWC,CAAU,GAEtDA,EAAW,IAAIzQ,CAAS,EAEpB,KAAK,qBAAqB,OAAS,IACrC,KAAK,mBAAmB,IAAIA,EAAW,KAAK,oBAAoB,EAChE,KAAK,qBAAuB,CAAC,EAEjC,CAEO,iBAAiBA,EAAyB,CAC/C,KAAK,mBAAmB,OAAOA,CAAS,EACxC,IAAMwQ,EAAY,KAAK,qBAAqB,IAAIxQ,CAAS,EACzD,GAAI,CAACwQ,EAEH,OAEF,KAAK,cAAc,yBAAyBxQ,CAAS,EACrD,KAAK,qBAAqB,OAAOA,CAAS,EAC1C,IAAMyQ,EAAa,KAAK,sBAAsB,IAAID,CAAS,EAE3D,GADAC,EAAW,OAAOzQ,CAAS,EACvByQ,EAAW,OAAS,EAAG,CACzB,KAAK,sBAAsB,OAAOD,CAAS,EAC3C,IAAMF,EAAiB,KAAK,eAAe,UAAWC,GAAUA,EAAM,YAAcC,CAAS,EACzFF,IAAmB,IACrB,KAAK,eAAe,OAAOA,EAAgB,CAAC,CAEhD,CACF,CAEO,aAAatQ,EAA0C,CAC5D,OAAO,KAAK,qBAAqB,IAAIA,CAAS,CAChD,CAEO,iBAA4B,CACjC,OAAO,KAAK,cAAc,gBAAgB,CAC5C,CAEO,gBAAgBwP,EAA0B,CAC/CtG,EAAU,UAAW,IAAM,sCAAsCsG,CAAQ,GAAG,EAC5E,KAAK,cAAc,gBAAgBA,CAAQ,CAC7C,CAEA,MAAa,aACXxP,EACAwP,EACAkB,EACAC,EACAxB,EACmB,CACnB,IAAMyB,EAAgBd,GAA4B,IAAIY,CAAY,EAClE,GAAI,CAACE,EACH,MAAM,IAAI,MAAM,+BAA+BF,CAAY,EAAE,EAE/D,OAAO,KAAK,cAAc,aACxB1Q,GAAa,KAAK,iBAClBwP,EACAoB,EACAD,EACAxB,CACF,CACF,CAEA,MAAa,sBACXnP,EACA0Q,EACA7F,EACmB,CACnB3B,EAAU,UAAW,IAAM,gDAAgDwH,CAAY,YAAY7F,CAAK,GAAG,EAC3G,IAAMnQ,EAAWoV,GAA4B,IAAIY,CAAY,EAC7D,GAAI,CAAChW,EACH,MAAM,IAAI,MAAM,+BAA+BgW,CAAY,EAAE,EAE/D,IAAMlB,EAAW,KAAK,cAAc,gBAAgB,EACpD,MAAM,KAAK,cAAc,aAAaxP,EAAWwP,EAAU9U,EAAUmQ,EAAO,EAAK,EACjF,IAAMuF,EAAY,KAAK,0BAA0B,IAAIpQ,CAAS,EAC9D,OAAKoQ,EAGHA,EAAU,KAAKZ,CAAQ,EAFvB,KAAK,0BAA0B,IAAIxP,EAAW,CAACwP,CAAQ,CAAC,EAInDA,CACT,CAEO,aAAaA,EAAoB7V,EAAwB,CAE9D,GAAI,CADS4I,GAAY,EACf,yBACR,MAAM,IAAI,MAAM,wEAAwE,EAE1F2G,EAAU,UAAW,IAAM,mCAAmCsG,CAAQ,WAAW7V,EAAK,UAAU,GAAG,EACnG,KAAK,cAAc,OAAO6V,EAAU7V,CAAI,CAC1C,CAEA,MAAa,eAAe6V,EAAoBV,EAA8D,CAC5G,OAAO,KAAK,cAAc,SAASU,EAAUV,CAAS,CACxD,CAEO,yBAAyBU,EAAoB5U,EAAgE,CAClH,MAAO,UAAY,CACjB,IAAMjB,EAAO,MAAM,KAAK,cAAc,SAAS6V,CAAQ,EACvD,OAAO/B,GAAW9T,EAAMiB,CAAI,CAC9B,CACF,CAEO,iBAAiBoF,EAAmB/I,EAAkByZ,EAAwBC,EAAgC,CACnH,IAAMC,EAAgBd,GAA4B,IAAIY,CAAY,EAClE,GAAI,CAACE,EACH,MAAM,IAAI,MAAM,+BAA+BF,CAAY,EAAE,EAG/D,IAAMG,EAAK,KAAK,cAAc,eAAe7Q,EAAW/I,EAAQ2Z,EAAeD,CAAU,EACzF,OAAAzH,EACE,UACA,IACE,qCAAqCjS,CAAM,eAAe2Z,CAAa,iBACrED,CACF,mBAAmBE,CAAE,GACzB,EACOA,CACT,CAGO,mBACLC,EACA5M,EACAD,EACA8M,EACAC,EACAC,EACAC,EAA4B,GACjB,CAEX,GAAI,CAACD,EACH,MAAM,IAAI,MAAM,2CAA2C,EAG7D,IAAIE,EAAWL,EACXA,EAAiB,WAAW,IAAI,IAClCK,EAAWL,EAAiB,UAAU,CAAC,GAEzC,IAAMM,EAAWH,EAAa,IAAIE,CAAQ,EAC1C,GAAI,CAACC,EACH,MAAM,IAAI,MAAM,kBAAkBD,CAAQ,gCAAgC,EAG5E,GAAIjN,EAAaD,EAAamN,EAAS,WACrC,MAAM,IAAI,MAAM,2EAA2E,EAG7F,IAAMjY,EAASiY,EAAS,MAAMlN,EAAYA,EAAaD,CAAU,EAAE,OAC/DoN,EACJ,OAAQL,EAAK,SAAU,CACrB,IAAK,UACHK,EAAa,IAAI,aAAalY,CAAM,EACpC,MACF,IAAK,UACHkY,EACE,OAAO,aAAiB,KAAe,aAAa,KAAO,IAAI,aAAalY,CAAM,EAAI,IAAI,YAAYA,CAAM,EAC9G,MACF,IAAK,QACHkY,EAAa,IAAI,WAAWlY,CAAM,EAClC,MACF,IAAK,SACHkY,EAAa,IAAI,YAAYlY,CAAM,EACnC,MACF,IAAK,QACC+X,GAEFG,EAAazD,GAAoB,IAAI,WAAWzU,CAAM,EAAG,EAAK,EAC9D6X,EAAK,SAAW,SAEhBK,EAAa,IAAI,cAAclY,CAAM,EAEvC,MACF,IAAK,SACHkY,EAAa,IAAI,eAAelY,CAAM,EACtC,MACF,IAAK,OACHkY,EAAa,IAAI,UAAUlY,CAAM,EACjC,MACF,IAAK,OACL,IAAK,QACL,IAAK,QACHkY,EAAa,IAAI,WAAWlY,CAAM,EAClC,MACF,QACE,MAAM,IAAI,MAAM,0BAA0B6X,EAAK,QAAQ,iDAAiD,CAC5G,CAEA,OAAA9H,EACE,UACA,IACE,yCAAyC8H,EAAK,QAAQ,YAAYA,EAAK,KAAK,MAC1EE,EAA4B,uEAAyE,EACvG,EACJ,EAEOH,EAAQ,SAASC,EAAMK,CAAU,CAC1C,CAEO,mBAAmBC,EAAyB,CACjD,KAAK,qBAAqB,KAAKA,CAAS,CAC1C,CAEO,aAAatR,EAAmBsR,EAA4B,CACjE,IAAMC,EAAa,KAAK,mBAAmB,IAAIvR,CAAS,EACxD,OAAKuR,EAGEA,EAAW,SAASD,CAAS,EAF3B,EAGX,CAEO,iBAAiBtR,EAA4B,CAElD,MAAO,CAAC,CADQ,KAAK,qBAAqB,IAAIA,CAAS,GACrC,gBAAgB,EAAE,MAAM,UAAU,SAAS,OAAO,CACtE,CAEO,OAAc,CAErB,CACF,IC7XA,IAAAwR,GAAAvc,EAAA,oBCAA,IAmFMwc,GA+BAC,GAKAC,GAKAC,GAWFC,GACEC,GAYOC,GAyCPC,GA+SOC,GA5ebC,GAAAjd,EAAA,kBAIAkU,KAEAqI,KA6EMC,GAAsC,IAAI,IAAI,CAClD,CAAC,GAAI,GAAG,EACR,CAAC,IAAK,GAAG,EACT,CAAC,IAAK,GAAG,EACT,CAAC,IAAK,GAAG,EACT,CAAC,KAAM,GAAG,EACV,CAAC,KAAM,GAAG,EACV,CAAC,KAAM,EAAE,EACT,CAAC,MAAO,EAAE,EACV,CAAC,MAAO,EAAE,EACV,CAAC,MAAO,EAAE,EACV,CAAC,OAAQ,EAAE,EACX,CAAC,OAAQ,EAAE,EACX,CAAC,OAAQ,EAAE,EACX,CAAC,QAAS,EAAE,EACZ,CAAC,QAAS,EAAE,EACZ,CAAC,QAAS,EAAE,EACZ,CAAC,QAAS,EAAE,EACZ,CAAC,SAAU,EAAE,EACb,CAAC,SAAU,EAAE,EACb,CAAC,SAAU,EAAE,EACb,CAAC,SAAU,EAAE,EACb,CAAC,SAAU,CAAC,EACZ,CAAC,SAAU,CAAC,EAGZ,CAAC,SAAU,CAAC,EACZ,CAAC,UAAW,CAAC,EACb,CAAC,UAAW,CAAC,CACf,CAAC,EAEKC,GAAsB,CAAC,EAKvBC,GAA4BlW,GAAiB,KAAK,KAAK,OAAOA,CAAI,EAAI,EAAE,EAAI,GAK5EmW,GAAwBnW,GAAiB,CAC7C,QAAS0W,EAAM,EAAGA,EAAMT,GAAU,OAAQS,IAAO,CAC/C,IAAMC,EAAgBV,GAAUS,CAAG,EACnC,GAAI1W,GAAQ2W,EACV,OAAOA,CAEX,CAEA,OAAO,KAAK,KAAK3W,EAAO,EAAE,EAAI,EAChC,EAEIoW,GAAO,EACLC,GAAqB,IAAMD,KAYpBE,GAAkB,MAC7B5c,EACAsF,EACA4X,EACAC,IACwB,CACxB,IAAMC,EAAaZ,GAAyBU,CAAY,EAClDG,EAAgBrd,EAAQ,OAAO,aAEnC,CAAE,KAAMod,EAAY,MAAO,eAAe,SAAW,eAAe,QAAS,CAC/E,EACA,GAAI,CACF,IAAME,EAAiBtd,EAAQ,kBAAkB,EACjDA,EAAQ,eAAe,EACvBsd,EAAe,mBACbhY,EACA,EACA+X,EACA,EACAD,CACF,EACApd,EAAQ,MAAM,EAEd,MAAMqd,EAAc,SAAS,WAAW,IAAI,EAE5C,IAAME,EAAcF,EAAc,eAAe,EACjD,GAAIF,EAAiB,CAEnB,IAAMK,EAAeL,EAAgB,EACrC,OAAAK,EAAa,IAAI,IAAI,WAAWD,EAAa,EAAGL,CAAY,CAAC,EACtDM,CACT,KAGE,QAAO,IAAI,WAAWD,EAAY,MAAM,EAAGL,CAAY,CAAC,CAE5D,QAAE,CACAG,EAAc,QAAQ,CACxB,CACF,EAEMR,GAAN,KAAmD,CAmBjD,YAAoB7c,EAAwB,CAAxB,aAAAA,EAClB,KAAK,aAAe,IAAI,IACxB,KAAK,YAAc,IAAI,IACvB,KAAK,mBAAqB,IAAI,IAC9B,KAAK,eAAiB,CAAC,EACvB,KAAK,uBAAyB,IAAI,IAElC,OAAW,CAACyI,CAAG,IAAK6T,GAClBC,GAAU,KAAK9T,CAAG,EAClB,KAAK,YAAY,IAAIA,EAAK,CAAC,CAAC,EAC5B,KAAK,mBAAmB,IAAIA,EAAK,CAAC,CAAC,EAGrC,KAAK,aAAe,CACtB,CAEA,OAAOiT,EAAelX,EAAwB,CAC5C,IAAMiZ,EAAiBjZ,EAAK,OACtBkZ,EAAYlZ,EAAK,WACjBmZ,EAAYnZ,EAAK,WACjB8B,EAAOkW,GAAyBmB,CAAS,EAGzCC,EAAe,KAAK,aAAa,IAAIlC,CAAE,EAC7C,GAAI,CAACkC,EACH,MAAM,IAAI,MAAM,uCAAuC,EAEzD,GAAI,OAAOA,EAAa,YAAY,IAAMD,EACxC,MAAM,IAAI,MAAM,yCAAyCC,EAAa,YAAY,eAAeD,CAAS,EAAE,EAI9G,IAAME,EAAwB,KAAK,QAAQ,OAAO,aAEhD,CAAE,iBAAkB,GAAM,KAAAvX,EAAM,MAAO,eAAe,UAAY,eAAe,QAAS,CAC5F,EAGMiX,EAAcM,EAAsB,eAAe,EACzD,IAAI,WAAWN,CAAW,EAAE,IAAI,IAAI,WAAWE,EAAgBC,EAAWC,CAAS,CAAC,EACpFE,EAAsB,MAAM,EAG5B,IAAMP,EAAiB,KAAK,QAAQ,OAAO,qBAAqB,EAChEA,EAAe,mBAAmBO,EAAuB,EAAGD,EAAa,QAAQ,OAAQ,EAAGtX,CAAI,EAChG,KAAK,QAAQ,OAAO,MAAM,OAAO,CAACgX,EAAe,OAAO,CAAC,CAAC,EAC1DO,EAAsB,QAAQ,EAE9B9J,EAAU,UAAW,IAAM,qCAAqC2H,CAAE,GAAG,CACvE,CAEA,OAAOoC,EAAqBC,EAAgC,CAE1D,IAAMC,EAAqB,KAAK,aAAa,IAAIF,CAAQ,EACzD,GAAI,CAACE,EACH,MAAM,IAAI,MAAM,2CAA2C,EAG7D,IAAMC,EAA0B,KAAK,aAAa,IAAIF,CAAa,EACnE,GAAI,CAACE,EACH,MAAM,IAAI,MAAM,gDAAgD,EAElE,GAAID,EAAmB,eAAiBC,EAAwB,aAC9D,MAAM,IAAI,MAAM,mDAAmD,EAGrE,IAAM3X,EAAOkW,GAAyBwB,EAAmB,YAAY,EAG/DV,EAAiB,KAAK,QAAQ,kBAAkB,EACtD,KAAK,QAAQ,eAAe,EAC5BA,EAAe,mBACbU,EAAmB,QAAQ,OAC3B,EACAC,EAAwB,QAAQ,OAChC,EACA3X,CACF,CACF,CAEA,uBAAuBtC,EAAmBkZ,EAAsBgB,EAA2C,CACzG,IAAIxC,EACJ,GAAIwC,EAAU,CAEZ,GADAxC,EAAKwC,EAAS,CAAC,EACXla,IAAWka,EAAS,CAAC,EACvB,OAAAnK,EACE,UACA,IACE,uDAAuDmJ,CAAY,WAAWxB,CAAE,6BACpF,EACOA,EACF,GAAI,KAAK,QAAQ,oBAAoB,IAAI,KAAK,QAAQ,gBAAiB,EAC5E,MAAM,IAAI,MAAM;AAAA,sDAC8B,CAElD,MACEA,EAAKiB,GAAmB,EAG1B,YAAK,aAAa,IAAIjB,EAAI,CAAE,QAAS,CAAE,GAAAA,EAAI,OAA2B,OAAA1X,CAAO,EAAG,aAAAkZ,CAAa,CAAC,EAC9FnJ,EACE,UACA,IAAM,uDAAuDmJ,CAAY,WAAWxB,CAAE,eACxF,EACOA,CACT,CAEA,yBAAyBA,EAAqB,CACxCA,IAAO,SACT,KAAK,aAAa,OAAOA,CAAE,EAC3B3H,EAAU,UAAW,IAAM,4DAA4D2H,CAAE,EAAE,EAE/F,CAGA,OAAOpV,EAAc4T,EAAQ,eAAe,QAAU,eAAe,SAAW,eAAe,SAAmB,CAChH,IAAMkD,EAAaX,GAAqBnW,CAAI,EAExChB,EAGE6Y,GAAajE,EAAQ,eAAe,WAAa,eAAe,QAEhEkE,GAAalE,EAAQ,eAAe,WAAa,eAAe,QACtE,GAAIiE,GAAaC,EAAW,CAE1B,IAAMC,GADcF,EAAY,KAAK,YAAc,KAAK,oBAC5B,IAAIf,CAAU,EACrCiB,EAICA,EAAQ,OAAS,EAEnB/Y,EAAY+Y,EAAQ,IAAI,EAGxB/Y,EAAY,KAAK,QAAQ,OAAO,aAAa,CAAE,KAAM8X,EAAY,MAAAlD,CAAM,CAAC,EAP1E5U,EAAY,KAAK,QAAQ,OAAO,aAAa,CAAE,KAAM8X,EAAY,MAAAlD,CAAM,CAAC,CAU5E,MAEE5U,EAAY,KAAK,QAAQ,OAAO,aAAa,CAAE,KAAM8X,EAAY,MAAAlD,CAAM,CAAC,EAG1E,IAAMoE,EAAU,CAAE,GAAI3B,GAAmB,EAAG,OAA2B,OAAQrX,CAAU,EACzF,YAAK,aAAa,IAAIgZ,EAAQ,GAAI,CAAE,QAAAA,EAAS,aAAc,OAAOhY,CAAI,CAAE,CAAC,EAEzEyN,EAAU,UAAW,IAAM,uCAAuCzN,CAAI,WAAWgY,EAAQ,EAAE,EAAE,EACtFA,CACT,CAEA,IAAI5C,EAAoC,CACtC,OAAO,KAAK,aAAa,IAAIA,CAAE,GAAG,OACpC,CAEA,QAAQ6C,EAA4B,CAClC,IAAM7C,EAAK,OAAO6C,GAAY,SAAW,OAAOA,CAAO,EAAIA,EACrDC,EAAa,KAAK,aAAa,IAAI9C,CAAE,EAC3C,GAAI,CAAC8C,EAAY,CACf,GAAI,KAAK,aAAa,OAAS,EAE7B,MAAO,GAEP,MAAM,IAAI,MAAM,+BAA+B,CAEnD,CAEA,OAAAzK,EAAU,UAAW,IAAM,sCAAsC2H,CAAE,gBAAgB8C,EAAW,QAAQ,EAAE,EAAE,EAE1G,KAAK,aAAa,OAAO9C,CAAE,EAC3B,KAAK,eAAe,KAAK8C,EAAW,QAAQ,MAAM,EAG3CA,EAAW,YACpB,CAEA,MAAM,SAAS9C,EAAeyB,EAAkD,CAC9E,IAAMqB,EAAa,KAAK,aAAa,IAAI,OAAO9C,CAAE,CAAC,EACnD,GAAI,CAAC8C,EACH,MAAM,IAAI,MAAM,qBAAqB,EAEvC,MAAM5B,GAAgB,KAAK,QAAS4B,EAAW,QAAQ,OAAQA,EAAW,aAAcrB,CAAe,CACzG,CAEA,uBAA8B,CAC5B,GAAI,KAAK,eAAe,SAAW,EAInC,GAAI,KAAK,QAAQ,gBAAkB,UAAW,CAC5C,QAAWnZ,KAAU,KAAK,eAAgB,CACxC,IAAMya,EAAgBnC,GAAe,IAAItY,EAAO,IAAI,EAGpD,IAAKA,EAAO,MAAQ,eAAe,WAAa,eAAe,QAAS,CAEtE,IAAM0a,EAAW,KAAK,YAAY,IAAI1a,EAAO,IAAI,GAAK,CAAC,EACnDya,IAAkB,QAAaC,EAAS,QAAUD,EACpDza,EAAO,QAAQ,EAEf0a,EAAS,KAAK1a,CAAM,CAGxB,UAAYA,EAAO,MAAQ,eAAe,WAAa,eAAe,QAAS,CAE7E,IAAM0a,EAAW,KAAK,mBAAmB,IAAI1a,EAAO,IAAI,GAAK,CAAC,EAC1Dya,IAAkB,QAAaC,EAAS,QAAUD,EACpDza,EAAO,QAAQ,EAEf0a,EAAS,KAAK1a,CAAM,CAExB,MACEA,EAAO,QAAQ,CAEnB,CACA,KAAK,eAAiB,CAAC,CACzB,KAAO,CAGL,IAAI2a,EAAkB,KAAK,uBAAuB,IAAI,KAAK,QAAQ,gBAAiB,EAC/EA,IACHA,EAAkB,CAAC,EACnB,KAAK,uBAAuB,IAAI,KAAK,QAAQ,iBAAmBA,CAAe,GAEjF,QAAW3a,KAAU,KAAK,eACxB2a,EAAgB,KAAK3a,CAAM,EAE7B,KAAK,eAAiB,CAAC,CACzB,CACF,CAEA,SAAU,CACR,KAAK,YAAY,QAASqa,GAAY,CACpCA,EAAQ,QAASra,GAAW,CAC1BA,EAAO,QAAQ,CACjB,CAAC,CACH,CAAC,EACD,KAAK,mBAAmB,QAASqa,GAAY,CAC3CA,EAAQ,QAASra,GAAW,CAC1BA,EAAO,QAAQ,CACjB,CAAC,CACH,CAAC,EAED,KAAK,aAAa,QAAS4a,GAAY,CACrCA,EAAQ,QAAQ,OAAO,QAAQ,CACjC,CAAC,EAED,KAAK,uBAAuB,QAASP,GAAY,CAC/CA,EAAQ,QAASra,GAAW,CAC1BA,EAAO,QAAQ,CACjB,CAAC,CACH,CAAC,EACD,KAAK,aAAe,IAAI,IACxB,KAAK,YAAc,IAAI,IACvB,KAAK,mBAAqB,IAAI,IAC9B,KAAK,uBAAyB,IAAI,GACpC,CAEA,iBAAkB,CAChB,KAAK,cAAgB,CACvB,CAEA,iBAAiB6G,EAAmB,CAElC,IAAMgU,EAAiB,KAAK,uBAAuB,IAAIhU,CAAS,EAC5DgU,IACFA,EAAe,QAAS7a,GAAW,CACjCA,EAAO,QAAQ,CACjB,CAAC,EACD,KAAK,uBAAuB,OAAO6G,CAAS,GAI9C,KAAK,cAAgB,EACjB,KAAK,eAAiB,IACxBkJ,EAAU,UAAW,IAAM,uCAAuC,EAClE,KAAK,aAAa,QAAS6K,GAAY,CACrCA,EAAQ,QAAQ,OAAO,QAAQ,CACjC,CAAC,EACD,KAAK,aAAe,IAAI,IAE5B,CACF,EAEa9B,GAAuB,IAAIxI,IACtC,IAAIuI,GAAmB,GAAGvI,CAAI,IC7ehC,IAGMwK,GAwBOC,EA3BbC,GAAAlf,EAAA,kBAGMgf,GAAN,KAAgC,CAC9B,YAAYG,EAAoC,CAC9C,OAAO,OAAO,KAAMA,CAAS,CAC/B,CAGA,IAAW,UAAmB,CAC5B,OAAK,KAAK,MACR,KAAK,IAAM,OAAO,oBAAoB,IAAI,EACvC,KAAK,EACL,IAAKlf,GAAS,GAAI,KAAiCA,CAAI,CAAC,EAAE,EAC1D,KAAK,GAAG,GAEN,KAAK,GACd,CACF,EASagf,EACXE,GAC8B,IAAIH,GAA0BG,CAAS,IC7BvE,IAiBaC,GAsMPC,GAuCOC,GAKAC,GAKAC,EAiBAC,EAiBAC,GAcAC,GAgBAC,GAmBAC,EAmCPC,GA0UOC,EAgBAC,EAeAC,GAeAC,GAmFPC,GAwKOC,GAj/BbC,EAAArgB,EAAA,kBAGAkS,IACA8C,IAaaoK,GAAiB,GAsMxBC,GAAoB,CAAC1Z,EAAc2a,IAAyD,CAChG,GAAIA,IAAe,EACjB,MAAM,IAAI,MAAM,mDAAmD,EAIrE,OAAQ,OAAO3a,CAAI,EAAG,CACpB,QACE,OAAO2a,EAAa,EAAI,MAAMA,CAAU,QAAU,MACpD,OACE,OAAOA,EAAa,EAAI,MAAMA,CAAU,QAAU,MACpD,OACE,OAAOA,EAAa,EAAI,MAAMA,CAAU,QAAU,MACpD,QACE,OAAOA,EAAa,EAAI,MAAMA,CAAU,QAAU,MACpD,OACE,GAAIA,EAAa,EACf,MAAM,IAAI,MAAM,4CAA4C,EAE9D,MAAO,CAAC,YAAa,KAAK,EAC5B,QACE,GAAIA,EAAa,EACf,MAAM,IAAI,MAAM,4CAA4C,EAE9D,MAAO,CAAC,YAAa,KAAK,EAC5B,OACE,GAAIA,IAAe,EACjB,MAAM,IAAI,MAAM,mBAAmB,EAErC,MAAO,CAAC,MAAO,YAAY,EAC7B,QACE,MAAO,MACT,QACE,MAAO,MACT,QACE,MAAM,IAAI,MAAM,sBAAsB3a,CAAI,EAAE,CAChD,CACF,EAEa2Z,GAA8B,CAAC3Z,EAAgB2a,EAA4B,IAAM,CAC5F,IAAMrZ,EAAaoY,GAAkB1Z,EAAM2a,CAAU,EACrD,OAAO,OAAOrZ,GAAe,SAAWA,EAAaA,EAAW,CAAC,CACnE,EAEasY,GAA4B,CAAC5Z,EAAgB2a,EAA4B,IAAM,CAC1F,IAAMrZ,EAAaoY,GAAkB1Z,EAAM2a,CAAU,EACrD,OAAO,OAAOrZ,GAAe,SAAWA,EAAaA,EAAW,CAAC,CACnE,EAEauY,EAA6B,IAAIja,IAA6D,CACzG,IAAMgb,EAAoC,CAAC,EAC3C,OAAAhb,EAAK,QAASkB,GAAQ,CAChBA,EAAI,SAAW,GACjB8Z,EAAgB,KACd,CAAE,QAAuB,KAAM9Z,CAAI,EACnC,CAAE,QAAuB,KAAMkO,EAAU,eAAelO,CAAG,CAAE,CAC/D,CAEJ,CAAC,EACM8Z,CACT,EAMad,EAAoBjZ,GAE3BA,EAAO,IAAM,EACR,EACEA,EAAO,IAAM,EACf,EAGF,EASIkZ,GAAa,CAACja,EAAW,MAAO6a,EAAqB3e,EAAQ,MACpE,CAAC2e,GAAcA,IAAe,EACzB,GAAG7a,CAAQ,IAAI9D,CAAK,IAGtB,MAAM2e,CAAU,IAAI7a,CAAQ,KAAK9D,CAAK,IASlCge,GAAY,CAACla,EAAkB6a,EAAoB3e,IAC1D8D,IAAa,MACR9D,EAEL2e,IAAe,EACV,OAAO3e,CAAK,IAGd,MAAM2e,CAAU,SAAS3e,CAAK,IAQ1Bie,GAAY,CAAC3f,EAAcqgB,IAClCA,IAAe,EACV,IAAIrgB,CAAI,QAAQA,CAAI,QAAQA,CAAI,QAAQA,CAAI,MAC1CqgB,IAAe,EACjB,IAAIrgB,CAAI,QAAQA,CAAI,MAClBqgB,IAAe,EACjB,IAAIrgB,CAAI,QAAQA,CAAI,QAAQA,CAAI,MAGlCA,EAUI4f,EAAe,CAC1B5f,EACA0a,EACA6F,EACA7a,IAEI1F,EAAK,WAAW,WAAW,GAAKugB,EAAS,EACvC,OAAO7F,GAAU,SACfhV,IAAS,MACJ,GAAG1F,CAAI,KAAK0a,CAAK,WAAWA,CAAK,eAAeA,CAAK,aAErD,GAAG1a,CAAI,KAAK0a,CAAK,WAAWA,CAAK,SAGtChV,IAAS,MACJ,GAAG1F,CAAI,IAAI,KAAK,MAAM0a,EAAQ,CAAC,CAAC,KAAK,KAAK,MAAOA,EAAQ,EAAK,CAAC,CAAC,KAAMA,EAAQ,EAAK,CAAC,IAEpF,GAAG1a,CAAI,IAAI,KAAK,MAAM0a,EAAQ,CAAC,CAAC,KAAKA,EAAQ,CAAC,IAIlD6F,EAAS,EAAI,GAAGvgB,CAAI,IAAI0a,CAAK,IAAM1a,EAcxC6f,GAAsB,CAC1B7f,EACAwgB,EACAC,EACAtG,EACAkG,IACkB,CAClB,IAAMK,EAAa,OAAOD,GAAgB,SACpCzK,EAAO0K,EAAaD,EAAcA,EAAY,OAC9CE,EAAe,CAAC,GAAG,IAAI,MAAM3K,CAAI,EAAE,KAAK,CAAC,EACzC4K,EAAc5K,EAAO,EAAI,MAAQA,GAAQ,EAAI,MAAMA,CAAI,QAAU,cAAcA,CAAI,IACnFhP,EAAaoY,GAAkBoB,EAAYH,CAAU,EACrDQ,EAAY,OAAO7Z,GAAe,SAAWA,EAAaA,EAAW,CAAC,EACtE8Z,EAAc,OAAO9Z,GAAe,SAAWA,EAAaA,EAAW,CAAC,EACxEtB,EAAO,CAAE,QAASkb,EAAa,MAAOC,EAAW,QAASC,EAAa,OAAQN,CAAW,EAE1FO,EAAgBva,GAAkC,OAAOA,GAAQ,SAAWA,EAAM,GAAGA,CAAG,IAExFwa,EAAqB,CACzB,gBAAiB,GACjB,gBAAiB,GACjB,2BAA4B,GAC5B,IAAK,GACL,aAAc,GACd,IAAK,GACL,aAAc,EAChB,EAEMC,EAAgBP,EAAa,YAAc,GAC3C/K,EAAQ,GAAGsL,CAAa,GAAGjhB,CAAI,SAC/BqW,EAAU,GAAG4K,CAAa,GAAGjhB,CAAI,WAEnCkhB,EAAa,GACjB,QAAS9gB,EAAI,EAAGA,EAAI4V,EAAO,EAAG5V,IAC5B8gB,GAAc;AAAA,aACL9gB,CAAC,gBAAgBwf,EAAavJ,EAASjW,EAAG4V,CAAI,CAAC;AAAA,cAC9C5V,CAAC,gBAAgBwf,EAAavJ,EAASjW,EAAG4V,CAAI,CAAC;AAAA,cAC/C5V,CAAC,UAAUA,CAAC;AAAA,oBACNA,CAAC;AAAA,MAGnB8gB,GAAc,WAAWlL,EAAO,CAAC,eAEjC,IAAMmL,EACJnL,EAAO,EACH,GACA;AAAA,WACGhW,CAAI,oBAAoB0F,EAAK,OAAO;AAAA,mBAC5BA,EAAK,OAAO;AAAA;AAAA,MAEzBwb,CAAU;AAAA;AAAA,KAIRE,EAAmBC,IACvBL,EAAmB,gBAAkB,GAC9BhL,EAAO,EAAIqL,EAAY,OAAOrhB,CAAI,IAAIqhB,CAAS,KAGlDC,EAAoB,CAAC,EAC3B,GAAItL,GAAQ,EACV,QAAS5V,EAAI4V,EAAO,EAAG5V,GAAK,EAAGA,IAC7BkhB,EAAQ,KAAK,GAAG1B,EAAavJ,EAASjW,EAAG4V,CAAI,CAAC,eAAe5V,CAAC,IAAI,EAItE,IAAMmhB,EACJvL,EAAO,EACH,GACA;AAAA,WACGhW,CAAI,aAAa0F,EAAK,OAAO;AAAA,aAC3B4b,EAAQ,KAAK,GAAG,CAAC;AAAA,KAGtBE,EAAmBC,IACvBT,EAAmB,gBAAkB,GAC9BhL,EAAO,EAAIyL,EAAa,OAAOzhB,CAAI,IAAIyhB,CAAU,KAGpDC,EAAU,IAAIC,IAClB3L,IAAS,EAAI,KAAO,GAAGtQ,EAAK,OAAO,IAAIic,EAAK,IAAIZ,CAAY,EAAE,KAAK,GAAG,CAAC,IAEnEa,EAAa,CAACH,EAAoBxE,IAClCjH,EAAO,EACF,GAAGyL,CAAU,GAEb,GAAG7B,EAAa6B,EAAYxE,EAAKjH,CAAI,CAAC,GAI3C6L,EAAa,CAACJ,EAAoBxE,EAAsBvb,KACxDsU,EAAO,EACF,GAAGyL,CAAU,IAAI/f,EAAK,IAEtB,GAAGke,EAAa6B,EAAYxE,EAAKjH,CAAI,CAAC,IAAItU,EAAK,IAIpDogB,EAAsE,CAAC,EACvEC,EAA6B,CAACN,EAAoBO,IAA0B,CAChFhB,EAAmB,2BAA6B,GAChD,IAAMiB,GAAU,GAAGD,EAAO,IAAI,uBAAuBhiB,CAAI,SACzD,GAAIiiB,MAAWH,EACb,MAAO,GAAGG,EAAO,IAAIR,CAAU,IAEjC,IAAMH,GAAU,CAAC,EACjB,QAASlhB,GAAI4V,EAAO,EAAG5V,IAAK,EAAGA,KAAK,CAClC,IAAM6c,GAAM+E,EAAO,WAAW,gBAAiB5hB,GAAI4hB,EAAO,KAAOhM,CAAI,EACrEsL,GAAQ,KAAK,GAAGM,EAAWvL,EAASjW,EAAC,CAAC,OAAO6c,EAAG,MAAM2E,EAAWjM,EAAOvV,EAAC,CAAC,GAAG,CAC/E,CACA,OAAA0hB,EAAyCG,EAAO,EAAI,MAAMA,EAAO,mBAAmBD,EAAO,KAAK,OAAO;AAAA,sBACrFV,GAAQ,OAAS,EAAIA,GAAQ,KAAK,GAAG,EAAI,IAAI;AAAA,cAGxD,GAAGW,EAAO,IAAIR,CAAU,GACjC,EAEMS,EAAc,CAAC3O,EAAyB7R,KAC3C,IAAM,CACL,GAAIgE,EAAK,UAAYA,EAAK,MACxB,MAAO,GAAG1F,CAAI,IAAIuT,CAAM,KAAK7R,CAAK,IAC7B,GAAIgE,EAAK,UAAY,aAAeA,EAAK,QAAU,MAExD,MAAO,GAAG1F,CAAI,IAAIuT,CAAM,mBAAmB7R,CAAK,8BAA8BA,CAAK,UAC9E,GAAIgE,EAAK,UAAY,aAAeA,EAAK,QAAU,MAExD,MAAO,GAAG1F,CAAI,IAAIuT,CAAM,mBAAmB7R,CAAK,UAC3C,GAAIgE,EAAK,UAAY,OAASA,EAAK,QAAU,aAElD,MAAO,GAAG1F,CAAI,IAAIuT,CAAM,8DAA8D7R,CAAK,MAE3F,MAAM,IAAI,MAAM,6CAA6CgE,EAAK,OAAO,mBAAmBA,EAAK,KAAK,MAAM,CAEhH,GAAG,EAECyc,EAAe5O,IAClB,IAAM,CACL,GAAI7N,EAAK,UAAYA,EAAK,MACxB,MAAO,GAAG1F,CAAI,IAAIuT,CAAM,IACnB,GAAI7N,EAAK,UAAY,aAAeA,EAAK,QAAU,MAExD,MAAO,OAAO1F,CAAI,IAAIuT,CAAM,OACvB,GAAI7N,EAAK,UAAY,aAAeA,EAAK,QAAU,MAExD,MAAO,OAAO1F,CAAI,IAAIuT,CAAM,OACvB,GAAI7N,EAAK,UAAY,OAASA,EAAK,QAAU,aAElD,MAAO,mBAAmB1F,CAAI,IAAIuT,CAAM,oBAAoBvT,CAAI,IAAIuT,CAAM,sBAAsBvT,CAAI,IAClGuT,CACF,wBAAwBvT,CAAI,IAAIuT,CAAM,oBAEtC,MAAM,IAAI,MAAM,6CAA6C7N,EAAK,OAAO,mBAAmBA,EAAK,KAAK,MAAM,CAEhH,GAAG,EAEC0c,GACJpM,EAAO,EACH,GACA;AAAA,WACGhW,CAAI,sBAAsB0F,EAAK,OAAO,QAAQmb,CAAS;AAAA,aACrDsB,EAAY,OAAOniB,CAAI,WAAW,CAAC;AAAA,KAGxCqiB,EACJrM,EAAO,EACH,IACC,IAAM,CACL,IAAMsM,EAAiB3B,EAAa,IAAKvgB,IAAM,IAAIA,EAAC,OAAO,EAAE,KAAK,IAAI,EAChEmiB,EAAa5B,EAAa,IAAKvgB,IAAM,IAAIA,EAAC,EAAE,EAAE,KAAK,IAAI,EAC7D,MAAO;AAAA,WACNJ,CAAI,IAAIsiB,CAAc,QAAQzB,CAAS;AAAA,iBACjC7gB,CAAI,aAAa0hB,EAAQa,CAAU,CAAC;AAAA,IAE7C,GAAG,EAEHC,EAAM,IAAId,IAA4C,CAC1D,GAAIA,EAAQ,SAAW1L,EACrB,MAAM,IAAI,MAAM,0BAA0BA,CAAI,EAAE,EAGlD,IAAMyM,EAAoBf,EAAQ,IAAIX,CAAY,EAAE,KAAK,GAAG,EAE5D,OAAI/K,IAAS,EACJmM,EAAY,IAAI,EACdnM,IAAS,EACXmM,EAAYM,EAAkB,CAAC,CAAC,GAEvCzB,EAAmB,IAAM,GACzBA,EAAmB,aAAe,GAClCA,EAAmB,gBAAkB,GAC9B,OAAOhhB,CAAI,IAAIyiB,CAAiB,IAE3C,EAEMC,EAAgBjB,GAChBzL,EAAO,EACFmM,EAAYV,CAAU,GAE7BT,EAAmB,aAAe,GAClCA,EAAmB,gBAAkB,GAC9B,OAAOhhB,CAAI,aAAayhB,CAAU,KAIvCkB,EACJ3M,EAAO,EACH,GACA;AAAA,WACGhW,CAAI,sBAAsB0F,EAAK,OAAO,YAAYmb,CAAS;AAAA,MAChEqB,EAAY,OAAOliB,CAAI,YAAa,OAAO,CAAC;AAAA,KAG1C4iB,GACJ5M,EAAO,EACH,IACC,IAAM,CACL,IAAMsM,EAAiB3B,EAAa,IAAKvgB,IAAM,IAAIA,EAAC,OAAO,EAAE,KAAK,IAAI,EAChEmiB,EAAa5B,EAAa,IAAKvgB,IAAM,IAAIA,EAAC,EAAE,EAAE,KAAK,IAAI,EAC7D,MAAO;AAAA,WACNJ,CAAI,IAAIsiB,CAAc,YAAYzB,CAAS;AAAA,UAC5C7gB,CAAI,aAAa0hB,EAAQa,CAAU,CAAC;AAAA,IAEtC,GAAG,EA2ET,MAAO,CACL,KAzCW,IAAM,CACjB,IAAMM,EAAQ,CAAC,EACXC,EAAmB,GACvB,OAAI9B,EAAmB,kBACrB6B,EAAM,KAAK1B,CAA6B,EACxC2B,EAAmB,IAEjB9B,EAAmB,kBACrB6B,EAAM,KAAKtB,CAA6B,EACxCuB,EAAmB,IAEjB9B,EAAmB,6BACrB,OAAO,OAAOc,CAAwC,EAAE,QAASiB,IAASF,EAAM,KAAKE,EAAI,CAAC,EAC1FD,EAAmB,IAEjB9B,EAAmB,MACrB6B,EAAM,KAAKD,EAAiB,EAC5BE,EAAmB,IAEjB9B,EAAmB,eACrB6B,EAAM,KAAKF,CAA0B,EACrCG,EAAmB,IAEjB9B,EAAmB,MACrB6B,EAAM,KAAKR,CAAiB,EAC5BS,EAAmB,IAEjB9B,EAAmB,eACrB6B,EAAM,KAAKT,EAA0B,EACrCU,EAAmB,IAEjB,CAACpC,GAAcoC,GACjBD,EAAM,QACJ,SAASlN,CAAK,MAAMjQ,EAAK,OAAO,IAAI+a,EAAY,KAAK,GAAG,CAAC,KACzD,SAASpK,CAAO,MAAM3Q,EAAK,OAAO,IAAIgP,EAAU,eAAe+L,CAAW,EAAE,KAAK,GAAG,CAAC,IACvF,EAEKoC,EAAM,KAAK;AAAA,CAAI,CACxB,EAIE,KAAAnd,EACA,gBAAA0b,EACA,gBAAAI,EACA,2BAAAO,EACA,QAAAL,EACA,WAAAE,EACA,WAAAC,EACA,IAlFU,IAAImB,IAAoD,CAClE,GAAIA,EAAgB,SAAWhN,EAAO,EACpC,MAAM,IAAI,MAAM,0BAA0BA,CAAI,EAAE,EAElD,IAAMtU,EAAQshB,EAAgBhN,CAAI,EAClC,GAAI,OAAOtU,GAAU,SACnB,MAAM,IAAI,MAAM,sBAAsB,EAGxC,IAAM+gB,GAAoBO,EAAgB,MAAM,EAAGhN,CAAI,EAAE,IAAI+K,CAAY,EAAE,KAAK,GAAG,EAEnF,OAAI/K,IAAS,EACJkM,EAAY,KAAMxgB,CAAK,EACrBsU,IAAS,EACXkM,EAAYO,GAAkB,CAAC,EAAG/gB,CAAK,GAE9Csf,EAAmB,IAAM,GACzBA,EAAmB,aAAe,GAClCA,EAAmB,gBAAkB,GAC9B,OAAOhhB,CAAI,IAAIyiB,EAAiB,KAAK/gB,CAAK,IAErD,EA8DE,YAAAwgB,EACA,aA7DmB,CAACT,EAAoB/f,IACpCsU,EAAO,EACFkM,EAAYT,EAAY/f,CAAK,GAEpCsf,EAAmB,aAAe,GAClCA,EAAmB,gBAAkB,GAC9B,OAAOhhB,CAAI,aAAayhB,CAAU,KAAK/f,CAAK,MAwDrD,IAAA8gB,EACA,YAAAL,EACA,aAAAO,EAEA,MAAAvI,EACA,KAAAna,EACA,QAAAqW,EACA,MAAAV,EACA,KAAAK,CACF,CACF,EAWa8J,EAAgB,CAC3B9f,EACA0F,EACA+a,EACAJ,EAA4B,IACVR,GAAoB7f,EAAM0F,EAAM+a,EAAa,QAASJ,CAAU,EAWvEN,EAAiB,CAC5B/f,EACA0F,EACA+a,EACAJ,EAA4B,IACVR,GAAoB7f,EAAM0F,EAAM+a,EAAa,SAAUJ,CAAU,EAUxEL,GAAuB,CAClChgB,EACA0F,EACA+a,IACkBZ,GAAoB7f,EAAM0F,EAAM+a,EAAa,eAAgB,CAAC,EAWrER,GAAmB,CAC9BjgB,EACA0F,EACA+a,EACAJ,EAA4B,IACVR,GAAoB7f,EAAM0F,EAAM+a,EAAa,WAAYJ,CAAU,EA8EjFH,GAAN,KAA+C,CAC7C,YACU+C,EACAC,EACR,CAFQ,6BAAAD,EACA,YAAAC,EAgHV,KAAQ,kBAAqC,CAAC,EAC9C,KAAQ,UAA6B,CAAC,EACtC,KAAQ,SAA8B,CAAC,EAwBvC,KAAQ,cAAgB,CAzIrB,CAEH,sCAAsC3c,EAA+B,CAGnE,MAAO,qBADY,OAAOA,GAAS,SAAW,GAAGA,CAAI,IAAMA,CACrB,eACxC,CAEA,UAAU4c,EAAmDhE,GAAgB,CAC3E,IAAMiE,EAAiB,OAAOD,GAAkB,SAAWA,EAAgBA,EAAc,CAAC,EACpFE,EAAiB,OAAOF,GAAkB,SAAW,EAAIA,EAAc,CAAC,EACxEG,EAAiB,OAAOH,GAAkB,SAAW,EAAIA,EAAc,CAAC,EAE9E,GACEC,EAAiB,KAAK,OAAO,0BAC7BC,EAAiB,KAAK,OAAO,0BAC7BC,EAAiB,KAAK,OAAO,yBAE7B,MAAM,IAAI,MACR,mBAAmBF,CAAc,KAAKC,CAAc,KAClDC,CACF,yCAAyC,KAAK,OAAO,wBAAwB,KAC3E,KAAK,OAAO,wBACd,KAAK,KAAK,OAAO,wBAAwB,IAC3C,EAGF,GAAIF,EAAiBC,EAAiBC,EAAiB,KAAK,OAAO,kCACjE,MAAM,IAAI,MACR,mBAAmBF,CAAc,KAAKC,CAAc,KAClDC,CACF,+CAA+C,KAAK,OAAO,iCAAiC,GAC9F,EAGF,IAAMC,EAAuB,KAAK,wBAAwB,CAAC,IAAM,GAAK,KAAK,wBAAwB,CAAC,IAAM,EACpGC,EAAYD,EACd;AAAA;AAAA;AAAA,wDAIA;AAAA;AAAA;AAAA;AAAA,yDAKEE,EAAsBF,EACxB;AAAA,gDAEA;AAAA;AAAA,8CAEsCH,EAAiBC,EAAiBC,CAAc,iBAE1F,MAAO,4BAA4BF,CAAc,KAAKC,CAAc,KAAKC,CAAc;AAAA,YAC/EE,CAAS;AAAA,MACfC,CAAmB;AAAA,GAEvB,CAEQ,uBAAuBC,EAA+B,CACxDA,EAAS,OAAS,IAChBA,EAAS,MAAM,WAAW,WAAW,GACvC,KAAK,SAAS,KAAK,CAAE,KAAMA,EAAS,MAAM,QAAQ,YAAa,EAAE,EAAG,KAAM,MAAO,OAAQA,EAAS,IAAK,CAAC,EAEtGA,EAAS,QAAQ,WAAW,WAAW,GACzC,KAAK,SAAS,KAAK,CAAE,KAAMA,EAAS,QAAQ,QAAQ,YAAa,EAAE,EAAG,KAAM,MAAO,OAAQA,EAAS,IAAK,CAAC,EAGhH,CAEQ,gBAAgBA,EAAyBC,EAA8B,CAC7E,GAAID,EAAS,QAAU,WACrB,MAAM,IAAI,MAAM,+FAA+F,EAEjH,KAAK,UAAU,KAAKA,CAAQ,EAC5B,KAAK,uBAAuBA,CAAQ,EACpC,IAAME,EAASF,EAAS,QAAU,QAAU,OAAS,aAC/C5C,EAAc4C,EAAS,QAAU,eAAiB,cAAgBA,EAAS,KAAK,QACtF,MAAO,sBAAsBC,CAAY,kBAAkBC,CAAM,KAAKF,EAAS,IAAI,WAAW5C,CAAW,IAC3G,CAEA,oBAAoB+C,EAAoC,CACtD,OAAOA,EAAU,IAAKtb,GAAM,KAAK,gBAAgBA,EAAG,KAAK,eAAe,CAAC,EAAE,KAAK;AAAA,CAAI,CACtF,CAEQ,yBAAyBmb,EAA+B,CAC9D,GAAIA,EAAS,QAAU,WACrB,MAAM,IAAI,MACR,sGACF,EAGF,KAAK,kBAAkB,KAAKA,CAAQ,EACpC,KAAK,uBAAuBA,CAAQ,CACtC,CAEA,6BAA6BG,EAA0C,CACrE,OAAAA,EAAU,QAAStb,GAAM,KAAK,yBAAyBA,CAAC,CAAC,EAClD,IACT,CAEA,gBAAgBvI,EAAc0F,EAA8B6a,EAAS,EAAiB,CACpF,YAAK,SAAS,KAAK,CAAE,KAAAvgB,EAAM,KAAA0F,EAAM,OAAA6a,CAAO,CAAC,EAClC,IACT,CAEA,iBAAiBuD,EAAqD,CACpE,YAAK,SAAW,KAAK,SAAS,OAAOA,CAAkB,EAChD,IACT,CAKQ,oBAA6B,CACnC,GAAI,KAAK,SAAS,SAAW,EAC3B,MAAO,GAGT,IAAMC,EAA4B,CAAC,EACnC,OAAW,CAAE,KAAA/jB,EAAM,KAAA0F,EAAM,OAAA6a,CAAO,IAAK,KAAK,SACxC,GAAIA,GAAUA,EAAS,EACjB7a,IAAS,MACXqe,EAAgB,KAAK,cAAc/jB,CAAI,iBAAiB0F,CAAI,MAAM,KAAK,KAAK6a,EAAS,CAAC,CAAC,GAAG,EAE1FwD,EAAgB,KAAK,GAAG/jB,CAAI,eAAe0F,CAAI,MAAM,KAAK,KAAK6a,EAAS,CAAC,CAAC,GAAG,MAE1E,CACL,IAAMyD,EAAWzD,GAAU,MAAQA,IAAW,EAAI7a,EAAO,MAAM6a,CAAM,IAAI7a,CAAI,IAC7Eqe,EAAgB,KAAK,GAAG/jB,CAAI,IAAIgkB,CAAQ,EAAE,CAC5C,CAGF,MAAO;AAAA,0BACeD,EAAgB,KAAK,IAAI,CAAC;AAAA,2BACzB,KAAK,aAAa,oCAC3C,CAMA,IAAI,2BAAoC,CACtC,OACE,KAAK,mBAAmB,EACxB,KAAK,UAAU,IAAK3jB,GAAMA,EAAE,KAAK,CAAC,EAAE,KAAK;AAAA,CAAI,EAC7C,KAAK,kBAAkB,IAAKA,GAAMA,EAAE,KAAK,CAAC,EAAE,KAAK;AAAA,CAAI,CAEzD,CAKA,IAAI,eAA0D,CAC5D,GAAI,KAAK,SAAS,SAAW,EAC3B,OAGF,IAAM6jB,EAA6Bve,GACjC,UAAkE,EAAE,CAAC,MAAO,MAAO,MAAO,KAAK,EAAE,QAAQA,CAAI,CAAC,EAChH,OAAO,KAAK,SAAS,IAAKwe,GAAM,CAACD,EAA0BC,EAAE,IAAI,EAAGA,EAAE,QAAU,CAAC,CAAC,CACpF,CACF,EAEa/D,GAAqB,CAACgE,EAAyCjB,IAC1E,IAAIhD,GAAiBiE,EAAejB,CAAM,ICl/B5C,IAeMkB,GAUAC,GAGAC,GAGAC,GAWAC,GAcAC,GAgBOC,GA4HAC,GAKAC,GAzMbC,GAAA9kB,EAAA,kBAGAkS,IAEA8C,IACAkK,KAGAmB,IAMMgE,GAAiB,CAACpZ,EAA+ByL,IAAkC,CACvF,GAAI,CAACzL,GAAUA,EAAO,SAAW,EAC/B,MAAM,IAAI,MAAM,6BAA6B,EAG/C,GAAIyL,EAAK,SAAW,GAAKA,EAAK,SAAWzL,EAAO,CAAC,EAAE,KAAK,OACtD,MAAM,IAAI,MAAM,aAAayL,EAAK,MAAM,8BAA8BzL,EAAO,CAAC,EAAE,KAAK,MAAM,EAAE,CAEjG,EAEMqZ,GAAkB,CAACxO,EAAmBY,IAC1CA,EAAK,SAAW,EAAIA,EAAO,CAAC,GAAG,IAAI,MAAMZ,CAAS,EAAE,KAAK,CAAC,EAAE,QAAQ,EAEhEyO,GAAiB,CAACQ,EAA+BrO,IACrD/B,EAAU,gBAAgBoQ,EAAYT,GAAgBS,EAAW,OAAQrO,CAAI,CAAC,EAE1E8N,GAAmB,CAAC9N,EAAgBT,EAAc+O,EAAsB/C,IAAkC,CAC9G,IAAIgD,EAAc,cAAchD,EAAO,KAAK,OAAO,QAAQ+C,EAAM,KAAK,OAAO;AAAA,aAClEA,EAAM,KAAK,OAAO,IAC7B,QAAS,EAAI,EAAG,EAAI/O,EAAM,EAAE,EAG1BgP,GAAe,KAAKvO,EAAK,CAAC,CAAC,OAAO,CAAC,KAErC,OAAQuO,GAAe,YACzB,EAEMR,GAAe,CAAC7O,EAA0BsP,IAAsE,CACpH,IAAMC,EAAqB,CAAC,EACtBC,EAAoB,CAAC,EAC3B,QAAS/kB,EAAI,EAAGA,EAAIuV,EAAM,OAAQ,EAAEvV,EAC9BuV,EAAMvV,CAAC,IAAM,GACf8kB,EAAS,KAAKvP,EAAMvV,CAAC,CAAC,EAEpBuV,EAAMsP,EAAa7kB,CAAC,CAAC,IAAM,GAC7B+kB,EAAQ,KAAKF,EAAa7kB,CAAC,CAAC,EAGhC,MAAO,CAAE,SAAA8kB,EAAU,QAAAC,CAAQ,CAC7B,EAEMV,GAAqB,CAAChO,EAAgBd,IAA6B,CAGvE,IAAIyP,EAAmB,EACvB,QAAShlB,EAAI,EAAGA,EAAIqW,EAAK,OAAQ,EAAErW,EACjC,GAAIuV,EAAMc,EAAKrW,CAAC,CAAC,IAAM,EAGvB,IAAIqW,EAAKrW,CAAC,EAAIglB,EACZ,MAAO,GAETA,EAAmB3O,EAAKrW,CAAC,EAE3B,MAAO,EACT,EAEaskB,GAA6B,CAACW,EAAyBC,IAAoC,CACtG,IAAMC,EAAgBF,EAAY,SAC5BxP,EAAYwP,EAAY,KAAK,OAC7B5O,EAAO4N,GAAgBxO,EAAWyP,CAAQ,EAC1CE,EAAclB,GAAee,EAAY,KAAM5O,CAAI,EACrDgP,EAAgBJ,EAAY,KAC5BK,EAAiBF,EACfG,EAAqB9P,EAAY,GAAK4O,GAAmBhO,EAAM4O,EAAY,IAAI,EACjFO,EACJ,GAAID,EACF,OAAAC,EAAmBC,GAA+B,CAChD,IAAMd,EAAQjF,EAAc,QAASyF,EAAeE,EAAe,CAAC,EAC9DzD,EAASjC,EAAe,SAAUwF,EAAeG,EAAgB,CAAC,EACxE,MAAO;AAAA,IACTG,EAAa,gBAAgB,cAAe,KAAK,EAAE,iBAAiBd,EAAO/C,CAAM,CAAC;AAAA,IAClF6D,EAAa,UAAU,CAAC;AAAA,MACtBA,EAAa,sCAAsC,sBAAsB,CAAC;AAAA;AAAA,IAG5E,EAEO,CACL,KAAM,gBACN,YAAa,CAAE,kBAAmB,CAAC,MAAM,CAAE,EAC3C,WAAY,IAAM,CAChB,IAAMC,EAAapR,EAAU,KAAK8Q,CAAW,EAC7C,MAAO,CACL,QAAS,CAAC,CAAE,KAAMA,EAAa,SAAUH,EAAY,QAAS,CAAC,EAC/D,cAAe,CAAE,EAAG,KAAK,KAAKS,EAAa,GAA0B,CAAkB,CAAE,EACzF,gBAAiB,CAAC,CAAE,QAAuB,KAAM,KAAK,KAAKA,EAAa,CAAC,CAAE,CAAC,CAC9E,CACF,EACA,gBAAAF,CACF,EAEF,GAAM,CAAE,SAAAV,EAAU,QAAAC,CAAQ,EAAIX,GAAaa,EAAY,KAAM5O,CAAI,EAC3DsP,EAAerR,EAAU,SAASyQ,EAAS,CAAC,EAAG,EAAG,CAAC,CAAC,EACpDa,EAAgBtR,EAAU,SAASyQ,EAAS,CAAC,EAAG,EAAG,CAAC,CAAC,EAE3D,GADkBD,EAAS,SAAW,GAAKa,GAAgBC,EAC5C,CACbP,EAAgBM,EACZ,CAACb,EAAS,CAAC,EAAGA,EAAS,CAAC,EAAIA,EAAS,CAAC,CAAC,EACvCc,EACE,CAACd,EAAS,CAAC,EAAIA,EAAS,CAAC,EAAGA,EAAS,CAAC,CAAC,EACvCA,EACNQ,EAAiB,CAACD,EAAc,CAAC,EAAGA,EAAc,CAAC,CAAC,EACpD,IAAMQ,EAAW,GACjB,OAAAL,EAAmBC,GAA+B,CAChD,IAAMd,EAAQjF,EAAc,IAAKyF,EAAeE,EAAc,MAAM,EAC9DzD,EAASjC,EAAe,SAAUwF,EAAeG,EAAe,MAAM,EAC5E,MAAO;AAAA,IACTG,EAAa,gBAAgB,cAAe,KAAK,EAAE,iBAAiBd,EAAO/C,CAAM,CAAC;AAAA,sCAChDA,EAAO,KAAK,KAAK,KAAKiE,EAAW,CAAC,MAAMA,CAAQ;AAAA,IAClFJ,EAAa,UAAU,CAACI,EAAUA,EAAU,CAAC,CAAC,CAAC;AAAA,oDACCA,CAAQ;AAAA;AAAA;AAAA,uCAGrBA,CAAQ;AAAA,uCACRA,CAAQ;AAAA;AAAA,uCAERlB,EAAM,aAAa,GAAGA,EAAM,KAAK,OAAO,wBAAwB,CAAC;AAAA;AAAA;AAAA;AAAA,wCAIhEkB,CAAQ;AAAA,wCACRA,CAAQ;AAAA;AAAA,QAExCjE,EAAO,aAAa,GAAGA,EAAO,KAAK,OAAO,2BAA4B,8BAA8B,CAAC;AAAA;AAAA,IAGzG,EACO,CACL,KAAM,kBACN,YAAa,CAAE,kBAAmB,CAAC,MAAM,CAAE,EAC3C,WAAY,IAAM,CAChB,IAAM8D,EAAapR,EAAU,KAAK8Q,CAAW,EAC7C,MAAO,CACL,QAAS,CAAC,CAAE,KAAMA,EAAa,SAAUH,EAAY,QAAS,CAAC,EAC/D,cAAe,CAAE,EAAG,KAAK,KAAKK,EAAe,CAAC,EAAIO,CAAQ,EAAG,EAAG,KAAK,KAAKP,EAAe,CAAC,EAAIO,CAAQ,CAAE,EACxG,gBAAiB,CACf,CAAE,QAAuB,KAAMH,CAAW,EAC1C,GAAGvG,EAA2BkG,EAAeC,CAAc,CAC7D,CACF,CACF,EACA,gBAAAE,CACF,CACF,CAEA,OAAAA,EAAmBC,GAA+B,CAChD,IAAMd,EAAQjF,EAAc,IAAKyF,EAAeE,EAAc,MAAM,EAC9DzD,EAASjC,EAAe,SAAUwF,EAAeG,EAAe,MAAM,EAC5E,MAAO;AAAA,IACPG,EAAa,gBAAgB,cAAe,KAAK,EAAE,iBAAiBd,EAAO/C,CAAM,CAAC;AAAA;AAAA,IAElFuC,GAAiB9N,EAAMZ,EAAWkP,EAAO/C,CAAM,CAAC;AAAA;AAAA,IAEhD6D,EAAa,UAAU,CAAC;AAAA,MACtBA,EAAa,sCAAsC,sBAAsB,CAAC;AAAA;AAAA,oBAE5D7D,EAAO,gBAAgB,YAAY,CAAC;AAAA;AAAA;AAAA,MAGlDA,EAAO,YAAY,aAAc+C,EAAM,aAAa,UAAU,CAAC,CAAC;AAAA,IAEpE,EACO,CACL,KAAM,YACN,YAAa,CAAE,KAAM,GAAGO,CAAQ,GAAI,kBAAmB,CAAC,MAAM,CAAE,EAChE,WAAY,IAAM,CAChB,IAAMQ,EAAapR,EAAU,KAAK8Q,CAAW,EAC7C,MAAO,CACL,QAAS,CAAC,CAAE,KAAMA,EAAa,SAAUH,EAAY,QAAS,CAAC,EAC/D,cAAe,CAAE,EAAG,KAAK,KAAKS,EAAa,EAAuB,CAAE,EACpE,gBAAiB,CACf,CAAE,QAAuB,KAAMA,CAAW,EAC1C,GAAGvG,EAA2BkG,EAAeC,CAAc,CAC7D,CACF,CACF,EACA,gBAAAE,CACF,CACF,EAEajB,GAAY,CAAC3f,EAAyBkhB,IAA0C,CAC3F9B,GAAepf,EAAQ,OAAQkhB,EAAW,IAAI,EAC9ClhB,EAAQ,QAAQ0f,GAA2B1f,EAAQ,OAAO,CAAC,EAAGkhB,EAAW,IAAI,CAAC,CAChF,EAEatB,GAA4BsB,GACvClH,EAA4B,CAAE,KAAMkH,EAAW,IAAiB,CAAC,IC1MnE,IAYMC,GAaAC,GAaAC,GAaAC,GAYAC,GAQAC,GAYAC,GAcAC,GASAC,GAaOC,GAsFPC,GA8COC,GAIAC,GAIAC,GAIAC,GAIAC,GAIAC,GAIAC,GAIAC,GAIAC,GAIAC,GA/RbC,GAAAznB,EAAA,kBAGAkS,IAEA8C,IAGAqL,IACAqH,KACA5C,KAEMsB,GAAuC,CAC3C,IAAK,sDACL,IAAK,sDACL,KAAM,wBACN,IAAK,wBACL,KAAM,wBACN,UAAW,oCACX,UAAW,6BACX,GAAI,6BACJ,GAAI,oCACJ,OAAQ,uBACV,EAEMC,GAA6C,CACjD,IAAK,sDACL,IAAK,sDACL,KAAM,wBACN,IAAK,wBACL,KAAM,wBACN,UAAW,wBACX,UAAW,wBACX,GAAI,wBACJ,GAAI,wBACJ,OAAQ,uBACV,EAEMC,GAA8C,CAClD,IAAK,aACL,IAAK,aACL,KAAM,IACN,IAAK,IACL,KAAM,IACN,UAAW,IACX,UAAW,IACX,GAAI,IACJ,GAAI,IACJ,OAAQ,GACV,EAEMC,GAAgD,CACpD,IAAK,YACL,IAAK,YACL,IAAK,YACL,KAAM,YACN,UAAW,YACX,UAAW,iBACX,GAAI,YACJ,GAAI,kBACJ,OAAQ,gBACV,EAEMC,GAAmB,CAACmB,EAAsB1R,IAA2B,CACzE,IAAM2R,EAAM,CAAC,EACb,QAASvnB,EAAI4V,EAAO0R,EAActnB,EAAI4V,EAAM,EAAE5V,EAC5CunB,EAAI,KAAKvnB,CAAC,EAEZ,OAAOunB,CACT,EAEMnB,GAA4B,CAAC7Q,EAA0BY,IAAkD,CAC7G,IAAMiP,EAAc,CAAC,EACfxP,EAAOL,EAAM,OACnB,QAASnP,EAAM,EAAGA,EAAMwP,EAAMxP,IACxB+P,EAAK,QAAQ/P,CAAG,IAAM,IACxBgf,EAAY,KAAK7P,EAAMnP,CAAG,CAAC,EAG/B,IAAMohB,EAAcrR,EAAK,IAAK/P,GAAQmP,EAAMnP,CAAG,CAAC,EAChD,MAAO,CAACgf,EAAaoC,CAAW,CAClC,EAEMnB,GAAuB,CAAC9Q,EAAiBY,IAA6B,CAC1E,IAAMP,EAAOL,EAAM,OAASY,EAAK,OAC3BsR,EAAc,CAAC,EACjBC,EAAW,EACf,QAASthB,EAAM,EAAGA,EAAMwP,EAAMxP,IACxB+P,EAAK,QAAQ/P,CAAG,IAAM,GACxBqhB,EAAY,KAAKlS,EAAMmS,GAAU,CAAC,EAElCD,EAAY,KAAK,CAAC,EAGtB,OAAOA,CACT,EAEMnB,GAAuB,CAACnQ,EAAgBP,IAA0B,CACtE,QAAS5V,EAAI,EAAGA,EAAImW,EAAK,OAAQ,EAAEnW,EACjC,GAAImW,EAAKA,EAAK,OAASnW,EAAI,CAAC,IAAM4V,EAAO,EAAI5V,EAC3C,MAAO,GAGX,MAAO,EACT,EAEMumB,GAAqB,CAACpQ,EAAgBP,IAA2B,CACrE,IAAM2R,EAAM,CAAC,EACb,GAAI,CAACjB,GAAqBnQ,EAAMP,CAAI,EAAG,CACrC,QAAS5V,EAAI,EAAGA,EAAI4V,EAAM,EAAE5V,EACtBmW,EAAK,QAAQnW,CAAC,IAAM,IACtBunB,EAAI,KAAKvnB,CAAC,EAGdmW,EAAK,QAASL,GAASyR,EAAI,KAAKzR,CAAI,CAAC,CACvC,CACA,OAAOyR,CACT,EAEaf,GAAgC,CAC3C5mB,EACA+nB,EACA/c,EACAgd,EACAC,EACAzC,EACAoC,IACgB,CAChB,IAAM9C,EAAa9Z,EAAO,CAAC,EAAE,KAEvB8a,EAAapR,EAAU,KAAK8Q,CAAW,EACvC0C,EAAaxT,EAAU,KAAKkT,CAAW,EAEvC7C,EAAQjF,EAAc,KAAM9U,EAAO,CAAC,EAAE,SAAU8Z,CAAU,EAC1D9C,EAASjC,EAAe,SAAUkI,EAAgBzC,CAAW,EAE/DrC,EAAgB,GAEhB2C,IAAe,IACjB3C,EAAgB,KAGlB,IAAMgF,EAAsB;AAAA,oDACsBhF,CAAa;AAAA,SAGzDyC,EAAmBC,GAA+B;AAAA,UAChDA,EAAa,gBAAgB,aAAc,KAAK,EAAE,iBAAiBd,EAAO/C,CAAM,CAAC;AAAA,UACjFmG,CAAmB;AAAA;AAAA;AAAA;AAAA,WAIlBtC,EAAa,UAAU1C,CAAa,CAAC;AAAA;AAAA,2CAELA,CAAa;AAAA;AAAA;AAAA,gCAGxBkD,GAAiB2B,CAAU,CAAC;AAAA;AAAA,wDAEJ7E,CAAa;AAAA,iCACpC4B,EAAM,YAAY,YAAY,CAAC;AAAA,yBACvCoB,GAAU6B,CAAU,CAAC;AAAA;AAAA;AAAA;AAAA;AAAA,wCAKN7E,CAAa;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,0BAM3BiD,GAAgB4B,CAAU,CAAC;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,YAQzChG,EAAO,YACP,cACA,GACEgG,IAAe,OACX,GAAGhG,EAAO,KAAK,OAAO,yCACtB,GAAGA,EAAO,KAAK,OAAO,IAAIsE,GAAmB0B,CAAU,CAAC,GAC9D,EACF,CAAC;AAAA;AAAA,WAKT,MAAO,CACL,KAAAhoB,EAEA,YAAa,CAAE,KAAM,GAAG+nB,CAAQ,IAAI5E,CAAa,GAAI,kBAAmB,CAAC,MAAM,CAAE,EACjF,gBAAAyC,EACA,WAAY,KAAO,CACjB,QAAS,CAAC,CAAE,KAAMJ,EAAa,SAAUyC,CAAe,CAAC,EACzD,cAAe,CAAE,EAAGnC,CAAW,EAC/B,gBAAiB,CAAC,CAAE,QAAuB,KAAMoC,CAAW,CAAC,CAC/D,EACF,CACF,EAEMrB,GAAe,CACnB7hB,EACAhF,EACAkmB,EACA8B,IACS,CACT,IAAMI,EACJpjB,EAAQ,OAAO,SAAW,EAAIkhB,EAAamC,GAAiCrjB,EAAQ,OAAQkhB,CAAU,EAEpGoC,EAAcF,EAAkB,KAChCE,EAAY,SAAW,GAAK,CAACF,EAAkB,oBACjDE,EAActjB,EAAQ,OAAO,CAAC,EAAE,KAAK,IAAI,CAACujB,EAAMnoB,IAAMA,CAAC,GAEzD,IAAMooB,EAAgB9T,EAAU,cAAc4T,EAAatjB,EAAQ,OAAO,CAAC,EAAE,KAAK,MAAM,EAEpFuR,EAAOiS,EACPzD,EAAQ/f,EAAQ,OAAO,CAAC,EACtByjB,EAAe9B,GAAmBpQ,EAAMvR,EAAQ,OAAO,CAAC,EAAE,KAAK,MAAM,EACvEyjB,EAAa,OAAS,IACxB1D,EAAQ/f,EAAQ,QAAQ0f,GAA2B1f,EAAQ,OAAO,CAAC,EAAGyjB,CAAY,EAAG,CACnF,OAAQ,CAAC,CAAC,EACV,QAAS,CAAC,EAAE,CACd,CAAC,EAAE,CAAC,EACJlS,EAAOgQ,GAAiBhQ,EAAK,OAAQwO,EAAM,KAAK,MAAM,GAGxD,GAAM,CAACS,EAAaoC,CAAW,EAAIpB,GAA0BzB,EAAM,KAAMxO,CAAI,EACzEmS,EAAmBlD,EACnB4C,EAAkB,WACpBM,EAAmBjC,GAAqBjB,EAAagD,CAAa,GAGpExjB,EAAQ,QACN4hB,GACE5mB,EACAooB,EAAkB,SAClB,CAACrD,CAAK,EACNiD,EACAhjB,EAAQ,OAAO,CAAC,EAAE,SAClB0jB,EACAd,CACF,EACA,CAAE,OAAQ,CAAC7C,CAAK,CAAE,CACpB,CACF,EAEa+B,GAAmB,CAAC9hB,EAAyBkhB,IAAuC,CAC/FW,GAAa7hB,EAAS,mBAAoBkhB,EAAY,MAAM,CAC9D,EAEaa,GAAiB,CAAC/hB,EAAyBkhB,IAAuC,CAC7FW,GAAa7hB,EAAS,iBAAkBkhB,EAAY,IAAI,CAC1D,EAEac,GAAiB,CAAChiB,EAAyBkhB,IAAuC,CAC7FW,GAAa7hB,EAAS,iBAAkBkhB,EAAY,IAAI,CAC1D,EAEae,GAAwB,CAACjiB,EAAyBkhB,IAAuC,CACpGW,GAAa7hB,EAAS,wBAAyBkhB,EAAY,WAAW,CACxE,EAEagB,GAAkB,CAACliB,EAAyBkhB,IAAuC,CAC9FW,GAAa7hB,EAAS,kBAAmBkhB,EAAY,KAAK,CAC5D,EAEaiB,GAAkB,CAACniB,EAAyBkhB,IAAuC,CAC9FW,GAAa7hB,EAAS,kBAAmBkhB,EAAY,KAAK,CAC5D,EAEakB,GAAmB,CAACpiB,EAAyBkhB,IAAuC,CAC/FW,GAAa7hB,EAAS,mBAAoBkhB,EAAY,MAAM,CAC9D,EAEamB,GAAkB,CAACriB,EAAyBkhB,IAAuC,CAC9FW,GAAa7hB,EAAS,kBAAmBkhB,EAAY,KAAK,CAC5D,EAEaoB,GAAwB,CAACtiB,EAAyBkhB,IAAuC,CACpGW,GAAa7hB,EAAS,wBAAyBkhB,EAAY,WAAW,CACxE,EAEaqB,GAAqB,CAACviB,EAAyBkhB,IAAuC,CACjGW,GAAa7hB,EAAS,qBAAsBkhB,EAAY,QAAQ,CAClE,ICjSA,IAuBM9B,GAsBAuE,GACOC,GAoFAP,GAePQ,GAyBAC,GAWAC,GAWAC,GAWAC,GAWAC,GAoBAC,GAqBAC,GAoBAC,GAWAC,GAWAC,GAWAC,GAyBOC,GAQAC,GAQAC,GAQAC,GAQAC,GAQAC,GAQAC,GAQAC,GAQAC,GAQAC,GArZbzC,GAAA1nB,EAAA,kBAGAkS,IAEA8C,IACAkK,KAGAmB,IACAoH,KAaMpD,GAAkBpZ,GAAwC,CAC9D,GAAI,CAACA,GAAUA,EAAO,SAAW,GAAKA,EAAO,OAAS,EACpD,MAAM,IAAI,MAAM,mCAAmC,EAGrD,GAAIA,EAAO,SAAW,GAAKA,EAAO,CAAC,EAAE,KAAK,SAAW,EACnD,MAAM,IAAI,MAAM,0BAA0B,CAE9C,EAcM2d,GAAkB5D,GAAU,CAAC,GAAI,GAAI,eAAeA,EAAM,aAAa,eAAe,CAAC,IAAK,EAAE,EACvF6D,GAA0B,CACrC5oB,EACAmqB,EACAnf,EACAof,EACAC,EACApC,EACAqC,EAAW,GACXC,EAAoB,KACJ,CAChB,IAAM/E,EAAwB,CAAC,EACzBV,EAAa9Z,EAAO,CAAC,EAAE,KACvB6K,EAAYiP,EAAW,OACvBvO,EAAO7B,EAAU,cAAc2V,EAAWxU,CAAS,EACnD2U,EAAkB,CAACD,GAAqBhU,EAAK,SAAW,EAC9DuO,EAAW,QAAQ,CAAC2F,EAAGrqB,IAAM,CACvBoqB,GAAmBjU,EAAK,QAAQnW,CAAC,GAAK,EACpCkqB,GACF9E,EAAY,KAAK,CAAC,EAGpBA,EAAY,KAAKiF,CAAC,CAEtB,CAAC,EACD,IAAMC,EAAalF,EAAY,OACzBM,EAAapR,EAAU,KAAK8Q,CAAW,EA4C7C,MAAO,CACL,KAAAxlB,EACA,YAAAmqB,EACA,gBA9CuBtE,GAA+B,CACtD,IAAM8E,EAAoB,CAAC,EAErB5F,EAAQjF,EAAc,KAAM9U,EAAO,CAAC,EAAE,SAAU6K,CAAS,EACzDmM,EAASjC,EAAe,SAAUkI,EAAgByC,CAAU,EAC5DE,EAAMR,EAASrF,EAAO/C,EAAQzL,CAAI,EACpC4P,EAAYyE,EAAI,CAAC,EAErB,QAASC,EAAI,EAAGC,EAAI,EAAGD,EAAIhV,EAAWgV,IAEhCL,GAAmBjU,EAAK,QAAQsU,CAAC,GAAK,GACpCP,GACFQ,IAGF3E,EAAY,YAAY0E,CAAC,eAAeA,CAAC,MAAM/F,EAAW+F,CAAC,CAAC,MAAMA,CAAC;AAAA,oBACvDD,EAAI,CAAC,EAAE,SAAS,YAAY,EAAI,qBAAqBC,CAAC,IAAM,EAAE;AAAA,oBAC9D9F,EAAM,WAAW,gBAAiB8F,EAAG,IAAIA,CAAC,EAAE,CAAC;AAAA,oBAC7C1E,CAAS;AAAA,qBAGrBwE,EAAQ,KAAK,GAAG5F,EAAM,WAAW,gBAAiB8F,EAAG7I,EAAO,WAAW,iBAAkB8I,CAAC,CAAC,CAAC,GAAG,EAC/FA,KAGJ,MAAO;AAAA;AAAA,UAEDjF,EAAa,gBAAgB,cAAe,KAAK,EAAE,iBAAiBd,EAAO/C,CAAM,CAAC;AAAA;AAAA,UAElF6D,EAAa,UAAU,CAAC;AAAA,YACtBA,EAAa,sCAAsC,sBAAsB,CAAC;AAAA,+BACvDd,EAAM,KAAK,OAAO;AAAA,iCAChB/C,EAAO,gBAAgB,YAAY,CAAC;AAAA;AAAA,YAEzD2I,EAAQ,KAAK;AAAA,CAAI,CAAC;AAAA,YAClBC,EAAI,CAAC,CAAC;AAAA,YACNA,EAAI,CAAC,CAAC;AAAA,YACNzE,CAAS;AAAA,YACTyE,EAAI,CAAC,CAAC;AAAA,YACNA,EAAI,SAAW,EAAI5I,EAAO,YAAY,aAAc,OAAO,EAAI4I,EAAI,MAAM,CAAC,EAAE,KAAK;AAAA,CAAI,CAAC;AAAA,UAEhG,EAME,WAAY,KAAO,CACjB,QAAS,CAAC,CAAE,KAAMpF,EAAa,SAAUyC,CAAe,CAAC,EACzD,cAAe,CAAE,EAAG,KAAK,KAAKnC,EAAa,EAAuB,CAAE,EACpE,gBAAiB,CACf,CAAE,QAAuB,KAAMA,CAAW,EAC1C,GAAGvG,EAA2BuF,EAAYU,CAAW,CACvD,CACF,EACF,CACF,EAEa6C,GAAmC,CAC9Crd,EACAkb,IACqB,CACrB,IAAM3P,EAAiB,CAAC,EACxB,OAAIvL,EAAO,CAAC,EAAE,KAAK,CAAC,EAAI,GACtBA,EAAO,CAAC,EAAE,iBAAiB,EAAE,QAASzC,GAAMgO,EAAK,KAAK,OAAOhO,CAAC,CAAC,CAAC,EAE3DyW,EAA4B,CACjC,KAAAzI,EACA,SAAU2P,EAAW,SACrB,kBAAmBA,EAAW,iBAChC,CAAC,CACH,EAEM2C,GAAmB,CACvB7jB,EACAhF,EACAkmB,EACAkE,IACS,CACT,IAAMpf,EAAShG,EAAQ,OACjBojB,EACJpd,EAAO,SAAW,EAAIkb,EAAamC,GAAiCrd,EAAQkb,CAAU,EAExFlhB,EAAQ,QACN4jB,GACE5oB,EACA,CAAE,KAAMooB,EAAkB,SAAU,kBAAmB,CAAC,MAAM,CAAE,EAChE,CAACpd,EAAO,CAAC,CAAC,EACVod,EAAkB,mBAAqBA,EAAkB,KAAK,SAAW,EAAIO,GAAOyB,EACpFhC,EAAkB,KAClBpd,EAAO,CAAC,EAAE,SACVod,EAAkB,SAClBA,EAAkB,iBACpB,EACA,CAAE,OAAQ,CAAC,CAAC,CAAE,CAChB,CACF,EAEMU,GAAoB,CAAC9jB,EAAyBkhB,IAAuC,CACzF9B,GAAepf,EAAQ,MAAM,EAO7B6jB,GAAiB7jB,EAAS,eAAgBkhB,EANf,CAACnB,EAAO/C,IAAW,CAC5C,eAAeA,EAAO,KAAK,OAAO,OAClC,GACA,YAAY+C,EAAM,aAAa,eAAe,CAAC,IAC/C,qBACF,CAC8D,CAChE,EAEMgE,GAAgB,CAAC/jB,EAAyBkhB,IAAuC,CACrF9B,GAAepf,EAAQ,MAAM,EAO7B6jB,GAAiB7jB,EAAS,WAAYkhB,EANX,CAACnB,EAAO/C,IAAW,CAC5C,eAAeA,EAAO,KAAK,OAAO,OAClC,GACA,gBAAgB+C,EAAM,aAAa,eAAe,CAAC,KACnD,EACF,CAC0D,CAC5D,EAEMiE,GAAgB,CAAChkB,EAAyBkhB,IAAuC,CACrF9B,GAAepf,EAAQ,MAAM,EAO7B6jB,GAAiB7jB,EAAS,WAAYkhB,EANX,CAACnB,EAAO/C,IAAW,CAC5C,WAAWA,EAAO,KAAK,KAAK,oBAAoBA,EAAO,KAAK,KAAK,OACjE,GACA,OAAO+C,EAAM,aAAa,eAAe,CAAC,sBAC1C,sBACF,CAC0D,CAC5D,EAEMkE,GAAuB,CAACjkB,EAAyBkhB,IAAuC,CAC5F9B,GAAepf,EAAQ,MAAM,EAO7B6jB,GAAiB7jB,EAAS,kBAAmBkhB,EANlB,CAACnB,EAAO/C,IAAW,CAC5C,eAAeA,EAAO,KAAK,OAAO,OAClC,GACA,gBAAgB+C,EAAM,aAAa,eAAe,CAAC,KACnD,qBACF,CACiE,CACnE,EAEMmE,GAAiB,CAAClkB,EAAyBkhB,IAAuC,CACtF9B,GAAepf,EAAQ,MAAM,EAgB7B6jB,GAAiB7jB,EAAS,YAAakhB,EAfZ,CAACnB,EAAOgG,EAASxU,IAAS,CACnD,IAAMyU,EAAU,CAAC,EACjB,QAASH,EAAI,EAAGA,EAAI9F,EAAM,KAAM8F,KAC1BtU,EAAK,QAAQsU,CAAC,GAAK,GAAKtU,EAAK,SAAW,IAC1CyU,EAAQ,KAAKjG,EAAM,WAAW,gBAAiB8F,EAAG,CAAC,CAAC,EAIxD,MAAO,CACL,GAAGG,EAAQ,KAAK;AAAA,CAAI,CAAC,GACrB,eAAejG,EAAM,aAAa,eAAe,CAAC,IAClD,sBAAsBA,EAAM,aAAa,eAAe,CAAC,KACzD,EACF,CACF,CAC2D,CAC7D,EAEMoE,GAAkB,CAACnkB,EAAyBkhB,IAAuC,CACvF9B,GAAepf,EAAQ,MAAM,EAiB7B6jB,GAAiB7jB,EAAS,aAAckhB,EAhBb,CAACnB,EAAO/C,EAAQzL,IAAS,CAClD,IAAIhQ,EAAO,EACX,QAASskB,EAAI,EAAGA,EAAI9F,EAAM,KAAM8F,KAC1BtU,EAAK,QAAQsU,CAAC,GAAK,GAAKtU,EAAK,SAAW,KAE1ChQ,GAAQvB,EAAQ,OAAO,CAAC,EAAE,KAAK6lB,CAAC,GAIpC,MAAO,CACL,oBACA,GACA,cAAc9F,EAAM,aAAa,eAAe,CAAC,KACjD,eAAe/C,EAAO,KAAK,KAAK,UAAUzb,CAAI,IAChD,CACF,CAC4D,CAC9D,EAEM6iB,GAAiB,CAACpkB,EAAyBkhB,IAAuC,CACtF9B,GAAepf,EAAQ,MAAM,EAgB7B6jB,GAAiB7jB,EAAS,YAAakhB,EAfZ,CAACnB,EAAOgG,EAASxU,IAAS,CACnD,IAAMyU,EAAU,CAAC,EACjB,QAASH,EAAI,EAAGA,EAAI9F,EAAM,KAAM8F,KAC1BtU,EAAK,QAAQsU,CAAC,GAAK,GAAKtU,EAAK,SAAW,IAC1CyU,EAAQ,KAAK,iBAAiBH,CAAC,QAAQ,EAI3C,MAAO,CACL,GAAGG,EAAQ,KAAK;AAAA,CAAI,CAAC,GACrB,eAAejG,EAAM,aAAa,eAAe,CAAC,IAClD,sBAAsBA,EAAM,aAAa,eAAe,CAAC,KACzD,EACF,CACF,CAC2D,CAC7D,EAEMsE,GAAkB,CAACrkB,EAAyBkhB,IAAuC,CACvF9B,GAAepf,EAAQ,MAAM,EAO7B6jB,GAAiB7jB,EAAS,aAAckhB,EANb,CAACnB,EAAO/C,IAAW,CAC5C,eAAeA,EAAO,KAAK,OAAO,OAClC,GACA,YAAY+C,EAAM,aAAa,eAAe,CAAC,IAC/C,EACF,CAC4D,CAC9D,EAEMuE,GAAiB,CAACtkB,EAAyBkhB,IAAuC,CACtF9B,GAAepf,EAAQ,MAAM,EAO7B6jB,GAAiB7jB,EAAS,YAAakhB,EANZ,CAACnB,EAAO/C,IAAW,CAC5C,eAAeA,EAAO,KAAK,OAAO,OAClC,GACA,YAAY+C,EAAM,aAAa,eAAe,CAAC,IAC/C,EACF,CAC2D,CAC7D,EAEMwE,GAAuB,CAACvkB,EAAyBkhB,IAAuC,CAC5F9B,GAAepf,EAAQ,MAAM,EAO7B6jB,GAAiB7jB,EAAS,kBAAmBkhB,EANlB,CAACnB,EAAO/C,IAAW,CAC5C,WAAWA,EAAO,KAAK,KAAK,oBAAoBA,EAAO,KAAK,KAAK,OACjE,GACA,OAAO+C,EAAM,aAAa,eAAe,CAAC,oBAC1C,EACF,CACiE,CACnE,EAEMyE,GAAuB,CAC3B7T,EACAY,EACAgU,IACY,CACZ,GAAIhU,EAAK,SAAW,EAClB,OAAOgU,EAGT,IAAIzE,EAAa,EACboC,EAAa,EACjB,QAAS1hB,EAAM,EAAGA,EAAM+P,EAAK,OAAQ/P,IAC/B+P,EAAK,QAAQ/P,CAAG,IAAM,GACxBsf,GAAcnQ,EAAMnP,CAAG,EAEvB0hB,GAAcvS,EAAMnP,CAAG,EAO3B,OAAO0hB,EAAa,IAAMpC,EAAa,IACzC,EAEa2D,GAAa,CAACzkB,EAAyBkhB,IAAuC,CACrFsD,GAAqBxkB,EAAQ,OAAO,CAAC,EAAE,KAAMkhB,EAAW,KAAMA,EAAW,iBAAiB,EAC5FiD,GAAgBnkB,EAASkhB,CAAU,EAEnCY,GAAiB9hB,EAASkhB,CAAU,CAExC,EAEawD,GAAW,CAAC1kB,EAAyBkhB,IAAuC,CACnFsD,GAAqBxkB,EAAQ,OAAO,CAAC,EAAE,KAAMkhB,EAAW,KAAMA,EAAW,iBAAiB,EAC5F6C,GAAc/jB,EAASkhB,CAAU,EAEjCa,GAAe/hB,EAASkhB,CAAU,CAEtC,EAEayD,GAAW,CAAC3kB,EAAyBkhB,IAAuC,CACnFsD,GAAqBxkB,EAAQ,OAAO,CAAC,EAAE,KAAMkhB,EAAW,KAAMA,EAAW,iBAAiB,EAC5F8C,GAAchkB,EAASkhB,CAAU,EAEjCc,GAAehiB,EAASkhB,CAAU,CAEtC,EAEa0D,GAAkB,CAAC5kB,EAAyBkhB,IAAuC,CAC1FsD,GAAqBxkB,EAAQ,OAAO,CAAC,EAAE,KAAMkhB,EAAW,KAAMA,EAAW,iBAAiB,EAC5F+C,GAAqBjkB,EAASkhB,CAAU,EAExCe,GAAsBjiB,EAASkhB,CAAU,CAE7C,EAEa2D,GAAY,CAAC7kB,EAAyBkhB,IAAuC,CACpFsD,GAAqBxkB,EAAQ,OAAO,CAAC,EAAE,KAAMkhB,EAAW,KAAMA,EAAW,iBAAiB,EAC5FgD,GAAelkB,EAASkhB,CAAU,EAElCgB,GAAgBliB,EAASkhB,CAAU,CAEvC,EAEa4D,GAAY,CAAC9kB,EAAyBkhB,IAAuC,CACpFsD,GAAqBxkB,EAAQ,OAAO,CAAC,EAAE,KAAMkhB,EAAW,KAAMA,EAAW,iBAAiB,EAC5FkD,GAAepkB,EAASkhB,CAAU,EAElCiB,GAAgBniB,EAASkhB,CAAU,CAEvC,EAEa6D,GAAa,CAAC/kB,EAAyBkhB,IAAuC,CACrFsD,GAAqBxkB,EAAQ,OAAO,CAAC,EAAE,KAAMkhB,EAAW,KAAMA,EAAW,iBAAiB,EAC5FmD,GAAgBrkB,EAASkhB,CAAU,EAEnCkB,GAAiBpiB,EAASkhB,CAAU,CAExC,EAEa8D,GAAY,CAAChlB,EAAyBkhB,IAAuC,CACpFsD,GAAqBxkB,EAAQ,OAAO,CAAC,EAAE,KAAMkhB,EAAW,KAAMA,EAAW,iBAAiB,EAC5FoD,GAAetkB,EAASkhB,CAAU,EAElCmB,GAAgBriB,EAASkhB,CAAU,CAEvC,EAEa+D,GAAkB,CAACjlB,EAAyBkhB,IAAuC,CAC1FsD,GAAqBxkB,EAAQ,OAAO,CAAC,EAAE,KAAMkhB,EAAW,KAAMA,EAAW,iBAAiB,EAC5FqD,GAAqBvkB,EAASkhB,CAAU,EAExCoB,GAAsBtiB,EAASkhB,CAAU,CAE7C,EAEagE,GAAe,CAACllB,EAAyBkhB,IAAuC,CACvFsD,GAAqBxkB,EAAQ,OAAO,CAAC,EAAE,KAAMkhB,EAAW,KAAMA,EAAW,iBAAiB,EAC5F4C,GAAkB9jB,EAASkhB,CAAU,EAErCqB,GAAmBviB,EAASkhB,CAAU,CAE1C,IC3ZA,IAcM9B,GAeO6G,GAmCAC,GAmCAC,GAnGbC,GAAArrB,EAAA,kBAOAkS,IAEAgN,KAGAwI,KAEMrD,GAAkBpZ,GAAwC,CAC9D,GAAI,CAACA,GAAUA,EAAO,SAAW,GAAKA,EAAO,OAAS,EACpD,MAAM,IAAI,MAAM,wCAAwC,EAE1D,GAAIA,EAAO,CAAC,EAAE,WAAa,EACzB,MAAM,IAAI,MAAM,qBAAqB,CAEzC,EAQaigB,GAAS,CAACjmB,EAAyBkhB,IAA0C,CACxF9B,GAAepf,EAAQ,MAAM,EAC7B,IAAMqmB,EAAwB,CAACtG,EAAO/C,EAAQzL,IAAS,CACrD,IAAMyU,EAAU,CAAC,EACjB,QAASH,EAAI,EAAGA,EAAI9F,EAAM,KAAM8F,KAC1BtU,EAAK,QAAQsU,CAAC,GAAK,GAAKtU,EAAK,SAAW,IAC1CyU,EAAQ,KAAK,iBAAiBH,CAAC,QAAQ,EAG3C,MAAO,CACL,GAAGG,EAAQ,KAAK;AAAA,CAAI,CAAC,GACrB,eAAejG,EAAM,aAAa,eAAe,CAAC;AAAA,2BAClD,OAAOA,EAAM,aAAa,eAAe,CAAC,IAAImB,EAAW,gBAAkB,EAAI,KAAO,GAAG;AAAA,mBAC5EnB,EAAM,aAAa,eAAe,CAAC;AAAA;AAAA,UAGhD,GACA/C,EAAO,YAAY,aAAc,YAAY,CAC/C,CACF,EAEAhd,EAAQ,QACN4jB,GACE,SACA,CAAE,KAAM1C,EAAW,SAAU,kBAAmB,CAAC,MAAM,CAAE,EACzD,CAAClhB,EAAQ,OAAO,CAAC,CAAC,EAClBqmB,EACA,CAACnF,EAAW,IAAI,IAEhBA,EAAW,QACb,EACA,CAAE,OAAQ,CAAC,CAAC,CAAE,CAChB,CACF,EAEagF,GAAS,CAAClmB,EAAyBkhB,IAA0C,CACxF9B,GAAepf,EAAQ,MAAM,EAC7B,IAAMqmB,EAAwB,CAACtG,EAAO/C,EAAQzL,IAAS,CACrD,IAAMyU,EAAU,CAAC,EACjB,QAASH,EAAI,EAAGA,EAAI9F,EAAM,KAAM8F,KAC1BtU,EAAK,QAAQsU,CAAC,GAAK,GAAKtU,EAAK,SAAW,IAC1CyU,EAAQ,KAAK,iBAAiBH,CAAC,QAAQ,EAG3C,MAAO,CACL,GAAGG,EAAQ,KAAK;AAAA,CAAI,CAAC,GACrB,eAAejG,EAAM,aAAa,eAAe,CAAC;AAAA,2BAClD,OAAOA,EAAM,aAAa,eAAe,CAAC,IAAImB,EAAW,gBAAkB,EAAI,KAAO,GAAG;AAAA,mBAC5EnB,EAAM,aAAa,eAAe,CAAC;AAAA;AAAA,UAGhD,GACA/C,EAAO,YAAY,aAAc,YAAY,CAC/C,CACF,EAEAhd,EAAQ,QACN4jB,GACE,SACA,CAAE,KAAM1C,EAAW,SAAU,kBAAmB,CAAC,MAAM,CAAE,EACzD,CAAClhB,EAAQ,OAAO,CAAC,CAAC,EAClBqmB,EACA,CAACnF,EAAW,IAAI,IAEhBA,EAAW,QACb,EACA,CAAE,OAAQ,CAAC,CAAC,CAAE,CAChB,CACF,EAEaiF,GAA4BjF,GACvClH,EAA4BkH,CAAoE,ICpGlG,IAqFMoF,GAmLAC,GA0BAC,GAuJAC,GAgMAC,GAkKOC,GA8FPC,GAqHOC,GA9+BbC,GAAA/rB,EAAA,kBAGAkS,IAEA8C,IACAuH,KAEA8D,IA6EMkL,GAA0B,CAACtgB,EAA+Bkb,IAAoD,CAmClH,IAAMnB,EAAQ/Z,EAAO,CAAC,EAChB+gB,EAAU/gB,EAAO,CAAC,EAClBghB,EAAOhhB,EAAO,CAAC,EACfihB,EAAYjhB,EAAO,CAAC,EACpBkhB,EAAOlhB,EAAO,CAAC,EACfmhB,EAAgBnhB,EAAO,CAAC,EAE9B,GAAIkhB,GAAQC,EACV,MAAM,IAAI,MAAM,oDAAoD,EAGtE,GAAIpH,EAAM,KAAK,SAAW,EACxB,MAAM,IAAI,MAAM,sCAAsC,EAGxD,IAAMqH,EAAYrH,EAAM,KAAK,CAAC,EACxBsH,EAAiBtH,EAAM,KAAK,CAAC,EAC7BuH,EAAkBvH,EAAM,KAAK,CAAC,EAEpC,GAAIiH,EAAK,KAAK,SAAW,EACvB,MAAM,IAAI,MAAM,+CAA+C,EAGjE,GAAID,EAAQ,KAAK,SAAW,EAC1B,MAAM,IAAI,MAAM,kDAAkD,EAGpE,GAAIA,EAAQ,KAAK,CAAC,IAAMO,EACtB,MAAM,IAAI,MAAM,uEAAuE,EAGzF,GAAIN,EAAK,KAAK,CAAC,IAAMD,EAAQ,KAAK,CAAC,EACjC,MAAM,IAAI,MAAM,oFAAoF,EAGtG,IAAIQ,EAAcP,EAAK,KAAK,CAAC,EAAI,EAC7BQ,EAAcD,EACdE,EAAcD,EAClB,GAAItG,EAAW,eAAe,OAAS,EAAG,CACxC,GAAIA,EAAW,eAAe,SAAW,EACvC,MAAM,IAAI,MAAM,mDAAmD,EAErE,QAAWwG,KAAMxG,EAAW,eAC1B,GAAIwG,EAAKxG,EAAW,WAAa,EAC/B,MAAM,IAAI,MAAM,mDAAmD,EAIvEqG,EAAcrG,EAAW,eAAe,CAAC,EACzCsG,EAActG,EAAW,eAAe,CAAC,EACzCuG,EAAcvG,EAAW,eAAe,CAAC,CAC3C,CAEA,IAAMyG,EAAmBN,EAEzB,GAAIE,IAAgBC,EAClB,MAAM,IAAI,MAAM,6DAA6D,EAG/E,GAAIR,EAAK,KAAK,CAAC,IAAMO,EAAcC,EAAcC,EAC/C,MAAM,IAAI,MAAM,+EAA+E,EAGjG,IAAIG,EAAqB,EACzB,GAAIV,EAAM,CACR,GAAIM,IAAgBC,EAClB,MAAM,IAAI,MAAM,oDAAoD,EAEtE,GAAIP,EAAK,KAAK,SAAW,EACvB,MAAM,IAAI,MAAM,qCAAqC,EAEvD,GAAIA,EAAK,KAAK,CAAC,IAAM,EACnB,MAAM,IAAI,MAAM,wCAAwC,EAE1D,GAAIA,EAAK,KAAK,CAAC,IAAME,EACnB,MAAM,IAAI,MAAM,kDAAkD,EAEpE,GAAIF,EAAK,KAAK,CAAC,IAAMhG,EAAW,SAC9B,MAAM,IAAI,MAAM,gDAAgD,EAElE,GAAIgG,EAAK,KAAK,CAAC,IAAMM,EAActG,EAAW,SAC5C,MAAM,IAAI,MAAM,gEAAgE,EAG7EA,EAAW,yBACd0G,EAAqBV,EAAK,KAAK,CAAC,EAGpC,CAEA,IAAMW,EAAsBF,EAAmBC,EACzCE,EAAoB,GAEpBC,EAAW,EACjB,GAAId,EAGF,MAAM,IAAI,MAAM,oBAAoB,EAGtC,GAAIC,EACF,MAAM,IAAI,MAAM,uBAAuB,EAGzC,GAAIC,EAAe,CACjB,GAAIA,EAAc,KAAK,SAAW,EAChC,MAAM,IAAI,MAAM,+CAA+C,EAIjE,GACEA,EAAc,KAAK,CAAC,IAAMC,GAC1BD,EAAc,KAAK,CAAC,IAAMjG,EAAW,UACrCiG,EAAc,KAAK,CAAC,IAAME,GAC1BF,EAAc,KAAK,CAAC,IAAMU,EAE1B,MAAM,IAAI,MAAM,+FAA+F,CAEnH,CAEA,MAAO,CACL,UAAAT,EACA,eAAAC,EACA,mBAAAO,EACA,iBAAAD,EACA,oBAAAE,EACA,kBAAAC,EACA,gBAAAR,EACA,WAAYC,EACZ,YAAAE,EACA,SAAU,KAAK,MAAMF,EAAcrG,EAAW,QAAQ,EACtD,UAAW,KAAK,MAAMuG,EAAcvG,EAAW,QAAQ,EACvD,SAAUA,EAAW,SACrB,iBAAkB,GAClB,uBAAwB,GACxB,gBAAiBA,EAAW,gBAC5B,SAAA6G,EACA,MAAO7G,EAAW,MAClB,oBAAqB,GACrB,aAAc,GACd,UAAW,CACb,CACF,EAEMqF,GAAc,CAClByB,EACAC,EACAC,IAGID,GAA4BD,EACvB;AAAA,8CACmCC,EAAyB,YAAY,GAAG,CAAC;AAAA;AAAA;AAAA;AAAA,oCAInDD,GAAc,YAAY,UAAU,CAAC;AAAA;AAAA;AAAA;AAAA;AAAA,SAO9D;AAAA,MACLE,EAAyB,2DAA6D,EAAE;AAAA;AAAA,MAMxF1B,GAAkC,CACtCzG,EACAqH,EACAe,EACAP,EACAP,EACAQ,EACAO,EACAH,IACG,CAEH,IAAM5M,EAAab,EAAiB4N,EAAU,EAAIP,CAAmB,EACjEQ,EAAK,GACHC,EAA0BT,EAAsBxM,EAClDiN,EAA0BD,IAC5BA,EAAK,IAEP,IAAME,EAAoB,KAAK,KAAKV,EAAsBxM,EAAagN,CAAE,EACnE/M,EAAoC,CACxC,CAAE,QAAuB,KAAM8L,CAAU,EACzC,CAAE,QAAuB,KAAMe,CAAS,EACxC,CAAE,QAAuB,KAAMP,CAAmB,EAClD,CAAE,QAAuB,KAAMP,CAAe,EAC9C,CAAE,QAAuB,KAAMiB,CAAwB,EACvD,CAAE,QAAuB,KAAMC,CAAkB,CACnD,EACM/nB,EAAW6Z,GAA4B0F,EAAM,SAAU1E,CAAU,EACjEmN,EAAUlO,KAA0Ce,CAAU,EAC9DoN,EAAwD,CAAC,MAAM,EACjEL,GACFK,EAAkB,KAAK,MAAM,EAE3BR,GACFQ,EAAkB,KAAK,MAAM,EAE/B,IAAM7H,EAAmBC,GAA+B,CACtD,IAAM6H,EAAc3N,EAAe,IAAKgF,EAAM,SAAUA,EAAM,KAAM1E,CAAU,EACxEsN,EAAe,CAACD,CAAW,EAC3BE,EAAqBR,EAAUtN,EAAc,WAAYsN,EAAQ,SAAUA,EAAQ,IAAI,EAAI,OAC7FQ,GACFD,EAAa,KAAKC,CAAkB,EAGtC,IAAMC,EAAiCZ,EACnCnN,EAAc,8BAA+BmN,EAAyB,SAAUA,EAAyB,IAAI,EAC7G,OACAY,GACFF,EAAa,KAAKE,CAA8B,EAElD,IAAMC,EAAgBxO,GAA0ByF,EAAM,QAAQ,EACxDgJ,EAA8B,CAClC,CAAE,KAAM,aAAc,KAAM,KAAM,EAClC,CAAE,KAAM,YAAa,KAAM,KAAM,EACjC,CAAE,KAAM,uBAAwB,KAAM,KAAM,EAC5C,CAAE,KAAM,kBAAmB,KAAM,KAAM,EACvC,CAAE,KAAM,wBAAyB,KAAM,KAAM,EAC7C,CAAE,KAAM,sBAAuB,KAAM,KAAM,CAC7C,EAEA,MAAO;AAAA,0CAC+BV,CAAE;AAAA,0CACFA,CAAE;AAAA,IACxCxH,EAAa,iBAAiBkI,CAAQ,EAAE,iBAAiB,GAAGJ,CAAY,CAAC;AAAA,IACzE9H,EAAa,UAAU,CAACwH,EAAI,EAAG,CAAC,CAAC,CAAC;AAAA;AAAA;AAAA;AAAA;AAAA,MAKhC9B,GAAYqC,EAAoBC,EAAgC,EAAK,CAAC;AAAA;AAAA,iCAE3CR,CAAE;AAAA,8BACLD,EAAU,iDAAmD,uBAAuB;AAAA,8BACpFI,CAAO;AAAA;AAAA,gCAELA,CAAO;AAAA;AAAA,+BAER,IAAM,CAC/B,OAAQnN,EAAY,CAClB,IAAK,GACH,MAAO,oBACT,IAAK,GACH,MAAO,gDACT,IAAK,GACH,MAAO,oGACT,QACE,MAAM,IAAI,MAAM,2BAA2BA,CAAU,EAAE,CAC3D,CACF,GAAG,CAAC;AAAA;AAAA;AAAA;AAAA,2BAImBgN,CAAE;AAAA;AAAA;AAAA;AAAA,uBAING,CAAO;AAAA;AAAA,0BAEJA,CAAO;AAAA;AAAA,+BAEF,IAAM,CAC/B,OAAQnN,EAAY,CAClB,IAAK,GACH,MAAO,aACT,IAAK,GACH,MAAO,8BACT,IAAK,GACH,MAAO,4DACT,QACE,MAAM,IAAI,MAAM,2BAA2BA,CAAU,EAAE,CAC3D,CACF,GAAG,CAAC;AAAA;AAAA;AAAA;AAAA,2BAImBgN,CAAE;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,0BAMHK,EAAY,KAAK,KAAK,IAAII,CAAa,WAAWA,CAAa;AAAA;AAAA;AAAA;AAAA,yBAIhEN,CAAO;AAAA,0BACNE,EAAY,KAAK,KAAK;AAAA;AAAA;AAAA,QAIxCN,EACI;AAAA;AAAA,uCAE2BM,EAAY,KAAK,KAAK,IAAII,CAAa;AAAA,WAElE,EACN;AAAA,IAEJ,EAEA,MAAO,CACL,KAAM,wBACN,YAAa,CAAE,KAAM,GAAGT,CAAE,IAAI7nB,CAAQ,IAAI6a,CAAU,GAAI,kBAAAoN,CAAkB,EAC1E,gBAAA7H,EACA,WAAY,KAAO,CACjB,QAAS,CAAC,EACV,cAAe,CAAE,EAAG,EAAG,EAAGyG,EAAgB,EAAGD,EAAYe,CAAS,EAClE,gBAAA7M,CACF,EACF,CACF,EAEMmL,GAAkC,CACtCuC,EACAC,EACAvlB,EACAwlB,EACA/B,EACAgC,EACAvB,EACAQ,EACAH,IACG,CACH,IAAMJ,EAAsBD,EAAqBuB,EAAW,iBACtDC,EAAa,CAACD,EAAW,UAAWA,EAAW,SAAUA,EAAW,eAAgBtB,CAAmB,EACvGwB,EAAaL,EAAc,GAAKE,EAChCI,EAAaH,EAAW,WAAaA,EAAW,WAAaA,EAAW,SACxEI,EAAkBF,EACpB,CAACF,EAAW,UAAWG,EAAYzB,EAAqBsB,EAAW,QAAQ,EAC3E,OACEK,EAAQL,EAAW,MAAQA,EAAW,MAAQ,EAG9CM,EAAQN,EAAW,QAAU,EAAI,EAAM,KAAK,KAAKA,EAAW,QAAQ,EAAIA,EAAW,MACnF9N,EAAab,EAAiB2O,EAAW,QAAQ,EACjDO,EAAqBP,EAAW,SAAW9N,EAC3CsO,EAAY,GACZC,EAAW,CACf,EAAG,KAAK,KAAK/B,EAAsB8B,CAAS,EAC5C,EAAG,KAAK,KAAKR,EAAW,eAAiBQ,CAAS,EAClD,EAAGR,EAAW,UAAYA,EAAW,QACvC,EACM7N,EAAoC,CACxC,CAAE,QAAuB,KAAM6N,EAAW,cAAe,EACzD,CAAE,QAAuB,KAAMO,CAAmB,EAClD,CAAE,QAAuB,KAAM7B,CAAoB,EACnD,CAAE,QAAuB,KAAMsB,EAAW,QAAS,EACnD,CAAE,QAAuB,KAAMA,EAAW,QAAS,EACnD,CAAE,OAAsB,KAAMM,CAAM,EACpC,CAAE,QAAuB,KAAM7B,CAAmB,EAClD,CAAE,QAAuB,KAAMuB,EAAW,gBAAiB,EAC3D,CAAE,QAAuB,KAAMK,CAAM,CACvC,EAEMK,EAAcR,GAAcH,GAAWxZ,EAAU,KAAKwZ,EAAQ,IAAI,EAAI,EACtET,EAAwD,CAAC,OAAQ,MAAM,EACzEoB,GACFpB,EAAkB,KAAK,MAAM,EAE3BtB,GACFsB,EAAkB,KAAK,MAAM,EAE3BL,GACFK,EAAkB,KAAK,MAAM,EAE3BR,GACFQ,EAAkB,KAAK,MAAM,EAE/B,IAAMtiB,EAAU,CAAC,CAAE,KAAMijB,EAAY,SAAUH,EAAE,SAAU,aAAiC,CAAC,EACzFI,GACFljB,EAAQ,KAAK,CAAE,KAAMojB,EAAkB,SAAUN,EAAE,SAAU,aAAiC,CAAC,EAEjG,IAAMrI,EAAmBC,GAA+B,CACtD,IAAMiJ,EAAShP,EAAc,IAAKmO,EAAE,SAAUA,EAAE,KAAM5N,CAAU,EAC1D0O,EAASjP,EAAc,MAAOpX,EAAI,SAAUA,EAAI,KAAM2X,CAAU,EAChE2O,EAAY,CAACF,EAAQC,CAAM,EACjC,GAAIF,EAAa,CACf,IAAMI,EAAenP,EAAc,WAAYoO,EAAQ,SAAUA,EAAQ,KAAM7N,CAAU,EACzF2O,EAAU,KAAKC,CAAY,CAC7B,CACI9C,GACF6C,EAAU,KAAKlP,EAAc,iBAAkBqM,EAAc,SAAUA,EAAc,IAAI,CAAC,EAE5F,IAAM+C,EAAuB9B,EAAUtN,EAAc,WAAYsN,EAAQ,SAAUA,EAAQ,IAAI,EAAI,OAC/F8B,GACFF,EAAU,KAAKE,CAAoB,EAErC,IAAMC,EAAmClC,EACrCnN,EAAc,8BAA+BmN,EAAyB,SAAUA,EAAyB,IAAI,EAC7G,OACAkC,GACFH,EAAU,KAAKG,CAAgC,EAEjD,IAAMnN,GAASjC,EAAe,SAAUkO,EAAE,SAAUG,CAAU,EACxDgB,EAAa,CAACpN,EAAM,EACtBqM,GACFe,EAAW,KAAKrP,EAAe,cAAekO,EAAE,SAAUM,EAAkBlO,CAAU,CAAC,EAEzF,IAAMmN,EAAUlO,KAA0Ce,CAAU,EAE9D0N,EAA8B,CAClC,CAAE,KAAM,IAAK,KAAM,KAAM,EACzB,CAAE,KAAM,IAAK,KAAM,KAAM,EACzB,CAAE,KAAM,IAAK,KAAM,KAAM,EACzB,CAAE,KAAM,YAAa,KAAM,KAAM,EACjC,CAAE,KAAM,YAAa,KAAM,KAAM,EACjC,CAAE,KAAM,QAAS,KAAM,KAAgC,EACvD,CAAE,KAAM,uBAAwB,KAAM,KAAM,EAC5C,CAAE,KAAM,qBAAsB,KAAM,KAAM,EAC1C,CAAE,KAAM,SAAU,KAAM,KAAM,CAChC,EACA,MAAO;AAAA,sBACWY,CAAS;AAAA;AAAA,gCAECG,EAAO,KAAK,OAAO,KAAKH,EAAYA,CAAS;AAAA,gCAC7CG,EAAO,KAAK,OAAO,KAAKH,EAAYA,CAAS;AAAA,IACzE9I,EAAa,iBAAiBkI,CAAQ,EAAE,iBAAiB,GAAGiB,EAAW,GAAGI,CAAU,CAAC;AAAA,IACrFvJ,EAAa,UAAU,CAAC8I,EAAWA,EAAW,CAAC,CAAC,CAAC;AAAA;AAAA;AAAA,sBAG/BH,IAAU,EAAI,UAAY,2BAA2B;AAAA,yBAClDA,IAAU,EAAI,qBAAuB,sCAAsC;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,MAM9FjD,GAAY2D,EAAsBC,EAAkC,EAAI,CAAC;AAAA;AAAA;AAAA,MAGzEN,GAAeR,EAAa,iFAAmF,EAAE;AAAA;AAAA,MAEjHA,EAAa,iEAAmE,EAAE;AAAA,kBACtEb,CAAO;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,QAQbqB,GAAeR,EACV;AAAA;AAAA;AAAA;AAAA;AAAA,iBAOA;AAAA;AAAA;AAAA,YAKP;AAAA,QAEFA,EACI;AAAA;AAAA,SAGA,EACN;AAAA;AAAA;AAAA;AAAA;AAAA,qBAKeb,CAAO;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,wBASJ,IAAM,CACtB,OAAQnN,EAAY,CAClB,IAAK,GACH,MAAO,QACT,IAAK,GACH,MAAO,oBACT,IAAK,GACH,MAAO,wCACT,QACE,MAAM,IAAI,MAAM,2BAA2BA,CAAU,EAAE,CAC3D,CACF,GAAG,CAAC;AAAA,8BACoB2B,GAAO,KAAK,KAAK,6BACrCmK,EAAgB,4BAA8B,KAChD;AAAA;AAAA,IAGN,EACA,MAAO,CACL,KAAM,iBACN,YAAa,CACX,KAAM,GAAG9L,CAAU,IAAI8L,IAAkB,MAAS,IAAI+B,IAAY,MAAS,IAAIF,CAAW,GAC1F,kBAAAP,CACF,EACA,WAAY,KAAO,CAAE,QAAAtiB,EAAS,cAAeyjB,EAAU,gBAAAtO,CAAgB,GACvE,gBAAAsF,CACF,CACF,EAEM8F,GAAoC,CACxCsC,EACAqB,EACA9mB,EACA+mB,EACAC,EACA3C,EACAQ,EAAkC,OAClCH,EAAmD,SAChD,CACH,IAAMJ,EAAsBD,EAAqB2C,EAAO,iBAClDf,EAAQe,EAAO,MAAQA,EAAO,MAAQ,EACtCC,EAAsBD,EAAO,YAAcf,EAC3CiB,EAAezB,EAAc,GAAKsB,EAClChB,EAAaiB,EAAO,WAAaA,EAAO,WAAaA,EAAO,SAC5DG,EAAoBD,EACtB,CAACF,EAAO,UAAWjB,EAAYzB,EAAqB0C,EAAO,QAAQ,EACnE,OACE/J,EAAc,CAAC+J,EAAO,UAAWA,EAAO,eAAgBC,CAAmB,EAC3Eb,EAAY,GACZC,EAAW,CACf,EAAG,KAAK,KAAKW,EAAO,UAAYZ,CAAS,EACzC,EAAG,KAAK,KAAKY,EAAO,eAAiBZ,CAAS,EAC9C,EAAGY,EAAO,UAAYA,EAAO,QAC/B,EAEMjP,EAAoC,CACxC,CAAE,QAAuB,KAAMiP,EAAO,cAAe,EACrD,CAAE,QAAuB,KAAM1C,CAAoB,EACnD,CAAE,QAAuB,KAAM0C,EAAO,SAAU,EAChD,CAAE,QAAuB,KAAMA,EAAO,QAAS,EAC/C,CAAE,QAAuB,KAAMA,EAAO,QAAS,EAC/C,CAAE,QAAuB,KAAMC,CAAoB,EACnD,CAAE,QAAuB,KAAM5C,CAAmB,EAClD,CAAE,QAAuB,KAAM2C,EAAO,gBAAiB,EACvD,CAAE,QAAuB,KAAMf,CAAM,CACvC,EAEMmB,EAAgBF,GAAgBH,GAAa5a,EAAU,KAAK4a,EAAU,IAAI,EAAI,EAC9E7B,EAAwD,CAAC,OAAQ,MAAM,EACzEkC,GACFlC,EAAkB,KAAK,MAAM,EAE3BL,GACFK,EAAkB,KAAK,MAAM,EAE3BR,GACFQ,EAAkB,KAAK,MAAM,EAE/B,IAAMtiB,EAAU,CAAC,CAAE,KAAMqa,EAAa,SAAU6J,EAAM,SAAU,aAAiC,CAAC,EAC9FI,GACFtkB,EAAQ,KAAK,CAAE,KAAMukB,EAAoB,SAAUL,EAAM,SAAU,aAAiC,CAAC,EAEvG,IAAMzJ,EAAmBC,GAA+B,CACtD,IAAM+J,EAAc9P,EAAc,QAASuP,EAAM,SAAUA,EAAM,IAAI,EAC/DQ,EAAU/P,EAAc,IAAKvX,EAAE,SAAUA,EAAE,IAAI,EAC/CymB,EAAY,CAACY,EAAaC,CAAO,EACnCF,GACFX,EAAU,KAAKlP,EAAc,aAAcwP,EAAU,SAAUA,EAAU,IAAI,CAAC,EAEhF,IAAMJ,EAAuB9B,EAAUtN,EAAc,WAAYsN,EAAQ,SAAUA,EAAQ,IAAI,EAAI,OAC/FA,GACF4B,EAAU,KAAKE,CAAqB,EAEtC,IAAMC,EAAmClC,EACrCnN,EAAc,8BAA+BmN,EAAyB,SAAUA,EAAyB,IAAI,EAC7G,OACAA,GACF+B,EAAU,KAAKG,CAAiC,EAGlD,IAAMC,EAAa,CADJrP,EAAe,SAAUsP,EAAM,SAAU7J,CAAW,CACzC,EACtBiK,GACFL,EAAW,KAAKrP,EAAe,gBAAiBsP,EAAM,SAAUK,CAAkB,CAAC,EAErF,IAAM3B,EAA8B,CAClC,CAAE,KAAM,IAAK,KAAM,KAAM,EACzB,CAAE,KAAM,IAAK,KAAM,KAAM,EACzB,CAAE,KAAM,IAAK,KAAM,KAAM,EACzB,CAAE,KAAM,YAAa,KAAM,KAAM,EACjC,CAAE,KAAM,YAAa,KAAM,KAAM,EACjC,CAAE,KAAM,gBAAiB,KAAM,KAAM,EACrC,CAAE,KAAM,uBAAwB,KAAM,KAAM,EAC5C,CAAE,KAAM,qBAAsB,KAAM,KAAM,EAC1C,CAAE,KAAM,SAAU,KAAM,KAAM,CAChC,EACA,MAAO;AAAA,sBACWY,CAAS;AAAA,gCACCiB,EAAY,KAAK,KAAK,KAAKjB,EAAYA,CAAS;AAAA,gCAChDiB,EAAY,KAAK,KAAK,KAAKjB,EAAYA,CAAS;AAAA,IAC5E9I,EAAa,iBAAiBkI,CAAQ,EAAE,iBAAiB,GAAGiB,EAAW,GAAGI,CAAU,CAAC;AAAA,IACrFvJ,EAAa,UAAU,CAAC8I,EAAWA,EAAW,CAAC,CAAC,CAAC;AAAA;AAAA;AAAA,qBAGhCH,IAAU,EAAI,UAAY,2BAA2B;AAAA,wBAClDA,IAAU,EAAI,qBAAuB,sCAAsC;AAAA;AAAA;AAAA;AAAA;AAAA,KAK9FjD,GAAY2D,EAAsBC,EAAkC,EAAI,CAAC;AAAA;AAAA;AAAA,KAGzEQ,GAAiBF,EAAe,uFAAyF,EAAE;AAAA;AAAA,KAE3HA,EAAe,uEAAyE,EAAE;AAAA,iBAC9EG,EAAY,KAAK,OAAO;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,UAQ3BD,GAAiBF,EACZ;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,QAQA;AAAA;AAAA;AAAA,cAKP;AAAA,UAEFA,EACI;AAAA;AAAA;AAAA,WAIA,EACN;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,IAgBN,EAEA,MAAO,CACL,KAAM,iBACN,YAAa,CAAE,KAAM,GAAGH,IAAc,MAAS,IAAItB,CAAW,GAAI,kBAAAP,CAAkB,EACpF,WAAY,KAAO,CAAE,QAAAtiB,EAAS,cAAeyjB,EAAU,gBAAAtO,CAAgB,GACvE,gBAAAsF,CACF,CACF,EAEa+F,GAAiB,CAC5B3mB,EACAipB,EACApD,EACAtiB,EACAunB,EACAC,EACA7B,EACAoB,EACAU,EACA7B,EACAf,EAAkC,OAClCH,EAAmD,SAChD,CAEH,IAAMe,EAAc,KAAK,IAAIhpB,EAAQ,YAAa,GAAKkpB,EAAU,EAAI,IAAMoB,EAAY,EAAI,EAAE,EACvF1C,EAAqBoB,EAAc,EAAIG,EAAW,mBAAqB,EACvEtB,EAAsBD,EAAqBuB,EAAW,iBACtDhC,EACJ6D,GAAsBtb,EAAU,KAAKsb,EAAmB,IAAI,EAAI,EAAIA,EAAqB,OAErFC,EAAU,CAAChC,EAAGpD,CAAC,EACjBmD,EAAc,GAAKE,GAAWxZ,EAAU,KAAKwZ,EAAQ,IAAI,EAAI,GAC/D+B,EAAQ,KAAK/B,CAAO,EAElB/B,GACF8D,EAAQ,KAAK9D,CAAa,EAExBiB,GACF6C,EAAQ,KAAK7C,CAAO,EAElBH,GACFgD,EAAQ,KAAKhD,CAAwB,EAGvC,IAAMoC,EAAQrqB,EAAQ,QACpBymB,GACEuC,EACAC,EACApD,EACAqD,EACA/B,EACAgC,EACAvB,EACAQ,EACAH,CACF,EACA,CAAE,OAAQgD,EAAS,QAASjC,EAAc,EAAI,CAAC,GAAI,CAAC,EAAI,CAAC,EAAE,CAAE,CAC/D,EAAE,CAAC,EAGHhpB,EAAQ,QACNwmB,GACE6D,EACAlB,EAAW,UACXA,EAAW,SACXvB,EACAuB,EAAW,eACXtB,EACAO,EACAH,CACF,EACA,CAAE,OAAQG,GAAWH,EAA2B,CAACoC,EAAOjC,EAASH,CAAwB,EAAI,CAACoC,CAAK,EAAG,QAAS,CAAC,CAAE,CACpH,EAGA,IAAMa,EAAU,CAACb,EAAO9mB,CAAC,EACrBylB,EAAc,GAAKsB,GAAa5a,EAAU,KAAK4a,EAAU,IAAI,EAAI,GACnEY,EAAQ,KAAKZ,CAAS,EAEpBlC,GACF8C,EAAQ,KAAK9C,CAAO,EAElBH,GACFiD,EAAQ,KAAKjD,CAAwB,EAEvCjoB,EAAQ,QACN0mB,GACEsC,EACAqB,EACA9mB,EACA+mB,EACAnB,EACAvB,EACAQ,EACAH,CACF,EACA,CACE,OAAQiD,EACR,QAASlC,EAAc,EAAI,CAAC,EAAG,CAAC,EAAI,CAAC,CAAC,CACxC,CACF,CACF,EAEMpC,GAAU,CAAC5mB,EAAyBmpB,IAAoC,CAC5E,IAAM3I,EAAc,CAAC2I,EAAW,UAAWA,EAAW,SAAUA,EAAW,eAAgBA,EAAW,QAAQ,EACxGhW,EAAIgW,EAAW,eACf/V,EAAI+V,EAAW,gBACf9V,EAAI8V,EAAW,SACfQ,EAAY,GACZC,EAAW,CACf,EAAG,KAAK,KAAKT,EAAW,SAAWQ,CAAS,EAC5C,EAAG,KAAK,KAAKR,EAAW,eAAiBQ,CAAS,EAClD,EAAGR,EAAW,UAAYA,EAAW,QACvC,EACMnjB,EAAS,CAAChG,EAAQ,OAAO,CAAC,EAAGA,EAAQ,OAAO,CAAC,EAAGA,EAAQ,OAAO,CAAC,CAAC,EACjEsb,EAAoC,CACxC,CAAE,QAAuB,KAAMnI,CAAE,EACjC,CAAE,QAAuB,KAAMC,CAAE,EACjC,CAAE,QAAuB,KAAMC,CAAE,EACjC,CAAE,QAAuB,KAAM8V,EAAW,QAAS,EACnD,CAAE,QAAuB,KAAMA,EAAW,QAAS,EACnD,CAAE,QAAuB,KAAMA,EAAW,UAAW,EACrD,CAAE,QAAuB,KAAMA,EAAW,WAAaA,EAAW,WAAaA,EAAW,WAAY,CACxG,EAEMvI,EAAmBC,GAA+B,CACtD,IAAMsK,EAAUpQ,EAAe,WAAY/U,EAAO,CAAC,EAAE,SAAUwa,CAAW,EACpE4K,EAAUrQ,EAAe,WAAY/U,EAAO,CAAC,EAAE,SAAUwa,CAAW,EACpE6K,EAAUtQ,EAAe,WAAY/U,EAAO,CAAC,EAAE,SAAUwa,CAAW,EACpET,EAAQjF,EAAc,QAAS9U,EAAO,CAAC,EAAE,SAAUA,EAAO,CAAC,EAAE,IAAI,EACjEslB,EAASxQ,EAAc,SAAU9U,EAAO,CAAC,EAAE,SAAUA,EAAO,CAAC,EAAE,IAAI,EACnEghB,EAAOlM,EAAc,OAAQ9U,EAAO,CAAC,EAAE,SAAUA,EAAO,CAAC,EAAE,IAAI,EAC/DxF,EAAWuf,EAAM,KAAK,QAEtBgJ,EAA8B,CAClC,CAAE,KAAM,IAAK,KAAM,KAAM,EACzB,CAAE,KAAM,IAAK,KAAM,KAAM,EACzB,CAAE,KAAM,IAAK,KAAM,KAAM,EACzB,CAAE,KAAM,YAAa,KAAM,KAAM,EACjC,CAAE,KAAM,YAAa,KAAM,KAAM,EACjC,CAAE,KAAM,cAAe,KAAM,KAAM,EACnC,CAAE,KAAM,MAAO,KAAM,KAAM,CAC7B,EACA,MAAO;AAAA,sBACWY,CAAS;AAAA,oCACKnpB,CAAQ,KAAKmpB,EAAYA,CAAS;AAAA,sCAChCnpB,CAAQ,KAAKmpB,EAAYA,CAAS;AAAA,sCAClCnpB,CAAQ,KAAKmpB,EAAYA,CAAS;AAAA,sCAClCnpB,CAAQ,KAAKmpB,EAAYA,CAAS;AAAA,IACpE9I,EAAa,iBAAiBkI,CAAQ,EAAE,iBAAiBhJ,EAAOuL,EAAQtE,EAAMmE,EAASC,EAASC,CAAO,CAAC;AAAA,IACxGxK,EAAa,UAAU,CAAC8I,EAAWA,EAAW,CAAC,CAAC,CAAC;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,mBAWlCnpB,CAAQ;AAAA,mBACRA,CAAQ;AAAA,mBACRA,CAAQ;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,IAoCzB,EAEA,OAAOR,EAAQ,QACb,CACE,KAAM,mBACN,YAAa,CAAE,kBAAmB,CAAC,OAAQ,OAAQ,MAAM,CAAE,EAC3D,WAAY,KAAO,CACjB,QAAS,CACP,CAAE,KAAMwgB,EAAa,SAAUxgB,EAAQ,OAAO,CAAC,EAAE,SAAU,aAAiC,EAC5F,CAAE,KAAMwgB,EAAa,SAAUxgB,EAAQ,OAAO,CAAC,EAAE,SAAU,aAAiC,EAC5F,CAAE,KAAMwgB,EAAa,SAAUxgB,EAAQ,OAAO,CAAC,EAAE,SAAU,aAAiC,CAC9F,EACA,cAAe4pB,EACf,gBAAAtO,CACF,GACA,gBAAAsF,CACF,EACA,CAAE,OAAA5a,EAAQ,QAAS,CAAC,GAAI,GAAI,EAAE,CAAE,CAClC,CACF,EAEa6gB,GAAY,CAAC7mB,EAAyBkhB,IAAqC,CACtF,IAAMqJ,EAASjE,GAAwBtmB,EAAQ,OAAQkhB,CAAU,EAE3D,CAAC+H,EAAGpD,EAAGtiB,CAAC,EAAIqjB,GAAQ5mB,EAASuqB,CAAM,EAEzC,OAAO5D,GACL3mB,EACAipB,EACApD,EACAtiB,EACAvD,EAAQ,OAAO,CAAC,EAChB,OACA,OACA,OACAA,EAAQ,OAAO,CAAC,EAChBuqB,CACF,CACF,IC//BA,IAsBMnL,GAoCAmM,GAgFOC,GAGAC,GA7IbC,GAAA3wB,EAAA,kBAGAyJ,KAEAyI,IAEA8C,IACAkK,KAGAmB,IAWMgE,GAAiB,CAACpZ,EAA+Bkb,IAA0C,CAC/F,GAAI,CAAClb,GAAUA,EAAO,SAAW,EAC/B,MAAM,IAAI,MAAM,sCAAsC,EAGxD,IAAM2lB,EAAkB,CAACC,EAA2BC,EAA6B1mB,IAAoB,CACnG,IAAM2mB,EAAID,EAAS,OACnB,GAAIC,IAAMF,EAAO,OACf,MAAM,IAAI,MAAM,GAAGzmB,CAAO,uBAAuB2mB,CAAC,EAAE,EAEtDD,EAAS,QAAQ,CAACtoB,EAAGnI,IAAM,CACzB,GAAImI,IAAMqoB,EAAOxwB,CAAC,EAChB,MAAM,IAAI,MAAM,GAAG+J,CAAO,SAAS/J,CAAC,gBAAgB,CAExD,CAAC,CACH,EAEA,GAAI4K,EAAO,CAAC,EAAE,KAAK,OAAS,EAAG,CAC7B,IAAM2K,EACJuQ,EAAW,SAAW,OAClBA,EAAW,QACTlb,EAAO,CAAC,EAAE,KAAK,MAAM,EAAE,EACvBA,EAAO,CAAC,EAAE,KAAK,MAAM,EAAE,EAAE,OAAOA,EAAO,CAAC,EAAE,KAAK,MAAM,EAAGA,EAAO,CAAC,EAAE,KAAK,OAAS,CAAC,CAAC,EACpFA,EAAO,CAAC,EAAE,KAAK,MAAM,EAAGkb,EAAW,QAAU,EAAI,MAAS,EAChEyK,EAAgB3lB,EAAO,CAAC,EAAE,KAAM2K,EAAO,qBAAqB,EAC5Dgb,EAAgB3lB,EAAO,CAAC,EAAE,KAAM2K,EAAO,iBAAiB,EACxDgb,EAAgB3lB,EAAO,CAAC,EAAE,KAAM2K,EAAO,oBAAoB,EAC3Dgb,EAAgB3lB,EAAO,CAAC,EAAE,KAAM2K,EAAO,mBAAmB,CAC5D,MACEgb,EAAgB3lB,EAAO,CAAC,EAAE,KAAM,CAAC,CAAC,EAAG,qBAAqB,EAC1D2lB,EAAgB3lB,EAAO,CAAC,EAAE,KAAM,CAAC,CAAC,EAAG,iBAAiB,EACtD2lB,EAAgB3lB,EAAO,CAAC,EAAE,KAAM,CAAC,CAAC,EAAG,oBAAoB,EACzD2lB,EAAgB3lB,EAAO,CAAC,EAAE,KAAM,CAAC,CAAC,EAAG,mBAAmB,CAE5D,EAEMulB,GAAsC,CAC1CvlB,EACAkb,IACgB,CAChB,GAAM,CAAE,QAAA6K,EAAS,QAAAC,EAAS,OAAAC,CAAO,EAAI/K,EAC/BgL,EAASlmB,EAAO,CAAC,EAAE,KACnBqV,EAAa2Q,EAAUxR,EAAiB0R,EAAOA,EAAO,OAAS,CAAC,CAAC,EAAI,EACrEC,EAAcF,IAAW,QAAUC,EAAO,OAAS,EAAI7Q,EAAa,EACpEyF,EAAapR,EAAU,KAAKwc,CAAM,EAAI7Q,EAEtC+Q,EAAoBJ,EACpBvQ,EAAc2Q,EAAoBF,EAAO,OAASA,EAClD1a,EAAIsJ,EAAc,IAAK9U,EAAO,CAAC,EAAE,SAAUA,EAAO,CAAC,EAAE,KAAMqV,CAAU,EACrEgR,EAAQvR,EAAc,QAAS9U,EAAO,CAAC,EAAE,SAAUA,EAAO,CAAC,EAAE,KAAMmmB,CAAW,EAC9EnF,EAAOlM,EAAc,OAAQ9U,EAAO,CAAC,EAAE,SAAUA,EAAO,CAAC,EAAE,KAAMmmB,CAAW,EAC5EG,EAAYxR,EAAc,YAAa9U,EAAO,CAAC,EAAE,SAAUA,EAAO,CAAC,EAAE,KAAMmmB,CAAW,EACtFI,EAAWzR,EAAc,WAAY9U,EAAO,CAAC,EAAE,SAAUA,EAAO,CAAC,EAAE,KAAMmmB,CAAW,EACpFK,EAAIzR,EAAe,IAAK/U,EAAO,CAAC,EAAE,SAAUyV,EAAaJ,CAAU,EAGnEoR,EAAc,IAAc,CAChC,IAAIC,EAAU,GACd,GAAIV,EACFU,EAAU,iBACRR,EAAO,SAAW,EACd,KACAD,IAAW,OACT,iBAAiBC,EAAO,OAAS,CAAC,OAAO7Q,CAAU,GACnD,kBACR,YAEI4Q,IAAW,OACbS,EAAU;AAAA,cACJF,EAAE,WAAW,gBAAiB,IAAK,GAAG,CAAC;AAAA,4BACzBA,EAAE,gBAAgB,eAAe,CAAC,QACjD,CAELE,EAAU,kBAAkBL,EAAM,KAAK,OAAO;AAAA,qDACDH,EAAO,OAAS,CAAC,KAE9D,QAAS9wB,EAAI,EAAGA,EAAIixB,EAAM,KAAMjxB,IAC9BsxB,GAAW,YAAYtxB,CAAC,qBAAqBA,CAAC,KAEhDsxB,GAAW,iBAAiBL,EAAM,gBAAgB,UAAU,CAAC,GAC/D,CAEF,OAAOK,CACT,EACMC,EAAgCC,GAAyB;AAAA,oBAC7Cb,CAAO;AAAA,IACvBa,EAAO,gBAAgB,aAAc,KAAK,EAAE,iBAAiBpb,EAAG6a,EAAOrF,EAAMsF,EAAWC,EAAUC,CAAC,CAAC;AAAA,IACpGI,EAAO,UAAU,CAAC;AAAA,IAClBA,EAAO,sCAAsC,qBAAqB,CAAC;AAAA,0BAC7CJ,EAAE,gBAAgB,gBAAgBnR,CAAU,EAAE,CAAC;AAAA,MACnEoR,EAAY,CAAC;AAAA,kBACDJ,EAAM,YAAY,SAAS,CAAC;AAAA,iBAC7BrF,EAAK,YAAY,SAAS,CAAC;AAAA,sBACtBsF,EAAU,YAAY,SAAS,CAAC;AAAA,qBACjCC,EAAS,YAAY,SAAS,CAAC;AAAA,cACtC/a,EAAE,YAAY,YAAY,CAAC;AAAA;AAAA,MAEnCgb,EAAE,YAAY,aAAc,OAAO,CAAC;AAAA,KAExC,MAAO,CACL,KAAM,qBACN,YAAa,CACX,KAAM,GAAGtL,EAAW,OAAO,IAAIA,EAAW,MAAM,IAAI8K,CAAO,IAAI3Q,CAAU,GACzE,kBAAmB+Q,EAAoB,CAAC,OAAQ,OAAQ,OAAQ,OAAQ,MAAM,EAAI,MACpF,EACA,gBAAiBO,EACjB,WAAY,KAAO,CACjB,QAAS,CAAC,CAAE,KAAM3mB,EAAO,CAAC,EAAE,KAAM,SAAUA,EAAO,CAAC,EAAE,QAAS,CAAC,EAChE,cAAe,CAAE,EAAG,KAAK,KAAK8a,EAAa,EAAuB,CAAE,EACpE,gBAAiBsL,EACb,CAAC,CAAE,QAAuB,KAAMtL,CAAW,EAAG,GAAGvG,EAA2B2R,CAAM,CAAC,EACnF,CAAC,CAAE,QAAuB,KAAMpL,CAAW,CAAC,CAClD,EACF,CACF,EAEa0K,GAA4BtK,GACvClH,EAA4BkH,CAAoE,EAErFuK,GAAY,CAACzrB,EAAyBkhB,IAA8C,CAC/F,GAAM,CAAE,OAAAlb,EAAQ,YAAAgjB,CAAY,EAAIhpB,EAC1BojB,EAAoBoI,GAAyB,CAAE,GAAGtK,EAAY,YAAA8H,CAAY,CAAC,EAIjF,GAHIxsB,EAAI,OAAO,sBACb4iB,GAAepZ,EAAQod,CAAiB,EAEtClC,EAAW,aACb,MAAM,IAAI,MAAM,uDAAuD,EAEvElhB,EAAQ,QAAQurB,GAAoCvlB,EAAQod,CAAiB,CAAC,CAElF,ICxJA,IASMhE,GAkBAyN,GAkCOC,GA7DbC,GAAAhyB,EAAA,kBAIAgV,IAGAqL,IAEMgE,GAAkBpZ,GAAwC,CAC9D,GAAIA,EAAO,CAAC,EAAE,KAAK,SAAW,EAC5B,MAAM,IAAI,MAAM,gCAAgC,EAGlD,GAAI,CAAC,CAAC,IAAK,IAAK,IAAI,EAAE,SAASA,EAAO,CAAC,EAAE,KAAK,CAAC,CAAC,EAC9C,MAAM,IAAI,MAAM,+CAA+C,EAGjE,GAAIA,EAAO,CAAC,EAAE,KAAK,SAAW,EAC5B,MAAM,IAAI,MAAM,uCAAuC,EAGzD,GAAIA,EAAO,CAAC,EAAE,KAAK,CAAC,IAAMA,EAAO,CAAC,EAAE,KAAK,CAAC,EACxC,MAAM,IAAI,MAAM,mDAAmD,CAEvE,EAEM6mB,GAA4B7mB,GAA+C,CAC/E,IAAMwa,EAAcxa,EAAO,CAAC,EAAE,KAExB7H,EAAW6H,EAAO,CAAC,EAAE,KAAK,CAAC,EAE3B8a,EAAapR,EAAU,KAAK8Q,CAAW,EAAI,EAE3ChgB,EAAWwF,EAAO,CAAC,EAAE,SACrB+Z,EAAQjF,EAAc,QAASta,EAAUggB,EAAa,CAAC,EACvDwG,EAAOlM,EAAc,OAAQta,EAAU,CAACrC,CAAQ,EAAG,CAAC,EACpD6uB,EAAWlS,EAAc,WAAYta,EAAUggB,EAAa,CAAC,EAC7DxD,EAASjC,EAAe,SAAUva,EAAUggB,EAAa,CAAC,EAahE,MAAO,CACL,KAAM,UACN,WAAY,KAAO,CACjB,QAAS,CAAC,CAAE,KAAMA,EAAa,SAAUxa,EAAO,CAAC,EAAE,QAAS,CAAC,EAC7D,cAAe,CAAE,EAAG,KAAK,KAAK8a,EAAa,EAAuB,CAAE,CACtE,GACA,gBAjBuBD,GAA+B;AAAA,qBACrC1iB,CAAQ;AAAA,IACzB0iB,EAAa,iBAAiBd,EAAOiH,EAAMgG,EAAUhQ,CAAM,CAAC;AAAA;AAAA,IAE5D6D,EAAa,UAAU,CAAC;AAAA,MACtBA,EAAa,sCAAsCC,CAAU,CAAC;AAAA,kBAClDf,EAAM,YAAY,YAAY,CAAC;AAAA,UACvCiH,EAAK,YAAY,uBAAuB,CAAC,MAAMgG,EAAS,YAAY,YAAY,CAAC;AAAA,MACrFhQ,EAAO,YAAY,aAAc,OAAO,CAAC;AAAA,IAU7C,CACF,EAEa8P,GAAW9sB,GAAkC,CACxDof,GAAepf,EAAQ,MAAM,EAC7BA,EAAQ,QAAQ6sB,GAAyB7sB,EAAQ,MAAM,CAAC,CAC1D,IChEA,IAsBMitB,GAsCAC,EAwCOC,GAIAC,GAIAC,GAIAC,GAIAC,GAIAC,GAGAC,GASAC,GAGAC,GA+BPC,GAsBOC,GAwBAC,GAIAC,GAIAC,GAQAC,GAGAC,GAsBAC,GAcAC,GAKAC,GAIAC,GAIAC,GAYAC,GAaAC,GAIAC,GAIAC,GAIAC,GAWAC,GASAC,GAQAC,GAcAC,GAIAC,GAIAC,GAIAC,GAIAC,GAEAC,GAKAC,GAUAC,GAGAC,GAcAC,GAcAC,GAIAC,GAmBAC,GAEAC,GAhcbC,GAAA/0B,EAAA,kBAGAkS,IAEA8C,IACAkK,KAGAmB,IAaM6R,GAAiC,CACrCpM,EACAkP,EACAxP,EACA0C,EACA+M,EACAC,EACAC,IACW,CACX,IAAMC,EAAU,KAAK,KAAKJ,EAAW,CAAC,EAElCK,EAAa,GACb,OAAOJ,GAAa,SACtBI,EAAa,GAAGJ,CAAQ,MAExBI,EAAaJ,EAAS,GAAG,EAG3B,IAAMjQ,EAAQjF,EAAc,YAAayF,EAAe,CAAC4P,CAAO,EAAG,CAAC,EAC9DnT,EAASjC,EAAe,aAAckI,EAAgB,CAACkN,CAAO,EAAG,CAAC,EAClEpH,EAA8B,CAAC,CAAE,KAAM,WAAY,KAAM,KAAM,CAAC,EACtE,OAAImH,GACFnH,EAAS,KAAK,GAAGmH,CAAsB,EAGlC;AAAA,QACDrP,EAAa,iBAAiBkI,CAAQ,EAAE,iBAAiBhJ,EAAO/C,CAAM,CAAC;AAAA;AAAA,IAE3EiT,GAA4B,EAAE;AAAA;AAAA,IAE9BpP,EAAa,UAAU,CAAC;AAAA,MACtBA,EAAa,sCAAsC,mBAAmB,CAAC;AAAA;AAAA,cAE/Dd,EAAM,YAAY,YAAY,CAAC;AAAA,MACvC/C,EAAO,YAAY,aAAcoT,CAAU,CAAC;AAAA,IAElD,EAEMlD,EAA+B,CACnCnN,EACA/kB,EACAg1B,EACAC,EACAlN,EACAE,EAAyBlD,EAAM,SAC/BjB,EACAoR,IACgB,CAChB,IAAM5U,EAAoC,CACxC,CAAE,QAAuB,KAAM,KAAK,KAAK5L,EAAU,KAAKqQ,EAAM,IAAI,EAAI,CAAC,CAAE,CAC3E,EACA,OAAIjB,GACFxD,EAAgB,KAAK,GAAGwD,CAAkB,EAGrC,CACL,KAAA9jB,EACA,YAAa,CAAE,KAAM+nB,EAAU,kBAAmB,CAAC,MAAM,CAAE,EAC3D,gBAAkBlC,GAChBoM,GACEpM,EACAnR,EAAU,KAAKqQ,EAAM,IAAI,EACzBA,EAAM,SACNkD,EACA+M,EACAC,EACAC,CACF,EACF,WAAaG,IAAkB,CAC7B,QAAS,CAAC,CAAE,KAAMtQ,EAAM,KAAM,SAAUkD,CAAe,CAAC,EACxD,cAAe,CACb,EAAG,KAAK,KAAKvT,EAAU,KAAK2gB,EAAa,CAAC,EAAE,IAAI,EAAI,GAA0B,CAAgB,CAChG,EACA,gBAAA/U,CACF,EACF,CACF,EAEa6R,GAAOntB,GAAkC,CACpDA,EAAQ,QAAQktB,EAA6BltB,EAAQ,OAAO,CAAC,EAAG,MAAO,KAAK,CAAC,CAC/E,EAEaotB,GAAQptB,GAAkC,CACrDA,EAAQ,QAAQktB,EAA6BltB,EAAQ,OAAO,CAAC,EAAG,OAAQ,MAAM,CAAC,CACjF,EAEaqtB,GAASrtB,GAAkC,CACtDA,EAAQ,QAAQktB,EAA6BltB,EAAQ,OAAO,CAAC,EAAG,QAAS,OAAO,CAAC,CACnF,EAEastB,GAAQttB,GAAkC,CACrDA,EAAQ,QAAQktB,EAA6BltB,EAAQ,OAAO,CAAC,EAAG,OAAQ,MAAM,CAAC,CACjF,EAEautB,GAASvtB,GAAkC,CACtDA,EAAQ,QAAQktB,EAA6BltB,EAAQ,OAAO,CAAC,EAAG,QAAS,OAAO,CAAC,CACnF,EAEawtB,GAAQxtB,GAAkC,CACrDA,EAAQ,QAAQktB,EAA6BltB,EAAQ,OAAO,CAAC,EAAG,OAAQ,MAAM,CAAC,CACjF,EACaytB,GAASztB,GAAkC,CACtDA,EAAQ,QAAQktB,EAA6BltB,EAAQ,OAAO,CAAC,EAAG,QAAS,OAAO,CAAC,CACnF,EAOa0tB,GAAuBxM,GAClClH,EAA4BkH,CAA4B,EAE7CyM,GAAO,CAAC3tB,EAAyBkhB,IAAqC,CACjF,IAAIoP,EACJ,OAAQpP,EAAW,GAAI,CACrB,QACEoP,EAAO,YACP,MACF,OACEA,EAAO,YACP,MACF,QACEA,EAAO,YACP,MACF,OACEA,EAAO,YACP,MACF,OACEA,EAAO,aACP,MACF,QACE,MAAM,IAAI,WAAW,0EAA0EpP,EAAW,EAAE,EAAE,CAClH,CACAlhB,EAAQ,QACNktB,EAA6BltB,EAAQ,OAAO,CAAC,EAAG,OAAQswB,EAAM,OAAWpP,EAAW,SAAUA,EAAW,EAAE,CAC7G,CACF,EAOM0M,GAAoC5nB,GAAkD,CAC1F,IAAIuqB,EACA7f,EACE8f,EAASxqB,EAAO,QAAU,GAAKA,EAAO,CAAC,EAAE,OAAS,EAClDyqB,EAASzqB,EAAO,QAAU,GAAKA,EAAO,CAAC,EAAE,OAAS,EAExD,OAAQA,EAAO,CAAC,EAAE,SAAU,CAC1B,OACEuqB,EAAMC,EAASxqB,EAAO,CAAC,EAAE,gBAAgB,EAAE,CAAC,EAAI,sBAChD0K,EAAM+f,EAASzqB,EAAO,CAAC,EAAE,gBAAgB,EAAE,CAAC,EAAI,qBAChD,MACF,QACEuqB,EAAMC,EAASxqB,EAAO,CAAC,EAAE,eAAe,EAAE,CAAC,EAAI,MAC/C0K,EAAM+f,EAASzqB,EAAO,CAAC,EAAE,eAAe,EAAE,CAAC,EAAI,MAC/C,MACF,QACE,MAAM,IAAI,MAAM,qBAAqB,CACzC,CAEA,OAAOgU,EAA4B,CAAE,IAAAuW,EAAK,IAAA7f,CAAI,CAAC,CACjD,EAEamd,GAAO,CAAC7tB,EAAyB0wB,IAAyC,CACrF,IAAMxP,EAAawP,GAAkC9C,GAAiC5tB,EAAQ,MAAM,EAC9FQ,EAAW8Z,GAA0Bta,EAAQ,OAAO,CAAC,EAAE,QAAQ,EACrEA,EAAQ,QACNktB,EACEltB,EAAQ,OAAO,CAAC,EAChB,OACCsN,GAAM,SAASA,CAAC,UAAU9M,CAAQ,yBAAyBA,CAAQ,mBACpE,OACA0gB,EAAW,SACX,OACA,CACE,CAAE,KAAMlhB,EAAQ,OAAO,CAAC,EAAE,SAAU,KAAMkhB,EAAW,GAAI,EACzD,CAAE,KAAMlhB,EAAQ,OAAO,CAAC,EAAE,SAAU,KAAMkhB,EAAW,GAAI,CAC3D,EACA,CACE,CAAE,KAAM,MAAO,KAAM1gB,CAAmC,EACxD,CAAE,KAAM,MAAO,KAAMA,CAAmC,CAC1D,CACF,EACA,CAAE,OAAQ,CAAC,CAAC,CAAE,CAChB,CACF,EAEastB,GAAQ9tB,GAAkC,CACrDA,EAAQ,QAAQktB,EAA6BltB,EAAQ,OAAO,CAAC,EAAG,OAAQ,MAAM,CAAC,CACjF,EAEa+tB,GAAO/tB,GAAkC,CACpDA,EAAQ,QAAQktB,EAA6BltB,EAAQ,OAAO,CAAC,EAAG,MAAO,KAAK,CAAC,CAC/E,EAEaguB,GAAQhuB,GAAkC,CACrDA,EAAQ,QAAQktB,EAA6BltB,EAAQ,OAAO,CAAC,EAAG,OAAQ,MAAM,CAAC,CACjF,EAMaiuB,GAAwB/M,GACnClH,EAA4BkH,CAA+B,EAEhDgN,GAAM,CAACluB,EAAyBkhB,IAAsC,CACjF,IAAM1gB,EAAW8Z,GAA0Bta,EAAQ,OAAO,CAAC,EAAE,QAAQ,EACrEA,EAAQ,QACNktB,EACEltB,EAAQ,OAAO,CAAC,EAChB,MACCsN,GAAM,YAAYA,CAAC,IACpB;AAAA,uBACiB9M,CAAQ,IAAI0gB,EAAW,KAAK;AAAA;AAAA,kBAEjC1gB,CAAQ,QAAQA,CAAQ;AAAA;AAAA;AAAA;AAAA,wBAIlBA,CAAQ,cAAcA,CAAQ;AAAA;AAAA,KAGhD0gB,EAAW,QACb,CACF,CACF,EAEaiN,GAAU,CAACwC,EAAU,QAAU;AAAA,YAChCA,CAAO;AAAA,YACPA,CAAO;AAAA,YACPA,CAAO;AAAA,YACPA,CAAO;AAAA,YACPA,CAAO;AAAA,YACPA,CAAO;AAAA;AAAA,sBAEGA,CAAO,cAAcA,CAAO;AAAA;AAAA;AAAA;AAAA,GAMrCvC,GAAOpuB,GAAkC,CACpD,IAAMQ,EAAW8Z,GAA0Bta,EAAQ,OAAO,CAAC,EAAE,QAAQ,EACrEA,EAAQ,QAAQktB,EAA6BltB,EAAQ,OAAO,CAAC,EAAG,MAAQsN,GAAM,YAAYA,CAAC,IAAK6gB,GAAQ3tB,CAAQ,CAAC,CAAC,CACpH,EAEa6tB,GAAOruB,GAAkC,CACpDA,EAAQ,QAAQktB,EAA6BltB,EAAQ,OAAO,CAAC,EAAG,MAAO,KAAK,CAAC,CAC/E,EAEasuB,GAAStuB,GAAkC,CACtDA,EAAQ,QAAQktB,EAA6BltB,EAAQ,OAAO,CAAC,EAAG,QAAS,OAAO,CAAC,CACnF,EAEauuB,GAAQvuB,GAAkC,CACrD,IAAMQ,EAAW8Z,GAA0Bta,EAAQ,OAAO,CAAC,EAAE,QAAQ,EACrEA,EAAQ,QACNktB,EACEltB,EAAQ,OAAO,CAAC,EAChB,OACCsN,GAAM,SAASA,CAAC,sBAAsBA,CAAC,0BACxC6gB,GAAQ3tB,CAAQ,CAClB,CACF,CACF,EAEaguB,GAAY,CAACxuB,EAAyBkhB,IAAsC,CACvF,IAAM1gB,EAAW8Z,GAA0Bta,EAAQ,OAAO,CAAC,EAAE,QAAQ,EACrEA,EAAQ,QACNktB,EACEltB,EAAQ,OAAO,CAAC,EAChB,YACCsN,GAAM,8BAA8BA,CAAC,KAAKA,CAAC,KAAKA,CAAC,YAAY9M,CAAQ,UACtE,6BAA6BA,CAAQ,IAAI0gB,EAAW,KAAK,KACzDA,EAAW,QACb,CACF,CACF,EAEauN,GAAOzuB,GAAkC,CACpDA,EAAQ,QAAQktB,EAA6BltB,EAAQ,OAAO,CAAC,EAAG,MAAQsN,GAAM,IAAIA,CAAC,EAAE,CAAC,CACxF,EAEaohB,GAAO1uB,GAAkC,CACpDA,EAAQ,QAAQktB,EAA6BltB,EAAQ,OAAO,CAAC,EAAG,MAAQsN,GAAM,IAAIA,CAAC,EAAE,CAAC,CACxF,EAEaqhB,GAAc3uB,GAAkC,CAC3DA,EAAQ,QAAQktB,EAA6BltB,EAAQ,OAAO,CAAC,EAAG,aAAesN,GAAM,OAAOA,CAAC,EAAE,CAAC,CAClG,EAEashB,GAAQ5uB,GAAkC,CACrD,IAAMQ,EAAW8Z,GAA0Bta,EAAQ,OAAO,CAAC,EAAE,QAAQ,EACrEA,EAAQ,QACNktB,EACEltB,EAAQ,OAAO,CAAC,EAChB,OACCsN,GAAM,eAAe9M,CAAQ,WAAW8M,CAAC,KAAKA,CAAC,WAAW9M,CAAQ,SACrE,CACF,CACF,EAEaquB,GAAW7uB,GAAkC,CACxDA,EAAQ,QAAQktB,EAA6BltB,EAAQ,OAAO,CAAC,EAAG,UAAYsN,GAAM,sBAAsBA,CAAC,KAAK,CAAC,CACjH,EAOawhB,GAA8B5N,GACzClH,EACEkH,CAIF,EAEW6N,GAAc,CAAC/uB,EAAyBkhB,IAA4C,CAC/F,IAAM1gB,EAAW8Z,GAA0Bta,EAAQ,OAAO,CAAC,EAAE,QAAQ,EACrEA,EAAQ,QACNktB,EACEltB,EAAQ,OAAO,CAAC,EAChB,cACCsN,GACC,YAAY9M,CAAQ,oBAAoBA,CAAQ,WAAW0gB,EAAW,KAAK,MAAM5T,CAAC,WAAW9M,CAAQ,KAAK0gB,EAAW,IAAI,MAC3H,OACAA,EAAW,QACb,CACF,CACF,EAEa8N,GAAOhvB,GAAkC,CACpDA,EAAQ,QAAQktB,EAA6BltB,EAAQ,OAAO,CAAC,EAAG,MAAO,KAAK,CAAC,CAC/E,EAEaivB,GAAQjvB,GAAkC,CACrDA,EAAQ,QAAQktB,EAA6BltB,EAAQ,OAAO,CAAC,EAAG,OAAQ,MAAM,CAAC,CACjF,EAEakvB,GAAQlvB,GAAkC,CACrDA,EAAQ,QAAQktB,EAA6BltB,EAAQ,OAAO,CAAC,EAAG,OAAQ,MAAM,CAAC,CACjF,EAEamvB,GAAOnvB,GAAkC,CACpDA,EAAQ,QAAQktB,EAA6BltB,EAAQ,OAAO,CAAC,EAAG,MAAO,KAAK,CAAC,CAC/E,EAEaovB,GAAkB9hB,GAAc,QAAQA,CAAC,yBAAyBA,CAAC,2BAA2BA,CAAC,MAE/F+hB,GAAQrvB,GAAkC,CAErDA,EAAQ,QAAQktB,EAA6BltB,EAAQ,OAAO,CAAC,EAAG,OAAQovB,EAAc,CAAC,CACzF,EAEaE,GAAe,CAACqB,EAAU,QAAU;AAAA,qBAC5BA,CAAO;AAAA,qBACPA,CAAO;AAAA,qBACPA,CAAO;AAAA;AAAA,oBAERA,CAAO,cAAcA,CAAO;AAAA,WACrCvB,GAAe,GAAG,CAAC;AAAA;AAAA,EAIjBG,GAAsB/d,GACjC,uCAAuCA,CAAC,qBAAqBA,CAAC,MAAMA,CAAC,uBAAuBA,CAAC,GAElFge,GAAYxvB,GAAkC,CACzD,IAAMQ,EAAW8Z,GAA0Bta,EAAQ,OAAO,CAAC,EAAE,QAAQ,EACrEA,EAAQ,QACNktB,EACEltB,EAAQ,OAAO,CAAC,EAChB,WACAuvB,GACAD,GAAa9uB,CAAQ,EACrB,OACAR,EAAQ,OAAO,CAAC,EAAE,QACpB,CACF,CACF,EAEayvB,GAAkB,CAACzvB,EAAyBkhB,IAAwC,CAC/F,IAAM1gB,EAAW8Z,GAA0Bta,EAAQ,OAAO,CAAC,EAAE,QAAQ,EACrE,OAAAA,EAAQ,QACNktB,EACEltB,EAAQ,OAAO,CAAC,EAChB,kBACCsN,GAAM,eAAe9M,CAAQ,WAAW8M,CAAC,KAAKA,CAAC,8BAChD,wCAAwC9M,CAAQ,KAAK0gB,EAAW,KAAK,KACrEA,EAAW,QACb,CACF,EACO,CACT,EAEawO,GAAO1vB,GAAkC,CACpDA,EAAQ,QAAQktB,EAA6BltB,EAAQ,OAAO,CAAC,EAAG,MAAO,KAAK,CAAC,CAC/E,EAEa2vB,GAAgB,CAACgB,EAAiBlH,IAAkB;AAAA,qBAC5CkH,CAAO,KAAKlH,CAAK;AAAA,cACxBkH,CAAO;AAAA,eACNA,CAAO;AAAA;AAAA,6BAEOA,CAAO,cAAcA,CAAO;AAAA;AAAA,kBAEvCA,CAAO;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EAYZf,GAAuBpe,GAAc,mBAAmBA,CAAC,IAEzDqe,GAAY,CAAC7vB,EAAyBkhB,IAAsC,CACvF,IAAM0P,EAAQtW,GAA0Bta,EAAQ,OAAO,CAAC,EAAE,QAAQ,EAClEA,EAAQ,QACNktB,EACEltB,EAAQ,OAAO,CAAC,EAChB,YACA4vB,GACAD,GAAciB,EAAO1P,EAAW,KAAK,EACrCA,EAAW,SACXlhB,EAAQ,OAAO,CAAC,EAAE,QACpB,CACF,CACF,IC5cA,IAUMof,GAkBAyR,GAyCOC,GArEbC,GAAAh2B,EAAA,kBAIAgV,IAGAqL,IACA0U,KAEM1Q,GAAkBpZ,GAAwC,CAC9D,GAAIA,EAAO,CAAC,EAAE,KAAK,SAAW,EAC5B,MAAM,IAAI,MAAM,gCAAgC,EAGlD,GAAI,CAAC,CAAC,KAAM,KAAM,KAAK,EAAE,SAASA,EAAO,CAAC,EAAE,KAAK,CAAC,CAAC,EACjD,MAAM,IAAI,MAAM,4CAA4C,EAG9D,GAAIA,EAAO,CAAC,EAAE,KAAK,SAAW,EAC5B,MAAM,IAAI,MAAM,uCAAuC,EAGzD,GAAIA,EAAO,CAAC,EAAE,KAAK,CAAC,IAAMA,EAAO,CAAC,EAAE,KAAK,CAAC,EACxC,MAAM,IAAI,MAAM,mDAAmD,CAEvE,EAEM6qB,GAAkC7qB,GAA+C,CACrF,IAAMwa,EAAcxa,EAAO,CAAC,EAAE,KAAK,MAAM,EACzCwa,EAAY,CAAC,EAAIA,EAAY,CAAC,EAAI,EAElC,IAAMT,EAAQjF,EAAc,QAAS9U,EAAO,CAAC,EAAE,SAAUA,EAAO,CAAC,EAAE,KAAM,CAAC,EACpEghB,EAAOlM,EAAc,OAAQ9U,EAAO,CAAC,EAAE,SAAU,CAACA,EAAO,CAAC,EAAE,KAAK,CAAC,CAAC,EAAG,CAAC,EACvEgX,EAASjC,EAAe,SAAU/U,EAAO,CAAC,EAAE,SAAUwa,EAAa,CAAC,EAEpEM,EAAapR,EAAU,KAAK8Q,CAAW,EAAI,EAC3ChgB,EAAW6Z,GAA4BrU,EAAO,CAAC,EAAE,QAAQ,EAsB/D,MAAO,CACL,KAAM,gBACN,WAAY,KAAO,CACjB,QAAS,CAAC,CAAE,KAAMwa,EAAa,SAAUxa,EAAO,CAAC,EAAE,QAAS,CAAC,EAC7D,cAAe,CAAE,EAAG,KAAK,KAAK8a,EAAa,EAAuB,CAAE,CACtE,GACA,gBA1BuBD,GAA+B;AAAA;AAAA,yBAEjC7a,EAAO,CAAC,EAAE,KAAK,CAAC,EAAI,EAAI,CAAC;AAAA;AAAA,IAE9C6a,EAAa,iBAAiBd,EAAOiH,EAAMhK,CAAM,CAAC;AAAA;AAAA,IAElDmR,GAAQ3tB,CAAQ,CAAC;AAAA;AAAA,IAEjBqgB,EAAa,UAAU,CAAC;AAAA,MACtBA,EAAa,sCAAsCC,CAAU,CAAC;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,MAQ9D9D,EAAO,YAAY,aAAc,uBAAuB,CAAC;AAAA,IAU7D,CACF,EAEa8T,GAAiB9wB,GAAkC,CAC9Dof,GAAepf,EAAQ,MAAM,EAC7BA,EAAQ,QAAQ6wB,GAA+B7wB,EAAQ,MAAM,CAAC,CAChE,ICxEA,IAoBMgxB,GAoHAC,GA0FAC,GAqBOC,GAIAC,GAIAC,GAWAC,GAIAC,GAwBAC,GAIAC,GAWAC,GAWAC,GAWAC,GA3UbC,GAAA92B,EAAA,kBAGAkS,IAEA8C,IAGAqL,IAYM4V,GAA8B,CAClCnQ,EACAiR,EACAC,EACAC,EACAC,EACAC,EACAC,EACAnC,EACAoC,EACAC,EACAC,EACArC,IACG,CACH,IAAIsC,EACAC,EACA,OAAOxC,GAAa,SACtBuC,EAAmBC,EAAmB,CAACllB,EAAGC,IAAM,GAAGyiB,CAAQ,KAAK1iB,CAAC,MAAMC,CAAC,KAC/D,OAAOyiB,GAAa,WAC7BuC,EAAmBC,EAAmBxC,GAEtCuC,EAAmBvC,EAAS,OAC5BwC,EAAmBxC,EAAS,QAG9B,IAAMhT,EAASjC,EAAe,aAAcuX,EAAYN,EAAW,OAAQ,CAAC,EACtE1kB,EAAIwN,EAAc,QAASsX,EAAON,EAAM,OAAQ,CAAC,EACjD,EAAIhX,EAAc,QAASuX,EAAON,EAAM,OAAQ,CAAC,EAEnDU,EACJ,GAAIR,EACF,GAAIC,EAAa,CACf,IAAMQ,EAAgBhjB,EAAU,KAAKoiB,CAAK,IAAM,EAC1Ca,EAAgBjjB,EAAU,KAAKqiB,CAAK,IAAM,EAC1Ca,EAAuBd,EAAM,OAAS,GAAKA,EAAMA,EAAM,OAAS,CAAC,EAAI,IAAM,EAC3Ee,EAAuBd,EAAM,OAAS,GAAKA,EAAMA,EAAM,OAAS,CAAC,EAAI,IAAM,EAC7EW,GAAiBC,EACnBF,EAAazV,EAAO,YAClB,aACAwV,EACEE,EAAgB,GAAGplB,EAAE,KAAK,KAAK,IAAIA,EAAE,YAAY,GAAG,CAAC,MAAQA,EAAE,YAAY,YAAY,EACvFqlB,EAAgB,GAAG,EAAE,KAAK,KAAK,IAAI,EAAE,YAAY,GAAG,CAAC,MAAQ,EAAE,YAAY,YAAY,CACzF,CACF,EAEAF,EAAa;AAAA,kCACazV,EAAO,gBAAgB,iBAAiB,CAAC;AAAA,4BAC/C1P,EAAE,2BAA2B,gBAAiB0P,CAAM,CAAC;AAAA,4BACrD,EAAE,2BAA2B,gBAAiBA,CAAM,CAAC;AAAA,cACnEA,EAAO,YACP,aACAwV,EACEL,GAA+BS,EAC3BtlB,EAAE,YAAY,cAAc,EAC5B,GAAGA,EAAE,KAAK,KAAK,IAAIA,EAAE,YAAY,cAAc,CAAC,kBACpD6kB,GAA+BU,EAC3B,EAAE,YAAY,cAAc,EAC5B,GAAG,EAAE,KAAK,KAAK,IAAI,EAAE,YAAY,cAAc,CAAC,iBACtD,CACF,CAAC;AAAA,WAGT,MACEJ,EAAazV,EAAO,YAClB,aACAwV,EAAiBllB,EAAE,YAAY,YAAY,EAAG,EAAE,YAAY,YAAY,CAAC,CAC3E,MAEG,CACL,GAAI,CAAC4kB,EACH,MAAM,IAAI,MAAM,sFAAsF,EAGxG,IAAMY,EAAmB,CAACC,EAAgBvhB,EAAWwhB,EAAW,KAAO,CACrE,IAAMC,EAAc,eAAezhB,CAAC,eAAeA,CAAC,IAC9C0hB,EAAc,eAAe1hB,CAAC,eAAeA,CAAC,IACpD,MAAO;AAAA,+BACkBA,CAAC,MAAMwL,EAAO,gBAAgB,qBAAqBxL,CAAC,GAAG,CAAC;AAAA,yBAC9DA,CAAC,MAAMlE,EAAE,2BAA2B,gBAAgBkE,CAAC,GAAIwL,CAAM,CAAC;AAAA,yBAChExL,CAAC,MAAM,EAAE,2BAA2B,gBAAgBA,CAAC,GAAIwL,CAAM,CAAC;AAAA,wBACjExL,CAAC,aAAaA,CAAC;AAAA,wBACfA,CAAC,aAAaA,CAAC;AAAA,4BACXA,CAAC,aAAaA,CAAC;AAAA,4BACfA,CAAC,aAAaA,CAAC;AAAA,cAC7BuhB,CAAM,IAAIvhB,CAAC,OAAOwhB,CAAQ,IAAIT,EAAiBU,EAAaC,CAAW,CAAC;AAAA,WAElF,EACIZ,IAAe,EACjBG,EAAa;AAAA;AAAA,cAELK,EAAiB,OAAQ,EAAG,KAAK,CAAC;AAAA,cAClCA,EAAiB,OAAQ,EAAG,KAAK,CAAC;AAAA,cAClCA,EAAiB,OAAQ,EAAG,KAAK,CAAC;AAAA,cAClCA,EAAiB,OAAQ,EAAG,KAAK,CAAC;AAAA,uGAG1CL,EAAa;AAAA,cACLK,EAAiB,yBAA0B,CAAC,CAAC;AAAA,cAC7CA,EAAiB,yBAA0B,CAAC,CAAC;AAAA,cAC7CA,EAAiB,yBAA0B,CAAC,CAAC;AAAA,cAC7CA,EAAiB,yBAA0B,CAAC,CAAC;AAAA,WAGzD,CAEA,MAAO;AAAA,UACCjS,EAAa,gBAAgB,WAAY,KAAK,EAAE,iBAAiBvT,EAAG,EAAG0P,CAAM,CAAC;AAAA;AAAA,UAE9EiT,GAA4B,EAAE;AAAA;AAAA,UAE9BpP,EAAa,UAAU,CAAC;AAAA,UACxBA,EAAa,sCAAsC,mBAAmB,CAAC;AAAA,UACvE4R,CAAU;AAAA,QAEpB,EAEMxB,GAA4B,CAChCj2B,EACA+nB,EACAzV,EACAC,EACAyiB,EACAC,EACAhN,EAAyB3V,EAAE,WACX,CAChB,IAAM6lB,EAAQ7lB,EAAE,KAAK,IAAKkE,GAAM,OAAOA,CAAC,GAAK,CAAC,EACxC4hB,EAAQ7lB,EAAE,KAAK,IAAKiE,GAAM,OAAOA,CAAC,GAAK,CAAC,EACxC6hB,EAAc,CAAC3jB,EAAU,SAASyjB,EAAOC,CAAK,EAChD5S,EAAc2S,EACdrS,EAAapR,EAAU,KAAKyjB,CAAK,EAEjClB,EAAY,GACZE,EAA8B,GAG5BmB,EAAc,CAACD,CAAW,EAChC,GAAIA,EAAa,CACf,IAAME,EAAkB9jB,GAAc,UAAU0jB,EAAOC,EAAO,EAAK,EACnE,GAAI,CAACG,EACH,MAAM,IAAI,MAAM,8CAA8C,EAEhE/S,EAAc+S,EAAgB,MAAM,EACpCzS,EAAapR,EAAU,KAAK8Q,CAAW,EACvC,IAAMkS,EAAgBhjB,EAAU,KAAKyjB,CAAK,IAAM,EAC1CR,EAAgBjjB,EAAU,KAAK0jB,CAAK,IAAM,EAC1CR,EAAuBO,EAAM,OAAS,GAAKA,EAAMA,EAAM,OAAS,CAAC,EAAI,IAAM,EAC3EN,EAAuBO,EAAM,OAAS,GAAKA,EAAMA,EAAM,OAAS,CAAC,EAAI,IAAM,EACjFE,EAAY,KAAKZ,CAAa,EAC9BY,EAAY,KAAKX,CAAa,EAC9BW,EAAY,KAAKV,CAAoB,EACrCU,EAAY,KAAKT,CAAoB,EAErC,IAAIW,EAAkB,EACtB,QAASp4B,EAAI,EAAGA,EAAIolB,EAAY,OAAQplB,IAAK,CAC3C,IAAMq4B,EAAON,EAAMA,EAAM,OAAS/3B,CAAC,EAC7Bs4B,EAAON,EAAMA,EAAM,OAASh4B,CAAC,EACnC,GAAIq4B,IAASC,EACXF,GAAmBC,MAEnB,MAEJ,CACID,EAAkB,IAAM,GAC1BrB,EAA8B,GAC9BF,EAAY,KACHS,GAAiBC,GAAiBC,GAAwBC,KACnEZ,EAAY,GAEhB,MAEEA,EAAY,GAEd,OAAAqB,EAAY,KAAKrB,CAAS,EAEnB,CACL,KAAAj3B,EACA,YAAa,CACX,KAAM+nB,EAAWuQ,EAAY,IAAK9hB,GAAMA,EAAE,SAAS,CAAC,EAAE,KAAK,GAAG,EAC9D,kBAAmB,CAAC,OAAQ,MAAM,CACpC,EACA,gBAAkBqP,GAChBmQ,GACEnQ,EACAsS,EACAC,EACA5S,EACAyR,EACAoB,EACAlB,EACAnC,EACA1iB,EAAE,SACFC,EAAE,SACF0V,EACAgN,CACF,EACF,WAAY,KAAO,CACjB,QAAS,CAAC,CAAE,KAAMzP,EAAa,SAAUyC,CAAe,CAAC,EACzD,cAAe,CAAE,EAAG,KAAK,KAAKnC,EAAa,GAA0B,CAAsB,CAAE,EAC7F,gBAAiB,CACf,CAAE,QAAuB,KAAM,KAAK,KAAKpR,EAAU,KAAK8Q,CAAW,EAAI,CAAC,CAAE,EAC1E,GAAGjG,EAA2B4Y,EAAOC,EAAO5S,CAAW,CACzD,CACF,EACF,CACF,EAEM0Q,GAAc,CAClBlxB,EACAhF,EACAg1B,EACAC,EACAlN,EACAE,IACS,CACTjjB,EAAQ,QACNixB,GACEj2B,EACA+nB,GAAY,GACZ/iB,EAAQ,OAAO,CAAC,EAChBA,EAAQ,OAAO,CAAC,EAChBgwB,EACAC,EACAhN,CACF,CACF,CACF,EAEakO,GAAOnxB,GAAkC,CACpDkxB,GAAYlxB,EAAS,MAAO,CAACsN,EAAGC,IAAM,GAAGD,CAAC,IAAIC,CAAC,EAAE,CACnD,EAEa6jB,GAAOpxB,GAAkC,CACpDkxB,GAAYlxB,EAAS,MAAO,CAACsN,EAAGC,IAAM,GAAGD,CAAC,IAAIC,CAAC,EAAE,CACnD,EAEa8jB,GAASrxB,GAAkC,CACtDkxB,GACElxB,EACA,QACA,CAAE,OAAQ,CAACsN,EAAGC,IAAM,OAAOD,CAAC,KAAKC,CAAC,IAAK,OAAQ,CAACD,EAAGC,IAAM,aAAaD,CAAC,KAAKC,CAAC,GAAI,EACjF,OACA,QAEF,CACF,EAEa+jB,GAAOtxB,GAAkC,CACpDkxB,GAAYlxB,EAAS,MAAO,CAACsN,EAAGC,IAAM,GAAGD,CAAC,IAAIC,CAAC,EAAE,CACnD,EAEagkB,GAAOvxB,GAAkC,CACpD,IAAMU,EAAOoa,EAAc,QAAS9a,EAAQ,OAAO,CAAC,EAAE,SAAUA,EAAQ,OAAO,CAAC,EAAE,IAAI,EAAE,KAAK,MAE7FkxB,GACElxB,EACA,MACA,CAAE,OAAQ,CAACsN,EAAGC,IAAM,cAAcD,CAAC,IAAIC,CAAC,IAAK,OAAQ,CAACD,EAAGC,IAAM,qBAAqBD,CAAC,IAAIC,CAAC,GAAI,EAC9F;AAAA,wBACoB7M,CAAI,SAASA,CAAI,QAAQA,CAAI;AAAA,iBACpCA,CAAI;AAAA,iBACJA,CAAI;AAAA,uBACEA,CAAI;AAAA,iBACVA,CAAI;AAAA;AAAA,+BAEUA,CAAI,6BAA6BA,CAAI,qBAAqBA,CAAI,IAZ1EA,IAAS,MAAQ,QAAU,EAY2D;AAAA;AAAA,oCAErEA,CAAI,eAAeA,CAAI,cAAcA,CAAI;AAAA;AAAA,oBAEzDA,CAAI;AAAA;AAAA,OAGtB,CACF,EAEa8wB,GAAOxxB,GAAkC,CACpDkxB,GAAYlxB,EAAS,MAAO,CAACsN,EAAGC,IAAM,GAAGD,CAAC,IAAIC,CAAC,EAAE,CACnD,EAEakkB,GAAWzxB,GAAkC,CACxDkxB,GACElxB,EACA,UACA,CAAE,OAAQ,CAACsN,EAAGC,IAAM,OAAOD,CAAC,IAAIC,CAAC,IAAK,OAAQ,CAACD,EAAGC,IAAM,aAAaD,CAAC,IAAIC,CAAC,GAAI,EAC/E,OACA,QAEF,CACF,EAEamkB,GAAQ1xB,GAAkC,CACrDkxB,GACElxB,EACA,OACA,CAAE,OAAQ,CAACsN,EAAGC,IAAM,OAAOD,CAAC,IAAIC,CAAC,IAAK,OAAQ,CAACD,EAAGC,IAAM,aAAaD,CAAC,IAAIC,CAAC,GAAI,EAC/E,OACA,QAEF,CACF,EAEaokB,GAAkB3xB,GAAkC,CAC/DkxB,GACElxB,EACA,iBACA,CAAE,OAAQ,CAACsN,EAAGC,IAAM,OAAOD,CAAC,KAAKC,CAAC,IAAK,OAAQ,CAACD,EAAGC,IAAM,aAAaD,CAAC,KAAKC,CAAC,GAAI,EACjF,OACA,QAEF,CACF,EAEaqkB,GAAe5xB,GAAkC,CAC5DkxB,GACElxB,EACA,cACA,CAAE,OAAQ,CAACsN,EAAGC,IAAM,OAAOD,CAAC,KAAKC,CAAC,IAAK,OAAQ,CAACD,EAAGC,IAAM,aAAaD,CAAC,KAAKC,CAAC,GAAI,EACjF,OACA,QAEF,CACF,ICpVA,IAeM6R,GA4BAuU,GAWAC,GAmBAC,GAuEOC,GAiBAC,GAjKbC,GAAAj5B,EAAA,kBAGAkS,IAEA8C,IACAkK,KAGAmB,IAMMgE,GAAiB,CAACpZ,EAA+BkL,IAAuB,CAC5E,GAAI,CAAClL,GAAUA,EAAO,OAAS,EAC7B,MAAM,IAAI,MAAM,gBAAgB,EAElC,IAAMiuB,EAAiB,EACjBC,EAAiBluB,EAAOiuB,CAAc,EACtCE,EAAYD,EAAe,SAC3BrjB,EAAYqjB,EAAe,KAAK,OACtCluB,EAAO,QAAQ,CAAC+Z,EAAO3kB,IAAM,CAC3B,GAAIA,IAAM64B,EAIV,IAAIlU,EAAM,WAAaoU,EACrB,MAAM,IAAI,MAAM,kCAAkC,EAGpD,GAAIpU,EAAM,KAAK,SAAWlP,EACxB,MAAM,IAAI,MAAM,0CAA0C,EAE5DkP,EAAM,KAAK,QAAQ,CAACve,EAAKpG,IAAM,CAC7B,GAAIA,IAAM8V,GAAQ1P,IAAQ0yB,EAAe,KAAK94B,CAAC,EAC7C,MAAM,IAAI,MAAM,kCAAkC,CAEtD,CAAC,EACH,CAAC,CACH,EAEMu4B,GAA0B,CAACS,EAAyBC,IAAwC;AAAA;AAAA,wCAE1DD,CAAe,MAAMC,CAAmB;AAAA,gCAChDD,CAAe;AAAA;AAAA;AAAA;AAAA;AAAA,aAKlCA,CAAe;AAAA,KAGtBR,GAAmB,CAAC5tB,EAAkCgX,IAA0B,CACpF,IAAMoX,EAAkBpuB,EAAO,OAEzBsuB,EAAsB,CAAC,EAC7B,QAASl5B,EAAI,EAAGA,EAAIg5B,EAAiB,EAAEh5B,EAAG,CACxC,IAAMm5B,EAAgBvX,EAAO,YAAY,aAAchX,EAAO5K,CAAC,EAAE,aAAa,SAAS,CAAC,EACpFg5B,IAAoB,EACtBE,EAAU,KAAKC,CAAa,EACnBn5B,IAAM,EACfk5B,EAAU,KAAK,qBAAqBl5B,CAAC,QAAQm5B,CAAa,IAAI,EACrDn5B,IAAMg5B,EAAkB,EACjCE,EAAU,KAAK,UAAUC,CAAa,IAAI,EAE1CD,EAAU,KAAK,0BAA0Bl5B,CAAC,OAAOm5B,CAAa,IAAI,CAEtE,CACA,OAAOD,EAAU,KAAK;AAAA,CAAI,CAC5B,EAEMT,GAA0B,CAC9B7tB,EACAwuB,EACAhU,EACAhgB,IACgB,CAChB,IAAMsgB,EAAapR,EAAU,KAAK8Q,CAAW,EAEvCiU,EAAmB,IAAI,MAAczuB,EAAO,MAAM,EAClDgkB,EAAY,IAAI,MAAqBhkB,EAAO,MAAM,EAEpD0uB,EAAc,EACZjM,EAAwD,CAAC,EACzDkM,EAAa,CAAC,EACdrZ,EAAoC,CAAC,CAAE,QAAuB,KAAMwF,CAAW,CAAC,EACtF,QAAS1lB,EAAI,EAAGA,EAAI4K,EAAO,OAAQ,EAAE5K,EACnCs5B,GAAe1uB,EAAO5K,CAAC,EAAE,KAAKo5B,CAAY,EAC1CC,EAAiBr5B,CAAC,EAAIs5B,EACtBC,EAAW,KAAK3uB,EAAO5K,CAAC,EAAE,KAAK,MAAM,EACrC4uB,EAAU5uB,CAAC,EAAI0f,EAAc,QAAQ1f,CAAC,GAAIoF,EAAUm0B,EAAWv5B,CAAC,CAAC,EACjEqtB,EAAkB,KAAK,MAAM,EAC7BnN,EAAgB,KAAK,CAAE,QAAuB,KAAMmZ,EAAiBr5B,CAAC,CAAE,CAAC,EAE3E,QAASA,EAAI,EAAGA,EAAI4K,EAAO,OAAQ,EAAE5K,EACnCkgB,EAAgB,KAAK,GAAGf,EAA2BvU,EAAO5K,CAAC,EAAE,IAAI,CAAC,EAEpEkgB,EAAgB,KAAK,GAAGf,EAA2BiG,CAAW,CAAC,EAE/D,IAAMxD,EAASjC,EAAe,SAAUva,EAAUggB,EAAY,MAAM,EAC9DoU,EAAc5X,EAAO,WAAW,UAAWwX,CAAY,EACvDH,EAAsB,MAAM,KAAK,MAAMI,EAAiB,MAAM,EAAE,KAAK,CAAC,EACzE,IAAKr5B,GAAM,4BAA4BA,CAAC,EAAE,EAC1C,KAAK,GAAG,EACLwlB,EAAmBC,GAA+B;AAAA;AAAA,KAErD,IAAM,CACPA,EAAa,gBAAgB,aAAc,KAAK,EAChD,QAASzlB,EAAI,EAAGA,EAAI4K,EAAO,OAAQ5K,IACjCylB,EAAa,gBAAgB,mBAAmBzlB,CAAC,GAAI,KAAK,EAE5D,OAAOylB,EAAa,iBAAiB,GAAGmJ,EAAWhN,CAAM,CAC3D,GAAG,CAAC;AAAA;AAAA,IAEF2W,GAAwBc,EAAiB,OAAQJ,CAAmB,CAAC;AAAA;AAAA,IAErExT,EAAa,UAAU,CAAC;AAAA,MACtBA,EAAa,sCAAsC,qBAAqB,CAAC;AAAA;AAAA,oBAE3D7D,EAAO,gBAAgB,YAAY,CAAC;AAAA;AAAA,2CAEb4X,CAAW;AAAA;AAAA,0CAEZH,EAAiB,MAAM,MAAMJ,CAAmB;AAAA,QAClFO,CAAW;AAAA;AAAA;AAAA,MAGbhB,GAAiB5J,EAAWhN,CAAM,CAAC;AAAA,KAGvC,MAAO,CACL,KAAM,SACN,YAAa,CAAE,KAAM,GAAGwX,CAAY,GAAI,kBAAA/L,CAAkB,EAC1D,WAAY,KAAO,CACjB,QAAS,CAAC,CAAE,KAAMjI,EAAa,SAAAhgB,CAAS,CAAC,EACzC,cAAe,CAAE,EAAG,KAAK,KAAKsgB,EAAa,EAAuB,CAAE,EACpE,gBAAAxF,CACF,GACA,gBAAAsF,CACF,CACF,EAEakT,GAAS,CAAC9zB,EAAyBkhB,IAAuC,CACrF,IAAMlb,EAAShG,EAAQ,OACjB8f,EAAa9Z,EAAO,CAAC,EAAE,KACvBwuB,EAAe9kB,EAAU,cAAcwR,EAAW,KAAMpB,EAAW,MAAM,EAC/EV,GAAepZ,EAAQwuB,CAAY,EACnC,IAAMhU,EAAcV,EAAW,MAAM,EACrCU,EAAYgU,CAAY,EAAIxuB,EAAO,OACjC,CAAC6uB,EAAK9U,IAAU8U,GAAO9U,EAAM,KAAK,OAASyU,EAAezU,EAAM,KAAKyU,CAAY,EAAI,GACrF,CACF,EAEA,IAAMM,EAAiB9uB,EAAO,OAAQ+Z,GAAUrQ,EAAU,KAAKqQ,EAAM,IAAI,EAAI,CAAC,EAC9E/f,EAAQ,QAAQ6zB,GAAwBiB,EAAgBN,EAAchU,EAAaxa,EAAO,CAAC,EAAE,QAAQ,EAAG,CACtG,OAAQ8uB,CACV,CAAC,CACH,EAEaf,GAAyB7S,GACpClH,EAA4B,CAAE,KAAMkH,EAAW,IAAe,CAAC,IClKjE,IAiBa6T,GAgCAC,GAmBAC,GAUAC,GA9EbC,GAAAp6B,EAAA,kBAGAkS,IACA8C,IAaaglB,GAAuB,CAClC7T,EACArF,EACAuZ,EAAW,QACA,CACX,OAAQlU,EAAW,WAAY,CAC7B,IAAK,OACH,MAAO,sBAAsBrF,CAAS,UACxC,IAAK,UACH,MAAO,YAAYA,CAAS,YAAYA,CAAS,yBACnD,IAAK,OACH,MAAO,wBAAwBA,CAAS,IAAIuZ,CAAQ,yBAAyBvZ,CAAS,IACpFuZ,CACF,yBACF,IAAK,cACH,MAAO,eAAevZ,CAAS,cAAcA,CAAS,UAAUuZ,CAAQ,8BACtEA,CACF,qBACF,IAAK,YACH,MAAO,kBAAkBA,CAAQ,6CAA6CvZ,CAAS,UACzF,IAAK,OACH,MAAO;AAAA;AAAA,UAGT,IAAK,GACH,MAAO,GAET,QACE,MAAM,IAAI,MAAM,0BAA0BqF,EAAW,UAAU,EAAE,CACrE,CACF,EAEa8T,GAA+B,CAC1C9T,EACAmU,IACG,CACCnU,EAAW,aAAe,OAC5BmU,EAAe,KACb,CAAE,OAAsB,KAAMnU,EAAW,OAAS,EAClD,CAAE,OAAsB,KAAMA,EAAW,OAAS,CACpD,EACSA,EAAW,aAAe,cACnCmU,EAAe,KACb,CAAE,OAAsB,KAAMnU,EAAW,KAAO,EAChD,CAAE,OAAsB,KAAMA,EAAW,IAAM,CACjD,EACSA,EAAW,aAAe,aACnCmU,EAAe,KAAK,CAAE,OAAsB,KAAMnU,EAAW,KAAO,CAAC,CAEzE,EAEa+T,GAA2B,CAAC/T,EAA0C6H,IAAgC,CAC7G7H,EAAW,aAAe,OAC5B6H,EAAS,KAAK,CAAE,KAAM,WAAY,KAAM,KAAM,EAAG,CAAE,KAAM,WAAY,KAAM,KAAM,CAAC,EACzE7H,EAAW,aAAe,cACnC6H,EAAS,KAAK,CAAE,KAAM,QAAS,KAAM,KAAM,EAAG,CAAE,KAAM,OAAQ,KAAM,KAAM,CAAC,EAClE7H,EAAW,aAAe,aACnC6H,EAAS,KAAK,CAAE,KAAM,QAAS,KAAM,KAAM,CAAC,CAEhD,EAEamM,GACXhU,GACiC,CACjC,IAAMoU,EAAcpU,GAAY,YAAyB,GACzD,GAAIoU,IAAe,cAAe,CAChC,GAAM,CAAC7L,EAAO8L,CAAI,EAAKrU,GAAY,mBAA0C,CAAC,GAAK,EAAG,EACtF,MAAO,CAAE,WAAAoU,EAAY,MAAA7L,EAAO,KAAA8L,CAAK,CACnC,SAAWD,IAAe,OAAQ,CAChC,GAAM,CAACE,EAASC,CAAO,EAAKvU,GAAY,mBAA0C,CAACrR,GAAUC,EAAQ,EACrG,MAAO,CAAE,WAAAwlB,EAAY,QAAAG,EAAS,QAAAD,CAAQ,CACxC,SAAWF,IAAe,YAAa,CACrC,GAAM,CAAC7L,CAAK,EAAKvI,GAAY,mBAAkC,CAAC,GAAI,EACpE,MAAO,CAAE,WAAAoU,EAAY,MAAA7L,CAAM,CAC7B,CACA,MAAO,CAAE,WAAA6L,CAAW,CACtB,IC7FA,IAqBaI,GAeAC,GApCbC,GAAA76B,EAAA,kBAqBa26B,GAAc,CAACG,EAAmBr1B,IAAqB,CAClE,OAAQq1B,EAAW,CACjB,IAAK,GACH,OAAOr1B,EACT,IAAK,GACH,MAAO,QAAQA,CAAQ,IACzB,IAAK,GACH,MAAO,QAAQA,CAAQ,IACzB,IAAK,GACH,MAAO,QAAQA,CAAQ,IACzB,QACE,MAAM,IAAI,MAAM,GAAGq1B,CAAS,8BAA8B,CAC9D,CACF,EAEaF,GAAeG,GAA6B;AAAA,QACjDA,EAAU,iDAAmD,EAAE;UCrCvE,IAqBaC,GArBbC,GAAAj7B,EAAA,kBAqBag7B,GAAiBE,GAAsB;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,UAO1CA,CAAS,YAAYA,CAAS,YAAYA,CAAS;AAAA;IC5B7D,IA6BaC,GAwBAC,GArDbC,GAAAr7B,EAAA,kBAGAkS,IAEA8C,IAGAqL,IAYA+Z,KASae,GAA+C,CAC1DG,EACAvb,EACAwb,EACAC,EACAC,IACG,CAGH,IAAMC,EAAqBF,EAAkBD,EAC7C,MAAO;AAAA,QACD,MAAM,KAAK,CAAE,OAAQA,CAAe,CAAC,EACpC,IACC,CAACI,EAAGt7B,IAAM;AAAA,YACRwf,EAAaE,EAAc,MAAO1f,EAAG0f,EAAc,IAAI,CAAC;AAAA,UAC1DA,EAAc,WAAWub,EAAmBj7B,EAAGwf,EAAa4b,EAAkBp7B,EAAIq7B,EAAoBF,CAAe,CAAC,CAAC;AAAA;AAAA,UAEvHzb,EAAc,WAAWub,EAAmBj7B,EAAG,CAAC,CAAC;AAAA,QAEnD,EACC,KAAK,EAAE,CAAC;AAAA,CAEjB,EAEa+6B,GAA+B,CAC1CnwB,EACA2wB,EACAnW,EACAoW,EACAC,EAAiB,GACjBC,IACgB,CAChB,IAAMC,EAAS/wB,EAAO,CAAC,EAAE,KACnBgxB,EAAShxB,EAAO,CAAC,EAAE,KAEnBmN,EAAI4jB,EAAOA,EAAO,OAAS,CAAC,EAC5B1jB,EAAI2jB,EAAOA,EAAO,OAAS,CAAC,EAC5B5jB,EAAI2jB,EAAOA,EAAO,OAAS,CAAC,EAC5B1b,EAAab,EAAiBnH,CAAC,EAC/B4jB,EAAczc,EAAiBpH,CAAC,EAChC8jB,EAAe1c,EAAiBrH,CAAC,EACjC2N,EAAapR,EAAU,KAAK8Q,CAAW,EAAInF,EAAa6b,EACxDpB,EAAU9vB,EAAO,OAAS,EAC1BmxB,EAAYP,EAAsBA,EAAoB,MAAM,EAAG,EAAE,EAAIpW,EAAY,MAAM,EAAG,EAAE,EAE5F4W,EAAsB,CADV1nB,EAAU,KAAKynB,CAAS,EACFhkB,EAAGE,CAAC,EAEtCiI,EAAoC,CACxC,CAAE,QAAuB,KAAMwF,CAAW,EAC1C,CAAE,QAAuB,KAAM3N,CAAE,EACjC,CAAE,QAAuB,KAAME,CAAE,EACjC,CAAE,QAAuB,KAAMD,CAAE,CACnC,EACA4hB,GAA6B2B,EAAsBrb,CAAe,EAClEA,EAAgB,KAAK,GAAGf,EAA2B4c,EAAWJ,EAAQC,CAAM,CAAC,EACzElB,GACFxa,EAAgB,KAAK,GAAGf,EAA2BvU,EAAO,CAAC,EAAE,IAAI,CAAC,EAEpEsV,EAAgB,KAAK,GAAGf,EAA2B6c,CAAmB,CAAC,EAEvE,IAAMxW,EAAmBC,GAA+B,CACtD,IAAMwW,EAAYpc,GAAiB,aAAcjV,EAAO,CAAC,EAAE,SAAUmxB,EAAU,MAAM,EAC/E7pB,EAAIwN,EAAc,IAAK9U,EAAO,CAAC,EAAE,SAAU+wB,EAAO,OAAQE,CAAW,EACrE1pB,EAAIuN,EAAc,IAAK9U,EAAO,CAAC,EAAE,SAAUgxB,EAAO,OAAQ3b,CAAU,EACpE2B,EAASjC,EAAe,SAAU/U,EAAO,CAAC,EAAE,SAAUoxB,EAAoB,OAAQ/b,CAAU,EAC5F+Z,EAAW/a,GAA4B2C,EAAO,KAAK,MAAM,EACzDsa,EAAkBvC,GAAqB4B,EAAsB3Z,EAAO,KAAK,MAAOoY,CAAQ,EACxFmC,EAAiB,CAACjqB,EAAGC,CAAC,EACxBiqB,EAAc,GAClB,GAAI1B,EAAS,CACX,IAAM2B,EAAiBZ,EAAiBxb,EAAa,EACrDkc,EAAe,KAAKzc,EAAc,OAAQ9U,EAAO,CAAC,EAAE,SAAUA,EAAO,CAAC,EAAE,KAAK,OAAQyxB,CAAc,CAAC,EACpGD,EAAc,GACZX,EAAiB,uBAAuBY,CAAc,KAAO,YAAYza,EAAO,KAAK,KAAK,kBAC5F,EACF,CAEA,IAAM+L,EAA8B,CAClC,CAAE,KAAM,cAAe,KAAM,KAAM,EACnC,CAAE,KAAM,IAAK,KAAM,KAAM,EACzB,CAAE,KAAM,IAAK,KAAM,KAAM,EACzB,CAAE,KAAM,IAAK,KAAM,KAAM,CAC3B,EACAkM,GAAyB0B,EAAsB5N,CAAQ,EAEvD,IAAM2O,GAAa,IAAc,CAC/B,IAAIC,EAAU,eAAerqB,EAAE,KAAK,KAAK,IACzC,QAASlS,EAAI,EAAGA,EAAI67B,EAAa77B,IAC/Bu8B,GAAW;AAAA,0BACOv8B,CAAC,yBAAyBA,CAAC,2BAA2BigB,CAAU,KAEpF,QAASjgB,EAAI,EAAGA,EAAI87B,EAAc97B,IAAK,CACrCu8B,GAAW,iCAAiCv8B,CAAC,yBAAyB67B,CAAW,KAEjF,QAAS,EAAI,EAAG,EAAIA,EAAa,IAC/BU,GAAW;AAAA,qBACAv8B,CAAC,WAAWmS,EAAE,KAAK,KAAK,UAAU0pB,IAAgB,EAAI,GAAK,IAAI,CAAC,GAAG,YAAY,CAAC,YAAY77B,CAAC;AAAA,CAE5G,CACA,OAAOu8B,CACT,EAEA,MAAO;AAAA,IACP9W,EACC,iBAAiBkI,CAAQ,EACzB,0BAA0BsO,CAAS,EACnC,iBAAiB,GAAGE,EAAgBva,CAAM,CAAC;AAAA,IAC5C6D,EAAa,UAAU,CAAC;AAAA,MACtBA,EAAa,sCAAsC,sBAAsB,CAAC;AAAA,4CACpCxF,CAAU,QAAQA,CAAU;AAAA,8CAC1BA,CAAU;AAAA,iCACvB6b,CAAY;AAAA,qCACRA,CAAY;AAAA;AAAA;AAAA,MAG3C1W,EAAY,SAAW,EAAI,GAAK,uBAAuB6W,EAAU,gBAAgB,OAAO,CAAC,GAAG;AAAA;AAAA,qBAE7E/pB,EAAE,KAAK,OAAO;AAAA,MAC7B4oB,GAA6C,YAAa5oB,EAAGA,EAAE,KAAO,EAAG+pB,EAAU,KAAM,eAAe,CAAC;AAAA,MACzG/pB,EAAE,WAAW,YAAaA,EAAE,KAAO,EAAG,CAAC,CAAC;AAAA,MACxCA,EAAE,WAAW,YAAaA,EAAE,KAAO,EAAG,CAAC,CAAC;AAAA,qBACzBA,EAAE,gBAAgB,WAAW,CAAC;AAAA;AAAA,qBAE9BC,EAAE,KAAK,OAAO;AAAA,MAC7B2oB,GAA6C,YAAa3oB,EAAGA,EAAE,KAAO,EAAG8pB,EAAU,KAAM,eAAe,CAAC;AAAA,MACzG9pB,EAAE,WAAW,YAAaA,EAAE,KAAO,EAAG,CAAC,CAAC;AAAA,MACxCA,EAAE,WAAW,YAAaA,EAAE,KAAO,EAAG,CAAC,CAAC;AAAA,qBACzBA,EAAE,gBAAgB,WAAW,CAAC;AAAA,wBAC3ByP,EAAO,KAAK,KAAK,KAAKka,CAAY;AAAA,oDACND,CAAW;AAAA,QACvDS,GAAW,CAAC;AAAA;AAAA,2BAEOR,CAAY;AAAA;AAAA,QAE/BM,CAAW;AAAA,QACXF,CAAe;AAAA,0BACGta,EAAO,KAAK,OAAO;AAAA,qBACxBA,EAAO,gBAAgB,aAAa,CAAC;AAAA,QAClDA,EAAO,YAAY,YAAY3B,CAAU,GAAI,OAAO,CAAC;AAAA;AAAA;AAAA,GAI3D,EACA,MAAO,CACL,KAAM,cACN,YAAa,CACX,KAAM,GAAGsb,EAAqB,UAAU,IAAItb,CAAU,IAAI4b,CAAW,IAAIC,CAAY,IAAIL,CAAc,GACvG,kBAAmBf,EAAU,CAAC,OAAQ,OAAQ,MAAM,EAAI,CAAC,OAAQ,MAAM,CACzE,EACA,WAAY,KAAO,CACjB,QAAS,CACP,CACE,KAAMgB,EAA6BA,EAA2BtW,CAAW,EAAIA,EAC7E,SAAUxa,EAAO,CAAC,EAAE,QACtB,CACF,EACA,cAAe,CAAE,EAAG,KAAK,KAAK8a,EAAa,EAAuB,CAAE,EACpE,gBAAAxF,CACF,GACA,gBAAAsF,CACF,CACF,IC9LA,IA6CMgX,GAgBAC,GAyBOC,GAkGPC,GAgBAC,GAKOC,GAqKPC,GA2EOC,GA7bbC,GAAAr9B,EAAA,kBAqBAkS,IAEA8C,IAEAqL,IAUA+Z,KAMAiB,KAEAR,KAEMgC,GAA6B,CAACjY,EAAoB0X,IAClD1X,EACK;AAAA;AAAA;AAAA,wDAG6C0X,EAAY,iBAAmB,EAAE;AAAA,UAG9E;AAAA;AAAA;AAAA,gDAGqCA,EAAY,iBAAmB,EAAE;AAAA,UAK3EQ,GAAyB,CAACQ,EAAqBC,IAC/CD,EACK;AAAA;AAAA;AAAA;AAAA,UAIDC,IAAqB,EAAI,GAAK,6DAA6D;AAAA;AAAA;AAAA;AAAA;AAAA,YAKzFA,IAAqB,EAAI,GAAK,2CAA2C;AAAA,WAG1E;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,YAMCA,IAAqB,EAAI,GAAK,yCAAyC;AAAA,WAKtER,GAA6B,CACxCS,EACApa,EACAzd,EAAO,MACP22B,EACAgB,EAAa,GACbG,EAAY,GACZC,EAAS,GACTC,EAAkB,KACP,CACX,IAAMC,EAAaxa,EAAc,CAAC,EAAIoa,EAAc,CAAC,EAC/CK,EAAaza,EAAc,CAAC,EAAIoa,EAAc,CAAC,EAC/CM,EAAaR,EAAaM,EAAaH,EACvCM,EAAaT,EAAaG,EAAYG,EACtCL,EAAmBO,EAAa1a,EAAc,CAAC,EAC/C4a,EAAgBP,EAAYra,EAAc,CAAC,EAEjD,GACE,GACIka,GAAcC,IAAqB,GAAKC,EAAc,CAAC,IAAM,GAC5D,CAACF,IAAeC,IAAqB,GAAKA,IAAqB,KAClEO,EAAa1a,EAAc,CAAC,IAAM,GAClCqa,EAAYra,EAAc,CAAC,IAAM,GACjCoa,EAAc,CAAC,IAAM,GAGvB,MAAM,IAAI,MAAM,iBAAiBF,CAAU,8BAA8BC,CAAgB,yBAAyBC,EAAc,CAAC,CAAC;AAAA,oCAClGD,CAAgB;AAAA,eACrCO,CAAU,yCAAyC1a,EAAc,CAAC,CAAC,eAAeqa,CAAS,0CAA0Cra,EAAc,CAAC,CAAC,kBAAkBoa,EAAc,CAAC,CAAC,aAAa,EAEjN,MAAO;AAAA,yCACgCD,CAAgB,IAAI53B,CAAI,MAAMm4B,EAAaP,CAAgB,MAAMQ,CAAU;AAAA,2CACzEp4B,CAAI,MAAMk4B,EAAaL,EAAc,CAAC,CAAC,MAAMC,CAAS;AAAA;AAAA,uBAE1ED,EAAc,CAAC,CAAC;AAAA,uBAChBA,EAAc,CAAC,CAAC;AAAA,2BACZD,CAAgB;AAAA,oBACvBE,CAAS;AAAA;AAAA,2BAEFra,EAAc,CAAC,CAAC,KAAKA,EAAc,CAAC,CAAC,KAAKA,EAAc,CAAC,CAAC;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,gBAUrEsa,EAAS,IAAM,iBAAiB;AAAA,IAC5CpB,EAAY,sBAAsBA,EAAU,gBAAgB,YAAY,CAAC,IAAM,EAAE;AAAA,8CACvCsB,CAAU;AAAA;AAAA,oBAEpCF,EAAS,GAAG,KAAK,KAAKC,EAAkBF,CAAS,CAAC,GAAK,0CAA0C;AAAA,iBACpGC,EAAS,qBAAqBC,CAAe,GAAK,GAAG;AAAA;AAAA,wBAE9Ch4B,CAAI;AAAA;AAAA;AAAA,8BAGEq4B,CAAa;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,YAM/BnB,GAA2BS,EAAYhB,CAAS,CAAC;AAAA;AAAA;AAAA;AAAA,0CAInB0B,CAAa;AAAA;AAAA;AAAA,sFAI3C1B,EAAY,iBAAmB,EACjC;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,YAUEiB,IAAqB,EAAI,GAAK,4DAA4D;AAAA;AAAA,YAE1FT,GAAuBQ,EAAYC,CAAgB,CAAC;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EAUhE,EAEMP,GAAyB,CAACpY,EAAoB0X,IAC9C1X,EACK;AAAA;AAAA;AAAA,yCAG8B0X,EAAY,iBAAmB,EAAE;AAAA,cAG/D;AAAA;AAAA;AAAA,iCAGsBA,EAAY,iBAAmB,EAAE;AAAA,cAK5DW,GAA2BK,GAC/BA,EAAa,gDAAkD,gDAIpDJ,GAAyB,CACpCM,EACApa,EACAzd,EAAO,MACP22B,EACAgB,EAAa,GACbG,EAAY,GACZC,EAAS,GACTC,EAAkB,GAClBM,EAA4B,KACjB,CACX,IAAML,EAAaJ,EAAc,CAAC,EAAIpa,EAAc,CAAC,EAC/Cya,EAAaL,EAAc,CAAC,EAAIpa,EAAc,CAAC,EAC/C0a,EAAaR,EAAaM,EAAaH,EACvCM,EAAaT,EAAaG,EAAYG,EAE5C,GACE,EAAEG,EAAa3a,EAAc,CAAC,IAAM,GAAK0a,EAAa1a,EAAc,CAAC,IAAM,GAAKqa,EAAYra,EAAc,CAAC,IAAM,GAEjH,MAAM,IAAI,MACR,cAAc2a,CAAU,yCAAyC3a,EAAc,CAAC,CAAC,gBAAgB0a,CAAU,yCAAyC1a,EAAc,CAAC,CAAC,eAAeqa,CAAS,yCAAyCra,EAAc,CAAC,CAAC,EACvP,EAEF,IAAM8a,EAAgBH,EAAa3a,EAAc,CAAC,EAC5C+a,EAAgBL,EAAa1a,EAAc,CAAC,EAC5C4a,EAAgBP,EAAYra,EAAc,CAAC,EAC3Cgb,EAAgBH,EAClB;AAAA;AAAA;AAAA,gDAG0CL,CAAU;AAAA,gDACVC,CAAU;AAAA;AAAA;AAAA;AAAA;AAAA,iDAKTE,CAAU,2BAA2B3a,EAAc,CAAC,CAAC;AAAA,mDACnD0a,CAAU,2BAA2B1a,EAAc,CAAC,CAAC;AAAA,YAC5F4Z,GAAuBM,EAAYhB,CAAS,CAAC;AAAA;AAAA;AAAA;AAAA,iDAIRmB,CAAS,2BAA2Bra,EAAc,CAAC,CAAC;AAAA,uDAC9Cya,CAAU,2BAA2Bza,EAAc,CAAC,CAAC;AAAA;AAAA;AAAA,uCAGrEkZ,EAAY,iBAAmB,EAAE;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,4BAO5C32B,CAAI;AAAA;AAAA;AAAA,2DAG2Byd,EAAc,CAAC,CAAC;AAAA;AAAA;AAAA,0BAI/Dka,EACI,oCAAoCla,EAAc,CAAC,CAAC,KACpD,iCAAiCA,EAAc,CAAC,CAAC,OACvD;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,0DAUgDA,EAAc,CAAC,CAAC;AAAA;AAAA,4DAEdA,EAAc,CAAC,CAAC;AAAA;AAAA;AAAA;AAAA,MAKtE;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,4CAMsCwa,CAAU;AAAA;AAAA,kCAEpBM,CAAa;AAAA,kCACbC,CAAa;AAAA,kCACbH,CAAa;AAAA;AAAA;AAAA;AAAA,sCAITE,CAAa;AAAA,wCACXC,CAAa;AAAA;AAAA;AAAA,QAG7CnB,GAAuBM,EAAYhB,CAAS,CAAC;AAAA;AAAA;AAAA;AAAA;AAAA,sCAKf0B,CAAa;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,8BAMrB1B,EAAY,iBAAmB,EAAE;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,wBAOvC32B,CAAI;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,QAOpBs3B,GAAwBK,CAAU,CAAC;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EAkBzC,MAAO;AAAA,yCACgC33B,CAAI,KAAKm4B,CAAU,MAAMC,CAAU;AAAA,yCACnCp4B,CAAI,KAAKk4B,CAAU,MAAMJ,CAAS;AAAA,yBAClDD,EAAc,CAAC,CAAC;AAAA,yBAChBA,EAAc,CAAC,CAAC;AAAA,sBACnBC,CAAS;AAAA;AAAA,2BAEJra,EAAc,CAAC,CAAC,KAAKA,EAAc,CAAC,CAAC,KAAKA,EAAc,CAAC,CAAC;AAAA;AAAA;AAAA;AAAA,kBAInEsa,EAAS,IAAM,iBAAiB;AAAA,MAC5CpB,EAAY,sBAAsBA,EAAU,gBAAgB,YAAY,CAAC,IAAM,EAAE;AAAA,sBAEjFoB,EAAS,GAAG,KAAK,KAAKC,EAAkBF,CAAS,CAAC,GAAK,0CACzD;AAAA,mBACeC,EAAS,qBAAqBC,CAAe,GAAK,GAAG;AAAA;AAAA,4BAE5Ch4B,CAAI;AAAA,MAC1By4B,CAAa;AAAA;AAAA,CAGnB,EAEMjB,GAA0B,CAC9BrC,EACAC,EACAwB,EACAzY,EACAgY,EAAiB,KACN,CACX,GAAM,CAACuC,EAAeC,EAAWC,EAAWve,CAAc,EAAI8D,EACxDre,EAAW6Z,GAA4BwE,EAAU,CAAC,EAAE,KAAK,MAAM,EAgErE,MA9De;AAAA,kEACiDua,EAAc,KAAK,OAAO,QAAQ1D,GAC9FG,EACAr1B,CACF,CAAC;AAAA,oBACek1B,GAAYG,EAAWr1B,CAAQ,CAAC;AAAA,0BAC1Bq1B,CAAS;AAAA;AAAA;AAAA,wBAGXwD,EAAU,KAAK,OAAO;AAAA,UACpCnD,GACA,WACAmD,EACAA,EAAU,KAAO,EACjBD,EAAc,KACd,cACF,CAAC;AAAA,UACCC,EAAU,WAAW,WAAYA,EAAU,KAAO,EAAG,UAAU,CAAC;AAAA,UAChEA,EAAU,WAAW,WAAYA,EAAU,KAAO,EAAG,YAAY,CAAC;AAAA,kBAC1DA,EAAU,aAAa,UAAU,CAAC;AAAA;AAAA;AAAA;AAAA;AAAA,kEAKcD,EAAc,KAAK,OAAO,QAAQ1D,GAC9FG,EACAr1B,CACF,CAAC;AAAA,oBACek1B,GAAYG,EAAWr1B,CAAQ,CAAC;AAAA,0BAC1Bq1B,CAAS;AAAA;AAAA;AAAA,wBAGXyD,EAAU,KAAK,OAAO;AAAA,UACpCpD,GACA,WACAoD,EACAA,EAAU,KAAO,EACjBF,EAAc,KACd,cACF,CAAC;AAAA,UACCE,EAAU,WAAW,WAAYA,EAAU,KAAO,EAAG,UAAU,CAAC;AAAA,UAChEA,EAAU,WAAW,WAAYA,EAAU,KAAO,EAAG,YAAY,CAAC;AAAA,kBAC1DA,EAAU,aAAa,UAAU,CAAC;AAAA;AAAA;AAAA;AAAA;AAAA,6DAKS5D,GAAYG,EAAWr1B,CAAQ,CAAC;AAAA,0BACnEq1B,CAAS;AAAA;AAAA;AAAA;AAAA,UAKzBC,EACI,mBAAmBe,EAAiB,cAAgB,GAAGnB,GAAYG,EAAWr1B,CAAQ,CAAC,aAAa,IACpG,EACN;AAAA,UACE82B,CAAe;AAAA,UACfvc,EAAe,aAAa,oBAAqB,OAAO,CAAC;AAAA;AAAA;AAAA,KAKnE,EAEaod,GAA0B,CACrCnyB,EACA2wB,EACAnW,EACAoW,EACAC,EAAiB,GACjBC,IACgB,CAChB,IAAMC,EAAS/wB,EAAO,CAAC,EAAE,KACnBgxB,EAAShxB,EAAO,CAAC,EAAE,KACnBuzB,EAAaxC,EAAO,MAAM,EAAG,EAAE,EAC/ByC,EAAaxC,EAAO,MAAM,EAAG,EAAE,EAC/BG,EAAYP,EAAsBA,EAAoB,MAAM,EAAG,EAAE,EAAIpW,EAAY,MAAM,EAAG,EAAE,EAC5F4G,EAAY1X,EAAU,KAAKynB,CAAS,EACpCsC,EAAY1C,EAAOA,EAAO,OAAS,CAAC,EACpC2C,EAAW3C,EAAOA,EAAO,OAAS,CAAC,EACnC4C,EAAY3C,EAAOA,EAAO,OAAS,CAAC,EACpC4C,EAASF,EAAW,IAAM,GAAKC,EAAY,IAAM,EAGjDpR,EAAoBkR,GAAa,EAAI,CAAC,EAAG,EAAG,CAAC,EAAI,CAAC,EAAG,EAAG,CAAC,EACzDtb,EAA0C,CAAC,EAAG,EAAG,CAAC,EAClDyL,EAAW,CACf,KAAK,KAAK+P,EAAYxb,EAAc,CAAC,EAAIoK,EAAkB,CAAC,CAAC,EAC7D,KAAK,KAAKkR,EAAYtb,EAAc,CAAC,EAAIoK,EAAkB,CAAC,CAAC,EAC7D,KAAK,KAAKnB,EAAYjJ,EAAc,CAAC,EAAIoK,EAAkB,CAAC,CAAC,CAC/D,EAEMlN,EAAaue,EAAS,EAAI,EAC1BC,EAAa,CAAC,GAAGN,EAAYE,EAAWC,EAAWre,CAAU,EAC7Dye,EAAQD,EAAW,OACnBE,EAAa,CAAC,GAAGP,EAAYE,EAAUC,EAAYte,CAAU,EAC7D2e,EAAQD,EAAW,OACnBE,EAAkB,CAAC7S,EAAWqS,EAAWE,EAAYte,CAAU,EAC/DC,EAAoC,CACxC,CAAE,OAAsB,KAAMme,CAAU,EACxC,CAAE,OAAsB,KAAME,CAAU,EACxC,CAAE,OAAsB,KAAMD,CAAS,CACzC,EACA1E,GAA6B2B,EAAsBrb,CAAe,EAClEA,EAAgB,KAAK,GAAGf,EAA2B4c,EAAW0C,EAAYE,CAAU,CAAC,EACrF,IAAMtR,EAAwD,CAAC,OAAQ,MAAM,EAEvEqN,EAAU9vB,EAAO,OAAS,EAC5B8vB,IACFxa,EAAgB,KAAK,GAAGf,EAA2BvU,EAAO,CAAC,EAAE,IAAI,CAAC,EAClEyiB,EAAkB,KAAK,MAAM,GAE/BnN,EAAgB,KAAK,GAAGf,EAA2B0f,CAAe,CAAC,EAEnE,IAAMrZ,EAAmBC,GAA+B,CACtD,IAAMqZ,EAAY/C,EAAU,OACtBE,GAAYpc,GAAiB,YAAajV,EAAO,CAAC,EAAE,SAAUk0B,EAAW,CAAC,EAC1E15B,EAAW6Z,GAA4BrU,EAAO,CAAC,EAAE,QAAQ,EAEzD/H,EAAI6c,EAAc,IAAK9U,EAAO,CAAC,EAAE,SAAU8zB,EAAOze,CAAU,EAC5Drd,EAAI8c,EAAc,IAAK9U,EAAO,CAAC,EAAE,SAAUg0B,EAAO3e,CAAU,EAC5D2B,EAASjC,EAAe,SAAU/U,EAAO,CAAC,EAAE,SAAUi0B,EAAgB,OAAQ5e,CAAU,EACxFkc,GAAiB,CAACt5B,EAAGD,CAAC,EAC5B,GAAI83B,EAAS,CACX,IAAM2B,EAAiBZ,EAAiBxb,EAAa,EACrDkc,GAAe,KAAKzc,EAAc,OAAQ9U,EAAO,CAAC,EAAE,SAAUA,EAAO,CAAC,EAAE,KAAK,OAAQyxB,CAAc,CAAC,CACtG,CACA,IAAM1O,GAA8B,CAClC,CAAE,KAAM,cAAe,KAAM,KAAM,EACnC,CAAE,KAAM,cAAe,KAAM,KAAM,EACnC,CAAE,KAAM,YAAa,KAAM,KAAM,CACnC,EACAkM,GAAyB0B,EAAsB5N,EAAQ,EACvD,IAAMqM,GAAW/a,GAA4B2C,EAAO,KAAK,MAAM,EACzDsa,EAAkBvC,GAAqB4B,EAAsB3Z,EAAO,KAAK,MAAOoY,EAAQ,EACxF+E,EAAmBjC,GACvB7c,EACAya,EACAwB,EACA,CAACD,GAAWp5B,EAAGD,EAAGgf,CAAM,EACxB6Z,CACF,EACA,MAAO;AAAA,IACPhW,EACC,iBAAiBkI,EAAQ,EACzB,0BAA0BsO,EAAS,EACnC,iBAAiB,GAAGE,GAAgBva,CAAM,CAAC;AAAA,IAC5Cmd,CAAgB;AAAA,IAEhBP,EACI9B,GAA2BvP,EAAmBpK,EAAe3d,EAAU62B,EAAS,EAChFY,GAAuB1P,EAAmBpK,EAAe3d,EAAU62B,EAAS,CAClF;AAAA,oBAEA,EACA,MAAO,CACL,KAAM,SACN,YAAa,CACX,KAAM,GAAG9O,CAAiB,IAAIoO,EAAqB,UAAU,IAAIiD,CAAM,IAAI/C,CAAc,GACzF,kBAAApO,CACF,EACA,WAAY,KAAO,CACjB,QAAS,CACP,CACE,KAAMqO,EAA6BA,EAA2BtW,CAAW,EAAIA,EAC7E,SAAUxa,EAAO,CAAC,EAAE,QACtB,CACF,EACA,cAAe,CAAE,EAAG4jB,EAAS,CAAC,EAAG,EAAGA,EAAS,CAAC,EAAG,EAAGA,EAAS,CAAC,CAAE,EAChE,gBAAAtO,CACF,GACA,gBAAAsF,CACF,CACF,IC1iBA,IAwCMwZ,GAqJOC,GA7LbC,GAAAv/B,EAAA,kBAqBAkS,IACAgC,KAGAmM,IASA+Z,KAEAS,KACAI,KACAoC,KAEMgC,GAAsB,CAC1BvD,EACA0D,EACAC,EACAC,EACAC,EAAU,GACVxZ,EACAyZ,EAAoB,EACpBC,EAAoB,EACpBtC,EAAmB,EACnB93B,EAAW,QACA,CACX,IAAMq6B,EAAevC,GAA6B,CAChD,OAAQA,EAAkB,CACxB,IAAK,GACH,MAAO,uBACT,IAAK,GACH,MAAO,kBAAkB93B,CAAQ,8CACnC,IAAK,GACH,MAAO,2BACT,QACE,MAAM,IAAI,MAAM,oBAAoB83B,CAAgB,oBAAoB,CAC5E,CACF,EACMwC,EAAexC,GAA6B,CAChD,OAAQA,EAAkB,CACxB,IAAK,GACH,MAAO,oDACT,IAAK,GACH,MAAO,wDACT,QACE,MAAM,IAAI,MAAM,oBAAoBA,CAAgB,oBAAoB,CAC5E,CACF,EACMyC,EAAgBlE,EAClB;AAAA;AAAA,MAGA;AAAA;AAAA,MAIEmE,EAAkBnE,EACpB;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,MAOA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,MAQEoE,EAAUpE,EAAiB,2BAA6B,2BACxDqE,EAASrE,EAAiB,2BAA6B,2BACvDsE,EAAMtE,EAAiB,MAAQ,MAC/BuE,EAAMvE,EAAiB,MAAQ,MAC/BwE,EAAe;AAAA;AAAA,qBAEFxE,EAAiB,gCAAkC,+BAA+B;AAAA,mBACpFsE,CAAG;AAAA,mBACHA,CAAG;AAAA;AAAA,iBAELC,CAAG;AAAA,iBACHA,CAAG;AAAA;AAAA;AAAA,gBAGJA,CAAG;AAAA,oBACC1F,GAAYiF,EAAmBn6B,CAAQ,CAAC;AAAA;AAAA;AAAA,8BAG9By6B,CAAO,2BAA2BC,CAAM;AAAA,QAC9DH,CAAa;AAAA;AAAA,QAEbF,EAAYF,CAAiB,CAAC;AAAA;AAAA,qBAI9BW,EAAUzE,EACZ0D,GAAaE,EACX;AAAA,wBACgBE,CAAiB;AAAA,MACnCU,CAAY,GACV;AAAA,wBACgBV,CAAiB;AAAA;AAAA,QAEjCU,CAAY;AAAA;AAAA,aAEP3F,GAAYiF,EAAmBn6B,CAAQ,CAAC,SAC/Ci6B,GAAYD,EACV;AAAA,wBACgBG,CAAiB;AAAA,MACnCU,CAAY,GACV;AAAA,wBACgBV,CAAiB;AAAA;AAAA,QAEjCU,CAAY;AAAA;AAAA,aAEP3F,GAAYiF,EAAmBn6B,CAAQ,CAAC,SAE7C+6B,EAAU1E,EACZ4D,GAAYD,EACVM,EAAYF,CAAiB,EAC7B;AAAA,wBACgBA,CAAiB;AAAA;AAAA,QAEjCE,EAAYF,CAAiB,CAAC;AAAA;AAAA,aAEzBlF,GAAYkF,EAAmBp6B,CAAQ,CAAC,SAC/C;AAAA,wBACkBo6B,CAAiB;AAAA;AAAA,QAEjCE,EAAYF,CAAiB,CAAC;AAAA;AAAA,aAEzBlF,GAAYkF,EAAmBp6B,CAAQ,CAAC,SAE7Cg7B,EAAU9F,GAAY4C,EAAkB93B,CAAQ,EAChDi7B,EAAQ5E,EAAiBnB,GAAYiF,EAAmBn6B,CAAQ,EAAIk1B,GAAYkF,EAAmBp6B,CAAQ,EAC3Gk7B,EAAQ7E,EAAiBnB,GAAYkF,EAAmBp6B,CAAQ,EAAIk1B,GAAYiF,EAAmBn6B,CAAQ,EAC3G82B,EAAkBvC,GAAqB7T,EAAYsa,EAASh7B,CAAQ,EAsB1E,MArBiB;AAAA,yDACsCi7B,CAAK;AAAA,QACtD5E,EAAiByE,EAAUC,CAAO;AAAA;AAAA;AAAA,yDAGeG,CAAK;AAAA,QACtD7E,EAAiB0E,EAAUD,CAAO;AAAA;AAAA;AAAA,gEAGsBE,CAAO;AAAA,0BAC7ClD,CAAgB;AAAA;AAAA;AAAA;AAAA,uBAInBzB,EAAiB,gCAAkC,+BAA+B;AAAA,QACjGmE,CAAe;AAAA,QACfrF,GAAY+E,CAAO,CAAC;AAAA,QACpBpD,CAAe;AAAA;AAAA;AAAA,MAKvB,EAEa+C,GAAgC,CAC3Cr0B,EACAkb,EACAV,EACAiZ,EACAE,EACAD,EACA5D,EACAkD,EACAlC,IACgB,CAChB,IAAMD,EAAiB3V,EAAW,SAAW,OACvCya,EAAa9E,EAAiB7wB,EAAO,CAAC,EAAE,KAAK,CAAC,EAAIA,EAAO,CAAC,EAAE,KAAK,CAAC,EAClEohB,EAAY5G,EAAY,CAAC,EACzBob,EAAW/E,EAAiBrW,EAAY,CAAC,EAAIA,EAAY,CAAC,EAC1Dqb,EAAYhF,EAAiBrW,EAAY,CAAC,EAAIA,EAAY,CAAC,EAC3Dsb,EAAcjF,EAAiBrW,EAAY,CAAC,EAAIA,EAAY,CAAC,EAE7DoZ,EAAS/C,IAAmB8E,EAAa,IAAM,GAAKA,EAAa,IAAM,IAAMG,EAAc,IAAM,EAGjGC,EAAYlF,EAAiBiF,EAAcF,EAAWC,EACtDG,EAAYnF,EAAiB+E,EAAWC,EAAYC,EACpDG,EAA0C,CAAC,EAAG,EAAG,CAAC,EAClD1T,EAAoBkR,GAAa,EAAI,CAAC,EAAG,EAAG,CAAC,EAAI,CAAC,EAAG,EAAG,CAAC,EACzD7P,EAAW,CACf,KAAK,KAAKmS,EAAYE,EAAc,CAAC,EAAI1T,EAAkB,CAAC,CAAC,EAC7D,KAAK,KAAKyT,EAAYC,EAAc,CAAC,EAAI1T,EAAkB,CAAC,CAAC,EAC7D,KAAK,KAAKnB,EAAY6U,EAAc,CAAC,EAAI1T,EAAkB,CAAC,CAAC,CAC/D,EAEAvZ,EAAU,UAAW,IAAM,iCAAiC4a,CAAQ,EAAE,EAEtE,IAAM0O,EAAmBsB,EAAU/C,GAAkB8E,EAAa,IAAM,EAAI,EAAI,EAAK,EAC/EhD,EAAasD,EAAc,CAAC,EAAI1T,EAAkB,CAAC,EACnDqQ,EAAaqD,EAAc,CAAC,EAAI1T,EAAkB,CAAC,EACnDiQ,EAAY,KAAK,IAAIyD,EAAc,CAAC,EAAI3D,EAAkB2D,EAAc,CAAC,CAAC,EAC1E1B,EAAYd,EAAYd,IAAe,EACvC6B,EAAYb,EAAYf,IAAe,EACvC6B,EAAWf,EAAWlB,IAAc,EACpC0D,EAAetC,EAAS,CAACtB,EAAkB,EAAG,CAAC,EAAI,CAAC,EAAG,EAAG,CAAC,EAE3Dhd,EAAoC,CACxC,CAAE,OAAsB,KAAMme,CAAU,EACxC,CAAE,OAAsB,KAAME,CAAU,EACxC,CAAE,OAAsB,KAAMD,CAAS,EACvC,CAAE,OAAsB,KAAM,CAACxY,EAAW,KAAK,CAAC,EAAGA,EAAW,KAAK,CAAC,CAAC,CAAE,EACvE,CAAE,OAAsB,KAAMA,EAAW,OAAQ,EACjD,CAAE,OAAsB,KAAMA,EAAW,SAAU,CACrD,EACA8T,GAA6B9T,EAAY5F,CAAe,EACxDA,EAAgB,KAAK,GAAGf,EAA2BvU,EAAO,CAAC,EAAE,KAAMA,EAAO,CAAC,EAAE,IAAI,CAAC,EAClF,IAAMyiB,EAAwD,CAAC,OAAQ,MAAM,EACzEqN,IACFxa,EAAgB,KAAK,GAAGf,EAA2BvU,EAAO,CAAC,EAAE,IAAI,CAAC,EAClEyiB,EAAkB,KAAK,MAAM,GAE/BnN,EAAgB,KAAK,GAAGf,EAA2BiG,CAAW,CAAC,EAE/D,IAAMI,GAAmBC,GAA+B,CACtD,IAAMkI,EAA8B,CAClC,CAAE,KAAM,cAAe,KAAM,KAAM,EACnC,CAAE,KAAM,cAAe,KAAM,KAAM,EACnC,CAAE,KAAM,YAAa,KAAM,KAAM,EACjC,CAAE,KAAM,MAAO,KAAM,MAAO,OAAQ,CAAE,EACtC,CAAE,KAAM,SAAU,KAAM,MAAO,OAAQ,CAAE,EACzC,CAAE,KAAM,WAAY,KAAM,MAAO,OAAQ,CAAE,CAC7C,EACAkM,GAAyB/T,EAAY6H,CAAQ,EAG7C,IAAM1N,EAAaue,EAAS,EAAI,EAC1BuC,EAAI9hB,GAA4BrU,EAAO,CAAC,EAAE,QAAQ,EACpDm0B,GAAmB;AAAA,qDAC0BP,EAAS,QAAQuC,CAAC,IAAMA,CAAC;AAAA,8BAChDvC,EAAS,QAAQuC,CAAC,IAAMA,CAAC;AAAA;AAAA,6EAEsBvC,EAAS,QAAQuC,CAAC,IAAMA,CAAC;AAAA;AAAA,qCAEjEvC,EAAS,MAAQ,EAAE;AAAA,SAE9CpoB,GAAIsJ,EACR,IACA9U,EAAO,CAAC,EAAE,SACVA,EAAO,CAAC,EAAE,KAAK,OACfsyB,IAAqB,EAAI,EAAIA,CAC/B,EACM8D,GAAIthB,EAAc,IAAK9U,EAAO,CAAC,EAAE,SAAUA,EAAO,CAAC,EAAE,KAAK,OAAQqV,CAAU,EAC5Ekc,EAAiB,CAAC/lB,GAAG4qB,EAAC,EACtBpf,EAASjC,EAAe,SAAU/U,EAAO,CAAC,EAAE,SAAUwa,EAAY,OAAQnF,CAAU,EAC1F,GAAIya,EAAS,CACX,IAAM9O,EAAOlM,EAAc,OAAQ9U,EAAO,CAAC,EAAE,SAAUA,EAAO,CAAC,EAAE,KAAK,OAAQqV,CAAU,EACxFkc,EAAe,KAAKvQ,CAAI,EACxBmT,IAAoB;AAAA,0DACgCP,EAAS,QAAQuC,CAAC,IAAMA,CAAC;AAAA,+BACpDtF,EAAiB,IAAM,GAAG,GAAG+C,EAAS,MAAQ,EAAE;AAAA,UAE3E,CAEA,MAAO;AAAA,UACD7D,GAAc,yBAAyB,CAAC;AAAA;AAAA;AAAA;AAAA,UAIxClV,EAAa,iBAAiBkI,CAAQ,EAAE,iBAAiB,GAAGwO,EAAgBva,CAAM,CAAC;AAAA,UACnFmd,EAAgB;AAAA,UAChBC,GACAvD,EACA0D,EACAC,EACAC,EACA3E,EACA5U,EACAgb,EAAa,CAAC,EACdA,EAAa,CAAC,EACdA,EAAa,CAAC,EACdC,CACF,CAAC;AAAA,UAECvC,EACI9B,GAA2BvP,EAAmB0T,EAAeE,EAAG,OAAW,CAACtF,EAAgB2B,CAAS,EACrGP,GACE1P,EACA0T,EACAE,EACA,OACA,CAACtF,EACD2B,EACA,GACA,OACAQ,CACF,CACN,EACN,EACA,MAAO,CACL,KAAM,eACN,YAAa,CACX,KAAM,GAAG9X,EAAW,QAAQ,IAAIoX,CAAgB,IAAIsB,CAAM,IAAIW,CAAS,IAAIC,CAAS,IAAIC,CAAQ,IAAI9B,CAAU,IAAIC,CAAU,IAAIJ,CAAS,GACzI,kBAAA/P,CACF,EACA,WAAY,KAAO,CACjB,QAAS,CACP,CACE,KAAMqO,EAA6BA,EAA2BtW,CAAW,EAAIA,EAC7E,SAAUxa,EAAO,CAAC,EAAE,QACtB,CACF,EACA,cAAe,CAAE,EAAG4jB,EAAS,CAAC,EAAG,EAAGA,EAAS,CAAC,EAAG,EAAGA,EAAS,CAAC,CAAE,EAChE,gBAAAtO,CACF,GACA,gBAAAsF,EACF,CACF,ICrVA,IAwCMyb,GAQAC,GAGAC,GAQAC,GAUAC,GAoBAC,GA6GOC,GA6EAC,GAnRbC,GAAA9hC,EAAA,kBAqBAkS,IACAgC,KAEAc,IAEAqL,IAUA+Z,KAEAS,KAEMyG,GAAgBS,GAAkB,CACtC,IAAIC,EAAU,EACd,QAAS3hC,EAAI,EAAGA,EAAI0hC,EAAI,OAAQ1hC,IAC9B2hC,GAAWD,EAAI1hC,CAAC,EAElB,OAAO2hC,CACT,EAEMT,GAAoBU,GACxB,OAAOA,GAAU,SAAW,CAACA,EAAOA,EAAOA,CAAK,EAAIA,EAEhDT,GAAyB,CAACU,EAAoBzqB,IAC9CA,GAAY,EACPyqB,EAGFA,GAAcA,EAAa,IAAMzqB,EAAW,GAG/CgqB,GAAoB,CACxB1c,EACAod,EACA1/B,EACAgV,EAAW,IACA,CACX,IAAM2qB,EAAqBZ,GAAuBW,EAAW1qB,CAAQ,EACrE,OAAO,KAAK,OAAOsN,EAAW,CAAC,GAAKtiB,EAAS,GAAKA,EAAS2/B,GAAsB,CAAC,CACpF,EAEMV,GAAuB,CAC3BW,EACAC,EACAvB,EACAzqB,EACAisB,IACqC,CACjCA,GAAW,OAEbA,EAAUd,GAAkBY,EAASC,EAAY,CAAC,EAAGhsB,EAAQ,CAAC,CAAC,GAEjE,IAAMksB,EAA6C,CAAC,EAAG,EAAG,EAAGzB,CAAW,EACxE,QAASpmB,EAAQ,EAAGA,EAAQ,EAAGA,IACzB0nB,EAAQ1nB,CAAK,EAAI,EAAI4nB,GAAWD,EAAY3nB,CAAK,IACnD6nB,EAAS7nB,CAAK,EAAI,KAAK,OAAO0nB,EAAQ1nB,CAAK,EAAI2nB,EAAY3nB,CAAK,EAAI,EAAI4nB,GAAWjsB,EAAQqE,CAAK,EAAI,CAAC,GAGzG,OAAO6nB,CACT,EAEMb,GAAqB,CACzBhrB,EACA8rB,EACAC,EACAC,EACAC,EACAC,EACAC,EACAC,EACAC,EACAC,IACkF,CAClF,IAAIC,EACAC,EACArC,EACAD,EAOJ,GALIlqB,IAAQ,UAEVA,EAAM,GAGJ,OAAOA,GAAQ,SAAU,CAC3BusB,EAAU,CAAE,IAAKvsB,EAAK,OAAQA,EAAK,KAAMA,EAAK,MAAOA,EAAK,MAAOA,EAAK,KAAMA,CAAI,EAChF,IAAM6rB,EAAWd,GACf,CAACe,EAASC,EAAUC,EAAS,CAAC,EAC9B,CAACI,EAAaC,EAAcC,CAAW,EACvC,EACA,CAACL,EAAaC,EAAcC,CAAW,EACvCnsB,CACF,EACAwsB,EAAWX,EAAS,CAAC,EACrB1B,EAAY0B,EAAS,CAAC,EACtB3B,EAAW2B,EAAS,CAAC,CACvB,SAAW,MAAM,QAAQ7rB,CAAG,EAAG,CAC7B,GAAI,CAACA,EAAI,MAAM,CAACysB,EAAKzH,EAAGoG,IAAQqB,IAAQrB,EAAI,CAAC,CAAC,EAC5C,MAAM,MAAM,kCAAkCprB,CAAG,EAAE,EAErDusB,EAAU,CAAE,IAAKvsB,EAAI,CAAC,EAAG,OAAQA,EAAI,CAAC,EAAG,KAAMA,EAAI,CAAC,EAAG,MAAOA,EAAI,CAAC,EAAG,MAAOA,EAAI,CAAC,EAAG,KAAMA,EAAI,CAAC,CAAE,EAClG,IAAM6rB,EAAWd,GACf,CAACe,EAASC,EAAUC,EAAS,CAAC,EAC9B,CAACI,EAAaC,EAAcC,CAAW,EACvC,EACA,CAACL,EAAaC,EAAcC,CAAW,EACvCnsB,EAAI,CAAC,CACP,EACAwsB,EAAWX,EAAS,CAAC,EACrB1B,EAAY0B,EAAS,CAAC,EACtB3B,EAAW2B,EAAS,CAAC,CACvB,SAAW7rB,IAAQ,aAAc,CAE/BwsB,EAAW,KAAK,KAAKV,EAAUG,CAAW,EAC1C9B,EAAY,KAAK,KAAK4B,EAAWG,CAAY,EAC7ChC,EAAW,KAAK,KAAK8B,EAAUG,CAAW,EAC1C,IAAMO,GAAiBF,EAAW,GAAKP,EAAcG,EAAcN,EAC7Da,GAAkBxC,EAAY,GAAK+B,EAAeG,EAAeN,EACjEa,GAAiB1C,EAAW,GAAKiC,EAAcG,EAAcN,EAC7Da,EAAQ,KAAK,MAAMH,EAAgB,CAAC,EACpCI,EAAOJ,EAAgBG,EACvBE,EAAM,KAAK,MAAMJ,EAAiB,CAAC,EACnCK,EAASL,EAAiBI,EAC1BE,EAAO,KAAK,MAAML,EAAgB,CAAC,EACnCM,EAAQN,EAAgBK,EAE9BV,EAAU,CAAE,IAAAQ,EAAK,OAAAC,EAAQ,KAAAC,EAAM,MAAAC,EAAO,MAAAL,EAAO,KAAAC,CAAK,CACpD,KACE,OAAM,MAAM,8BAA8B9sB,CAAG,EAAE,EAEjD,MAAO,CAAE,QAAAusB,EAAS,SAAAC,EAAU,UAAArC,EAAW,SAAAD,CAAS,CAClD,EAwCae,GAAoB,CAC/BS,EACAC,EACAhsB,EACAY,EACAP,EACAmtB,EAAY,GACZC,EAA+C,iBAChC,CACf,IAAI1X,EAAWoW,EAASC,EAAUC,EAAS/B,EAC3C,GAAImD,IAAe,eACjB,CAAC1X,EAAWoW,EAASC,EAAUC,EAAS/B,CAAU,EAAIyB,UAC7C0B,IAAe,gBACxB,CAAC1X,EAAWuU,EAAY6B,EAASC,EAAUC,CAAO,EAAIN,MAEtD,OAAM,IAAI,MAAM,sBAAsB0B,CAAU,EAAE,EAEpD,GAAM,CAACC,EAAgB,CAAEjB,EAAaC,EAAcC,CAAW,EAAIX,EAE7D,CAACM,EAAaC,EAAcC,CAAW,EAAIvB,GAAiBjrB,CAAO,EACnE,CAAC2tB,EAAeC,EAAgBC,CAAa,EAAI5C,GAAiBrqB,CAAS,EAE3EktB,EAAuB5C,GAAuBuB,EAAakB,CAAa,EACxEI,EAAwB7C,GAAuBwB,EAAckB,CAAc,EAC3EI,EAAuB9C,GAAuByB,EAAakB,CAAa,EACxE,CAAE,QAAAjB,EAAS,SAAAC,EAAU,UAAArC,EAAW,SAAAD,CAAS,EAAIc,GACjDhrB,EACA8rB,EACAC,EACAC,EACAC,EACAC,EACAC,EACAsB,EACAC,EACAC,CACF,EAEMvD,EAAc+C,EAAYE,EAAiBpD,EAAaoD,EAE1DxB,EAAqD,CAAC,EAAG,EAAG,EAAG,EAAG,CAAC,EACvE,OAAIuB,IAAe,gBACjBvB,EAAW,CAACnW,EAAW0U,EAAaoC,EAAUrC,EAAWD,CAAQ,EACxDkD,IAAe,iBACxBvB,EAAW,CAACnW,EAAW8W,EAAUrC,EAAWD,EAAUE,CAAW,GAG5D,CACL,UAAA1U,EACA,WAAA0X,EACA,QAAAtB,EACA,SAAAC,EACA,QAAAC,EACA,WAAA/B,EACA,SAAAuC,EACA,UAAArC,EACA,SAAAD,EACA,YAAAE,EACA,QAAAmC,EACA,YAAAN,EACA,aAAAC,EACA,YAAAC,EACA,YAAAC,EACA,aAAAC,EACA,YAAAC,EACA,qBAAAmB,EACA,sBAAAC,EACA,qBAAAC,EACA,cAAAL,EACA,eAAAC,EACA,cAAAC,EACA,QAAA9B,EACA,SAAAG,EACA,YAAAF,CACF,CACF,EAEaT,GAA+B,CAC1C52B,EACAkb,EACAV,EACAlO,EACAJ,EACA4sB,IACgB,CAChB,IAAM3sB,EAAgB2sB,IAAe,eAC/BnD,EAAaxpB,EAAgBnM,EAAO,CAAC,EAAE,KAAK,CAAC,EAAIA,EAAO,CAAC,EAAE,KAAK,CAAC,EAEjE4zB,EAAS,GACTqC,EAA0C,CAAC,GAAI,EAAG,CAAC,EACnDqD,EAAiB,CAAE,EAAG9e,EAAY,IAAI,CAACkW,EAAGt7B,IAAMA,CAAC,CAAE,EACnDwuB,EAAW,CAAC,KAAK,KAAKyS,GAAaiD,EAAe,EAAE,IAAK7Z,GAAMjF,EAAYiF,CAAC,CAAC,CAAC,EAAIwW,EAAc,CAAC,CAAC,EAAG,EAAG,CAAC,EAE/GjtB,EAAU,UAAW,IAAM,oCAAoC4a,CAAQ,EAAE,EAEzE,IAAM0O,EAAmBsB,EAAUznB,GAAiBwpB,EAAa,IAAM,EAAI,EAAI,EAAK,EAC9E7a,EAAapR,EAAU,KAAK8Q,CAAW,EACvClF,EAAoC,CACxC,CAAE,QAAuB,KAAMwF,CAAW,EAC1C,CAAE,QAAuB,KAAMxO,CAAW,EAC1C,CAAE,QAAuB,KAAMJ,CAAK,EACpC,CAAE,QAAuB,KAAMgP,EAAW,OAAQ,EAClD,CAAE,QAAuB,KAAMA,EAAW,SAAU,CACtD,EACA8T,GAA6B9T,EAAY5F,CAAe,EACxDA,EAAgB,KAAK,GAAGf,EAA2BvU,EAAO,CAAC,EAAE,KAAMA,EAAO,CAAC,EAAE,IAAI,CAAC,EAClF,IAAMyiB,EAAwD,CAAC,OAAQ,MAAM,EACvEqN,EAAU9vB,EAAO,SAAW,EAC9B8vB,IACFxa,EAAgB,KAAK,GAAGf,EAA2BvU,EAAO,CAAC,EAAE,IAAI,CAAC,EAClEyiB,EAAkB,KAAK,MAAM,GAE/BnN,EAAgB,KAAK,GAAGf,EAA2BiG,CAAW,CAAC,EAE/D,IAAMI,EAAmBC,GAA+B,CACtD,IAAMkI,EAA8B,CAClC,CAAE,KAAM,cAAe,KAAM,KAAM,EACnC,CAAE,KAAM,cAAe,KAAM,MAAO,OAAQzW,EAAW,MAAO,EAC9D,CAAE,KAAM,OAAQ,KAAM,MAAO,OAAQJ,EAAK,MAAO,EACjD,CAAE,KAAM,UAAW,KAAM,MAAO,OAAQgP,EAAW,QAAQ,MAAO,EAClE,CAAE,KAAM,YAAa,KAAM,MAAO,OAAQA,EAAW,UAAU,MAAO,CACxE,EACA+T,GAAyB/T,EAAY6H,CAAQ,EAE7C,IAAM1N,EAAaue,EAAS,EAAI,EAC1BuC,EAAI9hB,GAA4BrU,EAAO,CAAC,EAAE,QAAQ,EAElD,EAAI8U,EACR,IACA9U,EAAO,CAAC,EAAE,SACVA,EAAO,CAAC,EAAE,KAAK,OACfsyB,IAAqB,EAAI,EAAIA,CAC/B,EACM8D,EAAIthB,EAAc,IAAK9U,EAAO,CAAC,EAAE,SAAUA,EAAO,CAAC,EAAE,KAAK,OAAQqV,CAAU,EAC5Ekc,EAAiB,CAAC,EAAG6E,CAAC,EACtBpf,EAASjC,EAAe,SAAU/U,EAAO,CAAC,EAAE,SAAUwa,EAAY,OAAQnF,CAAU,EACtF8e,EAAmB,GACvB,GAAIrE,EAAS,CACX,IAAM9O,EAAOlM,EAAc,OAAQ9U,EAAO,CAAC,EAAE,SAAUA,EAAO,CAAC,EAAE,KAAK,OAAQqV,CAAU,EACxFkc,EAAe,KAAKvQ,CAAI,EACxBmT,GAAoB;AAAA,8DACoCP,EAAS,QAAQuC,CAAC,IAAMA,CAAC;AAAA,wBAC/DhqB,EAAgByI,EAAa,SAAU,EAAG,CAAC,EAAIA,EAAa,SAAU,EAAG,CAAC,CAAC,GACvFgf,EAAS,MAAQ,EACnB;AAAA,UAEN,CACA,IAAM4B,EAAU9F,GAAY4C,EAAkB6D,CAAC,EACzC7E,EAAkBvC,GAAqB7T,EAAYsa,EAASW,CAAC,EAEnE,MAAO;AAAA,cACGhC,CAAgB;AAAA;AAAA;AAAA,uBAGP,EAAE,aAAa,UAAU,CAAC;AAAA;AAAA;AAAA;AAAA,uBAI1BiC,EAAE,aAAa,UAAU,CAAC;AAAA;AAAA,YAErCvb,EAAa,iBAAiBkI,CAAQ,EAAE,iBAAiB,GAAGwO,EAAgBva,CAAM,CAAC;AAAA,YACnF6D,EAAa,UAAU,CAAC;AAAA,YACxBA,EAAa,sCAAsC,sBAAsB,CAAC;AAAA,6BACzD7D,EAAO,gBAAgB,YAAY,CAAC;AAAA,4BACrCpC,EAAa,SAAU,EAAG,EAAE,IAAI,CAAC;AAAA,yBAE7CzI,EAAgByI,EAAa,SAAU,EAAE,KAAO,EAAG,EAAE,IAAI,EAAIA,EAAa,SAAU,EAAG,EAAE,IAAI,CAC/F;AAAA,2CAEEzI,EAAgByI,EAAa,SAAU,EAAG,EAAE,IAAI,EAAIA,EAAa,SAAU,EAAG,EAAE,IAAI,CACtF;AAAA,gBACEzI,EAAgByI,EAAa,SAAU,EAAG,EAAE,IAAI,EAAIA,EAAa,SAAU,EAAG,EAAE,IAAI,CAAC;AAAA,gBAErFzI,EAAgByI,EAAa,SAAU,EAAG,EAAE,IAAI,EAAIA,EAAa,SAAU,EAAG,EAAE,IAAI,CACtF;AAAA;AAAA;AAAA;AAAA,8BAKEzI,EACIyI,EAAa,mBAAoB,EAAG,EAAE,IAAI,EAC1CA,EAAa,mBAAoB,EAAG,EAAE,IAAI,CAChD;AAAA,8BAEEzI,EACIyI,EAAa,mBAAoB,EAAG,EAAE,IAAI,EAC1CA,EAAa,mBAAoB,EAAG,EAAE,IAAI,CAChD;AAAA,8BAEEzI,EACIyI,EAAa,mBAAoB,EAAG,EAAE,IAAI,EAC1CA,EAAa,mBAAoB,EAAG,EAAE,IAAI,CAChD;AAAA,8BAEEzI,EACIyI,EAAa,mBAAoB,EAAG,EAAE,IAAI,EAC1CA,EAAa,mBAAoB,EAAG,EAAE,IAAI,CAChD;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,wBAyBUzI,EACI;AAAA;AAAA;AAAA;AAAA;AAAA,8BAMA;AAAA;AAAA;AAAA;AAAA;AAAA,6BAMN;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,0BAUIA,EACI;AAAA,0EAEA;AAAA,yEAEN;AAAA;AAAA,wBAGAA,EACI;AAAA;AAAA;AAAA,wBAIA;AAAA;AAAA;AAAA,qBAIN;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,wBAOEA,EACI;AAAA;AAAA;AAAA;AAAA,wBAKA;AAAA;AAAA;AAAA;AAAA,qBAKN;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,gBAUN2jB,EAAU,gDAAkD,EAAE;AAAA,gBAC9DwB,CAAe;AAAA;AAAA,YAG7B,EACA,MAAO,CACL,KAAM,cACN,YAAa,CAAE,KAAM,GAAGpW,EAAW,QAAQ,IAAI/O,CAAa,IAAImmB,CAAgB,IAAIxC,CAAO,GAAI,kBAAArN,CAAkB,EACjH,WAAY,KAAO,CACjB,QAAS,CAAC,CAAE,KAAMjI,EAAa,SAAUxa,EAAO,CAAC,EAAE,QAAS,CAAC,EAC7D,cAAe,CAAE,EAAG4jB,EAAS,CAAC,EAAG,EAAGA,EAAS,CAAC,EAAG,EAAGA,EAAS,CAAC,CAAE,EAChE,gBAAAtO,CACF,GACA,gBAAAsF,CACF,CACF,ICvfA,IAwBa2e,GA2IAC,GAnKbC,GAAA1kC,EAAA,kBAGAkS,IAEA8C,IAGAqL,IAUA+Z,KAMaoK,GAA+B,CAC1Cv5B,EACAkb,EACAV,EACAsW,IACgB,CAChB,IAAMhB,EAAU9vB,EAAO,OAAS,EAC1BwxB,EAAc1B,EAAU,8BAAgC,GACxD4J,EAAS15B,EAAO,CAAC,EAAE,KACnB25B,EAAS35B,EAAO,CAAC,EAAE,KAEnBmM,EAAgB+O,EAAW,SAAW,OACtC0e,EAAiBztB,EAAgBqO,EAAY,CAAC,EAAIA,EAAY,CAAC,EAC/Dqf,EAAyBD,EAAiB1e,EAAW,MACrD7F,EAAalJ,GAAiB0tB,GAA0B,EAAIrlB,EAAiBolB,CAAc,EAAI,EAC/F9e,EAAapR,EAAU,KAAK8Q,CAAW,EAAInF,EAE3CC,EAAoC,CACxC,CAAE,QAAuB,KAAMwF,CAAW,EAC1C,CAAE,QAAuB,KAAMI,EAAW,SAAU,EACpD,CAAE,QAAuB,KAAM,CAACA,EAAW,QAAQ,CAAC,EAAGA,EAAW,QAAQ,CAAC,CAAC,CAAE,EAC9E,CAAE,QAAuB,KAAM,CAACA,EAAW,KAAK,CAAC,EAAGA,EAAW,KAAK,CAAC,CAAC,CAAE,EACxE,CAAE,QAAuB,KAAM2e,CAAuB,CACxD,EACA7K,GAA6B9T,EAAY5F,CAAe,EACxDA,EAAgB,KACd,GAAGf,EAA2BmlB,EAAQ,CAACC,EAAO,CAAC,EAAGA,EAAO,CAAC,EAAGA,EAAO,CAAC,EAAGA,EAAO,CAAC,EAAItkB,CAAU,CAAC,CACjG,EACA,IAAMoN,EAAwDqN,EAAU,CAAC,OAAQ,OAAQ,MAAM,EAAI,CAAC,OAAQ,MAAM,EAClHxa,EAAgB,KACd,GAAGf,EAA2B,CAACiG,EAAY,CAAC,EAAGA,EAAY,CAAC,EAAGA,EAAY,CAAC,EAAGA,EAAY,CAAC,EAAInF,CAAU,CAAC,CAC7G,EAEA,IAAMuF,EAAmBC,GAA+B,CACtD,IAAM7D,EAASjC,EAAe,SAAU/U,EAAO,CAAC,EAAE,SAAUwa,EAAY,OAAQnF,CAAU,EACpF+Z,EAAW/a,GAA4B2C,EAAO,KAAK,MAAM,EACzDsa,EAAkBvC,GAAqB7T,EAAYlE,EAAO,KAAK,MAAOoY,CAAQ,EAC9E5jB,EAAIsJ,EAAc,IAAK9U,EAAO,CAAC,EAAE,SAAU05B,EAAO,MAAM,EACxDtD,EAAIthB,EAAc,IAAK9U,EAAO,CAAC,EAAE,SAAU25B,EAAO,OAAQtkB,CAAU,EACpE2O,EAAY,CAACxY,EAAG4qB,CAAC,EACnBtG,GACF9L,EAAU,KAAKlP,EAAc,IAAK9U,EAAO,CAAC,EAAE,SAAUA,EAAO,CAAC,EAAE,KAAMqV,CAAU,CAAC,EAGnF,IAAM0N,EAA8B,CAClC,CAAE,KAAM,cAAe,KAAM,KAAM,EACnC,CAAE,KAAM,YAAa,KAAM,MAAO,OAAQ7H,EAAW,UAAU,MAAO,EACtE,CAAE,KAAM,UAAW,KAAM,MAAO,OAAQ,CAAE,EAC1C,CAAE,KAAM,OAAQ,KAAM,MAAO,OAAQ,CAAE,EACvC,CAAE,KAAM,4BAA6B,KAAM,KAAM,CACnD,EACA+T,GAAyB/T,EAAY6H,CAAQ,EAE7C,IAAM+W,EAAkB3tB,EACpB;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,yBAgBiBX,EAAE,IAAI,QAAS,UAAW,SAAU,eAAe,CAAC;AAAA,yBACpD4qB,EAAE,IAAI,UAAW,SAAU,aAAc,gBAAgB,CAAC;AAAA;AAAA;AAAA;AAAA;AAAA,QAM3E;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,yBAgBiB5qB,EAAE,IAAI,QAAS,gBAAiB,UAAW,QAAQ,CAAC;AAAA,yBACpD4qB,EAAE,IAAI,iBAAkB,aAAc,UAAW,QAAQ,CAAC;AAAA;AAAA;AAAA;AAAA;AAAA,QAM/E,MAAO;AAAA,IACPvb,EAAa,iBAAiBkI,CAAQ,EAAE,iBAAiB,GAAGiB,EAAWhN,CAAM,CAAC;AAAA;AAAA,IAE9E6D,EAAa,UAAU,CAAC;AAAA,MACtBA,EAAa,sCAAsC,sBAAsB,CAAC;AAAA;AAAA,0BAEtD7D,EAAO,gBAAgB,YAAY,CAAC;AAAA;AAAA,8CAEhB7K,EAAgB,EAAI,CAAC;AAAA,yDACVA,EAAgB,EAAI,CAAC,oBACxEA,EAAgB,EAAI,CACtB;AAAA,2CACuCkJ,CAAU;AAAA,0DACKlJ,EAAgB,EAAI,CAAC;AAAA;AAAA,iBAE9D6K,EAAO,KAAK,KAAK,MAAMA,EAAO,KAAK,KAAK;AAAA,MACnD8iB,CAAe;AAAA,MACftI,CAAW;AAAA,MACXF,CAAe;AAAA,MACfta,EAAO,YAAY,aAAc,OAAO,CAAC;AAAA,IAE7C,EACA,MAAO,CACL,KAAM,cACN,YAAa,CAAE,KAAM,GAAGkE,EAAW,QAAQ,IAAI7F,CAAU,GAAI,kBAAAoN,CAAkB,EAC/E,WAAY,KAAO,CACjB,QAAS,CACP,CACE,KAAMqO,EAA6BA,EAA2BtW,CAAW,EAAIA,EAC7E,SAAUxa,EAAO,CAAC,EAAE,QACtB,CACF,EACA,cAAe,CAAE,EAAG,KAAK,KAAK8a,EAAa,EAAuB,CAAE,EACpE,gBAAAxF,CACF,GACA,gBAAAsF,CACF,CACF,EAEa4e,GAAwC,CACnDx5B,EACAkb,EACAV,EACAsW,IACgB,CAChB,IAAMhB,EAAU9vB,EAAO,OAAS,EAC1BqV,EAAab,EAAiBgG,EAAY,CAAC,CAAC,EAC5C0W,EAAe1c,EAAiBgG,EAAY,CAAC,CAAC,EAC9CM,EAAapR,EAAU,KAAK8Q,CAAW,EAAInF,EAAa6b,EACxDwI,EAAS,CAAC15B,EAAO,CAAC,EAAE,KAAK,CAAC,EAAGA,EAAO,CAAC,EAAE,KAAK,CAAC,EAAGA,EAAO,CAAC,EAAE,KAAK,CAAC,EAAGA,EAAO,CAAC,EAAE,KAAK,CAAC,EAAIqV,CAAU,EACjGskB,EAAS,CAAC35B,EAAO,CAAC,EAAE,KAAK,CAAC,EAAGA,EAAO,CAAC,EAAE,KAAK,CAAC,EAAGA,EAAO,CAAC,EAAE,KAAK,CAAC,EAAGA,EAAO,CAAC,EAAE,KAAK,CAAC,EAAIqV,CAAU,EACjG+b,EAAsB,CAAC5W,EAAY,CAAC,EAAGA,EAAY,CAAC,EAAGA,EAAY,CAAC,EAAGA,EAAY,CAAC,EAAInF,CAAU,EAElGC,EAAoC,CACxC,CAAE,QAAuB,KAAMwF,CAAW,EAC1C,CAAE,OAAsB,KAAM,CAACI,EAAW,QAAQ,CAAC,EAAGA,EAAW,QAAQ,CAAC,CAAC,CAAE,EAC7E,CAAE,OAAsB,KAAM,CAACA,EAAW,KAAK,CAAC,EAAGA,EAAW,KAAK,CAAC,CAAC,CAAE,CACzE,EACA8T,GAA6B9T,EAAY5F,CAAe,EACxDA,EAAgB,KAAK,GAAGf,EAA2BmlB,EAAQC,EAAQvI,CAAmB,CAAC,EACvF,IAAM2I,GAAW7I,EAAe,GAAKhW,EAAW,QAAQ,CAAC,EAAIye,EAAO,CAAC,EAC/D/e,EAAmBC,GAA+B,CACtD,IAAM7D,EAASjC,EAAe,SAAU/U,EAAO,CAAC,EAAE,SAAUoxB,EAAoB,OAAQ/b,CAAU,EAC5F+Z,EAAW/a,GAA4B2C,EAAO,KAAK,MAAM,EACzDsa,EAAkBvC,GAAqB7T,EAAYlE,EAAO,KAAK,MAAOoY,CAAQ,EAC9E5jB,EAAIsJ,EAAc,IAAK9U,EAAO,CAAC,EAAE,SAAU05B,EAAO,OAAQrkB,CAAU,EACpE+gB,EAAIthB,EAAc,IAAK9U,EAAO,CAAC,EAAE,SAAU25B,EAAO,OAAQtkB,CAAU,EACpE2O,EAAY,CAACxY,EAAG4qB,CAAC,EACnBtG,GACF9L,EAAU,KAAKlP,EAAc,IAAK9U,EAAO,CAAC,EAAE,SAAUA,EAAO,CAAC,EAAE,KAAMqV,CAAU,CAAC,EAEnF,IAAMmc,EAAc1B,EAAU,8BAAgC,GACxD/M,EAA8B,CAClC,CAAE,KAAM,cAAe,KAAM,KAAM,EACnC,CAAE,KAAM,UAAW,KAAM,MAAO,OAAQ,CAAE,EAC1C,CAAE,KAAM,OAAQ,KAAM,MAAO,OAAQ,CAAE,CACzC,EACA,OAAAkM,GAAyB/T,EAAY6H,CAAQ,EACtC;AAAA,IACPlI,EAAa,iBAAiBkI,CAAQ,EAAE,iBAAiB,GAAGiB,EAAWhN,CAAM,CAAC;AAAA,IAC9E6D,EAAa,UAAU,CAAC;AAAA,MACtBA,EAAa,sCAAsC,sBAAsB,CAAC;AAAA;AAAA;AAAA;AAAA,8CAIlCqW,CAAY;AAAA,oCACtBA,CAAY;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,wBAOxB1lB,EAAE,KAAK,KAAK,KAAKuuB,CAAO;AAAA,wBACxB/iB,EAAO,KAAK,KAAK,KAAKka,CAAY;AAAA;AAAA;AAAA,8CAGZyI,EAAO,CAAC,CAAC;AAAA;AAAA;AAAA,8BAGzBI,CAAO;AAAA;AAAA;AAAA,0BAGXvuB,EAAE,IAAI,QAAS,gBAAiB,eAAgB,eAAe,CAAC;AAAA;AAAA,0BAEhEA,EAAE,KAAK,KAAK;AAAA;AAAA;AAAA,gDAGUmuB,EAAO,CAAC,CAAC;AAAA,wBACjCvD,EAAE,IAAI,WAAY,UAAW,IAAK,gBAAgB,CAAC;AAAA,iCAC1ClF,CAAY;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,2BAOlBA,CAAY;AAAA;AAAA,QAE/BM,CAAW;AAAA,QACXF,CAAe;AAAA,QACfta,EAAO,IAAI,QAAS,MAAO,UAAW,iBAAkB,OAAO,CAAC;AAAA;AAAA,IAGtE,EAEA,MAAO,CACL,KAAM,wBACN,YAAa,CACX,KAAM,GAAGkE,EAAW,QAAQ,IAAI7F,CAAU,IAAI6b,CAAY,IAAI6I,CAAO,IAAIJ,EAAO,CAAC,CAAC,IAAIA,EAAO,CAAC,CAAC,GAC/F,kBAAmB7J,EAAU,CAAC,OAAQ,OAAQ,MAAM,EAAI,CAAC,OAAQ,MAAM,CACzE,EACA,WAAY,KAAO,CACjB,QAAS,CACP,CACE,KAAMgB,EAA6BA,EAA2BtW,CAAW,EAAIA,EAC7E,SAAUxa,EAAO,CAAC,EAAE,QACtB,CACF,EACA,cAAe,CAAE,EAAG,KAAK,KAAK8a,EAAa,EAAuB,CAAE,EACpE,gBAAAxF,CACF,GACA,gBAAAsF,CACF,CACF,IC5QA,IAgBaof,GAmCPC,GAEA7gB,GAkDA8gB,GA4BOC,GA0BPC,GAsMAC,GA8BAC,GAyBOC,GA1ZbC,GAAAzlC,EAAA,kBAIAgV,IAIAuqB,KACAuC,KACAzE,KACAqH,KACAtK,KACAiB,KACAvW,KAEamgB,GAAuB,CAClClgB,EACA9N,EACAC,EACAwuB,EACApvB,EACAc,IACa,CACb,IAAMiV,EAAYtH,EAAW,CAAC,EACxB4gB,EAAoB5gB,EAAW,MAAM3N,EAAgB,EAAI,EAAGA,EAAgB,EAAI,CAAC,EACjFwuB,EAAcD,EAAkB,OAChC5E,EAAc9pB,EAAY,CAAC,EAE3B4uB,EADqB5uB,EAAY,MAAM,CAAC,EACA,IAAI,CAACzO,EAAGnI,IAAMmI,GAAKA,EAAI,IAAM0O,EAAU7W,CAAC,EAAI,EAAE,EAEtFolB,EAD2BkgB,EAAkB,IAAI,CAACn9B,EAAGnI,IAAMmI,EAAIk9B,EAAWrlC,CAAC,EAAIqlC,EAAWrlC,EAAIulC,CAAW,CAAC,EACnE,IAAI,CAACp9B,EAAGnI,IACnD,KAAK,OAAOmI,EAAIq9B,EAAmBxlC,CAAC,EAAIiW,EAAQjW,CAAC,GAAKiW,EAAQjW,CAAC,CAAC,CAClE,EACA,OAAAolB,EAAY,OAAO,EAAG,EAAG4G,CAAS,EAClC5G,EAAY,OAAOrO,EAAgB,EAAI,EAAG,EAAG2pB,CAAW,EACjDtb,CACT,EAcMyf,GAA2B,CAAC,EAAG,EAAG,EAAG,CAAC,EAEtC7gB,GAAiB,CAACpZ,EAA+Bkb,IAAqC,CAG1F,GAAI,CAAClb,GAAWA,EAAO,SAAW,GAAKA,EAAO,SAAW,EACvD,MAAM,IAAI,MAAM,6BAA6B,EAG/C,GAAIA,EAAO,CAAC,EAAE,KAAK,OAAS,EAC1B,MAAM,IAAI,MAAM,kCAAkC,EAGpD,GAAIA,EAAO,CAAC,EAAE,KAAK,SAAWA,EAAO,CAAC,EAAE,KAAK,OAC3C,MAAM,IAAI,MAAM,8CAA8C,EAIhE,IAAM66B,EAAc76B,EAAO,CAAC,EAAE,KAAKkb,EAAW,SAAW,OAASlb,EAAO,CAAC,EAAE,KAAK,OAAS,EAAI,CAAC,EACzF86B,EAAkB96B,EAAO,CAAC,EAAE,KAAK,CAAC,EAAIkb,EAAW,MACvD,GAAI2f,IAAgBC,EAClB,MAAM,IAAI,MAAM,mDAAmD,EAIrE,GAAI96B,EAAO,SAAW,IAAMA,EAAO,CAAC,EAAE,KAAK,SAAW,GAAKA,EAAO,CAAC,EAAE,KAAK,CAAC,IAAMA,EAAO,CAAC,EAAE,KAAK,CAAC,GAC/F,MAAM,IAAI,MAAM,cAAc,EAGhC,IAAM26B,EAAc36B,EAAO,CAAC,EAAE,KAAK,OAAS,EAE5C,GAAIkb,EAAW,UAAU,SAAWyf,EAClC,MAAM,IAAI,MAAM,uBAAuBA,CAAW,GAAG,EAIvD,GAAIzf,EAAW,QAAQ,SAAWyf,EAChC,MAAM,IAAI,MAAM,qBAAqBA,CAAW,GAAG,EAIrD,GAAIzf,EAAW,KAAK,SAAWyf,EAAc,EAC3C,MAAM,IAAI,MAAM,kBAAkBA,EAAc,CAAC,GAAG,EAKtD,GAAIzf,EAAW,YAAY,SAAW,GAAKA,EAAW,YAAY,SAAWlb,EAAO,CAAC,EAAE,KAAK,OAAS,EACnG,MAAM,IAAI,MAAM,sBAAsB,CAE1C,EAEMk6B,GAA4B,CAA2Bhf,EAAelb,IAAqC,CAC/G,IAAMgM,EAAckP,EAAW,YAAY,MAAM,EAE7ClP,EAAY,OAAShM,EAAO,CAAC,EAAE,KAAK,OAAS,GAC/CgM,EAAY,KAAK,GAAG,MAAMhM,EAAO,CAAC,EAAE,KAAK,OAAS,EAAIgM,EAAY,MAAM,EAAE,KAAK,CAAC,CAAC,EAEnF,QAAS,EAAI,EAAG,EAAIhM,EAAO,CAAC,EAAE,KAAK,OAAQ,EAAE,EACvCgM,EAAY,EAAI,CAAC,IAAM,IACzBA,EAAY,EAAI,CAAC,EAAIhM,EAAO,CAAC,EAAE,KAAK,CAAC,GAGzC,IAAMkM,EAAOgP,EAAW,KAAK,MAAM,EACnCvR,GAAa,yBACX3J,EAAO,CAAC,EAAE,KACVkb,EAAW,QACXA,EAAW,UACXlP,EACAE,EACAgP,EAAW,SAAW,OACtBA,EAAW,OACb,EAGA,IAAM6f,EAAmB,OAAO,OAAO,CAAC,EAAG7f,CAAU,EACrD,cAAO,OAAO6f,EAAe,CAAE,YAAA/uB,EAAa,KAAAE,CAAK,CAAC,EAC3C6uB,CACT,EAEaZ,GAAuBjf,GAAwD,CAC1F,IAAMyV,EAAuBzB,GAAkChU,CAAU,EAEnE+K,EAAS/K,EAAW,OACpB9O,EAAU,CAAC,SAAU,QAAS,aAAc,YAAY,EAAE8O,EAAW,QAAkB,EACvFjP,EAAYiP,EAAW,UACvB8f,EAAQ9f,EAAW,MACnBlP,EAAckP,EAAW,aACzBhP,EAAOgP,EAAW,KAClB7P,EAAU6P,EAAW,QACrB+f,EAAY/f,EAAW,WAA6B,EAE1D,MAAO,CACL,QAAA9O,EACA,OAAA6Z,EACA,UAAAha,EACA,MAAA+uB,EACA,YAAAhvB,EACA,KAAAE,EACA,QAAAb,EACA,SAAA4vB,EACA,GAAGtK,EACH,SAAU,GAAGzV,EAAW,MAAM,IAAIyV,EAAqB,UAAU,GACnE,CACF,EAEMyJ,GAAS,CACbpgC,EACAgG,EACAkb,EACA4V,IACS,CAIT,IAAMD,EAAiB3V,EAAW,SAAW,OACvCV,EAAcwf,GAClBh6B,EAAO,CAAC,EAAE,KACVA,EAAO,CAAC,EAAE,KACVkb,EAAW,UACXA,EAAW,KACXA,EAAW,QACX2V,CACF,EACA,GAAI3V,EAAW,QAAU,EAAG,CAC1B,IAAMggB,EAAa,CAACl7B,EAAO,CAAC,CAAC,EAC7B,GAAI6wB,EAAgB,CAClB,IAAMsK,EACHnhC,EAAQ,iBAAiB,IAC1BA,EAAQ,QAAQ0f,GAA2B1Z,EAAO,CAAC,EAAGi6B,EAAwB,EAAG,CAC/E,OAAQ,CAAC,CAAC,EACV,QAAS,CAAC/e,EAAW,SAAW,GAAK,EAAE,CACzC,CAAC,EAAE,CAAC,EACFA,EAAW,UAAY,CAAClhB,EAAQ,iBAAiB,KACnDA,EAAQ,iBAAiB,GAAKmhC,GAEhCD,EAAW,KAAKC,CAAgB,CAClC,MACED,EAAW,KAAKl7B,EAAO,CAAC,CAAC,EAEvBA,EAAO,SAAW,GACpBk7B,EAAW,KAAKl7B,EAAO,CAAC,CAAC,EAMQ,CAAChG,EAAQ,YAAY,eAAe,QAAQ,GAG7E62B,GACA7wB,EAAO,CAAC,EAAE,KAAK,CAAC,IAAMkb,EAAW,OACjClb,EAAO,CAAC,EAAE,KAAK,CAAC,IAAM,GACtBkb,EAAW,UAAU,CAAC,IAAM,GAC5BA,EAAW,UAAU,CAAC,IAAM,EAE5BlhB,EAAQ,QACNw/B,GAAsC0B,EAAYhgB,EAAYV,EAAasW,CAA0B,EACrG,CAAE,OAAQoK,CAAW,CACvB,EAEAlhC,EAAQ,QAAQu/B,GAA6B2B,EAAYhgB,EAAYV,EAAasW,CAA0B,EAAG,CAC7G,OAAQoK,CACV,CAAC,EAEH,MACF,CAEA,IAAMpL,EAAU9vB,EAAO,SAAW,EAC5Bo7B,EAAcp7B,EAAO,CAAC,EAAE,KAAK6wB,EAAiB,EAAI,CAAC,EACnDwK,EAAar7B,EAAO,CAAC,EAAE,KAAK6wB,EAAiB,EAAI,CAAC,EAClDyK,EAAgBt7B,EAAO,CAAC,EAAE,KAAK6wB,EAAiB,EAAI,CAAC,EACrD0K,EAAev7B,EAAO,CAAC,EAAE,KAAK,CAAC,EAC/Bw7B,EAAcx7B,EAAO,CAAC,EAAE,KAAK,CAAC,EAE9B61B,EAAYrb,EAAYqW,EAAiB,EAAI,CAAC,EAC9C+E,EAAWpb,EAAYqW,EAAiB,EAAI,CAAC,EAC7CiF,EAActb,EAAYqW,EAAiB,EAAI,CAAC,EAEhD4K,EACJ5K,GACA0K,IAAiBH,GACjBI,IAAgBH,GAChBngB,EAAW,KAAK,CAAC,IAAM,GACvBA,EAAW,KAAK,CAAC,IAAM,EACzB,GACEugB,GACCF,IAAiB,GAChBC,IAAgB,GAChBtgB,EAAW,UAAU,CAAC,IAAM,GAC5BA,EAAW,UAAU,CAAC,IAAM,GAC5BA,EAAW,QAAQ,CAAC,IAAM,GAC1BA,EAAW,QAAQ,CAAC,IAAM,GAC1BA,EAAW,KAAK,CAAC,IAAM,GACvBA,EAAW,KAAK,CAAC,IAAM,EACzB,CAEA,IAAMwgB,EAAQlhB,EAAY,CAAC,EACvBmhB,EAAWC,EAAWC,EACpBC,EAAe,CAAC,EACtB,GAAIjL,EAAgB,CAClB,IAAMsK,EACHnhC,EAAQ,iBAAiB,IAC1BA,EAAQ,QAAQ0f,GAA2B1Z,EAAO,CAAC,EAAGi6B,EAAwB,EAAG,CAC/E,OAAQ,CAAC,CAAC,EACV,QAAS,CAAC/e,EAAW,SAAW,GAAK,EAAE,CACzC,CAAC,EAAE,CAAC,EAIN,GAHIA,EAAW,UAAY,CAAClhB,EAAQ,iBAAiB,KACnDA,EAAQ,iBAAiB,GAAKmhC,GAE5BM,EAAU,CACZ,IAAMM,EAAYX,EAAcC,EAAaC,EAC7CK,EAAY37B,EAAO,CAAC,EAAE,QAAQ,CAAC,EAAG07B,EAAOK,CAAS,CAAC,EACnDH,EAAYT,EAAiB,QAAQ,CAAC,EAAGY,EAAWjG,CAAW,CAAC,EAChE+F,EAAoB,CAAC,EAAGH,EAAO5F,CAAW,CAC5C,MACE6F,EAAY37B,EAAO,CAAC,EAAE,QAAQ,CAAC07B,EAAON,EAAcC,EAAYC,CAAa,CAAC,EAC9EM,EAAYT,EAAiB,QAAQ,CAAC,EAAGG,EAAexF,CAAW,CAAC,EACpE+F,EAAoB,CAACH,EAAO7F,EAAYD,EAAUE,CAAW,EAE/DgG,EAAa,KAAKH,CAAS,EAC3BG,EAAa,KAAKF,CAAS,CAC7B,MACED,EAAY37B,EAAO,CAAC,EAAE,QAAQ,CAAC07B,EAAOJ,EAAeF,EAAcC,CAAU,CAAC,EAC9EO,EAAY57B,EAAO,CAAC,EAAE,QAAQ,CAAC,EAAG81B,EAAawF,CAAa,CAAC,EAC7DO,EAAoB,CAACH,EAAO5F,EAAaD,EAAYD,CAAQ,EAC7DkG,EAAa,KAAKF,CAAS,EAC3BE,EAAa,KAAKH,CAAS,EAEzB7L,GACFgM,EAAa,KAAK97B,EAAO,CAAC,CAAC,EAE7B,IAAMqN,EAAIwuB,EAAkB,CAAC,EACvBzuB,EAAI0uB,EAAa,CAAC,EAAE,KAAKA,EAAa,CAAC,EAAE,KAAK,OAAS,CAAC,EAE1DzuB,EAAI,GAAKD,EAAI,EACfpT,EAAQ,QACNm2B,GACE2L,EACA5gB,EACAV,EACAqhB,EACAhL,EACAC,CACF,EACA,CAAE,OAAQgL,CAAa,CACzB,EAEA9hC,EAAQ,QACNm4B,GACE2J,EACA5gB,EACAV,EACAqhB,EACAhL,EACAC,CACF,EACA,CAAE,OAAQgL,CAAa,CACzB,EAEF,MACF,CAIA,IAAM9I,EAAgE,GAGhEmI,EACHnhC,EAAQ,iBAAiB,IAC1BA,EAAQ,QAAQ0f,GAA2B1Z,EAAO,CAAC,EAAGi6B,EAAwB,EAAG,CAC/E,OAAQ,CAAC,CAAC,EACV,QAAS,CAAC/e,EAAW,SAAW,GAAK,EAAE,CACzC,CAAC,EAAE,CAAC,EACFA,EAAW,UAAY,CAAClhB,EAAQ,iBAAiB,KACnDA,EAAQ,iBAAiB,GAAKmhC,GAIhC,IAAMD,EAAa,CAACl7B,EAAO,CAAC,EAAGm7B,CAAgB,EAC3CrL,GACFoL,EAAW,KAAKl7B,EAAO,CAAC,CAAC,EAI3B,IAAMyzB,EAAY5C,EAAiBgF,EAAYD,EAAWE,EACpDnC,EAAY9C,EAAiBiF,EAAcD,EAAYD,EACvDlC,EAAW6H,EAAeC,EAAcF,EAC9CthC,EAAQ,QACNq6B,GACE6G,EACAhgB,EACAV,EACAiZ,EACAE,EACAD,EACA5D,EACAkD,EACAlC,CACF,EACA,CAAE,OAAQoK,CAAW,CACvB,CACF,EAEMb,GAAS,CAACrgC,EAAyBkhB,IAAqC,CAE5E,IAAM/O,EAAgB+O,EAAW,SAAW,OACtClb,EAAS,CACbhG,EAAQ,OAAO,CAAC,EAAE,QAChBmS,EAEI,CAACnS,EAAQ,OAAO,CAAC,EAAE,KAAK,CAAC,EAAG,EAAGA,EAAQ,OAAO,CAAC,EAAE,KAAK,CAAC,EAAGA,EAAQ,OAAO,CAAC,EAAE,KAAK,CAAC,CAAC,EAEnF,CAACA,EAAQ,OAAO,CAAC,EAAE,KAAK,CAAC,EAAGA,EAAQ,OAAO,CAAC,EAAE,KAAK,CAAC,EAAG,EAAGA,EAAQ,OAAO,CAAC,EAAE,KAAK,CAAC,CAAC,CACzF,EAEAA,EAAQ,OAAO,CAAC,EAAE,QAAQ,CAACA,EAAQ,OAAO,CAAC,EAAE,KAAK,CAAC,EAAGA,EAAQ,OAAO,CAAC,EAAE,KAAK,CAAC,EAAG,EAAGA,EAAQ,OAAO,CAAC,EAAE,KAAK,CAAC,CAAC,CAAC,CAChH,EACIA,EAAQ,OAAO,SAAW,GAC5BgG,EAAO,KAAKhG,EAAQ,OAAO,CAAC,CAAC,EAE/B,IAAMkS,EAAO,CAAC,EAAGgP,EAAW,KAAK,CAAC,EAAG,EAAGA,EAAW,KAAK,CAAC,CAAC,EACpD7P,EAAU,CAAC,CAAC,EAAE,OAAO6P,EAAW,OAAO,EACvCjP,EAAY,CAAC,CAAC,EAAE,OAAOiP,EAAW,SAAS,EAC3ClP,EAAc,CAAC,CAAC,EAAE,OAAOkP,EAAW,WAAW,EAC/C8gB,EAAqB9B,GACzB,CAAE,GAAGhf,EAAY,KAAAhP,EAAM,QAAAb,EAAS,UAAAY,EAAW,YAAAD,CAAY,EACvDhM,CACF,EACAo6B,GAAOpgC,EAASgG,EAAQg8B,EAAqBxhB,GAC3CrO,EAAgB,CAACqO,EAAY,CAAC,EAAGA,EAAY,CAAC,EAAGA,EAAY,CAAC,CAAC,EAAI,CAACA,EAAY,CAAC,EAAGA,EAAY,CAAC,EAAGA,EAAY,CAAC,CAAC,CACpH,CACF,EAEM8f,GAAS,CAACtgC,EAAyBgG,EAA+Bkb,IAAqC,CAC3G,IAAM+K,EAAS/K,EAAW,SAAW,OAAS,eAAiB,gBACzD8gB,EAAqB9B,GAA0Bhf,EAAYlb,CAAM,EACjEkM,EAAOgP,EAAW,UAAY,SAAWA,EAAW,KAAOA,EAAW,QACtE+gB,EAAWtF,GACf32B,EAAO,CAAC,EAAE,KACVA,EAAO,CAAC,EAAE,KACVkb,EAAW,QACXA,EAAW,UACXhP,EACA,GACA+Z,CACF,EACAjsB,EAAQ,QACN48B,GACE52B,EACAg8B,EACAC,EAAS,SACT,CAACA,EAAS,YAAaA,EAAS,aAAcA,EAAS,WAAW,EAClE,CAACA,EAAS,QAAQ,MAAOA,EAAS,QAAQ,IAAKA,EAAS,QAAQ,IAAI,EACpEhW,CACF,CACF,CACF,EAEasU,GAAO,CAACvgC,EAAyBkhB,IAAqC,CAEjF,GADA9B,GAAepf,EAAQ,OAAQkhB,CAAU,EACrClhB,EAAQ,OAAO,CAAC,EAAE,KAAK,SAAW,EACpCqgC,GAAOrgC,EAASkhB,CAAU,UACjBlhB,EAAQ,OAAO,CAAC,EAAE,KAAK,SAAW,EAC3CsgC,GAAOtgC,EAASA,EAAQ,OAAQkhB,CAAU,MACrC,CACL,IAAM8gB,EAAqB9B,GAA0Bhf,EAAYlhB,EAAQ,MAAM,EAC/EogC,GAAOpgC,EAASA,EAAQ,OAAQgiC,CAAkB,CACpD,CACF,ICpaA,IAmCaE,GAnCbC,GAAApnC,EAAA,kBAmBAkS,IACAgC,KAEAc,IAEAqL,IAWa8mB,GAAmC,CAC9Cl8B,EACAkb,EACA4V,IACgB,CAChB,IAAMhB,EAAU9vB,EAAO,OAAS,EAC1Bwa,EAAcU,EAAW,YACzB2V,EAAiB3V,EAAW,SAAW,OACvC8f,EAAQ9f,EAAW,MACnBye,EAAS35B,EAAO,CAAC,EAAE,KACnBo8B,EAAwBzC,EAAO,CAAC,EAAIqB,EACpCnB,EAAyBF,EAAO,CAAC,EACjC1I,EAAcJ,EAAiBrc,EAAiB4nB,CAAqB,EAAI,EACzEC,EAAexL,GAAkBgJ,IAA2B,GAAKuC,GAAyB,EAC1FE,EAA2BD,EAC7B,KAAK,MAAMD,EAAwB,CAAC,EAAI,EACxC,KAAK,MAAMA,EAAwBnL,CAAW,EAAIA,EAChDsL,EAAyBH,EAAwBE,EACjDjnB,EAAawb,EAAiBrc,EAAiBqlB,CAAsB,EAAI,EACzE2C,EAAc3L,EAAkBgJ,IAA2B,EAAI5I,EAAc5b,EAAc,EAC3FyF,EAAapR,EAAU,KAAK8Q,CAAW,EAAInF,EAC3CuO,EAAW,CAAC,KAAK,KAAK9I,EAAa,EAAE,EAAG,EAAG,CAAC,EAClD9R,EAAU,UAAW,IAAM,uCAAuC4a,CAAQ,EAAE,EAE5E,IAAMnB,EAAwD,CAAC,OAAQ,MAAM,EACvEpX,EAAU,CAAC6P,EAAW,QAAQ,CAAC,EAAGA,EAAW,QAAQ,CAAC,CAAC,EACvD5O,EAAa,CAAC4O,EAAW,YAAY2V,EAAiB,EAAI,CAAC,EAAG3V,EAAW,YAAY2V,EAAiB,EAAI,CAAC,CAAC,EAC5G5kB,EAAY,CAACiP,EAAW,UAAU,CAAC,EAAGA,EAAW,UAAU,CAAC,CAAC,EAC7DuhB,EAAsB,CAC1BnwB,EAAW,CAAC,GACT4O,EAAW,UAAU,CAAC,GAAK,EACxB,GACCA,EAAW,YAAY2V,EAAiB,EAAI,CAAC,EAAI,IAAM3V,EAAW,UAAU,CAAC,EAAI,IACxF5O,EAAW,CAAC,GACT4O,EAAW,UAAU,CAAC,GAAK,EACxB,GACCA,EAAW,YAAY2V,EAAiB,EAAI,CAAC,EAAI,IAAM3V,EAAW,UAAU,CAAC,EAAI,GAC1F,EACMhP,EAAO,CACXuwB,EAAoB,CAAC,EAAI,EAAI,KAAK,OAAOvhB,EAAW,KAAK,CAAC,EAAIA,EAAW,KAAK,CAAC,GAAK,CAAC,EACrFuhB,EAAoB,CAAC,EAAI,EAAI,KAAK,OAAOvhB,EAAW,KAAK,CAAC,EAAIA,EAAW,KAAK,CAAC,GAAK,CAAC,CACvF,EAEM5F,EAAoC,CACxC,CAAE,QAAuB,KAAMwF,CAAW,EAC1C,CAAE,QAAuB,KAAMzP,CAAQ,EACvC,CAAE,QAAuB,KAAMiB,CAAW,EAC1C,CAAE,QAAuB,KAAML,CAAU,EACzC,CAAE,QAAuB,KAAMwwB,CAAoB,EACnD,CAAE,OAAsB,KAAMvwB,CAAK,EACnC,CAAE,QAAuB,KAAMowB,CAAyB,EACxD,CAAE,QAAuB,KAAMF,CAAsB,EACrD,CAAE,QAAuB,KAAMvC,CAAuB,EACtD,GAAGtlB,EAA2BvU,EAAO,CAAC,EAAE,KAAMA,EAAO,CAAC,EAAE,IAAI,CAC9D,EACI8vB,IACFxa,EAAgB,KAAK,GAAGf,EAA2BvU,EAAO,CAAC,EAAE,IAAI,CAAC,EAClEyiB,EAAkB,KAAK,MAAM,GAE/BnN,EAAgB,KAAK,GAAGf,EAA2BiG,CAAW,CAAC,EAE/D,IAAMI,EAAmBC,GAA+B,CACtD,IAAMkI,EAA8B,CAClC,CAAE,KAAM,cAAe,KAAM,KAAM,EACnC,CAAE,KAAM,UAAW,KAAM,MAAO,OAAQ1X,EAAQ,MAAO,EACvD,CAAE,KAAM,cAAe,KAAM,MAAO,OAAQiB,EAAW,MAAO,EAC9D,CAAE,KAAM,YAAa,KAAM,MAAO,OAAQA,EAAW,MAAO,EAC5D,CAAE,KAAM,wBAAyB,KAAM,MAAO,OAAQmwB,EAAoB,MAAO,EACjF,CAAE,KAAM,OAAQ,KAAM,MAAO,OAAQvwB,EAAK,MAAO,EACjD,CAAE,KAAM,+BAAgC,KAAM,KAAM,EACpD,CAAE,KAAM,2BAA4B,KAAM,KAAM,EAChD,CAAE,KAAM,4BAA6B,KAAM,KAAM,CACnD,EACM1R,EAAW6Z,GAA4BrU,EAAO,CAAC,EAAE,QAAQ,EACzD08B,EAAS7L,EAAiB,EAAI,EAC9B8L,EAAS9L,EAAiB,EAAI,EAC9B+L,GAAa/L,EAAiB,EAAI,EAElCuF,EAAIthB,EAAc,IAAK9U,EAAO,CAAC,EAAE,SAAUA,EAAO,CAAC,EAAE,KAAK,OAAQw8B,CAAW,EAC7EK,EAAK/nB,EAAc,KAAM9U,EAAO,CAAC,EAAE,SAAUA,EAAO,CAAC,EAAE,KAAK,OAAQixB,CAAW,EAC/EM,EAAiB,CAACsL,EAAIzG,CAAC,EACzBtG,GACFyB,EAAe,KAAKzc,EAAc,OAAQ9U,EAAO,CAAC,EAAE,SAAU,CAACwa,EAAYoiB,EAAU,CAAC,EAAE,OAAQvnB,CAAU,CAAC,EAE7G,IAAM2B,EAASjC,EAAe,SAAU/U,EAAO,CAAC,EAAE,SAAUwa,EAAY,OAAQnF,CAAU,EAEpFykB,GAAkB,IAAc,CACpC,IAAInI,EAAU,GACd,GAAI0K,EACEpL,IAAgB,EAClBU,GAAW;AAAA,uBACEkL,EAAG,YAAY,UAAU,CAAC;AAAA,uBAC1BzG,EAAE,YAAY,UAAU,CAAC;AAAA;AAAA;AAAA,yBAI7BnF,IAAgB,EACzBU,GAAW;AAAA,yCACoBn3B,CAAQ,KAAKqiC,EAAG,YAAY,UAAU,CAAC,KAAKA,EAAG,YAAY,eAAe,CAAC,WAAWriC,CAAQ,KAAK47B,EAAE,YAAY,UAAU,CAAC,KAAKA,EAAE,YAAY,eAAe,CAAC;AAAA;AAAA,2BAGrLnF,IAAgB,IACzBU,GAAW;AAAA,yCACoBn3B,CAAQ,KAAKqiC,EAAG,YAAY,UAAU,CAAC,KAAKA,EAAG,YAAY,eAAe,CAAC,KAAKA,EAAG,YAAY,eAAe,CAAC,KAAKA,EAAG,YAAY,eAAe,CAAC,WAAWriC,CAAQ,KAAK47B,EAAE,YAAY,UAAU,CAAC,KAAKA,EAAE,YAAY,eAAe,CAAC,KAAKA,EAAE,YAAY,eAAe,CAAC,KAAKA,EAAE,YAAY,eAAe,CAAC;AAAA;AAAA,oCAK9UzE,GAAW;AAAA,iCAECd,EACIgM,EAAG,YACD,GAAGA,EAAG,gBAAgB,GAAGA,EAAG,KAAK,OAAO,mCAAmC,CAAC,MAAM5L,CAAW,EAC/F,EACA4L,EAAG,IAAI,QAAS,eAAgB,OAAQ,MAAM,CACpD;AAAA,UAEN5L,IAAgB,EAClBU,GAAW;AAAA,2BACMyE,EAAE,gBAAgB,GAAGA,EAAE,KAAK,OAAO,uDAAuD,CAAC;AAAA,yBAC7FA,EAAE,YAAY,cAAcoG,CAAW,EAAE,CAAC;AAAA,oDAGzD,SAASM,EAAI,EAAGA,EAAI7L,EAAa6L,IAC/BnL,GAAW;AAAA,wBACCmL,CAAC,MAAM1G,EAAE,YAAY,GAAGA,EAAE,gBAAgB,GAAGA,EAAE,KAAK,OAAO,6CAA6C0G,CAAC,gBAAgB,CAAC,MAAMN,CAAW,EAAE,CAAC;AAAA,yCAC7HM,CAAC,aAAaA,CAAC,IAIlD,OAAOnL,CACT,EACMoL,GAAqB,IAAc,CACvC,GAAIR,IAA2B,EAC7B,MAAO,GAET,GAAI,CAACF,EACH,MAAM,IAAI,MAAM,gBAAgBA,CAAY,eAAe,EAE7D,IAAI1K,EAAU,GACd,GAAIV,IAAgB,EAAG,CACrBU,GAAW,oBACX,QAASv8B,EAAI,EAAGA,EAAImnC,EAAwBnnC,IAC1Cu8B,GAAW;AAAA,gBACLkL,EAAG,YAAY,cAAcznC,CAAC,EAAE,CAAC,MAAMghC,EAAE,YAAY,cAAchhC,CAAC,EAAE,CAAC,GAE/Eu8B,GAAW,GACb,SAAWV,IAAgB,EAAG,CAC5B,GAAIsL,IAA2B,EAC7B,MAAM,IAAI,MAAM,kCAAkCA,CAAsB,GAAG,EAE7E5K,GAAW;AAAA,yBACMkL,EAAG,YAAY,UAAU,CAAC;AAAA,yBAC1BzG,EAAE,YAAY,UAAU,CAAC;AAAA,mDAE5C,CACA,OAAOzE,CACT,EACMqL,GAAc;AAAA,kCACUhmB,EAAO,gBAAgB,gBAAgB3B,CAAU,EAAE,CAAC;AAAA,0BAC5D2B,EAAO,WAAW,gBAAiB,CAAC,CAAC;AAAA,uBACxCA,EAAO,WAAW,gBAAiB4lB,EAAU,CAAC;AAAA,sBAC/C5lB,EAAO,WAAW,gBAAiB0lB,CAAM,CAAC;AAAA,sBAC1C1lB,EAAO,WAAW,gBAAiB2lB,CAAM,CAAC;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,4BAQpC3lB,EAAO,KAAK,KAAK;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,2BAUlBxc,CAAQ,iBAAiBA,CAAQ,WAAWA,CAAQ;AAAA;AAAA,wCAEvCA,CAAQ,sBAAsBkiC,CAAM;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,6BAc/CliC,CAAQ,iBAAiBA,CAAQ,WAAWA,CAAQ;AAAA;AAAA,0CAEvCA,CAAQ,sBAAsBmiC,CAAM;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,kBAO5DN,EACI;AAAA,iCACWQ,EAAG,gBAAgB,GAAGA,EAAG,KAAK,OAAO,mCAAmC,CAAC,MAAM5L,CAAW;AAAA,iCAC1FmF,EAAE,gBAAgB,GAAGA,EAAE,KAAK,OAAO,6CAA6C,CAAC,MAAMoG,CAAW;AAAA,oBAE7G,EACN;AAAA,8FAC8EH,EAAe,EAAIpL,CAAW;AAAA,oBACxG6I,GAAgB,CAAC;AAAA,kDACauC,EAAe,EAAIpL,CAAW;AAAA;AAAA,kBAE9D8L,GAAmB,CAAC;AAAA;AAAA;AAAA;AAAA;AAAA,iCAKLjN,EAAU,gBAAgBza,CAAU,IAAM,EAAE;AAAA,cAC/D2B,EAAO,YAAY,aAAc,OAAO,CAAC;AAAA,YAGnD,MAAO;AAAA,MACL6D,EAAa,iBAAiBkI,CAAQ,EAAE,iBAAiB,GAAGwO,EAAgBva,CAAM,CAAC;AAAA,QACjF6D,EAAa,UAAU,CAAC;AAAA,QACxBA,EAAa,sCAAsC,sBAAsB,CAAC;AAAA,MAC5EmiB,EAAW,GACf,EAEA,MAAO,CACL,KAAM,kBACN,YAAa,CACX,KAAM,GAAG9hB,EAAW,QAAQ,IAAI+V,CAAW,GAAGuL,CAAW,GAAGnnB,CAAU,GAAGgnB,CAAY,GAAGE,CAAsB,GAC9G,kBAAA9Z,CACF,EACA,WAAY,KAAO,CACjB,cAAe,CAAE,EAAGmB,EAAS,CAAC,EAAG,EAAGA,EAAS,CAAC,EAAG,EAAGA,EAAS,CAAC,CAAE,EAChE,QAAS,CACP,CACE,KAAMkN,EAA6BA,EAA2BtW,CAAW,EAAIA,EAC7E,SAAUxa,EAAO,CAAC,EAAE,QACtB,CACF,EACA,gBAAAsV,CACF,GACA,gBAAAsF,CACF,CACF,IC9RA,IAWMqiB,GASAC,GAWAC,GA4CAC,GAmDOC,GA+BPjkB,GAuEAkkB,GA2BAC,GAkDOC,GAjTbC,GAAA1oC,EAAA,kBAMAonC,KAEAhN,KACAtV,KAEMojB,GAAkB,CACtBS,EACAlmC,EACAmmC,EACAlxB,EACAD,EACAoxB,KACIF,EAAQ,GAAKlmC,EAASmmC,GAAOlxB,EAAS,GAAKD,EAAW,EAAIoxB,EAE1DV,GAAoB,CAACW,EAAkBzxB,EAAiBF,EAAgB4xB,EAAcC,IAAiB,CAC3G,IAAMC,EAAW,KAAK,MAAMH,EAAW,CAAC,EACpCzxB,IAAY,cACdF,EAAK4xB,CAAI,EAAIE,EACb9xB,EAAK6xB,CAAI,EAAIF,EAAWG,GACf5xB,IAAY,eACrBF,EAAK4xB,CAAI,EAAID,EAAWG,EACxB9xB,EAAK6xB,CAAI,EAAIC,EAEjB,EAEMb,GAA8B,CAClCrjB,EACA9N,EACAC,EACAG,EACA4uB,EACA9uB,EACAb,EACAc,EACA8xB,EACAzjB,IACG,CACH,IAAMmgB,EAAc7gB,EAAW,OAAS,EAClCokB,EAAoB1jB,EAAY,SAAW,EAC7CyjB,EAAc,OAAStD,GACzBsD,EAAc,KAAK,GAAG,MAAMtD,EAAcsD,EAAc,MAAM,EAAE,KAAK,CAAC,CAAC,EAEzE,IAAM7c,EAAYtH,EAAW,CAAC,EACxBgc,EAAc9pB,EAAYG,EAAgB,EAAI,CAAC,EAAI6uB,EACzD,QAAS5lC,EAAI,EAAGyC,EAAIiiB,EAAW,OAAS6gB,GAAexuB,EAAgB,EAAI,GAAI/W,EAAIulC,EAAa,EAAEvlC,EAAG,EAAEyC,EAAG,CACxG,IAAM0U,EAASuN,EAAWjiB,CAAC,EACrB+lC,EAAUM,EAAoB3xB,EAASlB,EAAQjW,CAAC,EAAIolB,EAAYplB,CAAC,EACjEyoC,EAAWZ,GAAgB1wB,EAAQlB,EAAQjW,CAAC,EAAG8W,EAAK9W,CAAC,EAAG4W,EAAYnU,CAAC,EAAGoU,EAAU7W,CAAC,EAAGwoC,CAAO,EACnGV,GAAkBW,EAAUzxB,EAASF,EAAM9W,EAAGA,EAAIulC,CAAW,EACzDuD,GACF1jB,EAAY,KACVnP,EAAQjW,CAAC,GAAKmX,EAAS,GACrB0xB,EAAc7oC,CAAC,GACd4W,EAAYnU,CAAC,EAAI,GAAKoU,EAAU7W,CAAC,EAClC,EACA8W,EAAK9W,CAAC,EACN8W,EAAK9W,EAAIulC,CAAW,CACxB,CAEJ,CACAngB,EAAY,OAAO,EAAG,EAAG4G,CAAS,EAClC5G,EAAY,OAAOrO,EAAgB,EAAI,EAAG,EAAG2pB,CAAW,CAC1D,EAOMsH,GAAqC,CACzCliB,EACAlb,IACM,CACN,IAAMgM,EAAckP,EAAW,YAAY,MAAM,EAEjD,GAAIA,EAAW,YAAY,SAAW,GAAKA,EAAW,YAAY,OAAO,CAAC5T,EAAGC,IAAMD,EAAIC,EAAG,CAAC,IAAM,EAAG,CAClGyE,EAAY,OAAS,EACrB,QAAS5W,EAAI,EAAGA,EAAI4K,EAAO,CAAC,EAAE,KAAK,OAAQ,EAAE5K,EAC3C4W,EAAY,KAAKhM,EAAO,CAAC,EAAE,KAAK5K,CAAC,CAAC,CAEtC,CACA,IAAMy7B,EAAiB3V,EAAW,SAAW,OAC7ClP,EAAY,OAAO,EAAG,EAAGhM,EAAO,CAAC,EAAE,KAAK,CAAC,CAAC,EAC1CgM,EAAY,OAAO6kB,EAAiB,EAAI,EAAG,EAAG7wB,EAAO,CAAC,EAAE,KAAK,CAAC,CAAC,EAE/D,IAAMkM,EAAOgP,EAAW,KAAK,MAAM,EAC7BV,EAAcU,EAAW,YAAY,MAAM,EAC3C+iB,EAAgB/iB,EAAW,cAAc,MAAM,EAC/CpB,EAAa9Z,EAAO,CAAC,EAAE,KACzBiM,EAAYiP,EAAW,UAAU,MAAM,EAC3C,GAAIjP,EAAU,OAAO,CAAC3E,EAAGC,IAAMD,EAAIC,EAAG,CAAC,IAAM,EAAG,CAC9C,IAAMozB,EAAc36B,EAAO,CAAC,EAAE,KAAK,OAAS,EAC5CiM,EAAY,IAAI,MAAM0uB,CAAW,EAAE,KAAK,CAAC,CAC3C,CACA,IAAItvB,EAAU6P,EAAW,QAAQ,MAAM,EACvC,GAAI7P,EAAQ,OAAO,CAAC/D,EAAGC,IAAMD,EAAIC,EAAG,CAAC,IAAM,EAAG,CAC5C,IAAMozB,EAAc36B,EAAO,CAAC,EAAE,KAAK,OAAS,EAC5CqL,EAAU,IAAI,MAAMsvB,CAAW,EAAE,KAAK,CAAC,CACzC,CAGAwC,GACErjB,EACA9N,EACAC,EACAiP,EAAW,QACXA,EAAW,MACXhP,EACAb,EACAwlB,EACAoN,EACAzjB,CACF,EAGA,IAAMugB,EAAmB,OAAO,OAAO,CAAC,EAAG7f,CAAU,EACrD,cAAO,OAAO6f,EAAe,CAAE,YAAA/uB,EAAa,KAAAE,EAAM,cAAA+xB,EAAe,YAAAzjB,EAAa,UAAAvO,EAAW,QAAAZ,CAAQ,CAAC,EAC3F0vB,CACT,EAEasC,GAAgCniB,GAAiE,CAC5G,IAAMyV,EAAuBzB,GAAkChU,CAAU,EAEnE+K,EAAS/K,EAAW,OACpB9O,EAAU,CAAC,SAAU,QAAS,aAAc,YAAY,EAC5D,OAAO8O,EAAW,QAAW,IAAc,EAAKA,EAAW,OAC7D,EACMjP,EAAYiP,EAAW,UACvB8f,EAAQ9f,EAAW,MACnBlP,EAAckP,EAAW,YACzBhP,EAAOgP,EAAW,KAClB7P,EAAU6P,EAAW,QACrB+f,EAAY/f,EAAW,SAA2B,EAClD+iB,EAAgB/iB,EAAW,cAC3BV,EAAcU,EAAW,YAC/B,MAAO,CACL,QAAA9O,EACA,OAAA6Z,EACA,UAAAha,EACA,MAAA+uB,EACA,YAAAhvB,EACA,cAAAiyB,EACA,YAAAzjB,EACA,KAAAtO,EACA,QAAAb,EACA,SAAA4vB,EACA,GAAGtK,EACH,SAAU,GAAGzV,EAAW,MAAM,IAAIyV,EAAqB,UAAU,GACnE,CACF,EAEMvX,GAAiB,CAACpZ,EAA+Bkb,IAA8C,CAGnG,GAAI,CAAClb,GAAWA,EAAO,SAAW,GAAKA,EAAO,SAAW,EACvD,MAAM,IAAI,MAAM,6BAA6B,EAI/C,GAAIA,EAAO,CAAC,EAAE,KAAK,SAAW,GAAKA,EAAO,CAAC,EAAE,KAAK,SAAW,EAC3D,MAAM,IAAI,MAAM,2CAA2C,EAG7D,GAAIA,EAAO,CAAC,EAAE,KAAK,SAAWA,EAAO,CAAC,EAAE,KAAK,OAC3C,MAAM,IAAI,MAAM,8CAA8C,EAIhE,IAAM66B,EAAc76B,EAAO,CAAC,EAAE,KAAKkb,EAAW,SAAW,OAASlb,EAAO,CAAC,EAAE,KAAK,OAAS,EAAI,CAAC,EACzF86B,EAAkB96B,EAAO,CAAC,EAAE,KAAK,CAAC,EACxC,GAAI66B,IAAgBC,EAClB,MAAM,IAAI,MAAM,mDAAmD,EAGrE,IAAMqD,EAAcn+B,EAAO,CAAC,EAAE,KAAK,CAAC,EAAIkb,EAAW,MAGnD,GAAIlb,EAAO,SAAW,IAAMA,EAAO,CAAC,EAAE,KAAK,SAAW,GAAKA,EAAO,CAAC,EAAE,KAAK,CAAC,IAAMm+B,GAC/E,MAAM,IAAI,MAAM,cAAc,EAGhC,IAAMxD,EAAc36B,EAAO,CAAC,EAAE,KAAK,OAAS,EAG5C,GAFqBkb,EAAW,UAAU,OAAO,CAAC5T,EAAGC,IAAMD,EAAIC,EAAG,CAAC,EAAI,GAEnD2T,EAAW,UAAU,SAAWyf,EAClD,MAAM,IAAI,MAAM,uBAAuBA,CAAW,GAAG,EAKvD,GAFmBzf,EAAW,QAAQ,OAAO,CAAC5T,EAAGC,IAAMD,EAAIC,EAAG,CAAC,EAAI,GAEjD2T,EAAW,QAAQ,SAAWyf,EAC9C,MAAM,IAAI,MAAM,qBAAqBA,CAAW,GAAG,EAKrD,GADgBzf,EAAW,KAAK,OAAO,CAAC5T,EAAGC,IAAMD,EAAIC,EAAG,CAAC,EAAI,GAC9C2T,EAAW,KAAK,SAAWyf,EAAc,EACtD,MAAM,IAAI,MAAM,kBAAkBA,EAAc,CAAC,GAAG,EAItD,GAAIzf,EAAW,cAAc,SAAWyf,GAAezf,EAAW,cAAc,SAAW,EACzF,MAAM,IAAI,MAAM,4BAA4Byf,CAAW,GAAG,EAM5D,GADuBzf,EAAW,YAAY,OAAO,CAAC5T,EAAGC,IAAMD,EAAIC,EAAG,CAAC,EAAI,GAGzE2T,EAAW,YAAY,SAAW,GAClCA,EAAW,YAAY,SAAWlb,EAAO,CAAC,EAAE,KAAK,OAAS,EAE1D,MAAM,IAAI,MAAM,sBAAsB,EAIxC,GAAIkb,EAAW,YAAY,SAAW,GAAKA,EAAW,YAAY,SAAWlb,EAAO,CAAC,EAAE,KAAK,OAAS,EACnG,MAAM,IAAI,MAAM,sBAAsB,CAE1C,EAEMs9B,GAAkB,CACtBtjC,EACAgG,EACAkb,EACA4V,IACS,CAET,IAAMqK,EACHnhC,EAAQ,iBAAiB,IAC1BA,EAAQ,QAAQ0f,GAA2B1Z,EAAO,CAAC,EAAG,CAAC,EAAG,EAAG,EAAG,CAAC,CAAC,EAAG,CACnE,OAAQ,CAAC,CAAC,EACV,QAAS,CAACkb,EAAW,SAAW,GAAK,EAAE,CACzC,CAAC,EAAE,CAAC,EACFA,EAAW,UAAY,CAAClhB,EAAQ,iBAAiB,KACnDA,EAAQ,iBAAiB,GAAKmhC,GAIhC,IAAMiD,EAAsB,CAACp+B,EAAO,CAAC,EAAGm7B,CAAgB,EACpDn7B,EAAO,SAAW,GACpBo+B,EAAoB,KAAKp+B,EAAO,CAAC,CAAC,EAEpChG,EAAQ,QAAQkiC,GAAiCkC,EAAqBljB,EAAY4V,CAA0B,EAAG,CAC7G,OAAQsN,CACV,CAAC,CACH,EAEMb,GAAkB,CAACvjC,EAAyBkhB,IAA8C,CAE9F,IAAM/O,EAAgB+O,EAAW,SAAW,OAEtClb,EAAS,CACbhG,EAAQ,OAAO,CAAC,EAAE,QAChBmS,EAEI,CAACnS,EAAQ,OAAO,CAAC,EAAE,KAAK,CAAC,EAAG,EAAGA,EAAQ,OAAO,CAAC,EAAE,KAAK,CAAC,EAAGA,EAAQ,OAAO,CAAC,EAAE,KAAK,CAAC,CAAC,EAEnF,CAACA,EAAQ,OAAO,CAAC,EAAE,KAAK,CAAC,EAAGA,EAAQ,OAAO,CAAC,EAAE,KAAK,CAAC,EAAG,EAAGA,EAAQ,OAAO,CAAC,EAAE,KAAK,CAAC,CAAC,CACzF,EAEAA,EAAQ,OAAO,CAAC,EAAE,QAAQ,CAACA,EAAQ,OAAO,CAAC,EAAE,KAAK,CAAC,EAAGA,EAAQ,OAAO,CAAC,EAAE,KAAK,CAAC,EAAG,EAAGA,EAAQ,OAAO,CAAC,EAAE,KAAK,CAAC,CAAC,CAAC,CAChH,EACIA,EAAQ,OAAO,SAAW,GAC5BgG,EAAO,KAAKhG,EAAQ,OAAO,CAAC,CAAC,EAE/B,IAAIgS,EAAckP,EAAW,aACzBlP,EAAY,SAAW,GAAKA,EAAY,CAAC,IAAM,KACjDA,EAAc,CAAChS,EAAQ,OAAO,CAAC,EAAE,KAAK,CAAC,CAAC,GAE1C,IAAIiS,EAAYiP,EAAW,WACvBjP,EAAU,SAAW,GAAKA,EAAU,CAAC,IAAM,KAC7CA,EAAY,CAAC,CAAC,GAEhB,IAAIZ,EAAU6P,EAAW,SACrB7P,EAAQ,SAAW,GAAKA,EAAQ,CAAC,IAAM,KACzCA,EAAU,CAAC,CAAC,GAEd,IAAIa,EAAOgP,EAAW,KAClBhP,EAAK,SAAW,IAClBA,EAAO,CAAC,EAAG,CAAC,GAEdA,EAAO,CAAC,EAAGA,EAAK,CAAC,EAAG,EAAGA,EAAK,CAAC,CAAC,EAC9Bb,EAAU,CAAC,CAAC,EAAE,OAAOA,CAAO,EAC5BY,EAAY,CAAC,CAAC,EAAE,OAAOA,CAAS,EAChCD,EAAc,CAAC,CAAC,EAAE,OAAOA,CAAW,EACpC,IAAIiyB,EAAgB/iB,EAAW,cAC/B+iB,EAAgB,CAAC,CAAC,EAAE,OAAOA,CAAa,EACxC,IAAMjC,EAAqBoB,GACzB,CAAE,GAAGliB,EAAY,KAAAhP,EAAM,QAAAb,EAAS,UAAAY,EAAW,YAAAD,EAAa,cAAAiyB,CAAc,EACtEj+B,CACF,EAEAs9B,GAAgBtjC,EAASgG,EAAQg8B,EAAqBxhB,GACpDrO,EAAgB,CAACqO,EAAY,CAAC,EAAGA,EAAY,CAAC,EAAGA,EAAY,CAAC,CAAC,EAAI,CAACA,EAAY,CAAC,EAAGA,EAAY,CAAC,EAAGA,EAAY,CAAC,CAAC,CACpH,CACF,EAEagjB,GAAgB,CAACxjC,EAAyBkhB,IAA8C,CAEnG,GADA9B,GAAepf,EAAQ,OAAQkhB,CAAU,EACrClhB,EAAQ,OAAO,CAAC,EAAE,KAAK,SAAW,EACpCujC,GAAgBvjC,EAASkhB,CAAU,MAC9B,CACL,IAAM8gB,EAAqBoB,GAAmCliB,EAAYlhB,EAAQ,MAAM,EACxFsjC,GAAgBtjC,EAASA,EAAQ,OAAQgiC,CAAkB,CAC7D,CACF,ICzTA,IAeMqC,GAoDOC,GAOAC,GA1EbC,GAAAzpC,EAAA,kBAGAkS,IAEA8C,IACAkK,KAGAmB,IAMMipB,GAA0B,CAC9BlQ,EACArU,EACA2kB,EACAvjB,IACgB,CAChB,IAAMJ,EAAapR,EAAU,KAAKoQ,CAAU,EACtC9O,EAAO8O,EAAW,OAClBC,EAAQjF,EAAc,QAASqZ,EAAWnjB,CAAI,EAC9CgM,EAASjC,EAAe,SAAUoZ,EAAWnjB,CAAI,EACjD0zB,EACJD,EAAU,WAAa,EAAiBA,EAAU,cAAc,EAAE,CAAC,EAAI,OAAOA,EAAU,iBAAiB,EAAE,CAAC,CAAC,EACzGvzB,EAAOxB,EAAU,cAAcg1B,EAAW1zB,CAAI,EAC9C4P,EAAmBC,GAA+B,CACtD,IAAMnL,EAAQ,QAAQqK,EAAM,WAAW,eAAgB,eAAe,CAAC,KACjErP,EAAMkK,EAAa,uBAAwB,gBAAiB5J,CAAI,EAChE2zB,EAAazjB,EAAW,QAAUxL,GAASwL,EAAW,UAAY,OAAS,IAAM,IACjF0jB,EAAa1jB,EAAW,QAAUxQ,EAAMgF,GAASwL,EAAW,UAAY,GAAK,QACnF,MAAO;AAAA,kBACOL,EACC,gBAAgB,aAAc,KAAK,EACnC,gBAAgB,OAAQ,KAAK,EAC7B,iBAAiBd,EAAO/C,CAAM,CAAC;AAAA,kBAChC6D,EAAa,UAAU,CAAC;AAAA,oBACtBA,EAAa,sCAAsC,qBAAqB,CAAC;AAAA,uCACtD7D,EAAO,gBAAgB,YAAY,CAAC;AAAA,8BAC7CA,EAAO,KAAK,KAAK;AAAA,sCACT2nB,CAAU;AAAA,qCACXC,CAAU;AAAA;AAAA,sBAEzB7kB,EAAM,WAAW,eAAgB,gBAAiB,QAAQ,CAAC;AAAA,kCAC/CA,EAAM,aAAa,cAAc,CAAC;AAAA;AAAA,oBAEhD/C,EAAO,YAAY,aAAc,KAAK,CAAC;AAAA,kBAEzD,EACA,MAAO,CACL,KAAM,SACN,YAAa,CAAE,KAAMkE,EAAW,SAAU,kBAAmB,CAAC,MAAM,CAAE,EACtE,WAAY,KAAO,CACjB,QAAS,CAAC,CAAE,KAAMpB,EAAY,SAAUqU,CAAU,CAAC,EACnD,cAAe,CAAE,EAAG,KAAK,KAAKrT,EAAa,EAAuB,CAAE,EACpE,gBAAiB,CACf,CAAE,QAAuB,KAAMA,CAAW,EAC1C,CAAE,QAAuB,KAAM5P,CAAK,EACpC,GAAGqJ,EAA2BuF,EAAYA,CAAU,CACtD,CACF,GACA,gBAAAc,CACF,CACF,EAEa0jB,GAAS,CAACtkC,EAAyBkhB,IAAuC,CACrF,IAAMpB,EAAa9f,EAAQ,OAAO,CAAC,EAAE,KAC/Bm0B,EAAYn0B,EAAQ,OAAO,CAAC,EAAE,SAC9BkR,EAAOlR,EAAQ,OAAO,CAAC,EAC7BA,EAAQ,QAAQqkC,GAAwBlQ,EAAWrU,EAAY5O,EAAMgQ,CAAU,EAAG,CAAE,OAAQ,CAAC,CAAC,CAAE,CAAC,CACnG,EAEaqjB,GAAyBrjB,GAA0D,CAC9F,IAAM2jB,EAAa3jB,EAAW,YAAyB,EACjD4jB,EAAW5jB,EAAW,UAAuB,EACnD,OAAOlH,EAA4B,CAAE,UAAA6qB,EAAW,QAAAC,CAAQ,CAAC,CAC3D,IC9EA,IAoBM1lB,GASAG,GAWAwlB,GAmEOC,GAKAC,GAhHbC,GAAAnqC,EAAA,kBAGAkS,IAEA8C,IACAkK,KAGAmB,IAWMgE,GAAkBpZ,GAAwC,CAC9D,GAAI,CAACA,GAAUA,EAAO,SAAW,EAC/B,MAAM,IAAI,MAAM,gCAAgC,EAElD,GAAIA,EAAO,CAAC,EAAE,KAAK,SAAW,EAC5B,MAAM,IAAI,MAAM,iCAAiC,CAErD,EAEMuZ,GAAmB,CAAC9N,EAAgBT,EAAc+O,EAAsB/C,IAAkC,CAC9G,IAAMgD,EAAc,CAAC,EACrBA,EAAY,KAAK,cAAchD,EAAO,KAAK,OAAO,QAAQ+C,EAAM,KAAK,OAAO;AAAA,aACjEA,EAAM,KAAK,OAAO,GAAG,EAChC,QAAS,EAAI,EAAG,EAAI/O,EAAM,EAAE,EAC1BgP,EAAY,KAAKD,EAAM,WAAW,IAAKtO,EAAK,CAAC,EAAG,KAAK,CAAC,GAAG,CAAC,EAE5D,OAAAuO,EAAY,KAAK,YAAY,EACtBA,EAAY,KAAK;AAAA,CAAI,CAC9B,EAEM+kB,GAAgC,CAAC1kB,EAAyBa,IAAoD,CAClH,IAAI,EAAWikB,EAAW/I,EAAW0G,EACjCnyB,EACAc,EACEU,EAAgB+O,EAAW,SAAW,OACtCkkB,EAAYlkB,EAAW,UACvBmkB,EAAYnkB,EAAW,OAAS,MAClC/O,GACF,CAAC,EAAGgzB,EAAG/I,EAAG0G,CAAC,EAAIziB,EAAY,KAC3B1P,EAAQ00B,EACJ,CAAC,EAAGF,EAAG/I,EAAGgJ,EAAWA,EAAWtC,EAAIsC,GAAa,CAAC,EAClD,CAAC,EAAGD,EAAG/I,EAAG0G,EAAIsC,GAAa,EAAGA,EAAWA,CAAS,EACtD3zB,EAAO4zB,EAAY,CAAC,EAAG,EAAG,EAAG,EAAG,EAAG,CAAC,EAAI,CAAC,EAAG,EAAG,EAAG,EAAG,EAAG,CAAC,IAEzD,CAAC,EAAGF,EAAG/I,EAAG0G,CAAC,EAAI,CAACziB,EAAY,KAAK,CAAC,EAAGA,EAAY,KAAK,CAAC,EAAGA,EAAY,KAAK,CAAC,EAAGA,EAAY,KAAK,CAAC,CAAC,EAClG1P,EAAQ00B,EACJ,CAAC,EAAGD,EAAWA,EAAWtC,EAAIsC,GAAa,EAAGD,EAAG/I,CAAC,EAClD,CAAC,EAAG0G,EAAIsC,GAAa,EAAGA,EAAWA,EAAWD,EAAG/I,CAAC,EACtD3qB,EAAO4zB,EAAY,CAAC,EAAG,EAAG,EAAG,EAAG,EAAG,CAAC,EAAI,CAAC,EAAG,EAAG,EAAG,EAAG,EAAG,CAAC,GAE3D,IAAMC,EAAsBjlB,EAAY,QAAQ1P,CAAK,EAC/C40B,EAAoBD,EAAoB,KAAK,OAC7C/kB,EAAgBF,EAAY,SAE5BmlB,EAAgB1qB,EAAc,IAAKyF,EAAeglB,CAAiB,EACnEE,EAAe1qB,EAAe,SAAUwF,EAAeglB,CAAiB,EAExE3kB,EAAmBC,GAA+B;AAAA,IACtDA,EAAa,gBAAgB,cAAe,KAAK,EAAE,iBAAiB2kB,EAAeC,CAAY,CAAC;AAAA;AAAA,IAEhGlmB,GAAiB9N,EAAM8zB,EAAmBC,EAAeC,CAAY,CAAC;AAAA;AAAA,IAEtE5kB,EAAa,UAAU,CAAC;AAAA,MACtBA,EAAa,sCAAsC,sBAAsB,CAAC;AAAA;AAAA,oBAE5D4kB,EAAa,gBAAgB,YAAY,CAAC;AAAA;AAAA;AAAA,MAGxDA,EAAa,YAAY,aAAcD,EAAc,aAAa,UAAU,CAAC,CAAC;AAAA,KAGlF,MAAO,CACL,KAAM,eACN,YAAa,CACX,KAAM,GAAGnlB,EAAY,IAAI,IAAIa,EAAW,SAAS,IAAIA,EAAW,IAAI,GACpE,kBAAmB,CAAC,MAAM,CAC5B,EACA,WAAalb,GAAW,CACtB,IAAMwa,EAAcrO,EAChB,CAAC,EAAGgzB,EAAIC,EAAWhJ,EAAIgJ,EAAWtC,EAAIsC,GAAa,CAAC,EACpD,CAAC,EAAGtC,EAAIsC,GAAa,EAAGD,EAAIC,EAAWhJ,EAAIgJ,CAAS,EAClDtkB,EAAapR,EAAU,KAAK8Q,CAAW,EACvCklB,EAAkBJ,EAAoB,KACtCK,EAAiBj2B,EAAU,gBAAgBg2B,EAAiBj0B,CAAI,EACtE,MAAO,CACL,QAAS,CAAC,CAAE,KAAM+O,EAAa,SAAUxa,EAAO,CAAC,EAAE,QAAS,CAAC,EAC7D,cAAe,CAAE,EAAG,KAAK,KAAK8a,EAAa,EAAuB,CAAE,EACpE,gBAAiB,CACf,CAAE,QAAuB,KAAMA,CAAW,EAC1C,GAAGvG,EAA2BmrB,EAAiBC,CAAc,CAC/D,CACF,CACF,EACA,gBAAA/kB,CACF,CACF,EAEaokB,GAAe,CAAChlC,EAAyBkhB,IAA6C,CACjG9B,GAAepf,EAAQ,MAAM,EAC7BA,EAAQ,QAAQ+kC,GAA8B/kC,EAAQ,OAAO,CAAC,EAAGkhB,CAAU,CAAC,CAC9E,EAEa+jB,GAA+B/jB,GAC1ClH,EAA4B,CAC1B,UAAWkH,EAAW,UACtB,KAAMA,EAAW,KACjB,OAAQA,EAAW,MACrB,CAAC,ICrHH,IAsBM0kB,GACAC,GACAC,GACAC,GACAC,GAQAC,GAqBAC,GAiIAC,GAEAC,GAqHOC,GAOAC,GAtTbC,GAAAxrC,EAAA,kBAGAkS,IAEA8C,IACAkK,KAGAmB,IAaMwqB,GAAgB,qBAChBC,GAAc,IAAMD,GAAgB,KACpCE,GAAkB,IAAMD,GAAc,IACtCE,GAAa,IAAMF,GAAc,MAAQA,GACzCG,GAAiB,IAAMD,GAAa,IAQpCE,GAAN,KAAiB,CACf,YAAYO,EAAa,GAAI,CAC3B,KAAK,gBAAkB,IAAI,IAC3B,KAAK,WAAaA,CACpB,CAGA,UAAUC,EAAgB/wB,EAAe,CACvC,IAAIhZ,EAAQ,KAAK,gBAAgB,IAAI+pC,CAAM,EACvC/pC,IAAU,OACZA,EAAQ,CAACgZ,CAAK,EAEdhZ,EAAM,KAAKgZ,CAAK,EAElB,KAAK,gBAAgB,IAAI+wB,EAAQ/pC,CAAK,CACxC,CAIF,EAEMwpC,GAAN,KAAqB,CACnB,YACElgC,EACgB0gC,EAChB,CADgB,cAAAA,EAEhB,KAAK,YAAc,GACnB,KAAK,aAAe,IAAI,IACxB,KAAK,IAAM,IAAI,MACf,KAAK,WAAa,CAAC,EAGnB,GAAI,CAACC,EAAKC,CAAG,EAAIF,EAAS,SAAS,IAAI,EAAIA,EAAS,MAAM,KAAM,CAAC,EAAI,CAACA,EAAU,EAAE,EAClF,GAAI,CAACC,EAAI,MAAM,OAAOX,EAAc,CAAC,EACnC,MAAM,IAAI,MAAM,kBAAkB,EAapC,GAXmBW,EAAI,MAAM,GAAG,EACrB,QAAQ,CAACE,EAAWnxB,IAAU,CACvC,IAAMpV,EAAO0F,EAAO0P,CAAK,EAAE,KAAK,MAAM,EACtC,GAAI,CAACmxB,EAAU,MAAM,OAAOf,EAAe,CAAC,EAC1C,MAAM,IAAI,MAAM,kBAAkB,EAEpC,IAAMgB,EAAa,KAAK,YAAYD,EAAW,GAAMvmC,EAAMoV,CAAK,EAChE,KAAK,IAAI,KAAKoxB,CAAU,CAC1B,CAAC,EAGGF,IAAQ,GAEVA,GAAO,CAAC,GAAG,KAAK,aAAa,QAAQ,CAAC,EACnC,OAAO,CAAC,CAACG,EAAKC,CAAI,IAAMA,EAAK,QAAU,GAAKD,IAAQ,KAAK,EACzD,IAAI,CAAC,CAACA,CAAG,IAAMA,CAAG,EAClB,KAAK,EAAE,UAEN,CAACH,EAAI,MAAM,OAAOf,EAAW,CAAC,EAChC,MAAM,IAAI,MAAM,aAAa,EAKde,EAAI,MAAM,OAAOhB,GAAe,GAAG,CAAC,GAC3C,QAASa,GAAW,CAC9B,GAAIA,IAAW,MACb,KAAK,WAAa,KAAK,WAAW,OAAO,KAAK,YAAY,MACrD,CACL,IAAMO,EAAO,KAAK,aAAa,IAAIP,CAAM,EACzC,GAAIO,IAAS,OACX,MAAM,IAAI,MAAM,oBAAoB,EAEtC,KAAK,WAAW,KAAKA,EAAK,QAAQ,CACpC,CACF,CAAC,EACD,KAAK,IAAM,KAAK,YAAYJ,EAAK,GAAO,KAAK,UAAU,CACzD,CAGA,UAAUH,EAAgBQ,EAAkBT,EAAoB,CAC9D,IAAIQ,EAAO,KAAK,aAAa,IAAIP,CAAM,EACvC,GAAIO,IAAS,OAAW,CACtB,GAAIA,EAAK,WAAaC,GAAYD,EAAK,QAAU,EAC/C,MAAM,IAAI,MAAM,oBAAoB,EAEpCA,EAAK,QACLA,EAAK,aAAa,KAAKR,CAAU,CAErC,MACEQ,EAAO,CAAE,MAAO,EAAG,SAAAC,EAAU,aAAc,CAACT,CAAU,CAAE,EAE1D,KAAK,aAAa,IAAIC,EAAQO,CAAI,CACpC,CAGA,YAAYE,EAAcC,EAAkB7mC,EAAyBoV,EAAQ,GAAgB,CAC3F,IAAM1E,EAAO1Q,EAAK,OACd8mC,EAAW,GACXC,EAAe,CAAC,EAChBC,EAAU,EAEd,GAAI,CAACJ,EAAK,MAAM,OAAOpB,EAAe,CAAC,GAAK,CAACqB,GAAWD,IAAS,GAC/D,MAAM,IAAI,MAAM,kBAAkB,EAEpC,IAAMK,EAAeL,EAAK,MAAM,OAAOtB,GAAe,GAAG,CAAC,EACpDkB,EAAa,IAAIb,GAAWvwB,CAAK,EAEvC,OAAA6xB,GAAc,QAAQ,CAACd,EAAgBrrC,IAAc,CACnD,GAAIqrC,IAAW,MAAO,CACpB,GAAIW,EACF,MAAM,IAAI,MAAM,6CAA6C,EAE/DA,EAAW,GACX,IAAMI,EAAoBx2B,EAAOu2B,EAAa,OAAS,EACvD,GAAIC,EAAoB,EACtB,MAAM,IAAI,MAAM,wBAAwB,EAG1C,GADAH,EAAe/mC,EAAK,MAAMgnC,EAASA,EAAUE,CAAiB,EAC1D,KAAK,aACP,GACE,KAAK,aAAa,SAAWH,EAAa,QAC1C,KAAK,aAAa,SAAS,IAAMA,EAAa,SAAS,EAEvD,MAAM,IAAI,MAAM,8BAA8B,UAEvCF,EACT,KAAK,YAAc,GACnB,KAAK,aAAeE,MAEpB,OAAM,IAAI,MAAM,uCAAuC,EAGzD,QAASxpC,EAAI,EAAGA,EAAIwpC,EAAa,OAAQxpC,IAAK,CAC5C,IAAM4oC,EAAS,OAAO,aAAa,GAAoB5oC,CAAC,EACxDipC,EAAW,UAAUL,EAAQrrC,EAAIyC,CAAC,EAClC,KAAK,UAAU4oC,EAAQnmC,EAAKgnC,GAAS,EAAG5xB,CAAK,CAC/C,CACF,MACEoxB,EAAW,UAAUL,EAAQrrC,GAAK,KAAK,YAAc,KAAK,aAAa,OAAS,EAAI,EAAE,EACtF,KAAK,UAAUqrC,EAAQnmC,EAAKgnC,GAAS,EAAG5xB,CAAK,CAEjD,CAAC,EACMoxB,CACT,CAQF,EAEMX,GAAanrC,GAAyBA,EAAO,OAE7CorC,GAA0B,CAC9BqB,EACAjnC,EACAknC,EACAlnB,IACgB,CAEhB,IAAMwJ,EADQyd,EAAY,IAAKnnC,GAASA,EAAK,MAAM,EAC3B,IAAI,CAAC0Q,EAAM0E,IAAUoF,EAAc,QAAQpF,CAAK,GAAIlV,EAAUwQ,CAAI,CAAC,EACrF8P,EAAapR,EAAU,KAAK8Q,CAAW,EACvCxD,EAASjC,EAAe,SAAUva,EAAUggB,EAAY,MAAM,EAC9DmnB,EAAkB,CAAC,GAAGD,EAAe,aAAa,KAAK,CAAC,EAAE,OAC7DjB,GAAW,CAACiB,EAAe,IAAI,gBAAgB,IAAIjB,CAAM,CAC5D,EACM7lB,EAAmBC,GAA+B,CACtD,IAAM8E,EAAoB,CAAC,EACrBiiB,EAAW,kBACXC,EAAU,iBACVC,EAAY,eACZC,EAAgC,CAAC,EACjCC,EAAiC,CAAC,EAClCC,EAAiC,CAAC,EAClCC,EAA4B,CAAC,EAC7BC,EAAyBT,EAAe,aAAa,OAASA,EAAe,IAAI,gBAAgB,KACvGA,EAAe,aAAa,QAAQ,CAACV,EAAMP,IAAW,CACpD,GAAIiB,EAAe,IAAI,gBAAgB,IAAIjB,CAAM,EAAG,CAClD,IAAM2B,EAAcV,EAAe,IAAI,gBAAgB,IAAIjB,CAAM,IAAI,CAAC,EAClE2B,IAAgB,QAClBV,EAAe,IAAI,QAAQ,CAACR,EAAM9rC,IAAM,CACtC,GAAI4rC,EAAK,aAAa,SAAS5rC,CAAC,EAAG,CACjC,IAAMshB,EAAUwqB,EAAK,gBAAgB,IAAIT,CAAM,EAC/C,GAAI/pB,IAAY,OACd,MAAM,IAAI,MAAM,sBAAsB,EAExCA,EAAQ,QAAShH,GAAU,CACzBiQ,EAAQ,KACN,GAAGqE,EAAU5uB,CAAC,EAAE,WACd,QAAQA,CAAC,UACTsa,EACAsH,EAAO,WAAW,gBAAiBorB,CAAW,CAChD,CAAC,EACH,CACF,CAAC,CACH,CACF,CAAC,CAEL,MACEV,EAAe,IAAI,QAAQ,CAACR,EAAM9rC,IAAM,CACtC,GAAI4rC,EAAK,aAAa,SAAS5rC,CAAC,EAAG,CACjC,IAAMshB,EAAUwqB,EAAK,gBAAgB,IAAIT,CAAM,EAC/C,GAAI/pB,IAAY,OACd,MAAM,IAAI,MAAM,sBAAsB,EAExCA,EAAQ,QAAShH,GAAU,CACzBqyB,EAAoB,KAAK,GAAG/d,EAAU5uB,CAAC,EAAE,WAAW,QAAQA,CAAC,UAAWsa,EAAO,GAAG+wB,CAAM,EAAE,CAAC,EAAE,CAC/F,CAAC,EACDyB,EAAgB,KAAK,WAAWle,EAAU5uB,CAAC,EAAE,aAAa,QAAQA,CAAC,SAAS,CAAC,GAAG,CAClF,CACF,CAAC,EACD4sC,EAAqB,KACnB,WAAWvB,CAAM,cAAcA,CAAM,eAAeN,GAAUM,CAAM,CAAC,KAAKA,CAAM,OAClF,EACAwB,EAAqB,KAAK,GAAG,CAEjC,CAAC,EACD,IAAM9mB,EAAYgnB,EACd,CACE,GAAGxiB,EACH,aAAaqE,EAAU,IAAI,CAACuC,EAAUnxB,IAAMmxB,EAAS,aAAa,QAAQnxB,CAAC,SAAS,CAAC,EAAE,KAAK,KAAK,CAAC,GACpG,EACA,CACE,GAAGuqB,EACHkiB,EACA,GAAGG,EACH,GAAGD,EACHH,EACA,GAAGM,EACHJ,EACA,GAAGG,CACL,EACJ,MAAO;AAAA,cACGpnB,EACC,iBAAiB8mB,EAAgB,IAAKlB,IAAY,CAAE,KAAM,GAAGN,GAAUM,CAAM,CAAC,GAAI,KAAM,KAAM,EAAE,CAAC,EACjG,gBAAgB,aAAc,KAAK,EACnC,iBAAiB,GAAGzc,EAAWhN,CAAM,CAAC;AAAA;AAAA,cAEvC6D,EAAa,UAAU,CAAC;AAAA,cACxBA,EAAa,sCAAsC,qBAAqB,CAAC;AAAA,kCACrD7D,EAAO,gBAAgB,YAAY,CAAC;AAAA,cACxDgN,EAAU,IAAI,CAACqe,EAAMjtC,IAAM,YAAYA,CAAC,YAAY4uB,EAAU5uB,CAAC,EAAE,KAAK,OAAO,GAAG,EAAE,KAAK;AAAA,CAAI,CAAC;AAAA,cAC5F+lB,EAAU,KAAK;AAAA,CAAI,CAAC;AAAA,cACpBnE,EAAO,YAAY,aAAc,KAAK,CAAC;AAAA,YAEnD,EACA,MAAO,CACL,KAAM,SACN,YAAa,CAAE,KAAM0qB,EAAe,SAAU,kBAAmBD,EAAY,IAAI,IAAM,MAAM,CAAE,EAC/F,WAAY,IAAM,CAGhB,IAAMa,EAAwCX,EAC3C,OAAQlB,GAAWiB,EAAe,aAAa,IAAIjB,CAAM,CAAC,EAC1D,IAAKA,IAAY,CAAE,QAAuB,KAAMiB,EAAe,aAAa,IAAIjB,CAAM,GAAG,UAAY,CAAE,EAAE,EAC5G6B,EAAoB,KAAK,CAAE,QAAuB,KAAMxnB,CAAW,CAAC,EACpE,IAAMxF,EAAoCmsB,EACvC,IAAI,CAACnnC,EAAMo2B,IAAM,CAAC,GAAGnc,EAA2Bja,CAAI,CAAC,CAAC,EACtD,OAAO,CAACioC,EAAKC,IAAyBD,EAAI,OAAOC,CAAoB,EAAGF,CAAmB,EAC9F,OAAAhtB,EAAgB,KAAK,GAAGf,EAA2BiG,CAAW,CAAC,EACxD,CACL,QAAS,CAAC,CAAE,KAAMA,EAAa,SAAAhgB,CAAS,CAAC,EACzC,cAAe,CAAE,EAAG,KAAK,KAAKsgB,EAAa,EAAuB,CAAE,EACpE,gBAAAxF,CACF,CACF,EACA,gBAAAsF,CACF,CACF,EAEaylB,GAAS,CAACrmC,EAAyBkhB,IAAuC,CACrF,IAAMwmB,EAAiB,IAAIxB,GAAelmC,EAAQ,OAAQkhB,EAAW,QAAQ,EACvEV,EAAcknB,EAAe,WAC7BD,EAAcznC,EAAQ,OAAO,IAAI,CAAC+f,EAAO2W,IAAM3W,EAAM,IAAI,EAC/D/f,EAAQ,QAAQomC,GAAwBqB,EAAaznC,EAAQ,OAAO,CAAC,EAAE,SAAU0nC,EAAgBlnB,CAAW,CAAC,CAC/G,EAEa8lB,GAAyBplB,GAA0D,CAC9F,IAAMwlB,EAAYxlB,EAAW,SAAoB,QAAQ,OAAQ,EAAE,EACnE,OAAOlH,EAA4B,CAAE,SAAA0sB,CAAS,CAAC,CACjD,ICzTA,IAUMtnB,GAoBAqpB,GAYAzI,GAGA0I,GAmEOC,GAhHbC,GAAA7tC,EAAA,kBAGAkS,IAEA8C,IAGAqL,IAEMgE,GAAkBpZ,GAAwC,CAC9D,GAAI,CAACA,GAAUA,EAAO,SAAW,EAC/B,MAAM,IAAI,MAAM,0BAA0B,EAE5C,IAAM8Z,EAAa9Z,EAAO,CAAC,EAAE,KACvB2K,EAAQ,MAAM,KAAK3K,EAAO,CAAC,EAAE,iBAAiB,EAAG,MAAM,EAEzD6iC,EAAal4B,EAAM,OAASmP,EAAW,OAAS,EAAInP,EAAM,OAASmP,EAAW,OAC9EgpB,EAAkBhpB,EAAW,OAASnP,EAAM,OAAS,EAAImP,EAAW,OAASnP,EAAM,OACvF,KAAOk4B,EAAal4B,EAAM,QAAUm4B,EAAkBhpB,EAAW,OAAQ,EAAE+oB,EAAY,EAAEC,EACvF,GACEn4B,EAAMk4B,CAAU,IAAM/oB,EAAWgpB,CAAe,GAChDn4B,EAAMk4B,CAAU,IAAM,GACtB/oB,EAAWgpB,CAAe,IAAM,EAEhC,MAAM,IAAI,MAAM,oDAAoD,CAG1E,EAEML,GAAmB,CAAC92B,EAA2BC,IAAwC,CAC3F,IAAMm3B,EAAOp3B,EAAO,OAASC,EAAO,OAC9BjB,EAAkB,CAAC,EACzB,QAASvV,EAAI,EAAGA,EAAI2tC,EAAM,EAAE3tC,EAC1BuV,EAAM,KAAKgB,EAAOvW,CAAC,CAAC,EAEtB,QAASA,EAAI,EAAGA,EAAIwW,EAAO,OAAQ,EAAExW,EACnCuV,EAAM,KAAKiB,EAAOxW,CAAC,IAAM,EAAIuW,EAAOvW,EAAI2tC,CAAI,EAAIn3B,EAAOxW,CAAC,CAAC,EAE3D,OAAOuV,CACT,EAEMqvB,GAAuB,CAAClgB,EAA+BnP,IAC3DmP,EAAW,OAASnP,EAAM,OAAS83B,GAAiB3oB,EAAYnP,CAAK,EAAI83B,GAAiB93B,EAAOmP,CAAU,EAEvG4oB,GAA2B1iC,GAA+C,CAC9E,IAAM8Z,EAAa9Z,EAAO,CAAC,EAAE,KACvB2K,EAAQ,MAAM,KAAK3K,EAAO,CAAC,EAAE,iBAAiB,EAAG,MAAM,EACvDwa,EAAwBwf,GAAqBlgB,EAAYnP,CAAK,EAC9DnQ,EAAWwF,EAAO,CAAC,EAAE,SACrBgjC,EAAiBxoC,IAAa,GAAiBkP,EAAU,KAAKoQ,CAAU,IAAM,EAC9EmpB,EACJzoC,IAAa,GAAoBsf,EAAW,OAAS,GAAKA,EAAWA,EAAW,OAAS,CAAC,EAAI,IAAM,EAAvE,EAA+E,EACxGzE,EAAa2tB,GAEfxoB,EAAY,OAAS,GAAKA,EAAYA,EAAY,OAAS,CAAC,EAAI,IAAM,EADtE,EAGE,EACAM,EAAa,KAAK,KAAKpR,EAAU,KAAK8Q,CAAW,EAAInF,CAAU,EAE/DuF,EAAmBC,GAA+B,CACtD,IAAMd,EAAQjF,EAAc,QAASta,EAAUsf,EAAW,OAAQmpB,CAAW,EACvEjsB,EAASjC,EAAe,SAAUva,EAAUggB,EAAY,OAAQnF,CAAU,EAC5EoX,EACJ,GAAIjyB,IAAa,EAAe,CAC9B,IAAMsyB,EAAmB,CAACC,EAAgBvhB,EAAWwhB,EAAW,KAAO;AAAA,6BAChDxhB,CAAC,MAAMwL,EAAO,gBAAgB,kBAAkBxL,CAAC,GAAG,CAAC;AAAA,sBAC5DA,CAAC,MAAMuO,EAAM,2BAA2B,gBAAgBvO,CAAC,GAAIwL,CAAM,CAAC;AAAA,qBACrExL,CAAC,YAAYA,CAAC;AAAA,yBACVA,CAAC,YAAYA,CAAC;AAAA,YAC3BuhB,CAAM,IAAIvhB,CAAC,OAAOwhB,CAAQ,IAAIjT,EAAM,YAAY,QAAQvO,CAAC,EAAE,CAAC,aAAaA,CAAC;AAAA,UAEhFihB,EAAa;AAAA,0CACuBpX,CAAU;AAAA;AAAA,UAE1CyX,EAAiB,OAAQ,EAAG,KAAK,CAAC;AAAA,UAClCA,EAAiB,OAAQ,EAAG,KAAK,CAAC;AAAA,UAClCA,EAAiB,OAAQ,EAAG,KAAK,CAAC;AAAA,UAClCA,EAAiB,OAAQ,EAAG,KAAK,CAAC;AAAA,UAClC9V,EAAO,YAAY,aAAc,MAAM,CAAC;AAAA,QAE9C,MACEyV,EAAa;AAAA,8BACWzV,EAAO,gBAAgB,gBAAgB3B,CAAU,EAAE,CAAC;AAAA,4BACtD0E,EAAM,2BAA2B,gBAAiB/C,CAAM,CAAC;AAAA,qBAChEA,EAAO,KAAK,KAAK,IAAI+C,EAAM,YAAY,iBAAiBkpB,CAAW,EAAE,CAAC;AAAA,UACjFjsB,EAAO,YAAY,aAAc,MAAM,CAAC;AAAA,SAG9C,MAAO;AAAA,MACL6D,EAAa,gBAAgB,WAAY,KAAK,EAAE,iBAAiBd,EAAO/C,CAAM,CAAC;AAAA,MAC/E6D,EAAa,UAAU,CAAC;AAAA,MACxBA,EAAa,sCAAsC,mBAAmB,CAAC;AAAA,MACvE4R,CAAU,EACd,EAEMnX,EAAoC,CACxC,CAAE,QAAuB,KAAMwF,CAAW,EAC1C,GAAGvG,EAA2BuF,EAAYU,CAAW,CACvD,EACA,MAAO,CACL,KAAM,SACN,YAAa,CAAE,KAAM,GAAGA,EAAY,MAAM,IAAIyoB,CAAW,GAAG5tB,CAAU,GAAI,kBAAmB,CAAC,MAAM,CAAE,EACtG,gBAAAuF,EACA,WAAY,KAAO,CACjB,QAAS,CAAC,CAAE,KAAMJ,EAAa,SAAUxa,EAAO,CAAC,EAAE,QAAS,CAAC,EAC7D,cAAe,CAAE,EAAG,KAAK,KAAK8a,EAAa,EAAuB,CAAE,EACpE,gBAAAxF,CACF,EACF,CACF,EAEaqtB,GAAU3oC,GAAkC,CACvDof,GAAepf,EAAQ,MAAM,EAC7BA,EAAQ,QAAQ0oC,GAAwB1oC,EAAQ,MAAM,EAAG,CAAE,OAAQ,CAAC,CAAC,CAAE,CAAC,CAC1E,ICnHA,IAoBMkpC,GAsDO1Z,GA1Eb2Z,GAAApuC,EAAA,kBAGAkS,IAEA8C,IAGAqL,IAQA0U,KAIMoZ,GAA6B7Y,GAAqD,CACtF,IAAM7vB,EAAW6vB,EAAa,CAAC,EAAE,SAC3BvP,EAAapR,EAAU,KAAK2gB,EAAa,CAAC,EAAE,IAAI,EAChD+Y,EAAa15B,EAAU,KAAK2gB,EAAa,CAAC,EAAE,IAAI,EAEhDgZ,EAAUD,EAAa,IAAM,EAC7BxoB,EAAmBC,GAAuC,CAC9D,IAAMrP,EAAIsJ,EAAc,IAAKta,EAAU,CAAC,CAAC,EAAG,CAAC,EACvCwmB,EAAOlM,EAAc,OAAQta,EAAU,CAAC,CAAC,EAAG,CAAC,EAC7CgsB,EAAIzR,EAAe,IAAKva,EAAU,CAAC,CAAC,EAAG,CAAC,EAExCuoB,EAA8B,CAClC,CAAE,KAAM,kBAAmB,KAAM,KAAM,EACvC,CAAE,KAAM,YAAa,KAAM,KAAM,CACnC,EAEMugB,EAAqBluC,GAAqB;AAAA,gBACpCA,CAAC,oCAAoCA,CAAC;AAAA,gBACtCA,CAAC,MAAM4rB,EAAK,YAAY,OAAO5rB,CAAC,aAAa,CAAC,QAAQA,CAAC,gBAC7DmuC,EAAoBF,EACtB;AAAA,mBACWriB,EAAK,YAAY,uCAAuC,CAAC,IACpE,GAAGsiB,EAAkB,CAAC,CAAC,GAAGA,EAAkB,CAAC,CAAC,GAAGA,EAAkB,CAAC,CAAC,GAAGA,EAAkB,CAAC,CAAC;AAAA,mBACjF93B,EAAE,KAAK,KAAK,gCAE3B,MAAO,GAAGqP,EAAa,iBAAiBkI,CAAQ,EAAE,iBAAiBvX,EAAGwV,EAAMwF,CAAC,CAAC;AAAA;AAAA,MAEtE8C,GAAahV,GAA0B9Z,CAAQ,CAAC,CAAC;AAAA;AAAA,MAEvDqgB,EAAa,UAAU1G,EAAc,CAAC;AAAA,QACpC0G,EAAa,sCAAsC,0BAA0B,CAAC;AAAA;AAAA,gBAEtErP,EAAE,YAAY,YAAY,CAAC;AAAA,QACnC+3B,CAAiB;AAAA;AAAA,QAEjB/c,EAAE,YAAY,aAAoB+C,GAAmB,MAAM,CAAC,CAAC;AAAA,MAEnE,EAEA,MAAO,CACL,KAAM,mBACN,YAAa,CAAE,KAAM,GAAG8Z,CAAO,GAAI,kBAAmB,CAAC,OAAQ,MAAM,CAAE,EACvE,gBAAAzoB,EACA,WAAa5a,IAAY,CACvB,QAAS,CAAC,CAAE,KAAMA,EAAO,CAAC,EAAE,KAAM,SAAUA,EAAO,CAAC,EAAE,QAAS,CAAC,EAChE,gBAAiB,CACf,CAAE,QAAuB,KAAM,KAAK,KAAK8a,EAAa,CAAC,CAAE,EACzD,CAAE,QAAuB,KAAMsoB,CAAW,CAC5C,EACA,cAAe,CAAE,EAAG,KAAK,KAAKtoB,EAAa3G,GAAiB,CAAC,CAAE,CACjE,EACF,CACF,EAEaqV,GAAYxvB,GAAkC,CACrDA,EAAQ,OAAO,OAAS,GAAK0P,EAAU,KAAK1P,EAAQ,OAAO,CAAC,EAAE,IAAI,IAAM,EACpEwvB,GAASxvB,CAAO,EAEtBA,EAAQ,QAAQkpC,GAA0BlpC,EAAQ,MAAM,CAAC,CAE7D,IChFA,IAeMof,GAMAoqB,GAwGOC,GAGAC,GAhIbC,GAAA5uC,EAAA,kBAGAkS,IAEA8C,IACAkK,KAGAmB,IAMMgE,GAAkBpZ,GAAwC,CAC9D,GAAI,CAACA,GAAUA,EAAO,SAAW,EAC/B,MAAM,IAAI,MAAM,2BAA2B,CAE/C,EAEMwjC,GAA0B,CAACxjC,EAA+Bkb,IAA8C,CAC5G,IAAMpB,EAAa9Z,EAAO,CAAC,EAAE,KACvB4jC,EAAe5jC,EAAO,CAAC,EAAE,KAEzB6K,EAAYiP,EAAW,OACvB5O,EAAOxB,EAAU,cAAcwR,EAAW,KAAMrQ,CAAS,EAEzD2P,EAAcV,EAAW,MAAM,CAAC,EACtCU,EAAY,OAAOtP,EAAM,EAAG,GAAG04B,CAAY,EAE3C,IAAMC,EAAe/pB,EAAW5O,CAAI,EAC9BmK,EAAarV,EAAO,CAAC,EAAE,WAAa,EAAgB,EAAI,EACxD8a,EAAa,KAAK,KAAKpR,EAAU,KAAK8Q,CAAW,EAAInF,CAAU,EAE/DC,EAAoC,CACxC,CAAE,QAAuB,KAAMwF,CAAW,EAC1C,CAAE,OAAsB,KAAM+oB,CAAa,EAC3C,CAAE,QAAuB,KAAM34B,CAAK,EACpC,GAAGqJ,EAA2BvU,EAAO,CAAC,EAAE,KAAMA,EAAO,CAAC,EAAE,KAAMwa,CAAW,CAC3E,EAEMI,EAAmBC,GAA+B,CACtD,IAAMphB,EAAOqb,EAAc,OAAQ9U,EAAO,CAAC,EAAE,SAAUA,EAAO,CAAC,EAAE,KAAK,OAAQqV,CAAU,EAClFqB,EAAU5B,EAAc,eAAgB9U,EAAO,CAAC,EAAE,SAAUA,EAAO,CAAC,EAAE,KAAK,MAAM,EACjFgX,EAASjC,EAAe,SAAU/U,EAAO,CAAC,EAAE,SAAUwa,EAAY,OAAQnF,CAAU,EAEpFyuB,EAAmBt4B,GAA+B,CACtD,IAAMu4B,EAAcH,EAAa,OAC7BjS,EAAU,qBAAqBnmB,CAAC,OAAOkL,EAAQ,KAAK,OAAO,OAC/D,QAASthB,EAAI,EAAGA,EAAI2uC,EAAa3uC,IAC/Bu8B,GAAW,GAAGoS,EAAc,EAAI,iBAAiBv4B,CAAC,IAAIpW,CAAC,IAAM,iBAAiBoW,CAAC,EAAE,MAC/EgP,EAAY,OAAS,EAAI,gBAAgBhP,CAAC,oBAAoBpW,CAAC,IAAM,gBAAgBoW,CAAC,EACxF,IAEFmmB,GAAW;AAAA,mBACEnmB,CAAC,MAAMkL,EAAQ,aAAa,iBAAiBlL,CAAC,EAAE,CAAC;AAAA,mBACjDA,CAAC;AAAA,iBACHA,CAAC,SAASA,CAAC;AAAA;AAAA,2BAEDA,CAAC,MAAM/R,EAAK,KAAK,OAAO;AAAA,UAE7C,QAASrE,EAAI,EAAGyC,EAAI,EAAGzC,EAAIyV,EAAWzV,IAChCA,IAAM8V,GACRymB,GAAW,GAAG9mB,EAAY,EAAI,cAAcW,CAAC,IAAIpW,CAAC,IAAM,cAAcoW,CAAC,EAAE,aAAaA,CAAC,KACvF3T,GAAKksC,IAELpS,GAAW,GAAG9mB,EAAY,EAAI,cAAcW,CAAC,IAAIpW,CAAC,IAAM,cAAcoW,CAAC,EAAE,MACvEgP,EAAY,OAAS,EAAI,gBAAgBhP,CAAC,IAAI3T,CAAC,IAAM,gBAAgB2T,CAAC,EACxE,IACA3T,KAGJ,OAAO85B,CACT,EACIlF,EACJ,GAAIzsB,EAAO,CAAC,EAAE,WAAa,EAAe,CACxC,IAAM8sB,EAAmB,CAACC,EAAgBvhB,EAAWwhB,EAAW,KAAO;AAAA,6BAChDxhB,CAAC,MAAMwL,EAAO,gBAAgB,kBAAkBxL,CAAC,GAAG,CAAC;AAAA,YACtEs4B,EAAgBt4B,CAAC,CAAC;AAAA,sBACRA,CAAC,MAAM/R,EAAK,gBAAgB,cAAc+R,CAAC,EAAE,CAAC;AAAA,qBAC/CA,CAAC,YAAYA,CAAC;AAAA,yBACVA,CAAC,YAAYA,CAAC;AAAA,YAC3BuhB,CAAM,IAAIvhB,CAAC,OAAOwhB,CAAQ,IAAIvzB,EAAK,YAAY,QAAQ+R,CAAC,EAAE,CAAC,aAAaA,CAAC;AAAA,UAE/EihB,EAAa;AAAA,0CACuBpX,CAAU;AAAA;AAAA,UAE1CyX,EAAiB,QAAS,EAAG,KAAK,CAAC;AAAA,UACnCA,EAAiB,QAAS,EAAG,KAAK,CAAC;AAAA,UACnCA,EAAiB,QAAS,EAAG,KAAK,CAAC;AAAA,UACnCA,EAAiB,QAAS,EAAG,KAAK,CAAC;AAAA,UACnC9V,EAAO,YAAY,aAAc,OAAO,CAAC;AAAA,OAE/C,MACEyV,EAAa;AAAA,4BACSzV,EAAO,gBAAgB,YAAY,CAAC;AAAA,QACxD8sB,EAAgB,EAAE,CAAC;AAAA,oBACPrqC,EAAK,aAAa,aAAa,CAAC;AAAA,QAC5Cud,EAAO,YAAY,aAAc,OAAO,CAAC;AAAA,QAG7C,MAAO;AAAA,QACH6D,EACC,gBAAgB,aAAc,KAAK,EACnC,gBAAgB,eAAgB,KAAK,EACrC,gBAAgB,OAAQ,KAAK,EAC7B,iBAAiBphB,EAAMid,EAASM,CAAM,CAAC;AAAA,QACxC6D,EAAa,UAAU,CAAC;AAAA,UACtBA,EAAa,sCAAsC,qBAAqB,CAAC;AAAA,UACzE4R,CAAU;AAAA,QAElB,EACA,MAAO,CACL,KAAM,SACN,YAAa,CAAE,KAAMvR,EAAW,SAAU,kBAAmB,CAAC,OAAQ,MAAM,CAAE,EAC9E,WAAY,KAAO,CACjB,QAAS,CAAC,CAAE,KAAMV,EAAa,SAAUxa,EAAO,CAAC,EAAE,QAAS,CAAC,EAC7D,cAAe,CAAE,EAAG,KAAK,KAAK8a,EAAa,EAAuB,CAAE,EACpE,gBAAAxF,CACF,GACA,gBAAAsF,CACF,CACF,EAEa6oB,GAAyBvoB,GACpClH,EAA4B,CAAE,KAAMkH,EAAW,IAAe,CAAC,EAEpDwoB,GAAS,CAAC1pC,EAAyBkhB,IAAuC,CACrF,IAAMlb,EAAShG,EAAQ,OACvBof,GAAepZ,CAAM,EACrBhG,EAAQ,QAAQwpC,GAAwBxpC,EAAQ,OAAQkhB,CAAU,CAAC,CACrE,ICpIA,IAeM8oB,GAkFOC,GA2EAC,GA5KbC,GAAApvC,EAAA,kBAGAkS,IAEA8C,IAIAqL,IAMM4uB,GAAsB,CAC1BhqC,EACAoqC,EACAC,EACAhT,EACAtlB,EACAu4B,EACAC,EACAC,EACAC,IACG,CACH,IAAMnvB,EAAoC,CACxC,CAAE,QAAuB,KAAMgvB,CAAU,EACzC,CAAE,QAAuB,KAAMjT,CAAU,EACzC,CAAE,QAAuB,KAAMtlB,CAAU,EACzC,CAAE,QAAuB,KAAMs4B,CAAuB,EACtD,CAAE,QAAuB,KAAME,CAAkB,EACjD,CAAE,QAAuB,KAAMC,CAAiB,EAChD,CAAE,QAAuB,KAAMC,CAAa,CAC9C,EAEMjqB,EAAc,CAAC8pB,CAAS,EAC9BhvB,EAAgB,KAAK,GAAGf,EAA2B6vB,EAAY,KAAM5pB,CAAW,CAAC,EAEjF,IAAMI,EAAmBC,GAA+B,CACtD,IAAMnE,EAAU5B,EAAc,eAAgBsvB,EAAY,SAAUA,EAAY,KAAK,MAAM,EACrFptB,EAASjC,EAAe,8BAA6C,EAAG,CAAC,EACzE8D,EAAY,CAACnC,EAASM,CAAM,EAC5B+L,EAA8B,CAClC,CAAE,KAAM,cAAe,KAAM,KAAM,EACnC,CAAE,KAAM,aAAc,KAAM,KAAM,EAClC,CAAE,KAAM,aAAc,KAAM,MAAO,OAAQhX,EAAU,MAAO,EAC5D,CAAE,KAAM,6BAA8B,KAAM,MAAO,OAAQs4B,EAAuB,MAAO,EACzF,CAAE,KAAM,uBAAwB,KAAM,KAAM,EAC5C,CAAE,KAAM,qBAAsB,KAAM,KAAM,EAC1C,CAAE,KAAM,iBAAkB,KAAM,KAAM,CACxC,EACA,MAAO;AAAA,IACPxpB,EAAa,iBAAiBkI,CAAQ,EAAE,iBAAiB,GAAGlK,CAAS,CAAC;AAAA,IACtEgC,EAAa,UAAU,CAAC;AAAA,MACtBA,EAAa,sCAAsC,sBAAsB,CAAC;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,UAWtE9O,EAAU,SAAW,EACjB,qCACA,mDACN;AAAA;AAAA,QAGAs4B,EAAuB,SAAW,EAC9B,6EACA,qFACN;AAAA;AAAA;AAAA;AAAA,IAKJ,EAEA,OAAOrqC,EAAQ,QACb,CACE,KAAM,sBACN,YAAa,CAAE,KAAM,GAAG+R,EAAU,MAAM,IAAIs4B,EAAuB,MAAM,GAAI,kBAAmB,CAAC,MAAM,CAAE,EACzG,WAAY,KAAO,CACjB,QAAS,CAAC,CAAE,KAAM7pB,EAAa,SAAUxgB,EAAQ,OAAO,CAAC,EAAE,QAAS,CAAC,EACrE,cAAe,CAAE,EAAG,KAAK,KAAKsqC,EAAY,EAAE,CAAE,EAC9C,gBAAAhvB,CACF,GACA,gBAAAsF,CACF,EACA,CAAE,OAAQ,CAACwpB,CAAW,EAAG,QAAS,CAAC,EAAE,CAAE,CACzC,EAAE,CAAC,CACL,EAEaH,GAAW,CAACjqC,EAAyBkhB,IAAmC,CACnF,IAAMlb,EAAShG,EAAQ,OACjB8f,EAAa9Z,EAAO,CAAC,EAAE,KACvBmuB,EAAYnuB,EAAO,CAAC,EAAE,SACtB4jC,EAAe5jC,EAAO,CAAC,EAAE,KACzBykC,EAAeb,EAAaA,EAAa,OAAS,CAAC,EACnDU,EAAY56B,EAAU,gBAAgBk6B,EAAcA,EAAa,OAAS,CAAC,EAC3Ec,EAAYh7B,EAAU,kBAAkBoQ,EAAYoB,EAAW,UAAYupB,CAAY,EACvFE,EAAaj7B,EAAU,gBAAgBoQ,EAAYoB,EAAW,SAAS,EACvEspB,EAAmB96B,EAAU,kBAAkBoQ,EAAYoB,EAAW,SAAS,EAC/EqpB,EAAoBD,EAAYK,EAChCC,EAAqB,IAAI,MAAMH,CAAY,EAC7CI,EAAiBH,EACrB,QAAStvC,EAAI,EAAGA,EAAIqvC,EAAc,EAAErvC,EAClCwvC,EAAmBH,EAAe,EAAIrvC,CAAC,EAAIyvC,EAC3CA,GAAkB/qB,EAAWoB,EAAW,UAAYupB,EAAe,EAAIrvC,CAAC,EAG1E,IAAM0vC,EAAoBd,GACxBhqC,EACAgG,EAAO,CAAC,EACR4kC,EACA1pB,EAAW,UACXpB,EACAwqB,EACAC,EACAC,EACAC,CACF,EAEMM,EAAuB7pB,EAAW,UAAYupB,EACpD,GAAIM,EAAuBjrB,EAAW,OACpC,MAAM,IAAI,MAAM,wEAAwE,EAG1F,IAAMU,EAAcopB,EAAa,MAAM,EAAG,EAAE,EAAE,OAAO9pB,EAAW,MAAMirB,CAAoB,CAAC,EACrFjqB,EAAapR,EAAU,KAAK8Q,CAAW,EAEvClF,EAAoC,CACxC,CAAE,QAAuB,KAAMwF,CAAW,EAC1C,CAAE,QAAuB,KAAM4pB,CAAU,EACzC,GAAGnwB,EAA2BvU,EAAO,CAAC,EAAE,KAAM8kC,EAAkB,KAAMtqB,CAAW,CACnF,EAEMI,EAAmBC,GAA+B,CACtD,IAAMd,EAAQjF,EAAc,OAAQ9U,EAAO,CAAC,EAAE,SAAUA,EAAO,CAAC,EAAE,KAAK,MAAM,EACvE0W,EAAU5B,EAAc,mBAAkCgwB,EAAkB,KAAK,MAAM,EAEvF9tB,EAASjC,EAAe,SAAU/U,EAAO,CAAC,EAAE,SAAUwa,EAAY,MAAM,EAC9E,MAAO;AAAA,YACCK,EACC,gBAAgB,cAAe,KAAK,EACpC,gBAAgB,aAAc,KAAK,EACnC,iBAAiBd,EAAOrD,EAASM,CAAM,CAAC;AAAA,cACvC6D,EAAa,UAAU,CAAC;AAAA,cACxBA,EAAa,sCAAsC,sBAAsB,CAAC;AAAA;AAAA;AAAA,UAItF,EACA7gB,EAAQ,QACN,CACE,KAAM,WACN,YAAa,CAAE,KAAMkhB,EAAW,SAAU,kBAAmB,CAAC,OAAQ,MAAM,CAAE,EAC9E,WAAY,KAAO,CACjB,QAAS,CAAC,CAAE,KAAMV,EAAa,SAAU2T,CAAU,CAAC,EACpD,cAAe,CAAE,EAAG,KAAK,KAAKrT,EAAa,EAAuB,CAAE,EACpE,gBAAAxF,CACF,GACA,gBAAAsF,CACF,EACA,CAAE,OAAQ,CAAC5a,EAAO,CAAC,EAAG8kC,CAAiB,CAAE,CAC3C,CACF,EAEaZ,GAA2BhpB,IAE/B,CACL,UAFgBA,EAAW,WAG3B,SAAU,EACZ,KCjLF,IAwBa9B,GAyCP4rB,GAqHOC,GAMAC,GA5LbC,GAAApwC,EAAA,kBAGAkS,IAEA8C,IACAkK,KAGAmB,IAeagE,GAAiB,CAACpZ,EAA+Bkb,IAAqD,CACjH,GAAIlb,EAAO,OAAS,GAAKA,EAAO,OAAS,EACvC,MAAM,IAAI,MAAM,8CAA8C,EAEhE,IAAMolC,EAAe17B,EAAU,cAAcwR,EAAW,aAAclb,EAAO,CAAC,EAAE,KAAK,MAAM,EACrFqlC,EAAYnqB,EAAW,UACvBzhB,EAAOuG,EAAO,CAAC,EACfslC,EAAStlC,EAAO,CAAC,EACjBulC,EAAYvlC,EAAO,SAAW,EAAIA,EAAO,CAAC,EAAI,OACpD,GACEslC,EAAO,KAAK,SAAW7rC,EAAK,KAAK,QACjC,CAACA,EAAK,KACH,IAAI,CAACgmB,EAAGrqB,IAAOA,IAAMgwC,EAAe,KAAK,KAAK3lB,EAAI4lB,CAAS,IAAMC,EAAO,KAAKlwC,CAAC,EAAIqqB,IAAM6lB,EAAO,KAAKlwC,CAAC,CAAE,EACvG,OAAO,CAAC,EAAGmS,IAAM,GAAKA,EAAG,EAAI,EAEhC,MAAM,IAAI,MACR,oGACF,EASF,GAAIg+B,EAAW,CACb,GAAIA,EAAU,WAAa9rC,EAAK,SAC9B,MAAM,IAAI,MAAM,8DAA8D,EAEhF,GACE8rC,EAAU,KAAK,SAAWD,EAAO,KAAK,QACtC,CAACC,EAAU,KAAK,IAAI,CAAC9lB,EAAGrqB,IAAMqqB,IAAM6lB,EAAO,KAAKlwC,CAAC,CAAC,EAAE,OAAO,CAAC,EAAGmS,IAAM,GAAKA,EAAG,EAAI,EAEjF,MAAM,IAAI,MACR,0GACF,CAEJ,CACF,EAEMy9B,GAAwC,CAC5ChlC,EACAkb,IACgB,CAChB,IAAMpB,EAAa9Z,EAAO,CAAC,EAAE,KACvB4jC,EAAe5jC,EAAO,CAAC,EAAE,KACzB6K,EAAYiP,EAAW,OACvB0rB,EAAa97B,EAAU,cAAcwR,EAAW,WAAYrQ,CAAS,EACrEu6B,EAAe17B,EAAU,cAAcwR,EAAW,aAAcrQ,CAAS,EACzE2P,EAAcV,EAAW,MAAM,CAAC,EACtCU,EAAY,OAAOgrB,EAAY,EAAG,GAAG5B,CAAY,EACjD,IAAM9oB,EAAapR,EAAU,KAAK8Q,CAAW,EACvCirB,EAAazlC,EAAO,CAAC,EAAE,SAEvB0lC,EADY1lC,EAAO,CAAC,EAAE,WACG,GACzBsV,EAAoC,CACxC,CAAE,QAAuB,KAAMwF,CAAW,EAC1C,CAAE,QAAuB,KAAMsqB,CAAa,EAC5C,CAAE,QAAuB,KAAMI,CAAW,EAC1C,CAAE,QAAuB,KAAMtqB,EAAW,SAAU,EACpD,GAAG3G,EAA2B,GAAGvU,EAAO,IAAI,CAAC+Z,EAAO2W,IAAM3W,EAAM,IAAI,EAAGS,CAAW,CACpF,EAEMI,EAAmBC,GAA+B,CACtD,IAAMphB,EAAOqb,EAAc,OAAQ9U,EAAO,CAAC,EAAE,SAAUA,EAAO,CAAC,EAAE,KAAK,MAAM,EACtE0W,EAAU5B,EAAc,eAAgB9U,EAAO,CAAC,EAAE,SAAUA,EAAO,CAAC,EAAE,KAAK,MAAM,EACjFslC,EAASxwB,EAAc,SAAU9U,EAAO,CAAC,EAAE,SAAUA,EAAO,CAAC,EAAE,KAAK,MAAM,EAC1EulC,EACJvlC,EAAO,OAAS,EAAI8U,EAAc,YAAa9U,EAAO,CAAC,EAAE,SAAUA,EAAO,CAAC,EAAE,KAAK,MAAM,EAAI,OACxFgX,EAASjC,EAAe,SAAU0wB,EAAYjrB,EAAY,MAAM,EAChE+W,EAAiB,CAAC93B,EAAMid,EAAS4uB,CAAM,EACzCC,GACFhU,EAAe,KAAKgU,CAAS,EAE/B,IAAMxiB,EAA8B,CAClC,CAAE,KAAM,cAAe,KAAM,KAAM,EACnC,CAAE,KAAM,gBAAiB,KAAM,KAAM,EACrC,CAAE,KAAM,cAAe,KAAM,KAAM,EACnC,CAAE,KAAM,aAAc,KAAM,KAAM,CACpC,EACA,MAAO;AAAA,UACDlI,EAAa,iBAAiBkI,CAAQ,EAAE,iBAAiB,GAAGwO,EAAgBva,CAAM,CAAC;AAAA,UACnF6D,EAAa,UAAU,CAAC;AAAA,+BACH7D,EAAO,gBAAgB,YAAY,CAAC;AAAA,gCACnCN,EAAQ,KAAK,OAAO;AAAA,UAEtCktB,EAAa,OAAS,EACjB;AAAA,qCACkBA,EAAa,MAAM;AAAA,0BAC9B5sB,EAAO,WAAW,iBAAkB,0BAA0B,CAAC;AAAA,cAC3EN,EAAQ,WAAW,kBAAmB,IAAK,OAAO,CAAC;AAAA,aAG9C,qBAAqBM,EAAO,WAAW,iBAAkB,sBAAsB,CAAC,GAEvF;AAAA,6BACiBvd,EAAK,KAAK,OAAO;AAAA;AAAA,wBAEtBud,EAAO,WAAW,iBAAkB,GAAG,CAAC;AAAA,YACpDvd,EAAK,WAAW,eAAgB,IAAK,OAAO,CAAC;AAAA;AAAA,mCAEtBid,EAAQ,aAAa,iBAAiB,CAAC;AAAA;AAAA,kCAExCoD,EAAW0rB,CAAU,CAAC;AAAA;AAAA,UAE9C/rC,EAAK,WAAW,eAAgB,uBAAwB,yBAAyB,CAAC;AAAA,qDACvC+gB,EAAY,MAAM;AAAA,wBAC/CxD,EAAO,WAAW,iBAAkB,OAAO4sB,EAAa,MAAM,MAAM,CAAC;AAAA,YACjFnqC,EAAK,WAAW,eAAgB,IAAK,OAAO,CAAC;AAAA;AAAA,4BAE7BA,EAAK,gBAAgB,cAAc,CAAC;AAAA;AAAA;AAAA,2CAGrBA,EAAK,YAAY,iBAAiB,CAAC;AAAA;AAAA,mCAE3CisC,EAAW,aAAe,YAAY;AAAA;AAAA;AAAA,oCAGrCJ,EAAO,WAAW,eAAgB,wBAAwB,CAAC;AAAA,UACrFA,EAAO,WAAW,gBAAiB,yBAA0B,qBAAqB,CAAC;AAAA,sBACvEA,EAAO,aAAa,eAAe,CAAC;AAAA,UAE3CC,EAGI;AAAA;AAAA,wCAEqBA,EAAU,gBAAgB,oBAAoB,CAAC;AAAA;AAAA,8CAEzCA,EAAU,YAAY,uBAAuB,CAAC;AAAA;AAAA,qCAEvDG,EAAW,aAAe,YAAY;AAAA,sEARxD,oBAWP;AAAA,iCACqBpxB,GAA0BmxB,CAAU,CAAC;AAAA,UAC5DzuB,EAAO,YAAY,aAAc,kBAAkB,CAAC;AAAA,MAE5D,EACA,MAAO,CACL,KAAM,uBACN,YAAa,CACX,KAAM,GAAGkE,EAAW,QAAQ,IAAIlb,EAC7B,OAAO,CAAC0wB,EAAGt7B,IAAMA,IAAM,CAAC,EACxB,IAAK2kB,GAAUA,EAAM,KAAK,KAAK,GAAG,CAAC,EACnC,KAAK,GAAG,CAAC,GACZ,kBAAmB,MAAM,KAAK,CAAE,OAAQ/Z,EAAO,MAAO,EAAG,CAAC2lC,EAAIC,IAAO,MAAM,CAC7E,EACA,WAAY,KAAO,CACjB,QAAS,CAAC,CAAE,KAAMprB,EAAa,SAAUirB,CAAW,CAAC,EACrD,cAAe,CAAE,EAAG,KAAK,KAAK3qB,EAAa,EAAuB,CAAE,EACpE,gBAAAxF,CACF,GACA,gBAAAsF,CACF,CACF,EAEaqqB,GAAuB,CAACjrC,EAAyBkhB,IAAqD,CACjH,IAAMlb,EAAShG,EAAQ,OACvBof,GAAepZ,EAAQkb,CAAU,EACjClhB,EAAQ,QAAQgrC,GAAsChrC,EAAQ,OAAQkhB,CAAU,CAAC,CACnF,EAEagqB,GACXhqB,GAEAlH,EAA4B,CAC1B,UAAWkH,EAAW,UACtB,WAAYA,EAAW,WACvB,aAAcA,EAAW,YAC3B,CAAC,ICnMH,IAeM9B,GAeAysB,GAiEOC,GAGAC,GAlGbC,GAAAjxC,EAAA,kBAGAkS,IAEA8C,IACAkK,KAGAmB,IAMMgE,GAAkBpZ,GAAwC,CAC9D,GAAI,CAACA,GAAUA,EAAO,SAAW,EAC/B,MAAM,IAAI,MAAM,mCAAmC,EAGrD,GAAIA,EAAO,CAAC,EAAE,KAAK,OAAS,EAC1B,MAAM,IAAI,MAAM,2DAA2D,EAG7E,GAAIA,EAAO,CAAC,EAAE,KAAK,SAAWA,EAAO,CAAC,EAAE,KAAK,OAC3C,MAAM,IAAI,MAAM;AAAA,4DACwC,CAE5D,EAEM6lC,GAAkC,CACtC7lC,EACAkb,IACgB,CAChB,IAAMpB,EAAa9Z,EAAO,CAAC,EAAE,KACvBimC,EAAsBjmC,EAAO,CAAC,EAAE,SAChC6K,EAAYiP,EAAW,OAEvB8pB,EAAe5jC,EAAO,CAAC,EAAE,KACzBkmC,EAAkBlmC,EAAO,CAAC,EAAE,SAC5BkL,EAAOxB,EAAU,cAAcwR,EAAW,KAAMrQ,CAAS,EACzDg5B,EAAe/pB,EAAW5O,CAAI,EAE9BsP,EAAcopB,EAAa,MAAM,CAAC,EAClC9oB,EAAapR,EAAU,KAAK8Q,CAAW,EAEvCT,EAAQjF,EAAc,QAASmxB,EAAqBp7B,CAAS,EAC7D6L,EAAU5B,EAAc,eAAgBoxB,EAAiBtC,EAAa,MAAM,EAC5E5sB,EAASjC,EAAe,SAAUkxB,EAAqBzrB,EAAY,MAAM,EAEzElF,EAAoC,CACxC,CAAE,QAAuB,KAAMwF,CAAW,EAC1C,CAAE,OAAsB,KAAM+oB,CAAa,EAC3C,CAAE,QAAuB,KAAM34B,CAAK,CACtC,EACA,OAAAoK,EAAgB,KAAK,GAAGf,EAA2BuF,EAAY8pB,EAAcppB,CAAW,CAAC,EA4BlF,CACL,KAAM,iBACN,YAAa,CAAE,kBA7B6C,CAAC,OAAQ,MAAM,CA6B1C,EACjC,WAAY,KAAO,CACjB,QAAS,CAAC,CAAE,KAAMA,EAAa,SAAUxa,EAAO,CAAC,EAAE,QAAS,CAAC,EAC7D,cAAe,CAAE,EAAG,KAAK,KAAK8a,EAAa,EAAuB,CAAE,EACpE,gBAAAxF,CACF,GACA,gBA9BuBuF,GAA+B;AAAA,QAClDA,EACC,gBAAgB,aAAc,KAAK,EACnC,gBAAgB,eAAgB,KAAK,EACrC,gBAAgB,OAAQ,KAAK,EAC7B,iBAAiBd,EAAOrD,EAASM,CAAM,CAAC;AAAA,QACzC6D,EAAa,UAAU,CAAC;AAAA,QACxBA,EAAa,sCAAsC,qBAAqB,CAAC;AAAA;AAAA,4BAErD7D,EAAO,gBAAgB,YAAY,CAAC;AAAA;AAAA,kBAE9CN,EAAQ,YAAY,YAAY,CAAC;AAAA;AAAA;AAAA;AAAA,2BAIxBqD,EAAM,KAAK,OAAO;AAAA,QACrCA,EAAM,WAAW,eAAgB,gBAAiB,UAAU,CAAC;AAAA,oBACjDA,EAAM,aAAa,cAAc,CAAC;AAAA;AAAA,QAE9C/C,EAAO,YAAY,aAAc,OAAO,CAAC;AAAA,IAY/C,CACF,EAEa8uB,GAAiC5qB,GAC5ClH,EAA4B,CAAE,KAAMkH,EAAW,IAAe,CAAC,EAEpD6qB,GAAiB,CAAC/rC,EAAyBkhB,IAA+C,CACrG,IAAMlb,EAAShG,EAAQ,OACvBof,GAAepZ,CAAM,EACrBhG,EAAQ,QAAQ6rC,GAAgC7rC,EAAQ,OAAQkhB,CAAU,CAAC,CAC7E,ICtGA,IAkBM9B,GAyBA+sB,GAoQOC,GAcAC,GA7TbC,GAAAvxC,EAAA,kBAGAkS,IAEA8C,IAIAqL,IASMgE,GAAkBpZ,GAAwC,CAC9D,GAAI,CAACA,EACH,MAAM,IAAI,MAAM,kBAAkB,EAEpC,GAAIA,EAAO,OAAS,GAAKA,EAAO,OAAS,EACvC,MAAM,IAAI,MAAM,sBAAsB,EAIxC,GAAIA,EAAO,SAAW,GAAKA,EAAO,CAAC,EAAE,KAAK,OAAS,EACjD,MAAM,IAAI,MAAM,0BAA0B,EAG5C,GAAIA,EAAO,CAAC,EAAE,WAAaA,EAAO,CAAC,EAAE,UAAaA,EAAO,SAAW,GAAKA,EAAO,CAAC,EAAE,WAAaA,EAAO,CAAC,EAAE,SACxG,MAAM,IAAI,MAAM,4BAA4B,CAEhD,EASMmmC,GAAwB,CAACnmC,EAA+Bkb,IAA4C,CACxG,IAAM6V,EAAS/wB,EAAO,CAAC,EAAE,KAAK,MAAM,EAC9BgxB,EAAShxB,EAAO,CAAC,EAAE,KAAK,MAAM,EAC9B,CAACmN,EAAGE,EAAGD,CAAC,EAAIxD,GAAS,qBACzBmnB,EACA7V,EAAW,OACX8V,EACA9V,EAAW,OACXlb,EAAO,SAAW,EAAIA,EAAO,CAAC,EAAE,KAAO,MACzC,EACMwa,EAAc,CAACrN,EAAGE,CAAC,EACzB,GAAI,CAACmN,EACH,MAAM,IAAI,MAAM,qCAAqC,EAEvD,IAAMS,EAAW,GACXsrB,EAAW,KAAK,KAAKl5B,EAAI4N,CAAQ,EACjCurB,EAAW,KAAK,KAAKr5B,EAAI8N,CAAQ,EAEjCwrB,EAAY,GAEZ3rB,EAAapR,EAAU,KAAK8Q,CAAW,EACvClF,EAAoC,CACxC,CAAE,QAAuB,KAAMmxB,EAAYF,EAAWzrB,CAAW,EACjE,CAAE,QAAuB,KAAM3N,CAAE,EACjC,CAAE,QAAuB,KAAME,CAAE,EACjC,CAAE,QAAuB,KAAMD,CAAE,EACjC,CAAE,OAAsB,KAAM8N,EAAW,KAAM,EAC/C,CAAE,OAAsB,KAAMA,EAAW,IAAK,CAChD,EACMuH,EAAwD,CAAC,OAAQ,MAAM,EACzEziB,EAAO,SAAW,IACpBsV,EAAgB,KAAK,GAAGf,EAA2BvU,EAAO,CAAC,EAAE,IAAI,CAAC,EAClEyiB,EAAkB,KAAK,MAAM,GAE/BnN,EAAgB,KAAK,GAAGf,EAA2BiG,CAAW,CAAC,EAE/D,IAAMI,EAAmBC,GAA+B,CACtD,IAAI6rB,EAAO,GACPxrB,EAAW,QAAUA,EAAW,OAClCwrB,EAAO,0DACExrB,EAAW,QAAU,CAACA,EAAW,OAC1CwrB,EAAO,0DACE,CAACxrB,EAAW,QAAUA,EAAW,OAC1CwrB,EAAO,0DACE,CAACxrB,EAAW,QAAU,CAACA,EAAW,SAC3CwrB,EAAO,2DAGT,IAAMC,EAAiBzrB,EAAW,QAAU,EAAI,GAAK,2BAC/C5T,EAAIwN,EAAc,IAAK9U,EAAO,CAAC,EAAE,SAAUA,EAAO,CAAC,EAAE,IAAI,EACzDuH,EAAIuN,EAAc,IAAK9U,EAAO,CAAC,EAAE,SAAUA,EAAO,CAAC,EAAE,IAAI,EACzDxF,EAAW8M,EAAE,KAAK,MACpBw1B,EAA0B,KACxBjkB,EAAY,CAACvR,EAAGC,CAAC,EACnBvH,EAAO,SAAW,IACpB88B,EAAIhoB,EAAc,IAAK9U,EAAO,CAAC,EAAE,SAAUA,EAAO,CAAC,EAAE,KAAK,MAAM,EAChE6Y,EAAU,KAAKikB,CAAC,GAElB,IAAM9lB,EAASjC,EAAe,SAAU/U,EAAO,CAAC,EAAE,SAAUwa,EAAY,MAAM,EAC9E3B,EAAU,KAAK7B,CAAM,EACrB,IAAM+L,EAA8B,CAClC,CAAE,KAAM,cAAe,KAAM,KAAM,EACnC,CAAE,KAAM,IAAK,KAAM,KAAM,EACzB,CAAE,KAAM,IAAK,KAAM,KAAM,EACzB,CAAE,KAAM,IAAK,KAAM,KAAM,EACzB,CAAE,KAAM,QAAS,KAAM,KAAM,EAC7B,CAAE,KAAM,OAAQ,KAAM,KAAM,CAC9B,EACA,MAAO;AAAA,IACPlI,EAAa,iBAAiBkI,CAAQ,EAAE,iBAAiB,GAAGlK,CAAS,CAAC;AAAA;AAAA,IAEtEgC,EAAa,UAAU,CAAC;AAAA,MACtBA,EAAa,sCAAsC,sBAAsB,CAAC;AAAA;AAAA;AAAA;AAAA;AAAA,kBAK9DrgB,CAAQ;AAAA;AAAA,QAElBksC,CAAI;AAAA;AAAA;AAAA,MAGNC,CAAc;AAAA,MAEV7J,GAAK,KACA,iBAAiBA,EAAE,2BAA2B,aAAc9lB,CAAM,CAAC,cACxExc,CACF,qBAAqBsiC,EAAE,YAAY,SAAS,CAAC,IAExC,EACL;AAAA;AAAA,IAGN,EAEM8J,EAAyB/rB,GAA+B,CAC5D,IAAMvT,EAAIwN,EAAc,IAAK9U,EAAO,CAAC,EAAE,SAAUA,EAAO,CAAC,EAAE,IAAI,EACzDuH,EAAIuN,EAAc,IAAK9U,EAAO,CAAC,EAAE,SAAUA,EAAO,CAAC,EAAE,IAAI,EAC3D88B,EAA0B,KACxBjkB,EAAY,CAACvR,EAAGC,CAAC,EACnBvH,EAAO,SAAW,IACpB88B,EAAIhoB,EAAc,IAAK9U,EAAO,CAAC,EAAE,SAAUA,EAAO,CAAC,EAAE,KAAK,MAAM,EAChE6Y,EAAU,KAAKikB,CAAC,GAElB,IAAM9lB,EAASjC,EAAe,SAAU/U,EAAO,CAAC,EAAE,SAAUwa,EAAY,MAAM,EAC9E3B,EAAU,KAAK7B,CAAM,EACrB,IAAM+L,EAA8B,CAClC,CAAE,KAAM,aAAc,KAAM,KAAM,EAClC,CAAE,KAAM,IAAK,KAAM,KAAM,EACzB,CAAE,KAAM,IAAK,KAAM,KAAM,EACzB,CAAE,KAAM,IAAK,KAAM,KAAM,EACzB,CAAE,KAAM,QAAS,KAAM,KAAM,EAC7B,CAAE,KAAM,OAAQ,KAAM,KAAM,CAC9B,EAEI2O,EAAa,GACbmV,EAAsB,GACtB3rB,EAAW,QAAUA,EAAW,QAClC2rB,EAAsB;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,2CAMev/B,EAAE,KAAK,KAAK;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,2CAQZC,EAAE,KAAK,KAAK;AAAA;AAAA,QAGjDmqB,EAAa,2DACJxW,EAAW,QAAU,CAACA,EAAW,QAC1C2rB,EAAsB;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,2CAMev/B,EAAE,KAAK,KAAK;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,2CAQZC,EAAE,KAAK,KAAK;AAAA;AAAA,QAGjDmqB,EAAa,2DACJ,CAACxW,EAAW,QAAUA,EAAW,QAC1C2rB,EAAsB;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,2CAMev/B,EAAE,KAAK,KAAK;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,2CAQZC,EAAE,KAAK,KAAK;AAAA;AAAA,QAGjDmqB,EAAa,2DACJ,CAACxW,EAAW,QAAU,CAACA,EAAW,SAC3C2rB,EAAsB;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,2CAMev/B,EAAE,KAAK,KAAK;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,2CAQZC,EAAE,KAAK,KAAK;AAAA;AAAA,QAGjDmqB,EAAa,2DAGf,IAAMiV,EAAiBzrB,EAAW,QAAU,EAAI,GAAK,2BAErD,MAAO;AAAA,IACPL,EAAa,iBAAiBkI,CAAQ,EAAE,iBAAiB,GAAGlK,CAAS,CAAC;AAAA,uCACnCvR,EAAE,KAAK,OAAO,KAAK2T,CAAQ,MAAMA,CAAQ;AAAA,uCACzC1T,EAAE,KAAK,OAAO,KAAK0T,CAAQ,MAAMA,CAAQ;AAAA,IAC5EJ,EAAa,UAAU,CAACI,EAAUA,EAAU,CAAC,CAAC,CAAC;AAAA,qEACkBA,CAAQ;AAAA,qEACRA,CAAQ;AAAA,yCACpCA,CAAQ;AAAA;AAAA,kBAE/BjE,EAAO,KAAK,KAAK;AAAA;AAAA,QAE3B6vB,CAAmB;AAAA,4BACC5rB,CAAQ;AAAA;AAAA;AAAA,kCAGFA,CAAQ;AAAA,UAChCyW,CAAU;AAAA;AAAA;AAAA;AAAA;AAAA,MAKdiV,CAAc;AAAA;AAAA;AAAA,MAIV7J,GAAK,KACA,iBAAiBA,EAAE,2BAA2B,aAAc9lB,CAAM,CAAC,cACxEA,EAAO,KAAK,KACd,qBAAqB8lB,EAAE,YAAY,SAAS,CAAC,IAExC,EACL;AAAA;AAAA;AAAA;AAAA,IAKN,EAEA,OAAI2J,EACK,CACL,KAAM,aACN,YAAa,CAAE,KAAM,GAAGvrB,EAAW,QAAQ,GAAI,kBAAAuH,CAAkB,EACjE,WAAY,KAAO,CACjB,QAAS,CAAC,CAAE,KAAMjI,EAAa,SAAUxa,EAAO,CAAC,EAAE,QAAS,CAAC,EAC7D,cAAe,CAAE,EAAGumC,EAAWC,CAAS,EACxC,gBAAAlxB,CACF,GACA,gBAAiBsxB,CACnB,EAGK,CACL,KAAM,OACN,YAAa,CAAE,KAAM,GAAG1rB,EAAW,QAAQ,GAAI,kBAAAuH,CAAkB,EACjE,WAAY,KAAO,CACjB,QAAS,CAAC,CAAE,KAAMjI,EAAa,SAAUxa,EAAO,CAAC,EAAE,QAAS,CAAC,EAC7D,cAAe,CAAE,EAAG,KAAK,KAAK8a,EAAa,EAAuB,CAAE,EACpE,gBAAAxF,CACF,GACA,gBAAAsF,CACF,CACF,EAEawrB,GAAuBlrB,GAAwD,CAC1F,IAAM4rB,EAAS5rB,EAAW,OACpB6rB,EAAS7rB,EAAW,OACpBuI,EAAQvI,EAAW,MACnBqU,EAAOrU,EAAW,KACxB,MAAO,CACL,OAAA4rB,EACA,OAAAC,EACA,MAAAtjB,EACA,KAAA8L,EACA,SAAU,GAAGrU,EAAW,MAAM,IAAIA,EAAW,MAAM,IAAIA,EAAW,QAAU,CAAC,EAC/E,CACF,EAEamrB,GAAO,CAACrsC,EAAyBkhB,IAAqC,CACjF9B,GAAepf,EAAQ,MAAM,EAC7BA,EAAQ,QAAQmsC,GAAsBnsC,EAAQ,OAAQkhB,CAAU,CAAC,CACnE,IChUA,IAWK8rB,GAAMC,GAAMC,GAAMC,GAWjB/tB,GAiBAguB,GAaAC,GAaAC,GAgBAC,GAiCAC,GAmCAC,GA6CAC,GAyEOC,GAKAC,GAhRbC,GAAA9yC,EAAA,kBAGAkS,IAEA8C,IACAkK,KAGAmB,IAEI,CAAC4xB,GAAMC,GAAMC,GAAMC,IAAQ,CAAC,EAAG,EAAG,EAAG,CAAC,EAWpC/tB,GAAkBpZ,GAAwC,CAC9D,GAAIA,EAAO,CAAC,EAAE,KAAK,SAAW,EAC5B,MAAM,IAAI,MAAM,+BAA+B,EAEjD,GAAIA,EAAO,CAAC,EAAE,KAAK,SAAWA,EAAO,CAAC,EAAE,KAAK,OAC3C,MAAM,IAAI,MAAM,mDAAmD,EAGrE,GAAIA,EAAO,CAAC,EAAE,KAAK,OAAS,IAAMA,EAAO,CAAC,EAAE,KAAKA,EAAO,CAAC,EAAE,KAAK,OAAS,CAAC,EACxE,MAAM,IAAI,MAAM,2CAA2CA,EAAO,CAAC,EAAE,KAAK,OAAS,CAAC,EAAE,EAGxF,GAAIA,EAAO,CAAC,EAAE,KAAK,CAAC,IAAMA,EAAO,CAAC,EAAE,KAAK,CAAC,EACxC,MAAM,IAAI,MAAM,6CAA6C,CAEjE,EAEMonC,GAAmB;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EAanBC,GAAwB7sC,GAA6B;AAAA,wCACnBA,CAAQ,yBAAyBA,CAAQ;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,kBAO/DA,CAAQ;AAAA;AAAA;AAAA,EAKpB8sC,GAAiBpsB,GAA4C;AAAA;AAAA,MAG7DA,EAAW,eAAiB,EACxB;AAAA;AAAA;AAAA,MAIA;AAAA;AAAA;AAAA,KAIN;AAAA;AAAA,EAIEqsB,GAAarsB,GAA4C;AAAA,IAE3DA,EAAW,cAAgB,aACvB;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,SA0BA,EACN;AAAA,EAGIssB,GAAc,CAACztB,EAAsBvf,EAAkB0gB,IAC3D;AAAA,qGACmG1gB,CAAQ;AAAA,mBAC1FA,CAAQ;AAAA;AAAA,eAEZwsC,EAAI;AAAA,eACJC,EAAI,gBAChB,IAAM,CACL,OAAQ/rB,EAAW,YAAa,CAC9B,IAAK,QACH,MAAO;AAAA;AAAA,sBAEOgsB,EAAI;AAAA,sBACJC,EAAI;AAAA;AAAA,UAGpB,IAAK,SACH,MAAO;AAAA,oBACKD,EAAI;AAAA,oBACJC,EAAI;AAAA,UAElB,IAAK,aACH,MAAO;AAAA,oBACKD,EAAI;AAAA,oBACJC,EAAI;AAAA,UAElB,QACE,MAAM,IAAI,MAAM,gBAAgBjsB,EAAW,WAAW,mBAAmB,CAC7E,CACF,GAAG,EACH;AAAA,aACWnB,EAAM,aAAa,SAAS,CAAC;AAAA;AAAA,EAIpC0tB,GAAe,CAACzwB,EAAuBxc,EAAkB0gB,KAC5D,IAAM,CACL,OAAQA,EAAW,KAAM,CACvB,IAAK,UACH,MAAO;AAAA,yFAC0E8rB,EAAI,cAAcC,EAAI;AAAA,UAEzG,IAAK,WACH,MAAO;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,gEAMiDD,EAAI,cAAcC,EAAI;AAAA,gEACtBD,EAAI,cAAcC,EAAI;AAAA,gEACtBD,EAAI,cAAcC,EAAI;AAAA,gEACtBD,EAAI,cAAcC,EAAI;AAAA;AAAA,sBAEhEzsC,CAAQ;AAAA,sBACRA,CAAQ;AAAA,sBACRA,CAAQ;AAAA,sBACRA,CAAQ;AAAA;AAAA,UAGxB,IAAK,UACH,MAAO;AAAA;AAAA;AAAA,0BAGWA,CAAQ;AAAA;AAAA;AAAA,4EAG0CwsC,EAAI,cAAcC,EAAI;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,UAQ5F,QACE,MAAM,IAAI,MAAM,QAAQ/rB,EAAW,IAAI,mBAAmB,CAC9D,CACF,GAAG,EAAI,GAAGlE,EAAO,YAAY,aAAc,QAAQ,CAAC,GAEhD0wB,GAA8B,CAAC1nC,EAA+Bkb,IAAiD,CACnH,IAAM1P,EAAIsJ,EAAc,IAAK9U,EAAO,CAAC,EAAE,SAAUA,EAAO,CAAC,EAAE,KAAK,MAAM,EAEhE8nC,EAAY,CAAC9nC,EAAO,CAAC,EAAE,KAAK,CAAC,EAAGA,EAAO,CAAC,EAAE,KAAK,CAAC,EAAGA,EAAO,CAAC,EAAE,KAAK,CAAC,CAAC,EACpE+nC,EAAOjzB,EAAc,OAAQ9U,EAAO,CAAC,EAAE,SAAU8nC,EAAU,OAAQ,CAAC,EACtEttB,EAAc,CAACxa,EAAO,CAAC,EAAE,KAAK,CAAC,EAAGA,EAAO,CAAC,EAAE,KAAK,CAAC,EAAGA,EAAO,CAAC,EAAE,KAAK,CAAC,EAAGA,EAAO,CAAC,EAAE,KAAK,CAAC,CAAC,EACzFkb,EAAW,SAAW,SACxBV,EAAc,CAACxa,EAAO,CAAC,EAAE,KAAK,CAAC,EAAGA,EAAO,CAAC,EAAE,KAAK,CAAC,EAAGA,EAAO,CAAC,EAAE,KAAK,CAAC,EAAGA,EAAO,CAAC,EAAE,KAAK,CAAC,CAAC,EACzF,CAACgnC,GAAMC,GAAMC,GAAMC,EAAI,EAAI,CAAC,EAAG,EAAG,EAAG,CAAC,GAExC,IAAMnwB,EAASjC,EAAe,SAAU/U,EAAO,CAAC,EAAE,SAAUwa,EAAY,MAAM,EACxEhgB,EAAWgR,EAAE,KAAK,MAClBsP,EAAapR,EAAU,KAAK8Q,CAAW,EAEvClF,EAAoC,CACxC,CAAE,QAAuB,KAAMwF,CAAW,EAC1C,GAAGvG,EAA2BvU,EAAO,CAAC,EAAE,KAAM8nC,EAAWttB,CAAW,CACtE,EAEMI,EAAmBC,GAA+B;AAAA,IACtDA,EAAa,gBAAgB,cAAe,KAAK,EAAE,iBAAiBrP,EAAGu8B,EAAM/wB,CAAM,CAAC;AAAA,IACpFowB,EAAgB;AAAA,IAChBC,GAAqB7sC,CAAQ,CAAC;AAAA,IAC9B8sC,GAAcpsB,CAAU,CAAC;AAAA,IACzBqsB,GAAUrsB,CAAU,CAAC;AAAA,IACrBssB,GAAYh8B,EAAGhR,EAAU0gB,CAAU,CAAC;AAAA;AAAA,IAEpCL,EAAa,UAAU,CAAC;AAAA,MACtBA,EAAa,sCAAsC,sBAAsB,CAAC;AAAA,wCACxCqsB,EAAI;AAAA,wCACJC,EAAI;AAAA;AAAA,QAGpCjsB,EAAW,eAAiB,EACxB;AAAA;AAAA;AAAA;AAAA;AAAA,QAMA;AAAA;AAAA;AAAA;AAAA;AAAA,OAMN;AAAA;AAAA;AAAA,sBAGgBlE,EAAO,gBAAgB,YAAY,CAAC;AAAA,6CACbgwB,EAAI,cAAcE,EAAI,cAAcC,EAAI;AAAA,kBACnEY,EAAK,aAAa,cAAc,CAAC;AAAA;AAAA;AAAA;AAAA,QAI3CN,GAAazwB,EAAQxc,EAAU0gB,CAAU,CAAC;AAAA,KAGhD,MAAO,CACL,KAAM,aACN,YAAa,CAAE,KAAM,GAAGA,EAAW,QAAQ,GAAI,kBAAmB,CAAC,OAAQ,MAAM,CAAE,EACnF,WAAalb,GAAW,CACtB,IAAM8a,EAAapR,EAAU,KAAK8Q,CAAW,EAC7C,MAAO,CACL,QAAS,CAAC,CAAE,KAAMA,EAAa,SAAUxa,EAAO,CAAC,EAAE,QAAS,CAAC,EAC7D,cAAe,CAAE,EAAG,KAAK,KAAK8a,EAAa,EAAuB,CAAE,EACpE,gBAAAxF,CACF,CACF,EACA,gBAAAsF,CACF,CACF,EAEa+sB,GAAa,CAAC3tC,EAAyBkhB,IAA0C,CAC5F9B,GAAepf,EAAQ,MAAM,EAC7BA,EAAQ,QAAQ0tC,GAA4B1tC,EAAQ,OAAQkhB,CAAU,CAAC,CACzE,EAEa0sB,GAA6B1sB,GACxClH,EAA4B,CAC1B,aAAckH,EAAW,cACzB,KAAMA,EAAW,KACjB,YAAaA,EAAW,aACxB,OAAQA,EAAW,MACrB,CAAC,ICtRH,IAmBM8sB,GAGA5uB,GAoPO6uB,GAGPhO,GAEAiO,GAoDOC,GAiDAC,GApXbC,GAAAtzC,EAAA,kBAGAkS,IAEA8C,IACAkK,KACA3C,KAEAwP,KAOA1L,IACAyE,KAEMmuB,GAAW,CAAChoC,EAA+B5K,IAC/C4K,EAAO,OAAS5K,GAAK4K,EAAO5K,CAAC,EAAE,KAAK,OAAS,EAAI4K,EAAO5K,CAAC,EAAI,OAEzDgkB,GAAiB,CAACpZ,EAA+Bkb,IAAoD,CACzG,IAAMotB,EAAQtoC,EAAO,CAAC,EAChBtC,EAAMsqC,GAAShoC,EAAQ,CAAC,EACxBtJ,EAAQsxC,GAAShoC,EAAQ,CAAC,EAC1BghB,EAAOgnB,GAAShoC,EAAQ,CAAC,EACzBuoC,EAAiBP,GAAShoC,EAAQ,CAAC,EACnCmhB,EAAgB6mB,GAAShoC,EAAQ,CAAC,EAClCkjB,EAAU8kB,GAAShoC,EAAQ,CAAC,EAC5BskB,EAAY0jB,GAAShoC,EAAQ,CAAC,EA6CpC,GAAIsoC,EAAM,KAAK,SAAW,GAAKA,EAAM,KAAK,SAAW,EACnD,MAAM,IAAI,MAAM,mDAAmD,EAGrE,IAAMlnB,EAAYknB,EAAM,KAAK,CAAC,EACxBjnB,EAAiBinB,EAAM,KAAK,CAAC,EAC7BE,EAAaF,EAAM,KAAK,SAAW,EAAIA,EAAM,KAAK,CAAC,EAAIptB,EAAW,SAAWotB,EAAM,KAAK,CAAC,EAC3F3mB,EAAmBN,EAEnBO,EAAqB,EACrBE,EAAoB,EAClB2mB,EAAW,KAAK,MAAMD,EAAattB,EAAW,QAAQ,EAC5D,GAAIgI,GAAWoB,GAAa5a,EAAU,KAAKwZ,EAAQ,IAAI,GAAKxZ,EAAU,KAAK4a,EAAU,IAAI,EAAG,CAC1F,GAAIpB,EAAQ,KAAK,SAAW,EAC1B,MAAM,IAAI,MAAM,mDAAmD,EAErE,GAAIA,EAAQ,KAAK,CAAC,IAAM9B,GAAa8B,EAAQ,KAAK,CAAC,IAAMhI,EAAW,UAAYgI,EAAQ,KAAK,CAAC,IAAMulB,EAClG,MAAM,IAAI,MAAM,iFAAiF,EAEnG,GACEnkB,EAAU,KAAK,CAAC,IAAMlD,GACtBkD,EAAU,KAAK,CAAC,IAAMpJ,EAAW,UACjCoJ,EAAU,KAAK,CAAC,IAAMmkB,EAEtB,MAAM,IAAI,MAAM,mFAAmF,EAErG,GAAIvlB,EAAQ,KAAK,CAAC,IAAMoB,EAAU,KAAK,CAAC,EACtC,MAAM,IAAI,MAAM,gFAAgF,EAElG,GAAIA,EAAU,KAAK,SAAW,EAC5B,MAAM,IAAI,MAAM,qDAAqD,EAEvE1C,EAAqBsB,EAAQ,KAAK,CAAC,EACnCpB,EAAoBoB,EAAQ,KAAK,CAAC,CACpC,SAAYA,GAAWxZ,EAAU,KAAKwZ,EAAQ,IAAI,GAAOoB,GAAa5a,EAAU,KAAK4a,EAAU,IAAI,EACjG,MAAM,IAAI,MAAM,wEAAwE,EAG1F,IAAIokB,EACJ,GAAIhrC,GAAOgM,EAAU,KAAKhM,EAAI,IAAI,EAAI,EAAG,CACvC,GAAI4qC,EAAM,KAAK,SAAW,EACxB,MAAM,IAAI,MAAM,kEAAkE,EAEpF,GAAI5qC,EAAI,KAAK,OAAS,GAAKA,EAAI,KAAK,OAAS,EAC3C,MAAM,IAAI,MAAM,uDAAuD,EAEzE,GAAI4qC,EAAM,KAAK,CAAC,IAAM5qC,EAAI,KAAK,CAAC,EAC9B,MAAM,IAAI,MAAM,4DAA4D,EAG9E,GAAIA,EAAI,KAAK,SAAW,EAAG,CACzB,GAAIA,EAAI,KAAK,CAAC,IAAM4qC,EAAM,KAAK,CAAC,EAC9B,MAAM,IAAI,MAAM,6DAA6D,EAE/EI,EAAY,EACZ/mB,EAAmBjkB,EAAI,KAAK,CAAC,CAC/B,SAAWA,EAAI,KAAK,SAAW,EAAG,CAChC,GAAIA,EAAI,KAAK,CAAC,IAAMwd,EAAW,UAAYxd,EAAI,KAAK,CAAC,IAAM,GAAKA,EAAI,KAAK,CAAC,IAAM+qC,EAC9E,MAAM,IAAI,MAAM,4FAA4F,EAE9G,GAAI/xC,EACF,MAAM,IAAI,MAAM,yDAAyD,EAE3EgyC,EAAY,EACZ/mB,EAAmBjkB,EAAI,KAAK,CAAC,CAC/B,KAAO,CAEL,GAAIA,EAAI,KAAK,CAAC,IAAMwd,EAAW,UAAYxd,EAAI,KAAK,CAAC,IAAM+qC,EACzD,MAAM,IAAI,MAAM,wFAAwF,EAG1GC,EAAY,EACZ/mB,EAAmBjkB,EAAI,KAAK,CAAC,CAC/B,CACF,KAAO,CAEL,GAAI4qC,EAAM,KAAK,SAAW,EACxB,MAAM,IAAI,MAAM,kEAAkE,EAEpF,GAAIA,EAAM,KAAK,CAAC,IAAMptB,EAAW,UAAYotB,EAAM,KAAK,CAAC,IAAM,EAC7D,MAAM,IAAI,MAAM,8FAA8F,EAGhHI,EAAY,CACd,CAEA,GAAI1nB,GAAQtX,EAAU,KAAKsX,EAAK,IAAI,EAAI,EAAG,CACzC,GAAIA,EAAK,KAAK,SAAW,EACvB,MAAM,IAAI,MAAM,8CAA8C,EAGhE,GAAItjB,GACEA,EAAI,KAAK,SAAW,GAAKA,EAAI,KAAK,CAAC,IAAM,EAC3C,MAAM,IAAI,MAAM,oCAAoC,CAG1D,CAEA,IAAMmkB,EAAsBD,EAAqBD,EAE7CI,IACJ,GAAIwmB,GAAkB7+B,EAAU,KAAK6+B,EAAe,IAAI,EAAI,EAAG,CAC7DxmB,EAAW,EACX,IAAM4mB,EAAWJ,EAAe,KAUhC,MATII,EAAS,SAAW,EAClBA,EAAS,CAAC,IAAMvnB,EAClBW,EAAW,EACF4mB,EAAS,CAAC,IAAM,EAAIvnB,EAAY,IACzCW,EAAW,GAEJ4mB,EAAS,SAAW,GAAKA,EAAS,CAAC,IAAMvnB,GAAaunB,EAAS,CAAC,IAAM9mB,IAC/EE,EAAW,GAETA,IAAa,EACT,IAAI,MAAM,6FAA6F,EAEzG,IAAI,MAAM,oBAAoB,CACtC,CAEA,IAAI6mB,EAAe,GACfnnB,EAAc+mB,EAClB,GAAI9xC,GAASgT,EAAU,KAAKhT,EAAM,IAAI,EAAI,EAAG,CAC3C,GAAIA,EAAM,KAAK,SAAW,GAAKA,EAAM,KAAK,SAAW,EACnD,MAAM,IAAI,MAAM,qDAAqD,EAGvE,GAAI4xC,EAAM,KAAK,CAAC,IAAM5xC,EAAM,KAAK,CAAC,EAChC,MAAM,IAAI,MAAM,8DAA8D,EAGhF,GAAIA,EAAM,KAAK,SAAW,EAAG,CAC3B,GAAIirB,IAAqBjrB,EAAM,KAAK,CAAC,EACnC,MAAM,IAAI,MAAM,wEAAwE,EAE1F+qB,EAAc/qB,EAAM,KAAK,CAAC,CAC5B,KAAO,CAEL,GAAIirB,IAAqBjrB,EAAM,KAAK,CAAC,EACnC,MAAM,IAAI,MAAM,wEAAwE,EAE1F+qB,EAAc/qB,EAAM,KAAK,CAAC,EAAIA,EAAM,KAAK,CAAC,EAC1CkyC,EAAe,EACjB,CACF,CAEA,IAAMC,EAAsB,GAE5B,GAAIN,GAAkB7+B,EAAU,KAAK6+B,EAAe,IAAI,EAAI,EAC1D,MAAM,IAAI,MAAM,mCAAmC,EAGrD,GAAIpnB,GAAiBzX,EAAU,KAAKyX,EAAc,IAAI,EAAI,EAAG,CAC3D,GAAIA,EAAc,KAAK,SAAW,EAChC,MAAM,IAAI,MAAM,yDAAyD,EAI3E,GACEA,EAAc,KAAK,CAAC,IAAMC,GAC1BD,EAAc,KAAK,CAAC,IAAMjG,EAAW,UACrCiG,EAAc,KAAK,CAAC,IAAME,GAC1BF,EAAc,KAAK,CAAC,IAAMU,EAE1B,MAAM,IAAI,MAAM,+FAA+F,CAEnH,CAEA,MAAO,CACL,UAAAT,EACA,eAAAC,EACA,mBAAAO,EACA,iBAAAD,EACA,oBAAAE,EACA,kBAAAC,EACA,gBAAiB,EACjB,WAAA0mB,EACA,YAAA/mB,EACA,SAAAgnB,EACA,UAAW,KAAK,MAAMhnB,EAAcvG,EAAW,QAAQ,EACvD,SAAUA,EAAW,SACrB,iBAAkB,GAClB,uBAAwB,GACxB,gBAAiBA,EAAW,gBAC5B,SAAA6G,EACA,MAAO7G,EAAW,MAClB,oBAAA2tB,EACA,aAAAD,EACA,UAAAF,CACF,CACF,EAEaT,GAAqC/sB,GAChDlH,EAA4B,CAAE,GAAGkH,CAAW,CAAC,EAEzC+e,GAAgDjmB,EAA4B,CAAE,KAAM,CAAC,EAAG,EAAG,EAAG,CAAC,CAAE,CAAC,EAElGk0B,GAAmB,CACvBluC,EACA8uC,EACA9nB,EACAI,EACAC,EACAmnB,EACAO,IACG,CACH,IAAMvuB,EAAc,CAAC4G,EAAWC,EAAgBmnB,CAAU,EACpD1tB,EAAapR,EAAU,KAAK8Q,CAAW,EACvClF,EAAoC,CACxC,CAAE,QAAuB,KAAMwF,CAAW,EAC1C,CAAE,QAAuB,KAAMiuB,CAAW,EAC1C,CAAE,QAAuB,KAAMP,CAAW,CAC5C,EAEM5tB,EAAmBC,GAA+B,CACtD,IAAM7D,EAASjC,EAAe,gBAAiB+zB,EAAI,SAAUtuB,CAAW,EAClEwuB,EAAWl0B,EAAc,MAAOg0B,EAAI,SAAUtuB,CAAW,EACzDyuB,EAAYn0B,EAAc,OAAQkM,EAAK,SAAUxG,CAAW,EAE5DuI,EAA8B,CAClC,CAAE,KAAM,cAAe,KAAM,KAAM,EACnC,CAAE,KAAM,cAAe,KAAM,KAAM,EACnC,CAAE,KAAM,cAAe,KAAM,KAAM,CACrC,EACA,MAAO;AAAA,IACPlI,EAAa,iBAAiBkI,CAAQ,EAAE,iBAAiBimB,EAAUC,EAAWjyB,CAAM,CAAC;AAAA,IACrF6D,EAAa,UAAU,CAAC;AAAA,MACtBA,EAAa,sCAAsC,sBAAsB,CAAC;AAAA;AAAA;AAAA;AAAA,IAK9E,EAEA,OAAO7gB,EAAQ,QACb,CACE,KAAM,4BACN,YAAa,CAAE,kBAAmB,CAAC,OAAQ,MAAM,CAAE,EACnD,WAAY,KAAO,CACjB,QAAS,CAAC,CAAE,KAAMwgB,EAAa,SAAUsuB,EAAI,SAAU,aAAiC,CAAC,EACzF,cAAe,CAAE,EAAG,KAAK,KAAKhuB,EAAa,EAAuB,CAAE,EACpE,gBAAAxF,CACF,GACA,gBAAAsF,CACF,EACA,CAAE,OAAQ,CAACkuB,EAAK9nB,CAAI,EAAG,QAAS,CAAC,EAAE,CAAE,CACvC,EAAE,CAAC,CACL,EAEamnB,GAAiC,CAC5CnuC,EACAonB,EACAe,EACAd,EACAonB,EACA1uB,EACAiH,EACA+nB,IACG,CAGH,IAAIvJ,EAAgBzlB,EACpB,GAAMiH,GAAQtX,EAAU,KAAKsX,EAAK,IAAI,EAAI,EAWnC,CACL,GAAIK,IAAmB,EACrB,MAAM,IAAI,MAAM,mFAAmF,EAYnG,OAVAme,EAAgB0I,GACdluC,EACA+f,EACAiH,EACAI,EACAC,EACAc,EAAWsmB,EACXM,CACF,EACAvJ,EAAgBA,EAAc,QAAQ,CAACpe,EAAWC,EAAgBc,EAAUsmB,CAAQ,CAAC,EACjFtmB,IAAa,GAAKd,IAAmB,EAChCme,EAEFxlC,EAAQ,QAAQ0f,GAA2B8lB,EAAevF,GAAyB,IAAI,EAAG,CAC/F,OAAQ,CAACuF,CAAa,EACtB,QAAS,CAAC,EAAE,CACd,CAAC,EAAE,CAAC,CAER,KA7BE,QAHIzlB,EAAM,KAAK,SAAW,IACxBylB,EAAgBzlB,EAAM,QAAQ,CAACqH,EAAWC,EAAgBc,EAAUsmB,CAAQ,CAAC,GAE3EtmB,IAAa,GAAKd,IAAmB,EAChCme,EAEFxlC,EAAQ,QAAQ0f,GAA2B8lB,EAAevF,GAAyB,IAAI,EAAG,CAC/F,OAAQ,CAACuF,CAAa,EACtB,QAAS,CAAC,EAAE,CACd,CAAC,EAAE,CAAC,CAwBR,EAEa4I,GAAqB,CAACpuC,EAAyBkhB,IAAqC,CAC/F,IAAMqJ,EAASnL,GAAepf,EAAQ,OAAQkhB,CAAU,EAClDotB,EAAQtuC,EAAQ,OAAO,CAAC,EACxB0D,EAAMsqC,GAAShuC,EAAQ,OAAQ,CAAC,EAChCtD,EAAQsxC,GAAShuC,EAAQ,OAAQ,CAAC,EAClCgnB,EAAOgnB,GAAShuC,EAAQ,OAAQ,CAAC,EACjCuuC,EAAiBP,GAAShuC,EAAQ,OAAQ,CAAC,EAC3CmnB,EAAgB6mB,GAAShuC,EAAQ,OAAQ,CAAC,EAC1CkpB,EAAU8kB,GAAShuC,EAAQ,OAAQ,CAAC,EACpCsqB,EAAY0jB,GAAShuC,EAAQ,OAAQ,CAAC,EAC5C,GAAIsuC,EAAM,KAAK,SAAW,EACxB,MAAM,IAAI,MAAM,+BAA+B,EAGjD,GAAI5qC,GAAK,KAAK,SAAW,EACvB,MAAM,IAAI,MAAM,8BAA8B,EAIhD,IAAMwrC,EAASxrC,GAAOhH,GAASgH,EAAI,KAAK,SAAW,GAAKhH,EAAM,KAAK,SAAW,EAExEyyC,EAAIhB,GACRnuC,EACAuqB,EAAO,UACPA,EAAO,SACPA,EAAO,eACPA,EAAO,SACP+jB,EACAtnB,EACA,CACF,EAEA,GAAIkoB,EACF,OAAOvoB,GAAe3mB,EAASmvC,EAAGzrC,EAAKhH,EAAO6xC,EAAgB,OAAWrlB,EAASoB,EAAWnD,EAAeoD,CAAM,EAEpH,GAAI,CAAC7mB,GAAO,CAAChH,EACX,MAAM,IAAI,MAAM,gCAAgC,EAElD,IAAM0W,EAAI+6B,GACRnuC,EACAuqB,EAAO,UACPA,EAAO,SACPA,EAAO,iBACPA,EAAO,SACP7mB,EACAsjB,EACAuD,EAAO,UACT,EAEM6kB,EAAIjB,GACRnuC,EACAuqB,EAAO,UACPA,EAAO,SACPA,EAAO,iBACPA,EAAO,UACP7tB,EACAsqB,EACA,EAAIuD,EAAO,UACb,EAEA5D,GAAe3mB,EAASmvC,EAAG/7B,EAAGg8B,EAAGb,EAAgB,OAAWrlB,EAASoB,EAAWnD,EAAeoD,CAAM,CACvG,ICjbA,IAwBMnL,GAMAiwB,GAaAC,GASAC,GAqBOC,GAyDAC,GAOAC,GAzIbC,GAAA50C,EAAA,kBAGAkS,IAEA8C,IACAkK,KAGAmB,IAeMgE,GAAkBpZ,GAAwC,CAC9D,GAAI,CAACA,GAAUA,EAAO,OAAS,EAC7B,MAAM,IAAI,MAAM,gBAAgB,CAEpC,EAEMqpC,GAAkC,CACtCrpC,EACAkb,IACoB,CACpB,IAAM0uB,EAAuB,CAAC,EAC1BC,EAAqB3uB,EAAW,WACpC,OAAIlb,EAAO,CAAC,EAAE,KAAK,CAAC,EAAI,IACtBA,EAAO,CAAC,EAAE,iBAAiB,EAAE,QAASzC,GAAMqsC,EAAW,KAAK,OAAOrsC,CAAC,CAAC,CAAC,EACtEssC,EAAaD,EAAW,QAEnB51B,EAA4B,CAAE,WAAA61B,EAAY,KAAM3uB,EAAW,KAAM,WAAA0uB,CAAW,CAAC,CACtF,EAEMN,GAA4Blb,GAAoC;AAAA;AAAA,gCAEtCA,CAAe;AAAA,kBAC7BxZ,EAAa,8BAA+B,IAAKwZ,CAAe,CAAC;AAAA;AAAA;AAAA;AAAA,aAItEA,CAAe;AAAA,GAEtBmb,GAAuBppC,GAAsC,CACjE,IAAMiuB,EAAkBjuB,EAAQ,OAC1BmuB,EAAsB,CAAC,EAC7B,QAASl5B,EAAI,EAAGA,EAAIg5B,EAAiB,EAAEh5B,EAAG,CACxC,IAAMm5B,EAAgBpuB,EAAQ/K,CAAC,EAAE,aAAa,UAAW,mBAAmB,EACxEg5B,IAAoB,EACtBE,EAAU,KAAKC,CAAa,EACnBn5B,IAAM,EACfk5B,EAAU,KAAK,wBAAwBl5B,CAAC,QAAQm5B,CAAa,IAAI,EACxDn5B,IAAMg5B,EAAkB,EACjCE,EAAU,KAAK,UAAUC,CAAa,IAAI,EAE1CD,EAAU,KAAK,6BAA6Bl5B,CAAC,OAAOm5B,CAAa,IAAI,CAEzE,CACA,MAAO;AAAA,wDAC+CpuB,EAAQ,CAAC,EAAE,KAAK,OAAO;AAAA,UACrEmuB,EAAU,KAAK;AAAA,CAAI,CAAC;AAAA,QAE9B,EAEakb,GAAyB,CAACxpC,EAA+Bkb,IAA6C,CACjH,IAAMpB,EAAa9Z,EAAO,CAAC,EAAE,KACvB8pC,EAAYpgC,EAAU,KAAKoQ,CAAU,EACrCtf,EAAWwF,EAAO,CAAC,EAAE,SACrBkL,EAAOxB,EAAU,cAAcwR,EAAW,KAAMpB,EAAW,MAAM,EACjE3Z,EAAU,IAAI,MAAqB+a,EAAW,UAAU,EACxDnB,EAAQjF,EAAc,QAASta,EAAUsf,EAAW,MAAM,EAC1DiwB,EAAkB,IAAI,MAAc7uB,EAAW,UAAU,EACzD8uB,EAAkC,CAAC,EACnCC,EAA2B,CAAC,EAC9Bvb,EAAc,EACZpZ,EAAoC,CAAC,CAAE,QAAuB,KAAMw0B,CAAU,CAAC,EACrF,QAAS10C,EAAI,EAAGA,EAAI8lB,EAAW,WAAY9lB,IAAK,CAC9Cs5B,GAAexT,EAAW,WAAW9lB,CAAC,EACtC20C,EAAgB30C,CAAC,EAAIs5B,EACrB,IAAMlU,EAAcV,EAAW,MAAM,EACrCU,EAAYtP,CAAI,EAAIgQ,EAAW,WAAW9lB,CAAC,EAC3C60C,EAAa,KAAKzvB,CAAW,EAC7Bra,EAAQ/K,CAAC,EAAI2f,EAAe,SAAS3f,CAAC,GAAIoF,EAAUggB,EAAY,MAAM,EACtEwvB,EAAkB,KAAK,CAAE,KAAMC,EAAa70C,CAAC,EAAG,SAAU4K,EAAO,CAAC,EAAE,QAAS,CAAC,CAChF,CACAsV,EAAgB,KACd,CAAE,QAAuB,KAAMy0B,CAAgB,EAC/C,GAAGx1B,EAA2BuF,EAAY,GAAGmwB,CAAY,CAC3D,EACA,IAAMrvB,EAAmBC,GAA+B;AAAA,IACtDA,EACC,gBAAgB,aAAc,KAAK,EACnC,gBAAgB,qBAAsB,MAAOkvB,EAAgB,MAAM,EACnE,iBAAiBhwB,EAAO,GAAG5Z,CAAO,CAAC;AAAA,IACpCmpC,GAAyBS,EAAgB,MAAM,CAAC;AAAA,IAChDR,GAAoBppC,CAAO,CAAC;AAAA;AAAA,IAE5B0a,EAAa,UAAU,CAAC;AAAA,MACtBA,EAAa,sCAAsC,qBAAqB,CAAC;AAAA;AAAA,oBAE3Dd,EAAM,gBAAgB,YAAY,CAAC;AAAA,kBACrCA,EAAM,WAAW,UAAW7O,CAAI,CAAC;AAAA;AAAA;AAAA,iBAGlC0J,EAAa,8BAA+B,qBAAsBm1B,EAAgB,MAAM,CAAC;AAAA,QAClGhwB,EAAM,WAAW,UAAW7O,EAAM,OAAO,CAAC;AAAA;AAAA;AAAA,KAIhD,MAAO,CACL,KAAM,QACN,YAAa,CAAE,KAAMgQ,EAAW,SAAU,kBAAmB,CAAC,MAAM,CAAE,EACtE,gBAAAN,EACA,WAAY,KAAO,CACjB,QAASovB,EACT,cAAe,CAAE,EAAG,KAAK,KAAKF,EAAY,EAAuB,CAAE,EACnE,gBAAAx0B,CACF,EACF,CACF,EAEam0B,GAAQ,CAACzvC,EAAyBkhB,IAAsC,CACnF9B,GAAepf,EAAQ,MAAM,EAC7B,IAAMojB,EACJpjB,EAAQ,OAAO,SAAW,EAAIkhB,EAAamuB,GAAgCrvC,EAAQ,OAAQkhB,CAAU,EACvGlhB,EAAQ,QAAQwvC,GAAuBxvC,EAAQ,OAAQojB,CAAiB,EAAG,CAAE,OAAQ,CAAC,CAAC,CAAE,CAAC,CAC5F,EAEassB,GAAwBxuB,GAAyD,CAC5F,IAAMhQ,EAAOgQ,EAAW,KAClB0uB,EAAuB1uB,EAAW,WAClC2uB,EAAc3uB,EAAW,WAAwB,EAAI0uB,EAAW,OAAU1uB,EAAW,WAC3F,GAAI2uB,IAAeD,EAAW,OAC5B,MAAM,IAAI,MAAM,+CAA+C,EAEjE,OAAO51B,EAA4B,CAAE,KAAA9I,EAAM,WAAA2+B,EAAY,WAAAD,CAAW,CAAC,CACrE,ICjJA,IAsBaxwB,GA0MP6gB,GAEAiQ,GAcOC,GAhPbC,GAAAr1C,EAAA,kBAIAkf,KAGA6M,KACAunB,KACAsB,KACA9vB,KAYaT,GAAiB,CAC5BpZ,EACAkb,IACwB,CACxB,GAAIA,EAAW,SACb,MAAM,IAAI,MAAM,2DAA2D,EAE7E,GAAIA,EAAW,UAAYlb,EAAO,QAAU,EAC1C,MAAM,IAAI,MAAM,uEAAuE,EAEzF,IAAMsoC,EAAQtoC,EAAO,CAAC,EAChBtC,EAAMsC,EAAO,CAAC,EACdtJ,EAAQsJ,EAAO,CAAC,EAChBkjB,EAAUljB,EAAO,CAAC,EAClBskB,EAAYtkB,EAAO,CAAC,EAC1B,GAAIkb,EAAW,kBAAoB,GACjC,MAAM,IAAI,MAAM,kCAAkC,EAEpD,GAAIA,EAAW,UAAY,EACzB,MAAM,IAAI,MAAM,0BAA0B,EAE5C,GAAIA,EAAW,oBAAsB,EACnC,MAAM,IAAI,MAAM,qCAAqC,EAEvD,GAAIA,EAAW,cACb,MAAM,IAAI,MAAM,iCAAiC,EA+BnD,GAAIotB,EAAM,KAAK,SAAW,GAAKA,EAAM,KAAK,SAAW,EACnD,MAAM,IAAI,MAAM,mDAAmD,EAGrE,IAAM+B,EAAe,GACfjpB,EAAYknB,EAAM,KAAK,CAAC,EACxBjnB,EAAiBinB,EAAM,KAAK,CAAC,EAC/BE,EACFF,EAAM,KAAK,SAAW,EAAK+B,EAAe/B,EAAM,KAAK,CAAC,EAAI,EAAIA,EAAM,KAAK,CAAC,EAAKptB,EAAW,SAAWotB,EAAM,KAAK,CAAC,EAC/G3mB,EAAmBN,EAEnBO,EAAqB,EACnB0oB,EAAY,CAAC5sC,GAAOA,EAAI,KAAK,SAAW,EACxC+qC,EAEF,KAAK,MAFS6B,EAEH9B,GAActtB,EAAW,SAAW,EAAIA,EAAW,YADnDstB,EAAattB,EAAW,QACsC,EACzEovB,IACF9B,EAAaC,EAAWvtB,EAAW,UAErC,IAAMqvB,EAAarnB,GAAWA,EAAQ,KAAK,SAAW,EAChDsnB,EAAelmB,GAAaA,EAAU,KAAK,SAAW,EAU5D,GAPEimB,GACArnB,EAAQ,KAAK,SAAW,GACxBA,EAAQ,KAAK,CAAC,IAAM9B,GACpB8B,EAAQ,KAAK,CAAC,IAAMhI,EAAW,YAC/BgI,EAAQ,KAAK,CAAC,IAAMhI,EAAW,YAC/BgI,EAAQ,KAAK,CAAC,IAAMulB,EAGpB,MAAM,IAAI,MAAM,yCAAyC,EAE3D,GAAI8B,GAAcC,EAAc,CAC9B,GAAItnB,EAAQ,KAAK,SAAW,EAC1B,MAAM,IAAI,MAAM,mDAAmD,EAErE,GAAIoB,EAAU,KAAK,SAAW,EAC5B,MAAM,IAAI,MAAM,qDAAqD,EAEvE1C,EAAqBsB,EAAQ,KAAK,CAAC,CACrC,SAAWqnB,GAAcC,EACvB,MAAM,IAAI,MAAM,wEAAwE,EAG1F,IAAI9B,IACJ,GAAIhrC,GAAOA,EAAI,KAAK,OAAS,EAAG,CAC9B,GAAI4qC,EAAM,KAAK,SAAW,EACxB,MAAM,IAAI,MAAM,kEAAkE,EAEpF,GAAI5qC,EAAI,KAAK,OAAS,GAAKA,EAAI,KAAK,OAAS,EAC3C,MAAM,IAAI,MAAM,uDAAuD,EAEzE,GAAI4qC,EAAM,KAAK,CAAC,IAAM5qC,EAAI,KAAK,CAAC,EAC9B,MAAM,IAAI,MAAM,4DAA4D,EAG9E,GAAIA,EAAI,KAAK,SAAW,EAAG,CACzB,GAAI4qC,EAAM,KAAK,CAAC,EAAI5qC,EAAI,KAAK,CAAC,IAAM,EAClC,MAAM,IAAI,MAAM,sDAAsD,EAExEikB,EAAmBjkB,EAAI,KAAK,CAAC,CAC/B,SAAWA,EAAI,KAAK,SAAW,EAAG,CAChC,GAAIA,EAAI,KAAK,CAAC,IAAMwd,EAAW,UAAYxd,EAAI,KAAK,CAAC,IAAM,GAAKA,EAAI,KAAK,CAAC,IAAM+qC,EAC9E,MAAM,IAAI,MAAM,4FAA4F,EAE9G,GAAI/xC,EACF,MAAM,IAAI,MAAM,yDAAyD,EAE3EirB,EAAmBjkB,EAAI,KAAK,CAAC,CAC/B,KAAO,CAEL,GAAIA,EAAI,KAAK,CAAC,IAAMwd,EAAW,UAAYxd,EAAI,KAAK,CAAC,IAAM+qC,EACzD,MAAM,IAAI,MAAM,wFAAwF,EAE1G9mB,EAAmBjkB,EAAI,KAAK,CAAC,CAC/B,CACF,KAAO,CAEL,GAAI4qC,EAAM,KAAK,SAAW,GAAKA,EAAM,KAAK,SAAW,EACnD,MAAM,IAAI,MAAM,uEAAuE,EAEzF,GAAIA,EAAM,KAAK,SAAW,IAAMA,EAAM,KAAK,CAAC,IAAMptB,EAAW,UAAYotB,EAAM,KAAK,CAAC,IAAM,GACzF,MAAM,IAAI,MAAM,8FAA8F,EAGhHI,EAAY,CACd,CAEA,IAAM3mB,IACF6mB,EAAe,GACfnnB,EAAcvG,EAAW,WAAautB,EAAWvtB,EAAW,WAAastB,EAC7E,GAAI9xC,GAASA,EAAM,KAAK,OAAS,EAAG,CAClC,GAAIA,EAAM,KAAK,SAAW,GAAKA,EAAM,KAAK,SAAW,EACnD,MAAM,IAAI,MAAM,qDAAqD,EAGvE,GAAI4xC,EAAM,KAAK,CAAC,IAAM5xC,EAAM,KAAK,CAAC,EAChC,MAAM,IAAI,MAAM,8DAA8D,EAGhF,GAAIA,EAAM,KAAK,SAAW,EAAG,CAC3B,GAAIirB,IAAqBjrB,EAAM,KAAK,CAAC,EACnC,MAAM,IAAI,MAAM,wEAAwE,EAE1F+qB,EAAc/qB,EAAM,KAAK,CAAC,CAC5B,KAAO,CACL,GAAIirB,IAAqBjrB,EAAM,KAAK,CAAC,EACnC,MAAM,IAAI,MAAM,kFAAkF,EAEpG+qB,EAAc/qB,EAAM,KAAK,CAAC,EAAIA,EAAM,KAAK,CAAC,EAC1CkyC,EAAe,EACjB,CACF,CACA,IAAM6B,EAAWzqC,EAAO,OAAS,EAAIA,EAAO,CAAC,EAAI,OACjD,GAAIyqC,GAAYA,EAAS,KAAK,SAAW,GAAKA,EAAS,KAAK,CAAC,IAAMrpB,EACjE,MAAM,IAAI,MAAM,kFAAkF,EAMpG,MAAO,CACL,UAAAA,EACA,eAAAC,EACA,mBAAAO,EACA,iBAAAD,EACA,oBAT0B,GAU1B,kBATwB,GAUxB,gBAAiB,EACjB,WAAA6mB,EACA,YAAA/mB,EACA,SAAAgnB,EACA,UAAW,KAAK,MAAMhnB,EAAcvG,EAAW,UAAU,EACzD,SAAUA,EAAW,SACrB,WAAYA,EAAW,WACvB,MAAOA,EAAW,SAAWA,EAAW,WACxC,uBAAwB,GACxB,SAAA6G,EACA,MAAO7G,EAAW,MAClB,oBApB0B,GAqB1B,aAAA0tB,EACA,UAAAF,CACF,CACF,EAEMzO,GAAgDjmB,EAA4B,CAAE,KAAM,CAAC,EAAG,EAAG,EAAG,CAAC,CAAE,CAAC,EAElGk2B,GAAuB,CAAClwC,EAAyB+f,EAAmBwK,IAAgC,CACxG,IAAIib,EAAgBzlB,EACdoI,EAAWoC,EAAO,WACxB,OAAIxK,EAAM,KAAK,SAAW,GAAKwK,EAAO,mBAAqB,IACzDib,EAAgBzlB,EAAM,QAAQ,CAACwK,EAAO,UAAWA,EAAO,iBAAkBpC,EAAUoC,EAAO,QAAQ,CAAC,EACpGib,EAAgBxlC,EAAQ,QAAQ0f,GAA2B8lB,EAAevF,GAAyB,IAAI,EAAG,CACxG,OAAQ,CAACuF,CAAa,EACtB,QAAS,CAAC,EAAE,CACd,CAAC,EAAE,CAAC,GAGCA,CACT,EAEa2K,GAAsB,CAACnwC,EAAyBkhB,IAAoD,CAC/G,IAAMqJ,EAASnL,GAAepf,EAAQ,OAAQkhB,CAAU,EACxD,GAAIlhB,EAAQ,OAAO,CAAC,EAAE,KAAK,SAAW,EACpC,MAAM,IAAI,MAAM,+BAA+B,EAGjD,GAAIA,EAAQ,OAAO,CAAC,GAAG,KAAK,SAAW,EACrC,MAAM,IAAI,MAAM,8BAA8B,EAGhD,IAAMipB,EAAIjpB,EAAQ,OAAO,CAAC,EACpB6lB,EAAI7lB,EAAQ,OAAO,CAAC,GAAKA,EAAQ,OAAO,CAAC,EAAE,KAAK,OAAS,EAAIA,EAAQ,OAAO,CAAC,EAAI,OACjFuD,EAAIvD,EAAQ,OAAO,CAAC,GAAKA,EAAQ,OAAO,CAAC,EAAE,KAAK,OAAS,EAAIA,EAAQ,OAAO,CAAC,EAAI,OACjFkpB,EAAUlpB,EAAQ,OAAO,CAAC,GAAKA,EAAQ,OAAO,CAAC,EAAE,KAAK,SAAW,EAAIA,EAAQ,OAAO,CAAC,EAAI,OACzFsqB,EAAYtqB,EAAQ,OAAO,CAAC,GAAKA,EAAQ,OAAO,CAAC,EAAE,KAAK,SAAW,EAAIA,EAAQ,OAAO,CAAC,EAAI,OAC3FooB,EAAUpoB,EAAQ,OAAO,OAAS,EAAIA,EAAQ,OAAO,CAAC,EAAI,OAC1DioB,EAA2BjoB,EAAQ,OAAO,OAAS,EAAIA,EAAQ,OAAO,CAAC,EAAI,OAC3EspB,EAAaiB,EAAO,WAAaA,EAAO,WAAaA,EAAO,SAI5DmmB,EAAmC12B,EAA4B,CACnE,KAAM,EACN,WAAY,EACZ,WAAY,CAACuQ,EAAO,SAAWA,EAAO,SAAUjB,EAAaiB,EAAO,SAAUjB,EAAaiB,EAAO,QAAQ,CAC5G,CAAC,EACK,CAAC+jB,EAAO5qC,EAAKhH,CAAK,EACtB,CAACmpB,GAAK,CAACtiB,EACHvD,EAAQ,QAAQwvC,GAAuB,CAACvmB,CAAC,EAAGynB,CAAe,EAAG,CAAE,OAAQ,CAACznB,CAAC,EAAG,QAAS,CAAC,GAAI,GAAI,EAAE,CAAE,CAAC,EACpG,CAACA,EAAGpD,EAAItiB,CAAE,EAEV4rC,EAAIhB,GACRnuC,EACAuqB,EAAO,UACPA,EAAO,SACPA,EAAO,eACPA,EAAO,SACP+jB,EACA,OACA,CACF,EACA3nB,GACE3mB,EACAmvC,EACAe,GAAqBlwC,EAAS0D,EAAK6mB,CAAM,EACzC2lB,GAAqBlwC,EAAStD,EAAO6tB,CAAM,EAC3C,OACA,OACArB,EACAoB,EACA,OACAC,EACAnC,EACAH,CACF,CACF,ICvSA,IAwBM0oB,GAmFAC,GAiEAC,GAgGOC,GA5QbC,GAAAh2C,EAAA,kBAGAkS,IAEA8C,IAEA8P,KAEAzE,IAeMu1B,GAA2B,CAC/B3wC,EACA+f,EACAsM,EACArF,EACAgqB,EACA7L,EACArC,EACA/W,IACG,CACH,IAAM1Q,EAAab,EAAiB2qB,CAAC,EAC/B3c,EAAUnN,IAAe,EAAI,MAAQ,MAAMA,CAAU,IACrD41B,EAAS51B,IAAe,EAAI,QAAU,QAAQA,CAAU,IACxD61B,EAAcF,EAAIlO,EACpB3kB,EAAgB,GAChB+yB,IAAgB,IAClB/yB,EAAgB,KAElB,IAAM2B,EAAa,CAACkxB,EAAGlO,EAAGqC,EAAI9pB,CAAU,EAClCmF,EAAc,CAACwwB,EAAGlO,EAAG,CAAC,EACtBra,EAAwD,CAAC,OAAQ,OAAQ,MAAM,EAC/EnN,EAAoC,CAAC,EAC3CA,EAAgB,KAAK,GAAGf,EAA2BuF,EAAYU,CAAW,CAAC,EAE3E,IAAMI,EAAmBC,GAA+B,CACtD,IAAMrP,EAAIsJ,EAAc,IAAKiF,EAAM,SAAU,EAAG1E,CAAU,EACpD81B,EAAIr2B,EAAc,QAASuR,EAAM,SAAUA,EAAM,IAAI,EACrD9e,EAAIuN,EAAc,OAAQkM,EAAK,SAAUA,EAAK,IAAI,EAClDhK,EAASjC,EAAe,WAA0B,EAAG,CAAC,EACtD8D,EAAY,CAACrN,EAAG2/B,EAAG5jC,EAAGyP,CAAM,EAClC,MAAO;AAAA,4CACiCi0B,CAAM,KAAK9yB,CAAa;AAAA,2BACzCA,CAAa;AAAA,IACpC0C,EAAa,iBAAiB,GAAGhC,CAAS,CAAC;AAAA,IAC3CgC,EAAa,UAAU1C,CAAa,CAAC;AAAA;AAAA;AAAA;AAAA;AAAA,gBAKzBqK,CAAO;AAAA,wBACCA,CAAO;AAAA;AAAA,oBAEXA,CAAO,IAAIhX,EAAE,IAAI,QAAS,UAAW,GAAG,CAAC;AAAA;AAAA;AAAA;AAAA,oCAIzBy/B,CAAM;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,wBAUlBt2B,GAAU,yBAA0BU,CAAU,CAAC,kBAAkBA,CAAU;AAAA,gCACnEV,GAAU,yBAA0BU,CAAU,CAAC,kBAAkBA,CAAU;AAAA;AAAA,sFAErB0Q,CAAO;AAAA;AAAA;AAAA;AAAA;AAAA,IAM3F,EAEA,OAAO/rB,EAAQ,QACb,CACE,KAAM,uCAEN,YAAa,CAAE,KAAM,GAAGqb,CAAU,IAAI0Q,CAAO,IAAI5N,CAAa,GAAI,kBAAAsK,CAAkB,EACpF,WAAY,KAAO,CACjB,QAAS,CAAC,CAAE,KAAMjI,EAAa,UAAyB,CAAC,EACzD,cAAe,CAAE,EAAG0wB,CAAY,EAChC,gBAAA51B,CACF,GACA,gBAAAsF,CACF,EACA,CAAE,OAAQ,CAACb,EAAOsM,EAAOrF,CAAI,EAAG,QAAS,CAAC,EAAE,CAAE,CAChD,EAAE,CAAC,CACL,EAEM4pB,GAAgC,CACpC5wC,EACAgG,EACAkb,IACG,CACH,IAAMwe,EAAS15B,EAAO,CAAC,EAAE,KACnBwa,EAAckf,EACdxuB,EAAO,EACPmC,EAAIqsB,EAAO,CAAC,EACZ0R,EAAI1R,EAAO,CAAC,EACZ2R,EAAI3hC,EAAU,kBAAkBgwB,EAAQxuB,CAAI,EAC5CmK,EAAab,EAAiB62B,CAAC,EAC/BvwB,EAAapR,EAAU,KAAK8Q,CAAW,EAAInF,EAE3Ci2B,EAAoBX,GACxB3wC,EACAgG,EAAO,CAAC,EACRA,EAAO,CAAC,EACRA,EAAO,CAAC,EACRqN,EACAg+B,EACAD,EACAlwB,EAAW,OACb,EAEMpB,EAAa,CAACzM,EAAG+9B,EAAGC,EAAIh2B,CAAU,EAClCk2B,EAAa,CAACl+B,EAAG+9B,CAAC,EAClB3oB,EAAwD,CAAC,OAAQ,MAAM,EAEvE7H,EAAmBC,GAA+B,CACtD,IAAMrP,EAAIsJ,EAAc,IAAK9U,EAAO,CAAC,EAAE,SAAU8Z,EAAW,OAAQzE,CAAU,EACxEgR,EAAQvR,EAAc,gBAA+By2B,EAAW,OAAQ,CAAC,EACzEv0B,EAASjC,EAAe,SAAU/U,EAAO,CAAC,EAAE,SAAU8Z,EAAW,OAAQzE,CAAU,EACnFwD,EAAY,CAACrN,EAAG6a,EAAOrP,CAAM,EACnC,MAAO;AAAA,IACP6D,EAAa,gBAAgB,cAAe,KAAK,EAAE,iBAAiB,GAAGhC,CAAS,CAAC;AAAA,IACjFgC,EAAa,UAAU,CAAC;AAAA,IACxBA,EAAa,sCAAsC,sBAAsB,CAAC;AAAA,4BAClD7D,EAAO,gBAAgB,YAAY,CAAC;AAAA;AAAA;AAAA,0BAGtCqP,EAAM,aAAa,2BAA2B,CAAC;AAAA,oBACrD7a,EAAE,YAAY,YAAY,CAAC,MAAMwL,EAAO,KAAK,KAAK,qBAAqBA,EAAO,KAAK,KAAK;AAAA,QACpGA,EAAO,YAAY,aAAc,OAAO,CAAC;AAAA,IAE/C,EAEAhd,EAAQ,QACN,CACE,KAAM,wBACN,YAAa,CAAE,KAAM,GAAGqb,CAAU,GAAI,kBAAAoN,CAAkB,EACxD,WAAY,KAAO,CACjB,QAAS,CAAC,CAAE,KAAMjI,EAAa,SAAUxa,EAAO,CAAC,EAAE,QAAS,CAAC,EAC7D,cAAe,CAAE,EAAG,KAAK,KAAK8a,EAAa,EAAuB,CAAE,EACpE,gBAAiB,CACf,CAAE,QAAuB,KAAMA,CAAW,EAC1C,GAAGvG,EAA2BuF,EAAYyxB,EAAYzxB,CAAU,CAClE,CACF,GACA,gBAAAc,CACF,EACA,CAAE,OAAQ,CAAC5a,EAAO,CAAC,EAAGsrC,CAAiB,CAAE,CAC3C,CACF,EAEMT,GAAoC,CACxC7wC,EACAgG,EACAkb,IACG,CACH,IAAMwe,EAAS15B,EAAO,CAAC,EAAE,KACnBwa,EAAckf,EACdrsB,EAAIqsB,EAAO,CAAC,EACZ0R,EAAI1R,EAAOA,EAAO,OAAS,CAAC,EAC5B2R,EAAI3hC,EAAU,kBAAkBgwB,EAAQ,CAAC,EAAI0R,EAC7C/1B,EAAab,EAAiB42B,CAAC,EAC/BtwB,EAAapR,EAAU,KAAK8Q,CAAW,EAAInF,EAC3CC,EAAoC,CACxC,CAAE,QAAuB,KAAM+1B,CAAE,EACjC,CAAE,QAAuB,KAAM,KAAK,MAAMD,EAAI/1B,CAAU,CAAE,CAC5D,EACMoN,EAAwD,CAAC,OAAQ,MAAM,EAGzE+oB,EAAgB,GACdC,EAAkB,CAAC,EAAG/R,EAAO,OAAS,CAAC,EAC7C,QAAStkC,EAAI,EAAGA,EAAIskC,EAAO,OAAS,EAAGtkC,IACrCo2C,EAAgBA,GAAiB9R,EAAOtkC,EAAI,CAAC,IAAM,EACnDq2C,EAAgB,KAAKr2C,EAAI,CAAC,EAG5Bo2C,EAAgBA,GAAiB9R,EAAOA,EAAO,OAAS,CAAC,IAAM,EAE/D,IAAMgS,EAAcF,EAChBxxC,EAAQ,QAAQ0f,GAA2B1f,EAAQ,OAAO,CAAC,EAAGyxC,CAAe,EAAG,CAC9E,OAAQ,CAACzxC,EAAQ,OAAO,CAAC,CAAC,EAC1B,QAAS,CAAC,EAAE,CACd,CAAC,EAAE,CAAC,EACJA,EAAQ,OAAO,CAAC,EAAE,QAAQ,MAAM,KAAK,CAAE,OAAQ0/B,EAAO,MAAO,EAAG,CAAChJ,EAAGt7B,IAAMskC,EAAO+R,EAAgBr2C,CAAC,CAAC,CAAC,CAAC,EAEnGk2C,EAAoBX,GACxB3wC,EACA0xC,EACA1rC,EAAO,CAAC,EACRA,EAAO,CAAC,EACRqN,EACAg+B,EACAD,EACAlwB,EAAW,OACb,EACMN,EAAmBC,GAA+B,CACtD,IAAMrgB,EAAW6Z,GAA4BrU,EAAO,CAAC,EAAE,QAAQ,EACzD2rC,EAAYt2B,IAAe,EAAI,QAAU,MAAMA,CAAU,MACzDu2B,EAAaC,GAAgB,CACjC,IAAMn8B,EAAQm8B,IAAQ,EAAI,IAAM,IAC1BrpB,EAAUnN,IAAe,EAAI,MAAQ,MAAMA,CAAU,IAC3D,OAAQA,EAAY,CAClB,IAAK,GACH,MAAO,GAAG7a,CAAQ,IAAIgoB,CAAO,UAAU9S,CAAK,KAC9C,IAAK,GACH,MAAO,QAAQlV,CAAQ,KAAKgoB,CAAO,aAAa9S,CAAK,cAAcA,CAAK,KAC1E,IAAK,GACH,MAAO,QAAQlV,CAAQ,KAAKgoB,CAAO,aAAa9S,CAAK,cAAcA,CAAK,cAAcA,CAAK,cAAcA,CAAK,KAChH,QACE,MAAM,IAAI,MAAM,2BAA2B2F,CAAU,EAAE,CAC3D,CACF,EACMqN,EAAc5N,EAAc,QAAS9U,EAAO,CAAC,EAAE,SAAUA,EAAO,CAAC,EAAE,KAAMqV,CAAU,EACnFy2B,EAAe/2B,EAAe,SAAU/U,EAAO,CAAC,EAAE,SAAUwa,EAAanF,CAAU,EAEzF,MAAO;AAAA,2DACgDqN,EAAY,KAAK,OAAO;AAAA,iEAClBipB,CAAS;AAAA,kEACRG,EAAa,KAAK,OAAO;AAAA;AAAA;AAAA;AAAA,IAIvFjxB,EAAa,UAAU,CAAC;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,kDAMsB+wB,EAAU,CAAC,CAAC,KAAKA,EAAU,CAAC,CAAC;AAAA,IAE7E,EACA5xC,EAAQ,QACN,CACE,KAAM,4BACN,YAAa,CAAE,KAAM,GAAGqb,CAAU,GAAI,kBAAAoN,CAAkB,EACxD,WAAY,KAAO,CACjB,QAAS,CAAC,CAAE,KAAMjI,EAAa,SAAUxa,EAAO,CAAC,EAAE,QAAS,CAAC,EAC7D,cAAe,CAAE,EAAG,KAAK,KAAK8a,EAAa,EAAuB,CAAE,EACpE,gBAAAxF,CACF,GACA,gBAAAsF,CACF,EACA,CAAE,OAAQ,CAAC5a,EAAO,CAAC,EAAGsrC,CAAiB,CAAE,CAC3C,CACF,EAEaR,GAAe,CAAC9wC,EAAyBkhB,IAA6C,CAC7FA,EAAW,SAAW,OACxB2vB,GAAkC7wC,EAASA,EAAQ,OAAQkhB,CAAU,EAErE0vB,GAA8B5wC,EAASA,EAAQ,OAAQkhB,CAAU,CAErE,IClRA,IA0BM9B,GAMA2yB,GAuHOC,GAvJbC,GAAAl3C,EAAA,kBAGAkS,IAEA8C,IAGAqL,IAkBMgE,GAAkBpZ,GAAwC,CAC9D,GAAI,CAACA,GAAUA,EAAO,OAAS,EAC7B,MAAM,IAAI,MAAM,uCAAuC,CAE3D,EAEM+rC,GAA6B,CACjC/rC,EACAkb,EACA8H,IACgB,CAChB,IAAMkpB,EAAahxB,EAAW,WAExBwe,EAAS15B,EAAO,CAAC,EAAE,KACnBqmB,EAAQrmB,EAAO,CAAC,EAChBghB,EAAO,CAACkrB,GAAclsC,EAAO,CAAC,EAE9Bwa,EAAckf,EACdxuB,EAAOxB,EAAU,cAAcwR,EAAW,KAAMwe,EAAO,MAAM,EAC7DyS,EAAYziC,EAAU,gBAAgBgwB,EAAQxuB,CAAI,EAClDkhC,EAAW1iC,EAAU,kBAAkBgwB,EAAQxuB,CAAI,EAEnDmhC,EAAY3iC,EAAU,KAAK2c,EAAM,IAAI,EACrCimB,EAAWtrB,EAAOtX,EAAU,KAAKsX,EAAK,IAAI,EAAI,EACpD,GAAIqrB,IAAcD,GAAaprB,GAAQsrB,IAAaF,EAClD,MAAM,IAAI,MAAM,+BAA+BA,CAAQ;AAAA;AAAA,2BAEhCC,CAAS,qBAAqBC,CAAQ,EAAE,EAGjE,IAAMC,EAA6B,CAAC,EACpC,QAASn3C,EAAI,EAAGA,EAAIskC,EAAO,OAAQ,EAAEtkC,EAC/BA,EAAI8V,EACNqhC,EAAiB,KAAK7S,EAAOtkC,CAAC,CAAC,EAE/Bm3C,EAAiB,KAAK,CAAC,EAG3B,IAAMl3B,EAAab,EAAiB43B,CAAQ,EACtC3pB,EAAwD,CAAC,OAAQ,MAAM,EACvEnN,EAAoC,CACxC,CAAE,QAAuB,KAAM62B,CAAU,EACzC,CAAE,OAAsB,KAAMC,CAAS,EACvC,CAAE,QAAuB,KAAM,KAAK,MAAMA,EAAW/2B,CAAU,CAAE,EACjE,CAAE,OAAsB,KAAM6F,EAAW,OAAQ,CACnD,EACI8F,GACFyB,EAAkB,KAAK,MAAM,EAE/B,IAAM+pB,EAAoBxpB,EAAc,EAClCypB,EAAkBzpB,EAAc,EAEhCpI,EAAmBC,GAA+B,CACtD,IAAMrgB,EAAW6Z,GAA4BrU,EAAO,CAAC,EAAE,QAAQ,EACzD6Y,EAAY,CAChB/D,EAAc,IAAK9U,EAAO,CAAC,EAAE,SAAUA,EAAO,CAAC,EAAE,KAAMqV,CAAU,EACjEP,EAAc,QAASuR,EAAM,SAAUA,EAAM,KAAMhR,CAAU,CAC/D,EACI2L,GACFnI,EAAU,KAAK/D,EAAc,OAAQkM,EAAK,SAAUA,EAAK,KAAM3L,CAAU,CAAC,EAE5EwD,EAAU,KAAK9D,EAAe,SAAU/U,EAAO,CAAC,EAAE,SAAUwa,EAAanF,CAAU,CAAC,EAChFm3B,GACF3zB,EAAU,KAAK9D,EAAe,qBAAoCw3B,CAAgB,CAAC,EAEjFE,GACF5zB,EAAU,KAAK9D,EAAe,mBAAkCw3B,CAAgB,CAAC,EAGnF,IAAMxpB,EAA8B,CAClC,CAAE,KAAM,aAAc,KAAM,KAAM,EAClC,CAAE,KAAM,YAAa,KAAM,KAAM,EACjC,CAAE,KAAM,uBAAwB,KAAM,KAAM,EAC5C,CAAE,KAAM,UAAW,KAAM,KAAM,CACjC,EACA,MAAO;AAAA,IACPlI,EAAa,iBAAiBkI,CAAQ,EAAE,iBAAiB,GAAGlK,CAAS,CAAC;AAAA,IACtEgC,EAAa,UAAU,CAAC;AAAA,MACtBA,EAAa,sCAAsC,qBAAqB,CAAC;AAAA;AAAA,wBAEvDpG,GAAW,MAAOY,CAAU,CAAC;AAAA,+BACtBZ,GAAW,MAAOY,CAAU,CAAC;AAAA;AAAA;AAAA,oBAGxCX,GAAUla,EAAU6a,EAAY,eAAe,CAAC;AAAA;AAAA;AAAA;AAAA,iBAInDV,GAAU,cAAeU,CAAU,CAAC;AAAA,oCACjBV,GAAU,qBAAsBU,CAAU,CAAC,yBACzE62B,EAAa,GAAK,eACpB;AAAA;AAAA;AAAA,uBAGmBx3B,GAAUla,EAAU6a,EAAY,eAAe,CAAC;AAAA,uBAChDX,GAAUla,EAAU6a,EAAY,UAAU,CAAC;AAAA,6BACrCwD,EAAU,CAAC,EAAE,KAAK,KAAK,cAAcqzB,EAAa,GAAK,QAAQ;AAAA,UAClFlrB,EAAO,KAAKtM,GAAUla,EAAU6a,EAAY,SAAS,CAAC,GAAK,EAAE;AAAA;AAAA;AAAA;AAAA,MAIjEm3B,EAAoB,sCAAwC,EAAE;AAAA,MAC9DC,EAAkB,2CAA6C,EAAE;AAAA,IAErE,EACMtsC,EAAU,CAAC,CAAE,KAAMqa,EAAa,SAAUxa,EAAO,CAAC,EAAE,QAAS,CAAC,EACpE,OAAIwsC,GACFrsC,EAAQ,KAAK,CAAE,KAAMosC,EAAkB,UAAyB,CAAC,EAE/DE,GACFtsC,EAAQ,KAAK,CAAE,KAAMosC,EAAkB,UAAyB,CAAC,EAG5D,CACL,KAAM,qBACN,YAAa,CAAE,KAAM,GAAGl3B,CAAU,IAAI2N,CAAW,IAAIkpB,CAAU,GAAI,kBAAAzpB,CAAkB,EACrF,WAAY,KAAO,CACjB,QAAAtiB,EACA,cAAe,CAAE,EAAG,KAAK,KAAKgsC,EAAY,EAAuB,CAAE,EACnE,gBAAA72B,CACF,GACA,gBAAAsF,CACF,CACF,EAEaoxB,GAAY,CAAChyC,EAAyBkhB,IAA0C,CAC3F9B,GAAepf,EAAQ,MAAM,EAC7BA,EAAQ,QAAQ+xC,GAA2B/xC,EAAQ,OAAQkhB,EAAYlhB,EAAQ,WAAW,CAAC,CAC7F,IC1JA,IAUMof,GAUOszB,GApBbC,GAAA53C,EAAA,kBAIAgV,IAGAqmB,KACAgC,KAEMhZ,GAAkBpZ,GAAwC,CAC9D,GAAI,CAACA,GAAUA,EAAO,SAAW,EAC/B,MAAM,IAAI,MAAM,2BAA2B,EAG7C,GAAIA,EAAO,CAAC,EAAE,KAAKA,EAAO,CAAC,EAAE,KAAK,OAAS,CAAC,IAAMA,EAAO,CAAC,EAAE,KAAKA,EAAO,CAAC,EAAE,KAAK,OAAS,CAAC,EACxF,MAAM,IAAI,MAAM,kCAAkC,CAEtD,EAEa0sC,GAAU1yC,GAAkC,CACvDof,GAAepf,EAAQ,MAAM,EAC7B,IAAMwgB,EAAc/Q,GAAc,UAAUzP,EAAQ,OAAO,CAAC,EAAE,KAAMA,EAAQ,OAAO,CAAC,EAAE,KAAM,EAAI,EAChG,GAAI,CAACwgB,EACH,MAAM,IAAI,MAAM,uCAAuC,EAEzD,IAAMnN,EAAImN,EAAYA,EAAY,OAAS,CAAC,EACtCpN,EAAIpT,EAAQ,OAAO,CAAC,EAAE,KAAKA,EAAQ,OAAO,CAAC,EAAE,KAAK,OAAS,CAAC,EAClE,GAAIqT,EAAI,GAAKD,EAAI,EACfpT,EAAQ,QAAQm2B,GAA6Bn2B,EAAQ,OAAQ,CAAE,WAAY,EAAG,EAAGwgB,CAAW,CAAC,MACxF,CACL,IAAMrN,EAAIqN,EAAYA,EAAY,OAAS,CAAC,EACtCoyB,EAASljC,EAAU,KAAK1P,EAAQ,OAAO,CAAC,EAAE,KAAK,MAAM,EAAG,EAAE,CAAC,EAC3D6yC,EAASnjC,EAAU,KAAK1P,EAAQ,OAAO,CAAC,EAAE,KAAK,MAAM,EAAG,EAAE,CAAC,EACjE,GAAI4yC,IAAW,GAAKz/B,IAAM,GAAK0/B,IAAW,EAAG,CAE3C,IAAMC,EAAY9yC,EAAQ,OAAO,CAAC,EAAE,QAAQ,CAAC,EAAG4yC,EAAQx/B,CAAC,CAAC,EACpD2/B,EAAY/yC,EAAQ,OAAO,CAAC,EAAE,QAAQ,CAAC,EAAGoT,EAAGC,CAAC,CAAC,EAC/CwuB,EAAoB,CAAC,EAAG+Q,EAAQv/B,CAAC,EACjCyuB,EAAe,CAACgR,EAAWC,CAAS,EAC1C/yC,EAAQ,QAAQm4B,GAAwB2J,EAAc,CAAE,WAAY,EAAG,EAAGthB,EAAaqhB,CAAiB,EAAG,CACzG,OAAQC,CACV,CAAC,CACH,MACE9hC,EAAQ,QAAQm4B,GAAwBn4B,EAAQ,OAAQ,CAAE,WAAY,EAAG,EAAGwgB,CAAW,CAAC,CAE5F,CACF,IC/CA,IA2BMpB,GA+BO4zB,GAmNAC,GAuKAC,GAaAC,GAjcbC,GAAAr4C,EAAA,kBAGAkS,IAEA8C,IACAkK,KAGAmB,IAkBMgE,GAAiB,CAACpZ,EAA+Bkb,IAA4C,CACjG,GAAIlb,EAAO,OAAS,GAAKA,EAAO,OAAS,EACvC,MAAM,IAAI,MAAM,oCAAoC,EAEtD,IAAMsH,EAAItH,EAAO,CAAC,EACZ8zB,EAAQxsB,EAAE,KAAK,OACrB,GAAIA,EAAE,KAAKwsB,EAAQ,CAAC,IAAM5Y,EAAW,EACnC,MAAM,IAAI,MAAM,wDAAwD,EAE1E,IAAMmyB,EAAgB,KAAK,OAAOnyB,EAAW,EAAIA,EAAW,UAAY,GAAKA,EAAW,SAAS,EAC3FoyB,EAAYpyB,EAAW,UAAY,EAAKA,EAAW,KACnD3T,EAAIvH,EAAO,CAAC,EAClB,GAAI,CAAC0J,EAAU,SAASnC,EAAE,KAAM,CAAC2T,EAAW,EAAGmyB,EAAeC,CAAQ,CAAC,EACrE,MAAM,IAAI,MAAM,6EAA6E,EAG/F,IAAMC,EADSvtC,EAAO,CAAC,EACI,KAC3B,GAAI0J,EAAU,KAAK6jC,CAAW,IAAMryB,EAAW,EAAImyB,EACjD,MAAM,IAAI,MAAM,0BAA0B,EAE5C,GAAIrtC,EAAO,SAAW,EAAG,CAEvB,IAAMwtC,EADaxtC,EAAO,CAAC,EACQ,KAC7BytC,EACJvyB,EAAW,KAAO,EAAIA,EAAW,EAAImyB,EAAgBnyB,EAAW,EAAI,KAAK,OAAOmyB,EAAgB,GAAK,CAAC,EACxG,GAAI3jC,EAAU,KAAK8jC,CAAe,IAAMC,EACtC,MAAM,IAAI,MAAM,8BAA8B,CAElD,CACF,EAEaT,GAA+B,CAC1ChtC,EACAkb,IACgB,CAChB,IAAMpB,EAAa9Z,EAAO,CAAC,EAAE,KACvB8zB,EAAQha,EAAW,OACnB2Z,EAAY3Z,EAAWga,EAAQ,CAAC,EAChCJ,EAAWxY,EAAW,EACtByY,EAAYzY,EAAW,EACvBmW,EAAYvX,EAAW,MAAM,EAAGga,EAAQ,CAAC,EACzC1S,EAAY1X,EAAU,KAAK2nB,CAAS,EAEpCqc,EADW1tC,EAAO,CAAC,EAAE,KAAK,CAAC,EACE,EAC7BxF,EAAWwF,EAAO,CAAC,EAAE,SACrBixB,EAAczc,EAAiB0G,EAAW,CAAC,EAC3CshB,EAAchoB,EAAiBk5B,CAAe,EAC9Cr4B,EAAab,EAAiBmf,CAAS,EACvCnZ,EAAc6W,EAAU,OAAO,CAACoC,EAAWE,CAAS,CAAC,EACrDzC,EAAeuC,EAAY,GAAME,EAAYte,EAAc,IAAM,EAAI,EAAI,EACzEs4B,EAAejkC,EAAU,KAAK8Q,CAAW,EAAInF,EAAa6b,EAE1D/Y,EAAgB,GAEhB7C,EAAoC,CAAC,EACrCs4B,EAAiB,CAACxsB,EAAWqS,EAAWC,EAAWzC,CAAW,EAC9DD,EAAStnB,EAAU,aAAa1J,EAAO,CAAC,EAAE,IAAI,EAAE,MAAM,EAC5DgxB,EAAO,OAAO,GAAI,EAAG0c,EAAkBlR,CAAW,EAClDlnB,EAAgB,KAAK,GAAGf,EAA2Bq5B,CAAc,CAAC,EAClEt4B,EAAgB,KAAK,GAAGf,EAA2Byc,CAAM,CAAC,EAC1D1b,EAAgB,KAAK,GAAGf,EAA2BvU,EAAO,CAAC,EAAE,IAAI,CAAC,EAC9DA,EAAO,SAAW,GACpBsV,EAAgB,KAAK,GAAGf,EAA2B7K,EAAU,aAAa1J,EAAO,CAAC,EAAE,IAAI,CAAC,CAAC,EAE5F,IAAMi0B,EAAkB,CAAC7S,EAAWqS,EAAWE,EAAYte,CAAU,EACrEC,EAAgB,KAAK,GAAGf,EAA2B0f,CAAe,CAAC,EAEnE,IAAMrZ,EAAmBC,GAA+B,CACtD,IAAMhQ,EAAY+iC,EAAe,OAC3BtmC,EAAIwN,EAAc,IAAK9U,EAAO,CAAC,EAAE,SAAU6K,EAAWomB,CAAW,EACjE1pB,EAAIuN,EAAc,OAAsBkc,EAAO,OAAQwL,CAAW,EAClE8I,EAASxwB,EAAc,SAAU9U,EAAO,CAAC,EAAE,SAAUA,EAAO,CAAC,EAAE,KAAK,MAAM,EAC1EuxB,EAAiB,CAACjqB,EAAGC,EAAG+9B,CAAM,EAC9BuI,EACJ7tC,EAAO,SAAW,EAAI8U,EAAc,iBAAgC9U,EAAO,CAAC,EAAE,KAAK,MAAM,EAAI,OAC3F6tC,GACFtc,EAAe,KAAKsc,CAAU,EAEhC,IAAMnuB,GAAauU,EAAgB,OAC7Bjd,EAASjC,EAAe,SAAU/U,EAAO,CAAC,EAAE,SAAU0f,GAAYrK,CAAU,EAC5E7a,EAAW6Z,GAA4BrU,EAAO,CAAC,EAAE,QAAQ,EAEzD8tC,GAAe,IAAM,CACzB,OAAQ7c,EAAa,CACnB,IAAK,GACH,MAAO,SAASz2B,CAAQ,OAC1B,IAAK,GACH,MAAO,UAAUA,CAAQ,IAC3B,IAAK,GACH,MAAO,UAAUA,CAAQ,IAC3B,QACE,MAAM,IAAI,MAAM,GAAGy2B,CAAW,8BAA8B,CAChE,CACF,GAAG,EAEG8c,EAAiB,IAAc,CACnC,IAAIpc,GAAU;AAAA;AAAA,iCAEarqB,EAAE,gBAAgB,GAAGA,EAAE,KAAK,OAAO,2BAA2B,CAAC;AAAA,0BACtEwmC,CAAW;AAAA,uCACE,EAAI7c,CAAW;AAAA,4BAC1B3pB,EAAE,YAAY,cAAc,CAAC;AAAA;AAAA;AAAA,YAInD,QAASw1B,EAAI,EAAGA,EAAIznB,EAAa6b,EAAc4L,IAC7CnL,IAAW;AAAA,wBACK6K,IAAgB,EAAI,IAAIM,CAAC,QAAU,IAAIA,CAAC,UAAU;AAAA;AAAA;AAAA,mCAGvCgR,CAAW,IAAI,MAAM,KAC1C,CAAE,OAAQ,CAAE,EACZ,CAACpd,EAAGt7B,IAAM,GAAGoF,CAAQ,kBAAkBpF,CAAC,OAAOoF,CAAQ,kBAAkBpF,CAAC,IAC5E,EAAE,KAAK,IAAI,CAAC;AAAA,qCAEN67B,IAAgB,EACX,GAAG6c,CAAW,IAAI,MAAM,KAC7B,CAAE,OAAQ,CAAE,EACZ,CAACpd,EAAGt7B,IAAM,uBAAuBA,CAAC,OAAOy4C,EAAa,aAAa/Q,CAAC,GAAK,YAAY,YAAYA,CAAC,EACpG,EAAE,KAAK,IAAI,CAAC,KAEL,yBAAyBgR,CAAW,IAAI,MAAM,CAAC,EACnD,KAAK,GAAGD,EAAa,aAAa/Q,CAAC,GAAK,YAAY,EAAE,EACtD,KAAK,GAAG,CAAC,aAAaA,CAAC,GAE1B;AAAA,4CAC4B5L,CAAY,MAAM,KAAK,MAAM4L,EAAIznB,CAAU,CAAC,IAAIA,EAAa,EAAI,IAAIynB,EAAIznB,CAAU,IAAM,EAAE,OAAO,MAAM,KACtI,CAAE,OAAQ,EAAI4b,CAAY,EAC1B,CAACP,EAAGt7B,IACF,GACE67B,IAAgB,EACZ,UAAU77B,CAAC,4BAA4BA,CAAC,IACxC,cAAcA,CAAC,2BAA2BA,CAAC,IACjD,EACJ,EAAE,KAAK,KAAK,CAAC;AAAA,YAGnB,OAAOu8B,EACT,EACMqc,GAA2B,IAAc,CAC7C,IAAIrc,GAAU;AAAA,oCACgBtc,CAAU;AAAA,cAEhCw4B,EACI;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,uCAQA;AAAA;AAAA,+BAEarzC,CAAQ,MAC3B;AAAA,cAEN,QAASsiC,EAAI,EAAGA,EAAIznB,EAAa6b,EAAc4L,IAC7CnL,IAAW;AAAA,uBACImL,CAAC,MAAMwI,EAAO,YAAY,mCAAmC,CAAC;AAAA,cAEvEuI,EACI;AAAA;AAAA;AAAA;AAAA;AAAA,gCAKcA,EAAW,YAAY,uBAAuB,CAAC;AAAA,4BACnD/Q,CAAC,MAAMtiC,CAAQ,8BACzB,EACN;AAAA,6BAGN,OAAOm3B,EACT,EACMsc,GAAe,IAAc,CACjC,IAAItc,GAAU,qBAAqBtc,CAAU,IAC7C,QAASynB,EAAI,EAAGA,EAAIznB,EAAa6b,EAAc4L,IAC7CnL,IAAW;AAAA,mBACAmL,CAAC,WAAWv1B,EAAE,aAAa,GAAGA,EAAE,KAAK,OAAO,0BAA0B,CAAC;AAAA,6BAGpF,OAAAoqB,IAAW;AAAA;AAAA;AAAA;AAAA;AAAA,sCAKqBmc,CAAW;AAAA,wCACTA,CAAW,IACtCnc,EACT,EACA,MAAO;AAAA,iDACsC3a,EAAO,KAAK,KAAK,KAAKka,EAAe/Y,CAAa;AAAA,UACzF0C,EAAa,iBAAiB,GAAG0W,EAAgBva,CAAM,CAAC;AAAA,UACxD6D,EAAa,UAAU,CAAC1C,EAAe,EAAG,CAAC,CAAC,CAAC;AAAA,iCACtBnB,EAAO,gBAAgB,iBAAiBmB,CAAa,OAAO+Y,CAAY,EAAE,CAAC;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,yEAMnC/Y,CAAa;AAAA;AAAA,6CAEzC+C,EAAW,UAAY+V,CAAW;AAAA,cACjE+c,GAAyB,CAAC;AAAA,6CACKN,CAAe,aAAalR,CAAW;AAAA,gBACpEyR,GAAa,CAAC;AAAA,yCACWzR,CAAW;AAAA,kBAClCuR,EAAe,CAAC;AAAA,iCACD,EAAI9c,CAAW;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,6BAMnBC,CAAY;AAAA,gCACTla,EAAO,KAAK,KAAK,MAAMA,EAAO,KAAK,KAAK;AAAA;AAAA,wCAEhCmB,CAAa;AAAA;AAAA,2CAEV+Y,CAAY;AAAA;AAAA,cAEzCla,EAAO,aAAa,GAAGA,EAAO,KAAK,OAAO,iCAAkC,cAAc,CAAC;AAAA;AAAA,UAGvG,EACA,MAAO,CACL,KAAM,cACN,YAAa,CACX,KAAM,GAAGkE,EAAW,SAAS,IAAIA,EAAW,IAAI,IAAI+V,CAAW,IAAIuL,CAAW,IAAInnB,CAAU,IAAI6b,CAAY,IAAI/Y,CAAa,GAC7H,kBAAmB,MAAMnY,EAAO,MAAM,EAAE,KAAK,MAAM,CACrD,EACA,WAAY,KAAO,CACjB,QAAS,CAAC,CAAE,KAAMwa,EAAa,SAAAhgB,CAAS,CAAC,EACzC,cAAe,CAAE,EAAGmzC,CAAa,EACjC,gBAAAr4B,CACF,GACA,gBAAAsF,CACF,CACF,EAGaqyB,GAA0C,CACrDjtC,EACAkb,IACgB,CAChB,IAAMpB,EAAa9Z,EAAO,CAAC,EAAE,KACvB8zB,EAAQha,EAAW,OACnB2Z,EAAY3Z,EAAWga,EAAQ,CAAC,EAChCJ,EAAWxY,EAAW,EACtByY,EAAYzY,EAAW,EACvBmW,EAAYvX,EAAW,MAAM,EAAGga,EAAQ,CAAC,EACzC1S,EAAY1X,EAAU,KAAK2nB,CAAS,EAEpCqc,EADW1tC,EAAO,CAAC,EAAE,KAAK,CAAC,EACE,EAC7BxF,EAAWwF,EAAO,CAAC,EAAE,SACrBixB,EAAczc,EAAiB0G,EAAW,CAAC,EAC3CshB,EAAchoB,EAAiBk5B,CAAe,EAC9ClzB,EAAc6W,EAAU,OAAO,CAACoC,EAAWE,CAAS,CAAC,EAErDxb,EAAgB,IAChB+1B,EAAava,EAAY,IAAM,EAAI,EAAIA,EAAY,IAAM,EAAI,EAAI,EACjEwa,EAAah2B,EAAgB+1B,EAC7BjzB,EAAWkzB,EAAa3R,EAAc,EACtC4R,EAAiBnzB,EAAWgW,EAC5Bod,EAAgBpzB,EAAWC,EAAW,UACtCyyB,EAAejkC,EAAU,KAAK8Q,CAAW,EAAI0zB,EAE7C54B,EAAoC,CAAC,EACrCs4B,EAAiB,CAACxsB,EAAWqS,EAAWC,EAAWzC,CAAW,EAC9DD,EAAStnB,EAAU,aAAa1J,EAAO,CAAC,EAAE,IAAI,EAAE,MAAM,EAC5DgxB,EAAO,OAAO,GAAI,EAAG0c,EAAkBlR,CAAW,EAClDlnB,EAAgB,KAAK,GAAGf,EAA2Bq5B,CAAc,CAAC,EAClEt4B,EAAgB,KAAK,GAAGf,EAA2Byc,CAAM,CAAC,EAC1D1b,EAAgB,KAAK,GAAGf,EAA2BvU,EAAO,CAAC,EAAE,IAAI,CAAC,EAC9DA,EAAO,SAAW,GACpBsV,EAAgB,KAAK,GAAGf,EAA2B7K,EAAU,aAAa1J,EAAO,CAAC,EAAE,IAAI,CAAC,CAAC,EAE5F,IAAMi0B,EAAkB,CAAC7S,EAAWqS,EAAWE,CAAS,EACxDre,EAAgB,KAAK,GAAGf,EAA2B0f,CAAe,CAAC,EAEnE,IAAMrZ,EAAmBC,GAA+B,CACtD,IAAMhQ,EAAY+iC,EAAe,OAC3BtmC,EAAIwN,EAAc,IAAK9U,EAAO,CAAC,EAAE,SAAU6K,EAAWomB,CAAW,EACjE1pB,EAAIuN,EAAc,OAAsBkc,EAAO,OAAQwL,CAAW,EAClE8I,GAASxwB,EAAc,SAAU9U,EAAO,CAAC,EAAE,SAAUA,EAAO,CAAC,EAAE,KAAK,MAAM,EAC1EuxB,EAAiB,CAACjqB,EAAGC,EAAG+9B,EAAM,EAC9BuI,EACJ7tC,EAAO,SAAW,EAAI8U,EAAc,iBAAgC9U,EAAO,CAAC,EAAE,KAAK,MAAM,EAAI,OAC3F6tC,GACFtc,EAAe,KAAKsc,CAAU,EAEhC,IAAMnuB,EAAauU,EAAgB,OAC7Bjd,EAASjC,EAAe,SAAU/U,EAAO,CAAC,EAAE,SAAU0f,CAAU,EAChEllB,GAAW6Z,GAA4BrU,EAAO,CAAC,EAAE,QAAQ,EACzDsuC,GAAQ,IAAM,CAClB,OAAQrd,EAAa,CACnB,IAAK,GACH,MAAO;AAAA,+BACcz2B,EAAQ;AAAA,+BACRA,EAAQ,qGAC/B,IAAK,GACH,MAAO;AAAA,+BACcA,EAAQ;AAAA,+BACRA,EAAQ,qDAC/B,IAAK,GACH,MAAO;AAAA;AAAA,iDAGT,QACE,MAAM,IAAI,MAAM,GAAGy2B,CAAW,8BAA8B,CAChE,CACF,EAEA,MAAO;AAAA,sCAC2B3pB,EAAE,KAAK,KAAK,KAAK8mC,CAAc;AAAA,oDACjBp3B,EAAO,KAAK,KAAK,KAAKm3B,CAAU,MAAMD,CAAU;AAAA,UAC1FrzB,EAAa,iBAAiB,GAAG0W,EAAgBva,CAAM,CAAC;AAAA,UACxD6D,EAAa,UAAU,CAACszB,EAAYD,EAAY,CAAC,CAAC,CAAC;AAAA,iCAC5Bl3B,EAAO,gBAAgB,qBAAqBk3B,CAAU,EAAE,CAAC;AAAA;AAAA;AAAA;AAAA;AAAA,sDAKpCG,CAAa;AAAA;AAAA;AAAA;AAAA,uCAI5BD,CAAc;AAAA;AAAA,wDAEGA,CAAc,iBAAiBj2B,CAAa;AAAA;AAAA;AAAA;AAAA;AAAA,oCAKhE7Q,EAAE,aAAa,GAAGA,EAAE,KAAK,OAAO,qBAAqB,CAAC;AAAA;AAAA,oCAEtDA,EAAE,KAAK,KAAK;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,iCAOf+mC,CAAa;AAAA,cAEhCR,EACI;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,oCAOkBA,EAAW,YAAY,uBAAuB,CAAC;AAAA,+BACpDrzC,EAAQ,8BACrB;AAAA;AAAA,+BAEaA,EAAQ,MAC3B;AAAA,0BACc8qC,GAAO,YAAY,kCAAkC,CAAC;AAAA,2BACrD/9B,EAAE,aAAa,GAAGA,EAAE,KAAK,OAAO,mBAAmB,CAAC;AAAA,6CAClC2T,EAAW,UAAY+V,CAAW;AAAA,uCACxCuL,CAAW;AAAA,gBAClC8R,GAAM,CAAC;AAAA,8BACO9R,IAAgB,EAAI,SAAW,WAAW;AAAA;AAAA;AAAA,gDAGxBhiC,EAAQ,KAAK,MAAM,KACnD,CAAE,OAAQ,CAAE,EACZ,CAACk2B,GAAGt7B,IAAM,GAAGoF,EAAQ,kBAAkBpF,CAAC,OAAOoF,EAAQ,kBAAkBpF,CAAC,IAC5E,EAAE,KAAK,IAAI,CAAC;AAAA,wEAC8CoF,EAAQ,KAAK,MAAM,CAAC,EAAE,KAAK,YAAY,EAAE,KAAK,GAAG,CAAC;AAAA,yDACjE,MAAM,KAC/C,CAAE,OAAQ,CAAE,EACZ,CAACk2B,GAAGt7B,IAAM,GAAG,aAAaA,CAAC,0BAA0BA,CAAC,IAAI,EAC5D,EAAE,KAAK,KAAK,CAAC;AAAA,+BACI,EAAI67B,CAAW;AAAA;AAAA;AAAA;AAAA;AAAA,4BAKlBid,CAAU;AAAA,gCACNl3B,EAAO,KAAK,KAAK,MAAMA,EAAO,KAAK,KAAK;AAAA,mCACrCm3B,CAAU;AAAA;AAAA;AAAA;AAAA;AAAA,gBAK7Bn3B,EAAO,aAAa,GAAGA,EAAO,KAAK,OAAO,gCAAiC,cAAc,CAAC;AAAA;AAAA;AAAA,UAIxG,EACA,MAAO,CACL,KAAM,yBACN,YAAa,CACX,KAAM,GAAGkE,EAAW,SAAS,IAAI+V,CAAW,IAAIuL,CAAW,IAAI2R,CAAU,IAAID,CAAU,GACvF,kBAAmB,MAAMluC,EAAO,MAAM,EAAE,KAAK,MAAM,CACrD,EACA,WAAY,KAAO,CACjB,QAAS,CAAC,CAAE,KAAMwa,EAAa,SAAAhgB,CAAS,CAAC,EACzC,cAAe,CAAE,EAAGmzC,CAAa,EACjC,gBAAAr4B,CACF,GACA,gBAAAsF,CACF,CACF,EAEasyB,GAAc,CAAClzC,EAAyBkhB,IAA4C,CAC/F9B,GAAepf,EAAQ,OAAQkhB,CAAU,EAEvCA,EAAW,YAAc,IACzBlhB,EAAQ,YAAY,SAAS,OAAO,GACpCA,EAAQ,YAAY,eAAe,UAAU,EAE7CA,EAAQ,QAAQizC,GAAwCjzC,EAAQ,OAAQkhB,CAAU,CAAC,EAEnFlhB,EAAQ,QAAQgzC,GAA6BhzC,EAAQ,OAAQkhB,CAAU,CAAC,CAE5E,EAEaiyB,GAA8BjyB,GACzClH,EAA4BkH,CAAsE,IClcpG,IA0BM9B,GAmBAm1B,GA0BAC,GA2BAC,GAuBAC,GAuBAC,GAeAC,GAuDAC,GA+BOnjC,GArPbojC,GAAA/5C,EAAA,kBAGAkS,IAEA8C,IAGAqL,IAkBMgE,GAAkBpZ,GAAwC,CAC9D,GAAI,CAACA,GAAUA,EAAO,OAAS,EAC7B,MAAM,IAAI,MAAM,gBAAgB,EAElC,GAAIA,EAAO,CAAC,EAAE,WAAa,GAAkBA,EAAO,CAAC,EAAE,WAAa,GAClE,MAAM,IAAI,MAAM,sCAAsC,EAGxD,GAAIA,EAAO,QAAU,EAAG,CACtB,IAAI+uC,EAAY/uC,EAAO,CAAC,EAAE,KAAK,OAAS,IAAMA,EAAO,CAAC,EAAE,KAAK,CAAC,EAI9D,GAHIA,EAAO,SAAW,IACpB+uC,EAAY/uC,EAAO,CAAC,EAAE,KAAK,CAAC,EAAI,IAAMA,EAAO,CAAC,EAAE,KAAK,CAAC,GAEpD,CAAC+uC,EACH,MAAM,IAAI,MAAM,6EAA6E,CAEjG,CACF,EAEMR,GAAiB,CAACv3B,EAAuBnM,EAAmBmkC,IAA+B,CAC/F,IAAIC,EAAQ,GACZ,QAAS75C,EAAIyV,EAAY,EAAGzV,GAAK,EAAG,EAAEA,EACpC65C,GAAS;AAAA,sBACSj4B,EAAO,WAAW,UAAW5hB,CAAC,CAAC,OAAOwf,EAAa,gBAAiBxf,EAAG45C,CAAU,CAAC;AAAA;AAAA;AAAA;AAAA,2BAI7Ep6B,EAAa,mBAAoBxf,EAAGyV,CAAS,CAAC;AAAA;AAAA;AAAA,gCAGzC+J,EAAa,qBAAsBxf,EAAGyV,CAAS,CAAC;AAAA,UAI9E,MAAO;AAAA,oBACWmM,EAAO,KAAK,KAAK;AAAA;AAAA;AAAA;AAAA,cAIvBi4B,CAAK;AAAA;AAAA;AAAA,OAInB,EAEMT,GAAgB,CAACx3B,EAAuBnM,EAAmBmkC,IAA+B,CAC9F,IAAIC,EAAQ,GACZ,QAAS75C,EAAIyV,EAAY,EAAGzV,GAAK,EAAG,EAAEA,EACpC65C,GAAS;AAAA,0BACaj4B,EAAO,WAAW,UAAW5hB,CAAC,CAAC,OAAOwf,EAAa,gBAAiBxf,EAAG45C,CAAU,CAAC;AAAA;AAAA;AAAA;AAAA;AAAA,yCAKnEp6B,EAAa,mBAAoBxf,EAAGyV,CAAS,CAAC;AAAA;AAAA,gCAEvD+J,EAAa,mBAAoBxf,EAAGyV,CAAS,CAAC;AAAA;AAAA;AAAA;AAAA,oCAI1C+J,EAAa,qBAAsBxf,EAAGyV,CAAS,CAAC;AAAA,cAIlF,MAAO;AAAA;AAAA;AAAA,gBAGOokC,CAAK;AAAA;AAAA,WAGrB,EAEMR,GAAa,CAACz3B,EAAuBnM,EAAmBmkC,IAA+B,CAC3F,IAAIC,EAAQ,GACZ,QAAS75C,EAAIyV,EAAY,EAAGzV,GAAK,EAAG,EAAEA,EACpC65C,GAAS;AAAA,0BACaj4B,EAAO,WAAW,UAAW5hB,CAAC,CAAC,OAAOwf,EAAa,gBAAiBxf,EAAG45C,CAAU,CAAC;AAAA;AAAA;AAAA;AAAA,+BAI7Ep6B,EAAa,mBAAoBxf,EAAGyV,CAAS,CAAC;AAAA,4BACjD+J,EAAa,mBAAoBxf,EAAGyV,CAAS,CAAC;AAAA;AAAA,oCAEtC+J,EAAa,qBAAsBxf,EAAGyV,CAAS,CAAC;AAAA,cAIlF,MAAO;AAAA;AAAA;AAAA,gBAGOokC,CAAK;AAAA;AAAA,WAGrB,EAEMP,GAAa,CAAC13B,EAAuBnM,EAAmBmkC,IAA+B,CAC3F,IAAIC,EAAQ,GACZ,QAAS75C,EAAIyV,EAAY,EAAGzV,GAAK,EAAG,EAAEA,EACpC65C,GAAS;AAAA,0BACaj4B,EAAO,WAAW,UAAW5hB,CAAC,CAAC,OAAOwf,EAAa,gBAAiBxf,EAAG45C,CAAU,CAAC;AAAA;AAAA,6BAE/Ep6B,EAAa,mBAAoBxf,EAAGyV,CAAS,CAAC;AAAA;AAAA,+BAE5C+J,EAAa,mBAAoBxf,EAAGyV,CAAS,CAAC;AAAA,6BAChD+J,EAAa,mBAAoBxf,EAAGyV,CAAS,CAAC;AAAA;AAAA,oCAEvC+J,EAAa,qBAAsBxf,EAAGyV,CAAS,CAAC;AAAA,cAIlF,MAAO;AAAA;AAAA;AAAA,gBAGOokC,CAAK;AAAA;AAAA,WAGrB,EAEMN,GAAgB,CAAC33B,EAAuBnM,EAAmBqQ,IAAsC,CACrG,OAAQA,EAAW,KAAM,CACvB,IAAK,GACH,OAAOqzB,GAAev3B,EAAQnM,EAAWqQ,EAAW,KAAK,MAAM,EACjE,IAAK,GACH,OAAOszB,GAAcx3B,EAAQnM,EAAWqQ,EAAW,KAAK,MAAM,EAChE,IAAK,GACH,OAAOuzB,GAAWz3B,EAAQnM,EAAWqQ,EAAW,KAAK,MAAM,EAC7D,IAAK,GACH,OAAOwzB,GAAW13B,EAAQnM,EAAWqQ,EAAW,KAAK,MAAM,EAC7D,QACE,MAAM,IAAI,MAAM,cAAc,CAClC,CACF,EAEM0zB,GAAuB,CAAC5uC,EAA+Bkb,IAA2C,CACtG,IAAMV,EAAc9Q,EAAU,SAAS1J,EAAO,CAAC,EAAE,KAAK,MAAM,EAAGkb,EAAW,IAAI,EACxEnP,EAAY/L,EAAO,CAAC,EAAE,KACtB8a,EAAapR,EAAU,KAAK8Q,CAAW,EACvClF,EAAoC,CACxC,CAAE,QAAuB,KAAMwF,CAAW,EAC1C,CAAE,OAAsB,KAAMI,EAAW,IAAK,CAChD,EAEMg0B,EAAmBlvC,EAAO,QAAU,GAAKA,EAAO,CAAC,EAAE,KACrDkb,EAAW,OAAS,GACtB5F,EAAgB,KAAK,CAAE,KAAM45B,EAAmBlvC,EAAO,CAAC,EAAE,WAA2B,KAAMkb,EAAW,KAAM,CAAC,EAG/G5F,EAAgB,KAAK,GAAGf,EAA2BvU,EAAO,CAAC,EAAE,KAAMwa,CAAW,CAAC,EAC/E,IAAMiI,EAAwD,CAAC,MAAM,EAE/D7H,EAAmBC,GAA+B,CACtD,IAAM7D,EAASjC,EAAe,SAAU/U,EAAO,CAAC,EAAE,SAAUwa,EAAY,MAAM,EACxET,EAAQjF,EAAc,IAAK9U,EAAO,CAAC,EAAE,SAAU+L,EAAU,MAAM,EAC/DvR,EAAWuf,EAAM,KAAK,MACtBo1B,EAAaR,GAAc33B,EAAQjL,EAAU,OAAQmP,CAAU,EAC/D6H,EAA8B,CAClC,CAAE,KAAM,cAAe,KAAM,KAAM,EACnC,CAAE,KAAM,OAAQ,KAAM,MAAO,OAAQ7H,EAAW,KAAK,MAAO,CAC9D,EACA,OAAIA,EAAW,OAAS,GACtB6H,EAAS,KAAK,CAAE,KAAM,iBAAkB,KAAOmsB,EAAmB10C,EAAW,KAAiC,CAAC,EAG1G;AAAA,cACGqgB,EAAa,iBAAiBkI,CAAQ,EAAE,iBAAiBhJ,EAAO/C,CAAM,CAAC;AAAA,cACvE6D,EAAa,UAAU,CAAC;AAAA,cACxBA,EAAa,sCAAsC,sBAAsB,CAAC;AAAA;AAAA,4BAE5D7D,EAAO,gBAAgB,YAAY,CAAC;AAAA;AAAA,0BAEtCxc,CAAQ;AAAA,cACpB20C,CAAU;AAAA;AAAA,UAGtB,EAEA,MAAO,CACL,KAAM,MACN,YAAa,CAAE,KAAM,GAAGj0B,EAAW,IAAI,GAAGg0B,CAAgB,GAAI,kBAAAzsB,CAAkB,EAChF,WAAY,KAAO,CACjB,QAAS,CAAC,CAAE,KAAMjI,EAAa,SAAUxa,EAAO,CAAC,EAAE,QAAS,CAAC,EAC7D,cAAe,CAAE,EAAG,KAAK,KAAK0J,EAAU,KAAK8Q,CAAW,EAAI,EAAuB,CAAE,EACrF,gBAAAlF,CACF,GACA,gBAAAsF,CACF,CACF,EAEMi0B,GAAgC,CAAC7uC,EAA+Bkb,IAA6C,CACjH,GAAIlb,EAAO,OAAS,EAAG,CACrB,IAAMovC,EAAepvC,EAAO,CAAC,EAAE,iBAAiB,EAC1CtJ,EACJsJ,EAAO,QAAU,GAAKA,EAAO,CAAC,EAAE,KAC5BA,EAAO,CAAC,EAAE,WAAa,GACrBA,EAAO,CAAC,EAAE,eAAe,EAAE,CAAC,EAC5BA,EAAO,CAAC,EAAE,gBAAgB,EAAE,CAAC,EAC/B,EAEA6K,EAAY7K,EAAO,CAAC,EAAE,KAAK,OAC3BqvC,EAAa,IAAI,WAAW,EAAIxkC,CAAS,EAAE,KAAK,CAAC,EACvD,GAAI7K,EAAO,QAAU,EAAG,CACtB,IAAMuL,EAAOvL,EAAO,CAAC,EAAE,iBAAiB,EACxC,QAAS5K,EAAI,EAAGA,EAAImW,EAAK,OAAQnW,IAC/Bi6C,EAAW,OAAO9jC,EAAKnW,CAAC,CAAC,CAAC,EAAI,OAAOg6C,EAAah6C,CAAC,CAAC,EACpDi6C,EAAW,OAAO9jC,EAAKnW,CAAC,CAAC,EAAIyV,CAAS,EAAI,OAAOukC,EAAah6C,EAAImW,EAAK,MAAM,CAAC,CAElF,MACE6jC,EAAa,QAAQ,CAAC7xC,EAAGnI,IAAOi6C,EAAW,OAAOj6C,CAAC,CAAC,EAAI,OAAOmI,CAAC,CAAE,EAGpE,IAAM2O,EAAiB,CAAC,EACxB,OAAAmjC,EAAW,QAAS9xC,GAAM2O,EAAK,KAAK3O,CAAC,CAAC,EAE/B,CAAE,KAAM2d,EAAW,KAAM,MAAAxkB,EAAO,KAAAwV,CAAK,CAC9C,KACE,QAAOgP,CAEX,EAEaxP,GAAM,CAAC1R,EAAyBkhB,IAAoC,CAC/E9B,GAAepf,EAAQ,MAAM,EAC7B,IAAMojB,EAAoByxB,GAA8B70C,EAAQ,OAAQkhB,CAAU,EAClFlhB,EAAQ,QAAQ40C,GAAqB50C,EAAQ,OAAQojB,CAAiB,EAAG,CAAE,OAAQ,CAAC,CAAC,CAAE,CAAC,CAC1F,ICzPA,IA2BMhE,GAMAk2B,GAsCAC,GA6EAC,GAmKAC,GAGAC,GAGAC,GAGAC,GAaAC,GAwDOC,GAYAC,GAKPC,GAWOC,GAKAC,GAUPC,GAmDOC,GAKAC,GAgBAC,GAKAC,GA7fbC,GAAAz7C,EAAA,kBAGAyJ,KAEAyI,IAEA8C,IAIAqL,IAgBMgE,GAAkBpZ,GAAwC,CAC9D,GAAIxJ,EAAI,OAAO,uBAAyB,CAACwJ,GAAUA,EAAO,SAAW,GACnE,MAAM,IAAI,MAAM,4BAA4B,CAEhD,EAEMsvC,GAA0C,CAC9Cv1B,EACAmB,EACApP,IAC8B,CAC9B,IAAM+kB,EAAiB3V,EAAW,SAAW,OACvCu1B,EAA2B12B,EAAM,KAAK,MAAM,EAC9C8W,GACF4f,EAAyB,OAAO,EAAG,EAAGA,EAAyB,IAAI,CAAE,EAEvE,IAAMC,EAAe,OAAO,eAAe,KAAKx1B,EAAY,WAAW,EACjElP,EAAckP,EAAW,YAAY,MAAM,EAC3C7P,EAAU6P,EAAW,QAAQ,MAAM,EACnCjP,EAAsBykC,EAAgBx1B,EAAiC,UAAU,MAAM,EAAI,CAAC,EAC5FhP,EAAOgP,EAAW,KAAK,MAAM,EACnCvR,GAAa,qBAAqBmC,EAAkB2kC,EAA0BzkC,EAAaX,EAASY,EAAWC,CAAI,EAEnH,IAAMykC,EAA4BhnC,GAAa,uBAC7CmC,EACA2kC,EACAplC,EACAY,EACAD,EACAE,EACAgP,EAAW,OACb,EAEM6f,EAAgB,OAAO,OAAO,CAAC,EAAG7f,CAAU,EAC9Cw1B,EACF,OAAO,OAAO3V,EAAe,CAAE,YAAA/uB,EAAa,QAAAX,EAAS,KAAAa,EAAM,UAAAD,EAAW,SAAUiP,EAAW,QAAS,CAAC,EAErG,OAAO,OAAO6f,EAAe,CAAE,YAAA/uB,EAAa,QAAAX,EAAS,KAAAa,EAAM,SAAUgP,EAAW,QAAS,CAAC,EAE5F,IAAM01B,EAA2BD,EAA0B,MAAM,EACjE,OAAAC,EAAyB,KAAKA,EAAyB,OAAO,EAAG,CAAC,EAAE,CAAC,CAAC,EAC/D,CAAC7V,EAAelK,EAAiB+f,EAA2BD,CAAyB,CAC9F,EAEMpB,GAAuB,CAC3B/0B,EACAU,IACqE,CACrE,IAAM2V,EAAiB3V,EAAW,SAAW,OACvCJ,EAAapR,EAAU,KAAK8Q,CAAW,EACvCq2B,EAAannC,EAAU,KAAKwR,EAAW,WAAW,EAClD5F,EAAoC,CACxC,CAAE,QAAuB,KAAMwF,CAAW,EAC1C,CAAE,QAAuB,KAAM+1B,CAAW,CAC5C,EACM9tB,EAA8B,CAClC,CAAE,KAAM,aAAc,KAAM,KAAM,EAClC,CAAE,KAAM,aAAc,KAAM,KAAM,CACpC,EACA,GAAI7H,EAAW,YAAY,QAAU,EAAG,CACtC,IAAM41B,EAAK51B,EAAW,YAAYA,EAAW,YAAY,OAAS,CAAC,EAC7D61B,EAAK71B,EAAW,QAAQA,EAAW,QAAQ,OAAS,CAAC,EACrD81B,EAAU91B,EAAW,KAAKA,EAAW,KAAK,OAAS,EAAI,CAAC,EACxD+1B,EAAQ/1B,EAAW,KAAKA,EAAW,KAAK,OAAS,CAAC,EAClDg2B,EAAoB,CAAC,EAAEF,EAAUC,GACvC37B,EAAgB,KACd,CAAE,QAAuB,KAAMw7B,CAAG,EAClC,CAAE,QAAuB,KAAMC,CAAG,EAClC,CAAE,QAAuB,KAAMC,CAAQ,EACvC,CAAE,QAAuB,KAAMC,CAAM,CACvC,EACAluB,EAAS,KACP,CAAE,KAAM,KAAM,KAAM,KAAM,EAC1B,CAAE,KAAM,KAAM,KAAM,KAAM,EAC1B,CAAE,KAAM,UAAW,KAAM,KAAM,EAC/B,CAAE,KAAM,QAAS,KAAM,KAAM,CAC/B,EAEA,IAAIouB,EAAoB,GACxB,GAAIj2B,EAAW,YAAY,SAAW,EAAG,CACvC,IAAMk2B,EAAKl2B,EAAW,YAAYA,EAAW,YAAY,OAAS,CAAC,EAC7Dm2B,EAAKn2B,EAAW,QAAQA,EAAW,QAAQ,OAAS,CAAC,EACrDo2B,EAAUp2B,EAAW,KAAKA,EAAW,KAAK,OAAS,EAAI,CAAC,EACxDq2B,EAAQr2B,EAAW,KAAKA,EAAW,KAAK,OAAS,CAAC,EACxDi2B,EAAoB,CAAC,EAAEG,EAAUC,GACjCj8B,EAAgB,KACd,CAAE,QAAuB,KAAM87B,CAAG,EAClC,CAAE,QAAuB,KAAMC,CAAG,EAClC,CAAE,QAAuB,KAAMC,CAAQ,EACvC,CAAE,QAAuB,KAAMC,CAAM,CACvC,EAEAxuB,EAAS,KACP,CAAE,KAAM,KAAM,KAAM,KAAM,EAC1B,CAAE,KAAM,KAAM,KAAM,KAAM,EAC1B,CAAE,KAAM,UAAW,KAAM,KAAM,EAC/B,CAAE,KAAM,QAAS,KAAM,KAAM,CAC/B,CACF,CACA,MAAO,CAACzN,EAAiByN,EAAU,GAAMmuB,EAAmBC,CAAiB,CAC/E,KAAO,CACL,GAAItgB,EACF,MAAM,IAAI,MAAM,uEAAuE,EAEzF,IAAM2gB,EAAgB9nC,EAAU,eAAewR,EAAW,WAAW,EACrE5F,EAAgB,KACd,CAAE,QAAuB,KAAMk8B,CAAc,EAC7C,CAAE,QAAuB,KAAMt2B,EAAW,IAAK,EAC/C,CAAE,QAAuB,KAAMA,EAAW,OAAQ,CACpD,EACA6H,EAAS,KACP,CAAE,KAAM,gBAAiB,KAAM,MAAO,OAAQyuB,EAAc,MAAO,EACnE,CAAE,KAAM,OAAQ,KAAM,MAAO,OAAQt2B,EAAW,KAAK,MAAO,EAC5D,CAAE,KAAM,UAAW,KAAM,MAAO,OAAQA,EAAW,QAAQ,MAAO,CACpE,EAEA,IAAMu2B,EAAUv2B,EAAW,KAAK,OAAO,CAAC2T,EAAK6iB,IAAQ7iB,EAAM6iB,CAAG,EAC9D,MAAO,CAACp8B,EAAiByN,EAAU,CAAC,CAAC0uB,EAAS,GAAO,EAAK,CAC5D,CACF,EAEMjC,GAAsB,CAC1B30B,EACArP,EACAR,EACA2mC,EACAz2B,EACA02B,EACAC,EACA1mC,EACA4X,EACA0uB,EACAP,EACAC,IACW,CACX,IAAMtgB,EAAiB3V,EAAW,SAAW,OACvC1gB,EAAWgR,EAAE,KAAK,MAClBwL,EAASjC,EAAe,SAAUvJ,EAAE,KAAK,OAAQmmC,CAAe,EAEtE,GAAIz2B,EAAW,YAAY,QAAU,EAAG,CACtC,IAAI42B,EAAQ,GACRC,EAAQ,GACRC,EAAW,GACTC,EAAUjnC,GAAQ6lB,EAAiB,EAAI,GAsB7C,GArBIqgB,EACFY,EAAQ;AAAA;AAAA,6BAEeG,CAAO,eAAeA,CAAO;AAAA,iCACzBA,CAAO,qBAAqBA,CAAO;AAAA,4CACxBA,CAAO;AAAA;AAAA;AAAA;AAAA,kCAIjBzmC,EAAE,gBAAgB,UAAU,CAAC;AAAA,oBAC3ComC,CAAG;AAAA,mBAGjBE,EAAQ;AAAA;AAAA,6BAEeG,CAAO,eAAeA,CAAO;AAAA,kCACxBzmC,EAAE,gBAAgB,UAAU,CAAC;AAAA,oBAC3ComC,CAAG;AAAA,mBAIf12B,EAAW,YAAY,SAAW,EAAG,CACvC,IAAMg3B,EAAUlnC,GAAQ6lB,EAAiB,EAAI,GACzCsgB,EACFY,EAAQ;AAAA;AAAA,6BAEaG,CAAO,eAAeA,CAAO;AAAA,iCACzBA,CAAO,qBAAqBA,CAAO,yBAAyBA,CAAO;AAAA;AAAA;AAAA;AAAA,gBAM5FH,EAAQ;AAAA;AAAA,6BAEaG,CAAO,eAAeA,CAAO;AAAA,kBAGpDF,EAAW;AAAA;AAAA,aAGb,CAoBA,MAlBoB;AAAA,cACVn3B,EAAa,iBAAiBkI,CAAQ,EAAE,iBAAiBvX,EAAGwL,CAAM,CAAC;AAAA;AAAA,cAEnE6D,EAAa,UAAU,CAAC;AAAA,gBACtBA,EAAa,sCAAsC,qBAAqB,CAAC;AAAA;AAAA,8BAE3D7D,EAAO,gBAAgB,YAAY,CAAC;AAAA,+BACnCA,EAAO,gBAAgB,YAAY,CAAC;AAAA;AAAA,4BAEvCxc,CAAQ,IAAI2Q,CAAK;AAAA;AAAA,gBAE7B4mC,CAAK;AAAA,gBACLD,CAAK;AAAA,gBACLE,CAAQ;AAAA,gBACRH,CAAG;AAAA;AAAA;AAAA,cAKjB,KAAO,CACL,GAAIhhB,EACF,MAAM,IAAI,MAAM,uEAAuE,EAEzF,IAAMshB,EAAcj3B,EAAW,YAAY,OACrCk3B,EAAWl3B,EAAW,KAAK,OAC7Bm3B,EAAU,GACd,OAAIZ,EACFY,EAAU;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,gCAQgB7mC,EAAE,gBAAgB,UAAU,CAAC;AAAA,kBAC3ComC,CAAG;AAAA,iBAGfS,EAAU;AAAA;AAAA,8BAEc7mC,EAAE,gBAAgB,UAAU,CAAC;AAAA,gBAC3ComC,CAAG;AAAA,cAGK;AAAA,cACV/2B,EAAa,iBAAiBkI,CAAQ,EAAE,iBAAiBvX,EAAGwL,CAAM,CAAC;AAAA;AAAA,cAEnE6D,EAAa,UAAU,CAAC;AAAA,gBACtBA,EAAa,sCAAsC,qBAAqB,CAAC;AAAA,8BAC3D7D,EAAO,gBAAgB,YAAY,CAAC;AAAA,+BACnCA,EAAO,gBAAgB,YAAY,CAAC;AAAA;AAAA,wCAE3Bm7B,CAAW;AAAA;AAAA,4BAEvB33C,CAAQ,IAAI2Q,CAAK;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,uCAMNgnC,EAAc,CAAC;AAAA,0CACZv9B,EAAa,yBAA0B,IAAKu9B,CAAW,CAAC;AAAA,2CACvDv9B,EAAa,yBAA0B,IAAKu9B,CAAW,CAAC;AAAA;AAAA,0BAEzEA,EAAc,CAAC;AAAA;AAAA;AAAA,+BAGVnnC,EAAOmnC,CAAW,UAAUnnC,CAAI;AAAA,+CAChB4J,EAC3B,mBACA,OAAO5J,EAAOmnC,CAAW,IACzBA,CACF,CAAC;AAAA,oCACiBnnC,EAAOmnC,CAAW,QAAQv9B,EAAa,gBAAiB,SAAUw9B,CAAQ,CAAC;AAAA,oBAC3FC,CAAO;AAAA;AAAA,gBAEXR,CAAG;AAAA;AAAA;AAAA,cAKjB,CACF,EAcMpC,GAAiCv0B,GACrC,GAAGA,EAAW,MAAM,IAAIA,EAAW,QAAQ,IAAIA,EAAW,OAAO,IAAIA,EAAW,YAAY,MAAM,GAE9Fw0B,GAA4Cx0B,GAChD,GAAGu0B,GAA8Bv0B,CAAU,CAAC,IAAIA,EAAW,eAAe,GAEtEy0B,GAAwCz0B,GAC5C,GAAGu0B,GAA8Bv0B,CAAU,CAAC,IAAIA,EAAW,YAAY,IAAIA,EAAW,SAAS,GAE3F00B,GAA6B10B,IAA+D,CAChG,OAAQA,EAAW,OACnB,QAAS,CAAC,SAAU,QAAS,aAAc,YAAY,EAAEA,EAAW,QAAkB,EACtF,SAAUA,EAAW,UACrB,YAAaA,EAAW,aACxB,QAASA,EAAW,QACpB,KAAMA,EAAW,IACnB,GAMM20B,GAA+B,CACnC76C,EACA+kB,EACAjO,EACAoP,IACgB,CAChB,GAAM,CAAC8gB,EAAoBxhB,CAAW,EAAI80B,GACxCv1B,EACAmB,EACApP,CACF,EACMN,EAAIsJ,EAAc,IAAKiF,EAAM,SAAUA,EAAM,KAAK,MAAM,EACxDvf,EAAWgR,EAAE,KAAK,MAElBomC,EAAM,kBACRC,EAAM,GACN7V,EAAmB,gBACrB6V,GAAO,YAAYr3C,CAAQ,yBAE3Bq3C,GAAO,YAAYr3C,CAAQ,oCAE7B,GAAM,CAAC8a,EAAiByN,EAAU0uB,EAASP,EAAmBC,CAAiB,EAAI5B,GACjF/0B,EACAwhB,CACF,EACA1mB,EAAgB,KAAK,GAAGf,EAA2BwF,EAAM,KAAMS,CAAW,CAAC,EAC3E,IAAMiI,EAAwD,CAAC,MAAM,EACrE,MAAO,CACL,KAAAztB,EACA,YAAa,CACX,KAAM,GAAGkmB,EAAW,QAAQ,IAAIu2B,CAAO,IAAIP,CAAiB,IAAIC,CAAiB,GACjF,kBAAA1uB,CACF,EACA,WAAY,KAAO,CACjB,QAAS,CAAC,CAAE,KAAMjI,EAAa,SAAUT,EAAM,QAAS,CAAC,EACzD,cAAe,CAAE,EAAG,KAAK,KAAKrQ,EAAU,KAAK8Q,CAAW,EAAI,EAAuB,CAAE,EACrF,gBAAAlF,CACF,GACA,gBAAkBuF,GAChB20B,GACE30B,EACArP,EACAuO,EAAM,KAAK,OACXS,EAAY,OACZwhB,EACA4V,EACAC,EACA,EACA9uB,EACA0uB,EACAP,EACAC,CACF,CACJ,CACF,EAEarB,GAA8B50B,GAA+D,CACxG,IAAMo3B,EAAmBp3B,EAAW,oBAAiC,EAE/Dq3B,EAAO3C,GAA0B10B,CAAU,EAEjD,GAAIq3B,EAAK,WAAa,EACpB,MAAM,IAAI,MAAM,wEAAwE,EAE1F,IAAMC,EAAwB,CAAE,gBAAAF,EAAiB,GAAGC,EAAM,SAAU,EAAG,EACvE,MAAO,CAAE,GAAGC,EAAuB,SAAU9C,GAAyC8C,CAAqB,CAAE,CAC/G,EAEazC,GAAc,CAAC/1C,EAAyBkhB,IAA4C,CAC/F9B,GAAepf,EAAQ,MAAM,EAC7BA,EAAQ,QAAQ61C,GAA6B,cAAe71C,EAAQ,OAAO,CAAC,EAAG,GAAOkhB,CAAU,CAAC,CACnG,EAEM80B,GAAuB,CAC3B,QAAS,GACT,SAAU,EACV,gBAAiB,GACjB,YAAa,CAAC,EACd,QAAS,CAAC,EACV,KAAM,CAAC,EACP,aAAc,EACd,UAAW,CAAC,CACd,EAEaC,GAAoC/0B,GAA+D,CAC9G,IAAM+K,EAAS/K,EAAW,OAC1B,MAAO,CAAE,OAAA+K,EAAQ,GAAG+pB,GAAsB,SAAU/pB,CAAO,CAC7D,EAEaiqB,GAAoB,CAACl2C,EAAyBkhB,IAA4C,CACrG9B,GAAepf,EAAQ,MAAM,EAC7BA,EAAQ,QAAQ61C,GAA6B,oBAAqB71C,EAAQ,OAAO,CAAC,EAAG,GAAMkhB,CAAU,CAAC,CACxG,EAOMi1B,GAA2B,CAC/Bn7C,EACA+kB,EACAjO,EACAoP,IACgB,CAChB,GAAM,CAAC8gB,EAAoBxhB,CAAW,EAAI80B,GACxCv1B,EACAmB,EACApP,CACF,EACM8lC,EAAM;AAAA;AAAA,MAGNC,EAAM,GACNrmC,EAAIsJ,EAAc,IAAKiF,EAAM,SAAUA,EAAM,KAAK,MAAM,EACxD0I,EAAwD,CAAC,MAAM,EAC/D,CAACnN,EAAiByN,EAAU0uB,EAASP,EAAmBC,CAAiB,EAAI5B,GACjF/0B,EACAwhB,CACF,EACA,OAAA1mB,EAAgB,KAAK,GAAGf,EAA2BwF,EAAM,KAAMS,CAAW,CAAC,EACpE,CACL,KAAAxlB,EACA,YAAa,CACX,KAAM,GAAGkmB,EAAW,QAAQ,IAAIu2B,CAAO,IAAIP,CAAiB,IAAIC,CAAiB,GACjF,kBAAA1uB,CACF,EACA,WAAY,KAAO,CACjB,QAAS,CAAC,CAAE,KAAMjI,EAAa,SAAUT,EAAM,QAAS,CAAC,EACzD,cAAe,CAAE,EAAG,KAAK,KAAKrQ,EAAU,KAAK8Q,CAAW,EAAI,EAAuB,CAAE,EACrF,gBAAAlF,CACF,GACA,gBAAkBuF,GAChB20B,GACE30B,EACArP,EACAuO,EAAM,KAAK,OACXS,EAAY,OACZwhB,EACA4V,EACAC,EACA93B,EAAM,WAAa,GAAmB,OAAS,KAC/CgJ,EACA0uB,EACAP,EACAC,CACF,CACJ,CACF,EAEaf,GAAU,CAACp2C,EAAyBkhB,IAAwC,CACvF9B,GAAepf,EAAQ,MAAM,EAC7BA,EAAQ,QAAQm2C,GAAyB,UAAWn2C,EAAQ,OAAO,CAAC,EAAG,GAAOkhB,CAAU,CAAC,CAC3F,EAEam1B,GAA0Bn1B,GAA2D,CAChG,IAAMu3B,EAAev3B,EAAW,cAC1BjP,EAAYiP,EAAW,UAEvBq3B,EAAO3C,GAA0B10B,CAAU,EAEjD,GAAIu3B,IAAiB,EACnB,MAAM,IAAI,MAAM,6DAA6D,EAE/E,GAAIF,EAAK,WAAa,EACpB,MAAM,IAAI,MAAM,oEAAoE,EAEtF,IAAMG,EAAoB,CAAE,aAAAD,EAAc,UAAAxmC,EAAW,GAAGsmC,EAAM,SAAU,EAAG,EAC3E,MAAO,CAAE,GAAGG,EAAmB,SAAU/C,GAAqC+C,CAAiB,CAAE,CACnG,EAEapC,GAAgCp1B,GAA2D,CACtG,IAAM+K,EAAS/K,EAAW,OAC1B,MAAO,CAAE,OAAA+K,EAAQ,GAAG+pB,GAAsB,SAAU/pB,CAAO,CAC7D,EAEasqB,GAAgB,CAACv2C,EAAyBkhB,IAAwC,CAC7F9B,GAAepf,EAAQ,MAAM,EAC7BA,EAAQ,QAAQm2C,GAAyB,gBAAiBn2C,EAAQ,OAAO,CAAC,EAAG,GAAMkhB,CAAU,CAAC,CAChG,IChgBA,IAuBM9B,GAqDAu5B,GA0JOC,GAKAC,GA3ObC,GAAA/9C,EAAA,kBAGAkS,IAEA8C,IACAkK,KAGAmB,IAcMgE,GAAiB,CAACpZ,EAA+Bkb,IAAgD,CACrG,GAAIlb,EAAO,OAAS,GAAKA,EAAO,OAAS,EACvC,MAAM,IAAI,MAAM,0CAA0C,EAE5D,GAAIA,EAAO,SAAW,GAAKA,EAAO,CAAC,EAAE,OAASA,EAAO,CAAC,EAAE,KACtD,MAAM,IAAI,MAAM,oDAAoD,EAEtE,GAAIA,EAAO,SAAW,GAAKA,EAAO,CAAC,EAAE,WAAaA,EAAO,CAAC,EAAE,SAC1D,MAAM,IAAI,MAAM,kDAAkD,EAEpE,GAAIA,EAAO,CAAC,EAAE,WAAa,GAAkBA,EAAO,OAAS,EAC3D,MAAM,IAAI,MAAM,2DAA2D,EAE7E,GAAIA,EAAO,CAAC,EAAE,KAAK,SAAW,GAAKA,EAAO,CAAC,EAAE,KAAK,SAAW,GAAKA,EAAO,CAAC,EAAE,KAAK,SAAWA,EAAO,CAAC,EAAE,KAAK,OACzG,MAAM,IAAI,MAAM,uFAAuF,EAGzG,GAAIA,EAAO,OAAS,EAAG,CAErB,GAAIA,EAAO,CAAC,EAAE,WAAaA,EAAO,CAAC,EAAE,SACnC,MAAM,IAAI,MAAM,kDAAkD,EAGpE,GAAIA,EAAO,CAAC,EAAE,KAAK,SAAWA,EAAO,CAAC,EAAE,KAAK,OAC3C,MAAM,IAAI,MAAM,sDAAsD,EAExE,GAAI,CAACA,EAAO,CAAC,EAAE,KAAK,IAAI,CAACyf,EAAGrqB,IAAMqqB,IAAMzf,EAAO,CAAC,EAAE,KAAK5K,CAAC,CAAC,EAAE,OAAO,CAACkS,EAAGC,IAAMD,GAAKC,EAAG,EAAI,EACtF,MAAM,IAAI,MAAM,uDAAuD,CAE3E,CAEA,GAAI2T,EAAW,UAAY,EAAG,CAE5B,GAAIlb,EAAO,CAAC,EAAE,KAAK,SAAW,GAAMA,EAAO,CAAC,EAAE,KAAK,SAAW,GAAKA,EAAO,CAAC,EAAE,KAAK,CAAC,IAAM,EACvF,MAAM,IAAI,MAAM,oDAAoD,EAEtE,GACE,CAACA,EAAO,CAAC,EAAE,KAAK,IAAI,CAACyf,EAAG,IAAM,IAAMvE,EAAW,MAAQuE,IAAMzf,EAAO,CAAC,EAAE,KAAK,CAAC,CAAC,EAAE,OAAO,CAACsH,EAAGC,IAAMD,GAAKC,EAAG,EAAI,EAE7G,MAAM,IAAI,MAAM,wFAAwF,EAG1G,GAAIvH,EAAO,CAAC,EAAE,KAAK,SAAWA,EAAO,CAAC,EAAE,KAAK,OAC3C,MAAM,IAAI,MAAM,6EAA6E,EAE/F,IAAM+yC,EAAK/yC,EAAO,CAAC,EAAE,KAAKkb,EAAW,IAAI,EACnC83B,EAAKhzC,EAAO,CAAC,EAAE,KAAKkb,EAAW,IAAI,EACzC,GAAIA,EAAW,UAAY,KAAK,KAAK63B,EAAKC,CAAE,GAAK93B,EAAW,UAAY,KAAK,KAAK63B,GAAMC,EAAK,GAAK,CAAC,EACjG,MAAM,IAAI,MAAM,+EAA+E,CAEnG,CACF,EAEML,GAAoC,CACxC3yC,EACAkb,IACgB,CAChB,IAAMhQ,EAAOxB,EAAU,cAAcwR,EAAW,KAAMlb,EAAO,CAAC,EAAE,KAAK,MAAM,EACrEmuB,EAAYnuB,EAAO,CAAC,EAAE,SACtB0lC,EAAWvX,IAAc,EACzB3T,EAAcxa,EAAO,CAAC,EAAE,KACxBxF,EAAWwF,EAAO,CAAC,EAAE,SACrB8a,EAAapR,EAAU,KAAK8Q,CAAW,EACvCy4B,EAAW9kB,IAAc,GAAiBA,IAAc,EACxDrU,EAAam5B,EAAW,CAAC,KAAK,KAAKvpC,EAAU,KAAK1J,EAAO,CAAC,EAAE,IAAI,EAAI,CAAC,CAAC,EAAIA,EAAO,CAAC,EAAE,KACpFurC,EAAavrC,EAAO,CAAC,EAAE,KACvBkzC,EAAiBlzC,EAAO,OAAS,EAAIA,EAAO,CAAC,EAAI,OACjDmzC,EAAiBD,EACnBD,EACE,CAAC,KAAK,KAAKvpC,EAAU,KAAKwpC,EAAe,IAAI,EAAI,CAAC,CAAC,EACnDA,EAAe,KACjB,OAGEE,EAAuB7H,EAAW,SAAW,GAAMA,EAAW,SAAW,GAAKA,EAAW,CAAC,IAAM,EAChG8H,EAAsBD,IAAyB,IAAS7H,EAAW,SAAW,EAG9E+H,EAAgB9+B,EAAiBsG,CAAU,EAC3Cy4B,EAAgBH,IAAyB,CAACH,GAAYK,IAAkB,GACxEj+B,EAAak+B,EAAgBD,EAAgB,EAC7CE,EAAiBD,GAAiB,CAACN,EAAWK,EAAgB,EAC9Dv5B,EAAQjF,EAAc,QAASm+B,KAA6B9kB,EAAWrU,EAAW,OAAQ05B,CAAc,EACxGntB,EAAQvR,EAAc,QAASta,EAAU+wC,EAAW,MAAM,EAC1DhG,EAAY2N,EACdp+B,EAAc,aAAcm+B,KAA6B9kB,EAAWglB,EAAgB,MAAM,EAC1F,OACEn8B,EAASjC,EAAe,SAAUva,EAAUggB,EAAY,OAAQnF,CAAU,EAC1Ekc,EAAiB,CAACxX,EAAOsM,CAAK,EAChCkf,GACFhU,EAAe,KAAKgU,CAAS,EAE/B,IAAM9D,EAAc,CAAC3nB,EAAYyxB,CAAU,EACvC2H,GACFzR,EAAY,KAAK0R,CAAe,EAElC,IAAM79B,EAAoC,CACxC,CAAE,QAAuB,KAAMwF,EAAazF,CAAW,EACvD,CAAE,QAAuB,KAAMnK,CAAK,EACpC,CAAE,QAAuB,KAAMgQ,EAAW,SAAU,EACpD,GAAG3G,EAA2B,GAAGktB,EAAajnB,CAAW,CAC3D,EACMI,EAAmBC,GAA+B,CACtD,IAAMkI,EAA8B,CAClC,CAAE,KAAM,cAAe,KAAM,KAAM,EACnC,CAAE,KAAM,OAAQ,KAAM,KAAM,EAC5B,CAAE,KAAM,aAAc,KAAM,KAAM,CACpC,EACA,MAAO;AAAA,QACHlI,EAAa,iBAAiBkI,CAAQ,EAAE,iBAAiB,GAAGwO,EAAgBva,CAAM,CAAC;AAAA,QACnF6D,EAAa,UAAU,CAAC;AAAA,YACpBA,EAAa,sCAAsC,sBAAsB,CAAC;AAAA,iCACrD7D,EAAO,gBAAgB,YAAY,CAAC;AAAA;AAAA;AAAA,YAIrDi8B,EACK;AAAA,0BACKl5B,EAAM,YAAY,gBAAgB,CAAC;AAAA,0BACnC2rB,EAAW,oBAAsB,mBAAmB;AAAA,4BAClDrwB,IAAe,EAAI,wBAA0B,OAAO,IAE3D,iBAAiB0E,EAAM,YAAY,YAAY,CAAC,GAEvD;AAAA;AAAA;AAAA,YAIEq5B,EAEK,oBAAoB/sB,EAAM,YAAY,GAAG,CAAC,GACxCgtB,EAEF;AAAA,gCACWr8B,EAAO,WAAW,iBAAkB,eAAe,CAAC;AAAA,+BACrDqP,EAAM,YAAY,aAAa,CAAC,IAG1C;AAAA,iCACYA,EAAM,KAAK,OAAO;AAAA,0BACzBA,EAAM,WAAW,gBAAiB,eAAe,CAAC;AAAA,cAC9DA,EAAM,WAAW,gBAAiB,gBAAiB,OAAO,CAAC;AAAA,+BAC1CA,EAAM,aAAa,eAAe,CAAC,GAEpD;AAAA;AAAA;AAAA,YAIEkf,EACE6N,EAEEH,EACK;AAAA,yCACgB1N,EAAU,YAAY,GAAG,CAAC;AAAA,wCAC3BG,EAAW,+BAAiC,8BAA8B;AAAA,yDAGzF,0BAA0BH,EAAU,YAAY,GAAG,CAAC,GAEpD8N,EAELJ,EACK;AAAA,yCACgBj8B,EAAO,WAAW,iBAAkB,eAAe,CAAC;AAAA,yCACpDuuB,EAAU,YAAY,sBAAsB,CAAC;AAAA,wCAC9CG,EAAW,+BAAiC,8BAA8B;AAAA,6EAGzF;AAAA,yCACgB1uB,EAAO,WAAW,iBAAkB,eAAe,CAAC;AAAA,yCACpDuuB,EAAU,YAAY,kBAAkB,CAAC,IAI9D0N,EACK;AAAA,0CACiB5sB,EAAM,gBAAgB,eAAe,CAAC;AAAA,yCACvCkf,EAAU,YAAY,uBAAuB,CAAC;AAAA,uCAChDG,EAAW,+BAAiC,8BAA8B;AAAA,+EAGxF,0BAA0BH,EAAU,aAAa,eAAe,CAAC,IAIrE,0BAA0B0N,EAAYvN,EAAW,MAAQ,MAAS3rB,EAAM,KAAK,KAAK,MAEzF;AAAA;AAAA,QAEN/C,EAAO,YAAY,aAAc,GAAGA,EAAO,KAAK,KAAK,4CAA4C,CAAC;AAAA,QAExG,EACA,MAAO,CACL,KAAM,mBACN,YAAa,CACX,KAAMkE,EAAW,SACjB,kBAAmBqqB,EAAY,CAAC,OAAQ,OAAQ,MAAM,EAAI,CAAC,OAAQ,MAAM,CAC3E,EACA,gBAAA3qB,EACA,WAAY,KAAO,CACjB,QAAS,CAAC,CAAE,KAAMJ,EAAa,SAAAhgB,CAAS,CAAC,EACzC,cAAe,CAAE,EAAG,KAAK,KAAKsgB,EAAazF,EAAa,EAAE,EAAG,EAAG,EAAG,EAAG,CAAE,EACxE,gBAAAC,CACF,EACF,CACF,EAEas9B,GAAmB,CAAC54C,EAAyBkhB,IAAgD,CACxG9B,GAAepf,EAAQ,OAAQkhB,CAAU,EACzClhB,EAAQ,QAAQ24C,GAAkC34C,EAAQ,OAAQkhB,CAAU,CAAC,CAC/E,EAEa23B,GAAmC33B,GAC9ClH,EAA4B,CAAE,KAAMkH,EAAW,KAAgB,UAAWA,EAAW,SAAoB,CAAC,IC5O5G,IAgBMu4B,GAUAC,GAuCOC,GAjEbC,GAAA7+C,EAAA,kBAGAyJ,KAEAyI,IAGAmO,IAQMq+B,GAAwB,CAACtoC,EAAe0oC,EAAeC,IAAwB,CACnF,IAAMC,EAAiB5oC,IAAU0oC,EAC3BG,EAA8B7oC,EAAQ0oC,GAASC,EAAQ,EACvDG,EAA8B9oC,EAAQ0oC,GAASC,EAAQ,EAE7D,GAAIC,GAAkBC,GAA+BC,EACnD,MAAM,IAAI,MAAM,2CAA2C,CAE/D,EAEMP,GAAyB,CAACvoC,EAAe0oC,EAAeC,EAAet5C,IAAoC,CAC/G,IAAM8T,EAAc,KAAK,IAAI,KAAK,MAAMulC,EAAQ1oC,GAAS2oC,CAAK,CAAC,EACzDt5B,EAAwB,CAAClM,CAAW,EACpCwM,EAAaxM,EACbgH,EAAoC,CACxC,CAAE,QAAuB,KAAMwF,CAAW,EAC1C,CAAE,KAAMtgB,EAAU,KAAM2Q,CAAM,EAC9B,CAAE,KAAM3Q,EAAU,KAAMs5C,CAAM,EAC9B,GAAGv/B,EAA2BiG,CAAW,CAC3C,EAEMI,EAAmBC,GAA+B,CACtD,IAAM7D,EAASjC,EAAe,SAAUva,EAAUggB,EAAY,MAAM,EAC9D05B,EAAWl9B,EAAO,KAAK,MACvB+L,EAA8B,CAClC,CAAE,KAAM,aAAc,KAAM,KAAM,EAClC,CAAE,KAAM,QAAS,KAAMmxB,CAAmC,EAC1D,CAAE,KAAM,QAAS,KAAMA,CAAmC,CAC5D,EACA,MAAO;AAAA,UACDr5B,EAAa,iBAAiBkI,CAAQ,EAAE,iBAAiB/L,CAAM,CAAC;AAAA,UAChE6D,EAAa,UAAU,CAAC;AAAA,UACxBA,EAAa,sCAAsC,qBAAqB,CAAC;AAAA,gDACnCq5B,CAAQ;AAAA,QAEtD,EAEA,MAAO,CACL,KAAM,QACN,YAAa,CAAE,KAAM,GAAG15C,CAAQ,EAAG,EACnC,gBAAAogB,EACA,WAAY,KAAO,CACjB,QAAS,CAAC,CAAE,KAAMJ,EAAa,SAAAhgB,CAAS,CAAC,EACzC,cAAe,CAAE,EAAG,KAAK,KAAKsgB,EAAa,EAAuB,CAAE,EACpE,gBAAAxF,CACF,EACF,CACF,EAEaq+B,GAAS35C,GAAkC,CACtD,IAAImR,EAAQ,EACR0oC,EAAQ,EACRC,EAAQ,EACR95C,EAAQ,OAAO,CAAC,EAAE,WAAa,GACjCmR,EAAQnR,EAAQ,OAAO,CAAC,EAAE,cAAc,EAAE,CAAC,EAC3C65C,EAAQ75C,EAAQ,OAAO,CAAC,EAAE,cAAc,EAAE,CAAC,EAC3C85C,EAAQ95C,EAAQ,OAAO,CAAC,EAAE,cAAc,EAAE,CAAC,GAClCA,EAAQ,OAAO,CAAC,EAAE,WAAa,IACxCmR,EAAQnR,EAAQ,OAAO,CAAC,EAAE,gBAAgB,EAAE,CAAC,EAC7C65C,EAAQ75C,EAAQ,OAAO,CAAC,EAAE,gBAAgB,EAAE,CAAC,EAC7C85C,EAAQ95C,EAAQ,OAAO,CAAC,EAAE,gBAAgB,EAAE,CAAC,GAE3CxD,EAAI,OAAO,sBACbi9C,GAAsBtoC,EAAO0oC,EAAOC,CAAK,EAG3C95C,EAAQ,QAAQ05C,GAAuBvoC,EAAO0oC,EAAOC,EAAO95C,EAAQ,OAAO,CAAC,EAAE,QAAQ,EAAG,CAAE,OAAQ,CAAC,CAAE,CAAC,CACzG,ICnFA,IAuBMm6C,GAyDAC,GAgHOC,GAGAC,GAnMbC,GAAAx/C,EAAA,kBAGAkS,IAEA8C,IACAkK,KAGAmB,IAcM++B,GAAyB,CAACK,EAAmBC,EAAal3C,EAAW7C,IAAwB,CACjG,GAAI85C,IAAc,QAAU95C,IAAS,OAASA,IAAS,OAASA,IAAS,MACvE,MAAM,IAAI,MAAM,SAASA,CAAI,oCAAoC85C,CAAS,GAAG,EAG/E,IAAME,EAAa;AAAA;AAAA;AAAA,qCAIbC,EAAW;AAAA;AAAA,yDAEsCF,CAAG;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,iBAQ1D,OAAQD,EAAW,CACjB,IAAK,OACH,MAAO,GAAGC,CAAG,IAAIl3C,CAAC,IACpB,IAAK,MACH,OAAI7C,IAAS,OAASA,IAAS,MACtB,cAAc+5C,CAAG,aAAa/5C,CAAI,KAAK6C,CAAC,MAIxC;AAAA,gBACCm3C,CAAU,WAAWh6C,CAAI,kBAAkB6C,CAAC,IAAIo3C,CAAQ,GAEpE,IAAK,MACH,OAAIj6C,IAAS,OAASA,IAAS,MACtB,cAAc+5C,CAAG,aAAa/5C,CAAI,KAAK6C,CAAC,MAIxC;AAAA,kBACGm3C,CAAU,gCAAgCn3C,CAAC,KAAKo3C,CAAQ,GAEtE,IAAK,MACH,OAAIj6C,IAAS,OAASA,IAAS,MACtB,cAAc+5C,CAAG,aAAa/5C,CAAI,KAAK6C,CAAC,MAIxC,GAAGm3C,CAAU,eAAeh6C,CAAI,iBAAiB6C,CAAC,KAAKo3C,CAAQ,GAE1E,IAAK,MAEH,MAAO,GAAGD,CAAU,YAAYh6C,CAAI,kBAAkB6C,CAAC,KAAKo3C,CAAQ,GAEtE,QACE,MAAM,IAAI,MAAM,aAAaH,CAAS,oBAAoB,CAC9D,CACF,EAEMJ,GAA6B,CAACp0C,EAA+Bkb,IAAiD,CAClH,IAAMpB,EAAa9Z,EAAO,CAAC,EAAE,KACvB4jC,EAAe5jC,EAAO,CAAC,EAAE,KACzBwa,EAAcV,EAEdzE,EAAa,EACbyF,EAAa,KAAK,KAAKpR,EAAU,KAAKk6B,CAAY,EAAIvuB,CAAU,EAChEu/B,EAAqBhR,EAAaA,EAAa,OAAS,CAAC,EACzDiR,EAAqBnrC,EAAU,kBAAkBoQ,EAAY86B,CAAkB,EAE/Et/B,EAAoC,CACxC,CAAE,QAAuB,KAAMwF,CAAW,EAC1C,CAAE,QAAuB,KAAM85B,CAAmB,EAClD,CAAE,QAAuB,KAAMC,CAAmB,EAClD,GAAGtgC,EAA2BvU,EAAO,CAAC,EAAE,KAAMA,EAAO,CAAC,EAAE,KAAMwa,CAAW,CAC3E,EAEMI,EAAmBC,GAA+B,CACtD,IAAMnE,EAAU5B,EAAc,UAAW9U,EAAO,CAAC,EAAE,SAAUA,EAAO,CAAC,EAAE,KAAK,MAAM,EAC5E80C,EAAUhgC,EAAc,UAAW9U,EAAO,CAAC,EAAE,SAAUA,EAAO,CAAC,EAAE,KAAK,OAAQqV,CAAU,EACxF2B,EACJkE,EAAW,YAAc,QAAUA,EAAW,YAAc,GACxDlG,GAAqB,SAAUhV,EAAO,CAAC,EAAE,SAAUwa,EAAY,MAAM,EACrEzF,EAAe,SAAU/U,EAAO,CAAC,EAAE,SAAUwa,EAAY,OAAQnF,CAAU,EAEjF,MAAO;AAAA,QACHwF,EACC,gBAAgB,cAAe,KAAK,EACpC,gBAAgB,uBAAwB,KAAK,EAC7C,gBAAgB,uBAAwB,KAAK,EAC7C,iBAAiBnE,EAASo+B,EAAS99B,CAAM,CAAC;AAAA,QAC3C6D,EAAa,UAAU,CAAC;AAAA,UACtBA,EAAa,sCAAsC,sBAAsB,CAAC;AAAA;AAAA,QAE5EK,EAAW,YAAc,MAAM;AAAA,cACzBxR,EAAU,KAAKk6B,CAAY,CAAC;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,QAkBlC1oB,EAAW,YAAc,MAAM;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,MAUjClb,EAAO,CAAC,EAAE,KAAK,SAAW,EACtB;AAAA;AAAA,4CAGA;AAAA;AAAA,8FAGN;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,MAiBEm0C,GACAj5B,EAAW,UACX,0BACA,QACAlE,EAAO,KAAK,KACd,CAAC;AAAA;AAAA;AAAA,QAIH,EACA,MAAO,CACL,KAAM,YACN,YAAa,CACX,KAAM,GAAGkE,EAAW,QAAQ,IAAIA,EAAW,SAAS,GACpD,kBAAmB,CAAC,OAAQ,MAAM,CACpC,EACA,WAAY,KAAO,CACjB,QAAS,CAAC,CAAE,KAAMV,EAAa,SAAUxa,EAAO,CAAC,EAAE,QAAS,CAAC,EAC7D,cAAe,CAAE,EAAG,KAAK,KAAK8a,EAAa,EAAuB,CAAE,EACpE,gBAAAxF,CACF,GACA,gBAAAsF,CACF,CACF,EAEay5B,GAA4Bn5B,GACvClH,EAA4B,CAAE,UAAWkH,EAAW,SAAoB,CAAC,EAE9Do5B,GAAY,CAACt6C,EAAyBkhB,IAA0C,CAC3FlhB,EAAQ,QAAQo6C,GAA2Bp6C,EAAQ,OAAQkhB,CAAU,EAAG,CACtE,OAAQ,CAAClhB,EAAQ,OAAO,CAAC,EAAGA,EAAQ,OAAO,CAAC,CAAC,EAC7C,QAAS,CAAC,CACZ,CAAC,CACH,ICxMA,IA6CM+6C,GAuCAC,GAaA57B,GA8DA67B,GAUAC,GAoDAC,GAmCAC,GAaAC,GA2BAC,GA2BAC,GA4BAC,GAwCAC,GAWAC,GAaAC,GA2DAC,GA0FAC,GA+EAC,GAoJAC,GAOOC,GAkBAC,GAhzBbC,GAAAnhD,EAAA,kBAGAkS,IAEA8C,IACAkK,KAGAmB,IAoCM2/B,GAAiB,CAACzP,EAAkBpqB,IAAuC,CAS/E,GARAoqB,EAAO,MACJ5uC,GACCA,EAAQ,IACP,IAAM,CACL,MAAM,IAAI,MAAM,oDAAoD,CACtE,EACJ,EAEI4uC,EAAO,OAAS,GAClB,GAAIpqB,EAAW,OAAS,UACtB,GACE,EACEoqB,EAAO,SAAW,GAClBA,EAAO,SAAW,GACjBA,EAAO,SAAW,GAAKA,EAAO,CAAC,IAAM,GAAKA,EAAO,CAAC,IAAM,GACxDA,EAAO,SAAW,GAAKA,EAAO,CAAC,IAAM,GAAKA,EAAO,CAAC,IAAM,GACxDA,EAAO,SAAW,GAAKA,EAAO,CAAC,IAAM,GAAKA,EAAO,CAAC,IAAM,GAG3D,MAAM,IAAI,MACR;AAAA,oGAEF,UAEOpqB,EAAW,OAAS,SAE3B,EACEoqB,EAAO,SAAW,GACjBA,EAAO,SAAW,GAAKA,EAAO,CAAC,IAAM,GAAKA,EAAO,CAAC,IAAM,GACxDA,EAAO,SAAW,GAAKA,EAAO,CAAC,IAAM,GAAKA,EAAO,CAAC,IAAM,GAG3D,MAAM,IAAI,MAAM,+DAA+D,EAIvF,EAEM0P,GAAe,CAAC1P,EAA2B/5B,EAAyBP,IAA2B,CACnGO,EAAK,MACF7U,GACEA,GAAS,GAAKA,EAAQsU,IACtB,IAAM,CACL,MAAM,IAAI,MAAM,qEAAqE,CACvF,EACJ,EACA,IAAMmrC,EAAY,IAAI,MAAMnrC,CAAI,EAAE,KAAK,CAAG,EAC1C,OAAAO,EAAK,QAAQ,CAAC7U,EAAOgZ,IAAWymC,EAAUz/C,CAAK,EAAI4uC,EAAO51B,CAAK,CAAE,EAC1DymC,CACT,EAEM/8B,GAAiB,CACrBpZ,EACAkb,EACAk7B,EACA9Q,EACA+Q,EACAC,IACS,CACT,GAAM,CAACC,EAAeC,EAAkBC,CAAe,EACrDL,EAAe,GAAK,CAAC,EAAG,EAAG,CAAC,EAAI,CAAC,GAAIp2C,EAAO,OAAS,EAAI,EAAI,GAAI,EAAE,EAC/DgL,EAAOhL,EAAO,CAAC,EAAE,KAAK,OAC5B,GAAIu2C,EAAgB,GAAKv2C,EAAO,OAASu2C,GAAiBv2C,EAAOu2C,CAAa,EAAE,KAAK,OAAS,EAC5Fv2C,EAAOu2C,CAAa,EAAE,gBAAgB,EAAE,QAAS7/C,GAAU4/C,EAAI,KAAK5/C,CAAK,CAAC,UACjEwkB,EAAW,0BAA4B,qBAChD,MAAM,IAAI,MAAM,2FAA2F,EAG7G,GACEs7B,EAAmB,GACnBx2C,EAAO,OAASw2C,GAChBx2C,EAAOw2C,CAAgB,EAAE,KAAK,SAAW,GACzCx2C,EAAOw2C,CAAgB,EAAE,KAAK,CAAC,EAAI,EACnC,CAEA,GADAx2C,EAAOw2C,CAAgB,EAAE,gBAAgB,EAAE,QAAS9/C,GAAU4uC,EAAO,KAAK5uC,CAAK,CAAC,EAE9E4uC,EAAO,SAAW,GAClBA,EAAO,SAAWt6B,GAClBorC,GAAgB,IAChB9Q,EAAO,SAAWpqB,EAAW,KAAK,OAElC,MAAM,IAAI,MAAM,6FAA6F,EAE/G65B,GAAezP,EAAQpqB,CAAU,EAC7BA,EAAW,KAAK,OAAS,GAC3B85B,GAAa1P,EAAQpqB,EAAW,KAAMlQ,CAAI,EAAE,QAAQ,CAACtU,EAAOgZ,IAAW41B,EAAO51B,CAAK,EAAIhZ,CAAM,CAEjG,CACA,GACE+/C,EAAkB,GAClBz2C,EAAO,OAASy2C,GAChBz2C,EAAOy2C,CAAe,EAAE,KAAK,SAAW,GACxCz2C,EAAOy2C,CAAe,EAAE,KAAK,CAAC,EAAI,IAElCz2C,EAAOy2C,CAAe,EAAE,iBAAiB,EAAE,QAAS//C,GAAU2/C,EAAM,KAAK,OAAO3/C,CAAK,CAAC,CAAC,EACnF2/C,EAAM,SAAW,GAAKA,EAAM,SAAWrrC,GAAQorC,GAAgB,IAAMC,EAAM,SAAWn7B,EAAW,KAAK,QACxG,MAAM,IAAI,MAAM,4FAA4F,EAIhH,GAAIA,EAAW,KAAK,OAAS,EAAG,CAC9B,GAAIoqB,EAAO,SAAW,GAAKA,EAAO,SAAWpqB,EAAW,KAAK,OAC3D,MAAM,IAAI,MAAM,0FAA0F,EAE5G,GAAIm7B,EAAM,SAAW,GAAKA,EAAM,SAAWn7B,EAAW,KAAK,OACzD,MAAM,IAAI,MAAM,8FAA8F,CAElH,CACA,GAAI,OAAOoqB,EAAW,KAAe,OAAO+Q,EAAU,KAAe/Q,EAAO,OAAS,GAAK+Q,EAAM,OAASrrC,EACvG,MAAM,IAAI,MAAM,yDAAyD,CAE7E,EAEMiqC,GAAyB,CAAC3tC,EAAWC,EAAWu1B,EAAWlS,IAA0B;AAAA;AAAA;AAAA;AAAA,eAI5EtjB,CAAC,QAAQC,CAAC;AAAA,gBACTqjB,CAAK,WAAWkS,CAAC;AAAA,gBACjBlS,CAAK,WAAWkS,CAAC,QAAQlS,CAAK,IAAIkS,CAAC;AAAA;AAAA,EAI7CoY,GAA6C,CACjDwB,EACA9rB,IAEA;AAAA,2DACyDA,CAAK,OAC7D,IAAM,CACL,OAAQ8rB,EAAwB,CAC9B,IAAK,aACH,MAAO;AAAA;AAAA,qBAEM9rB,CAAK,gBAAgBA,CAAK;AAAA;AAAA,cAEjCqqB,GAAuB,WAAY,iBAAkB,gBAAiBrqB,CAAK,CAAC;AAAA;AAAA,UAGpF,IAAK,qBACH,MAAO;AAAA,8BACeA,CAAK,uBAAuBA,CAAK;AAAA;AAAA;AAAA,qBAIzD,IAAK,uBACH,MAAO,WAAWA,CAAK,uBAAuBA,CAAK,YACrD,IAAK,gBACH,MAAO;AAAA;AAAA;AAAA,sBAGOqqB,GAAuB,WAAY,qBAAsB,oBAAqBrqB,CAAK,CAAC;AAAA,qBAEpG,IAAK,qBACH,MAAO;AAAA,6BACcA,CAAK,gBAAgBA,CAAK;AAAA,2BAC5BA,CAAK,gBAAgBA,CAAK,yBAAyBA,CAAK;AAAA,0BACzDA,CAAK;AAAA;AAAA,mCAEIA,CAAK,yBAAyBA,CAAK;AAAA,qBAEhE,IAAK,uBACH,MAAO,uBAAuBA,CAAK,YAAYA,CAAK;AAAA,uCACrBA,CAAK;AAAA,mCACTA,CAAK;AAAA;AAAA,sCAEFA,CAAK,uBAAuBA,CAAK,mBACjE,IAAK,aACH,MAAO,YAAYA,CAAK,uBAAuBA,CAAK,mBACtD,QACE,MAAM,IAAI,MAAM,6BAA6B8rB,CAAsB,mBAAmB,CAC1F,CACF,GAAG,EACH,IAEIvB,GAA8B,CAACwB,EAA0BP,EAAsBxrB,IACnF,6CAA6CA,CAAK,4BAA4BA,CAAK,MAClF,IAAM,CACL,OAAQ+rB,EAAa,CACnB,IAAK,oBACH,MAAO,yIAKT,IAAK,QACH,MAAO,2BACT,IAAK,OACH,MAAO,0BACT,IAAK,qBACH,MAAO,0KAKT,IAAK,SACL,QACE,GAAIP,EAAe,GACjB,MAAO,mLAOT,MAAM,IAAI,MAAM,gBAAgBO,CAAW,mBAAmB,CAClE,CACF,GAAG,EACH,IAEIvB,GAAY,CAACkB,EAAwB/qC,EAAyBP,IAA2B,CAC7F,IAAM4rC,EAAS,IAAI,MAAM5rC,CAAI,EAAE,KAAK,CAAC,EAAE,OAAO,IAAI,MAAMA,CAAI,EAAE,KAAK,CAAC,CAAC,EAC/D6rC,EAAWP,EAAI,SAAW,EAAIM,EAASN,EAAI,MAAM,EACvD,OAAI/qC,EAAK,OAAS,GAChBA,EAAK,QAAQ,CAAChO,EAAGnI,IAAM,CACrBwhD,EAAOr5C,CAAC,EAAIs5C,EAASzhD,CAAC,EACtBwhD,EAAOxhD,EAAI4V,CAAI,EAAI6rC,EAAStrC,EAAK,OAASnW,CAAC,CAC7C,CAAC,EACMwhD,GAEFC,CACT,EAEMxB,GAAkB,CACtBv7B,EACAwrB,EACA+Q,EACA9qC,IACa,CACb,IAAIiP,EAAwB,CAAC,EAC7B,GAAI67B,EAAM,OAAS,EACjB,GAAI9qC,EAAK,OAAS,EAAG,CAEnB,GADAuO,EAAW,QAASvc,GAAMid,EAAY,KAAKjd,CAAC,CAAC,EACzC,KAAK,IAAI,GAAGgO,CAAI,EAAIuO,EAAW,OACjC,MAAM,IAAI,MAAM,sBAAsB,EAExCvO,EAAK,QAAQ,CAAChO,EAAGnI,IAAOolB,EAAYjd,CAAC,EAAI84C,EAAMjhD,CAAC,CAAE,CACpD,MACEihD,EAAM,QAAS94C,GAAMid,EAAY,KAAKjd,CAAC,CAAC,MAErC,CACL,GAAI+nC,EAAO,SAAW,EACpB,MAAM,IAAI,MAAM,yCAAyC,EAEzD9qB,EAAcV,EAAW,IAAI,CAACpjB,EAAOgZ,IAAU,KAAK,MAAMhZ,EAAQ4uC,EAAO51B,CAAK,CAAC,CAAC,CAEpF,CACA,OAAO8K,CACT,EAEM86B,GAAoB,CAACx7B,EAA+BwrB,EAAkBpqB,IAAiC,CAC3G,IAAM47B,GAAiB,IAAM,CAC3B,OAAQ57B,EAAW,sBAAuB,CACxC,IAAK,aACH,OAAOA,EAAW,KAAK,OAAS,EAC5B,KAAK,IAAI,GAAGA,EAAW,KAAK,IAAK,GAAMoqB,EAAO,CAAC,CAAC,EAAG,OAAO,SAAS,EACnE,KAAK,IAAI,GAAGA,EAAQ,OAAO,SAAS,EAC1C,IAAK,cACH,OAAOpqB,EAAW,KAAK,OAAS,EAC5B,KAAK,IAAI,GAAGA,EAAW,KAAK,IAAK,GAAMoqB,EAAO,CAAC,CAAC,EAAG,OAAO,SAAS,EACnE,KAAK,IAAI,GAAGA,EAAQ,OAAO,SAAS,EAC1C,QACE,MAAM,IAAI,MAAM,4BAA4BpqB,EAAW,qBAAqB,mBAAmB,CACnG,CACF,GAAG,EACHoqB,EAAO,KAAK,EAAK,EAAGA,EAAO,MAAM,EACjC,IAAMyR,EAAsBj9B,EAAW,MAAM,EAC7C,OAAIoB,EAAW,KAAK,OAAS,GAC3BA,EAAW,KAAK,QAAS3d,GAAO+nC,EAAO/nC,CAAC,EAAIu5C,CAAc,EAC1D57B,EAAW,KAAK,QAAS3d,GAAOw5C,EAAoBx5C,CAAC,EAAI,KAAK,MAAMuc,EAAWvc,CAAC,EAAI+nC,EAAO/nC,CAAC,CAAC,CAAE,IAE/F+nC,EAAO,KAAKwR,EAAe,EAAGxR,EAAO,MAAM,EAC3CyR,EAAoB,QAAQ,CAACx5C,EAAGnI,IAAO2hD,EAAoB3hD,CAAC,EAAI,KAAK,MAAMmI,EAAI+nC,EAAOlwC,CAAC,CAAC,CAAE,GAErF2hD,CACT,EAEMxB,GAA4C,CAChDv+B,EACA8C,EACAU,EACAw8B,EACAC,IACW;AAAA,mEACsDjgC,EAAO,KAAK,OAAO,cAChFA,EAAO,KAAK,KACd,KAAKwD,EAAY,MAAM;AAAA,oCACSxD,EAAO,KAAK,KAAK,KAAKwD,EAAY,MAAM;AAAA,gCAC5CA,EAAY,MAAM;AAAA,6BACrBxD,EAAO,WAAW,iBAAkB,GAAG,CAAC;AAAA,sBAC/CpC,EAAa,kBAAmB,IAAKoiC,CAAY,CAAC;AAAA,wBAChDpiC,EAAa,eAAgB,IAAKqiC,CAAS,CAAC;AAAA,uBAC7CriC,EAAa,eAAgB,OAAOkF,EAAW,MAAM,GAAIm9B,CAAS,CAAC;AAAA;AAAA,kCAExDjgC,EAAO,KAAK,KAAK;AAAA;AAAA,gCAEnBpC,EAAa,uBAAwB,IAAKkF,EAAW,MAAM,CAAC;AAAA,iCAC3DlF,EAAa,wBAAyB,IAAK4F,EAAY,MAAM,CAAC;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,OAQzFg7B,GAAyC,CAC7Cz7B,EACA/C,EACA8C,EACAU,EACAw8B,EACAC,EACAC,IACW;AAAA,gEACmDlgC,EAAO,KAAK,OAAO,QAAQ+C,EAAM,KAAK,OAAO;AAAA,2BAClFA,EAAM,KAAK,OAAO;AAAA,gCACbS,EAAY,MAAM;AAAA,6BACrBxD,EAAO,WAAW,iBAAkB,GAAG,CAAC;AAAA;AAAA,sBAE/CpC,EAAa,kBAAmB,IAAKoiC,CAAY,CAAC;AAAA;AAAA;AAAA;AAAA,0BAI9CpiC,EAAa,eAAgB,IAAKqiC,CAAS,CAAC;AAAA,yBAC7CriC,EAAa,eAAgB,OAAOkF,EAAW,MAAM,GAAIm9B,CAAS,CAAC;AAAA,gCAC5DriC,EAAa,uBAAwB,IAAKkF,EAAW,MAAM,CAAC;AAAA,iCAC3DlF,EAAa,wBAAyB,IAAK4F,EAAY,MAAM,CAAC;AAAA;AAAA;AAAA,iBAG9E08B,CAAgB,4CAA4ClgC,EAAO,KAAK,KAAK;AAAA;AAAA;AAAA,wCAGtDA,EAAO,KAAK,KAAK;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,UAS/C+C,EAAM,WAAW,gBAAiB,IAAK,aAAa,CAAC;AAAA;AAAA;AAAA,OAIzD07B,GAAoB,CAAC17B,EAAsBD,IAA0C;AAAA,0CACjDC,EAAM,KAAK,OAAO;AAAA,gCAC5BD,EAAW,MAAM;AAAA,4BACrBC,EAAM,WAAW,gBAAiB,GAAG,CAAC;AAAA,gDAClBnF,EAAa,uBAAwB,IAAKkF,EAAW,MAAM,CAAC;AAAA;AAAA;AAAA;AAAA;AAAA,OAOtG47B,GAA4B,CAChC37B,EACAo9B,EACAC,EACAC,IAEAt9B,EAAM,KAAOs9B,EACT;AAAA,MACAt9B,EAAM,WAAW,gBAAiBo9B,EAAY,SAAS,CAAC;AAAA,MACxDp9B,EAAM,WAAW,gBAAiBq9B,EAAU,OAAO,CAAC;AAAA,EAEpD,GAEAzB,GAAwB,CAC5B57B,EACA/C,EACA8C,EACAo9B,EACAI,IACW,CAEX,GAAM,CAACF,EAAUG,EAAWC,EAAUL,CAAU,EAC9Cr9B,EAAW,SAAW,EAAI,CAAC,GAAI,EAAG,EAAG,EAAE,EAAa,CAAC,EAAG,EAAG,EAAG,CAAC,EAC3D8Q,EAAQ7Q,EAAM,KAAK,MACzB,MAAO;AAAA,wEAC+D6Q,CAAK;AAAA,2BAClD7Q,EAAM,KAAK,OAAO;AAAA,QACrCA,EAAM,WAAW,gBAAiBw9B,EAAW,mBAAmBz9B,EAAWy9B,CAAS,CAAC,QAAQ,CAAC;AAAA,QAC9Fx9B,EAAM,WAAW,gBAAiBy9B,EAAU,mBAAmB19B,EAAW09B,CAAQ,CAAC,QAAQ,CAAC;AAAA,QAC5F9B,GAA0B37B,EAAOo9B,EAAYC,EAAU,CAAC,CAAC;AAAA,eAClDr9B,EAAM,aAAa,eAAe,CAAC;AAAA;AAAA;AAAA,+CAGH/C,EAAO,KAAK,OAAO,QAAQ4T,CAAK;AAAA;AAAA,gBAE/DA,CAAK,sBAAsB2sB,CAAS;AAAA,gBACpC3sB,CAAK,sBAAsB4sB,CAAQ;AAAA,QAE3CN,EACI,yBAAyBp9B,EAAWy9B,CAAS,CAAC,8BAA8Bz9B,EAAW09B,CAAQ,CAAC;AAAA,iBAC3FF,CAAkB;AAAA,SAEvB,EACN;AAAA,8BACwBx9B,EAAWy9B,CAAS,CAAC;AAAA,8BACrBz9B,EAAW09B,CAAQ,CAAC;AAAA;AAAA;AAAA;AAAA;AAAA,2BAKvB19B,EAAW,OAAS,EAAI,uBAAuBq9B,CAAU,KAAO,GAAG;AAAA,0BACpEr9B,EAAW,OAAS,EAAI,uBAAuBs9B,CAAQ,KAAO,GAAG;AAAA,iBAC1ExsB,CAAK;AAAA,iBACLA,CAAK;AAAA,iBACLA,CAAK;AAAA,iBACLA,CAAK;AAAA,iBACLA,CAAK,gBAAgBA,CAAK;AAAA,iBAC1BA,CAAK,UAAUA,CAAK;AAAA,iBACpBA,CAAK,gBAAgBA,CAAK;AAAA,iBAC1BA,CAAK,UAAUA,CAAK;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,MAWrC,EAEMgrB,GAAuB,CAC3B77B,EACA/C,EACA8C,EACAU,EACA8qB,EACAgR,EACAmB,EACAP,EACAI,EACAI,IACW,CACX,IAAMC,EAAO79B,EAAW,SAAW,EAC7B89B,EAAS,GACT,CAACL,EAAWC,CAAQ,EAAIG,EAAO,CAAC,EAAG,CAAC,EAAIC,EAAS,CAAC,EAAG,CAAC,EAAI,CAAC,EAAG,CAAC,EAC/DhtB,EAAQ7Q,EAAM,KAAK,MACnB89B,EAAoC5lC,GAAwB,CAChE,IAAM6lC,EAAY7lC,IAAQslC,EAAY,MAAQ,MAC9C,MAAO;AAAA,WACAO,CAAS,qCAAqC/9B,EAAM,KAAK,OAAO,qBACnE/C,EAAO,KAAK,OACd,QAAQ4T,CAAK;AAAA,6BACU5T,EAAO,WAAW,iBAAkB/E,CAAG,CAAC;AAAA,2BAC1C2Y,CAAK,+DAA+D0a,EAAOrzB,CAAG,CAAC;AAAA,UAChGuI,EAAYvI,CAAG,CAAC,KAAK6H,EAAW7H,CAAG,CAAC,KAAKqkC,EAAIrkC,CAAG,CAAC,KAAKqkC,EAAIrkC,CAAG,CAAC,MAAM6H,EAAW,MAAM;AAAA,gCAC/D8Q,CAAK;AAAA;AAAA;AAAA,cAGvBssB,CAAgB,0CAA0Cp9B,EAAW7H,CAAG,CAAC;AAAA,mBACpEqlC,CAAkB;AAAA;AAAA,0BAEX1sB,CAAK,gBAAgBA,CAAK;AAAA;AAAA,gBAEpCktB,CAAS,KAAKltB,CAAK,oBAAoBA,CAAK;AAAA,gBAC5CktB,CAAS,WAAWA,CAAS,OAAOh+B,EAAW7H,CAAG,CAAC;AAAA,cAEjDylC,EACK;AAAA,mCAEER,EACF,UAAUI,CAAkB,IAE5B,GAAGQ,CAAS,iBAAiBA,CAAS,KAAKh+B,EAAW7H,CAAG,CAAC,SAEjE;AAAA;AAAA,kCAEkB8H,EAAM,KAAK,OAAO;AAAA,YACxCA,EAAM,WAAW,qBAAsB9H,EAAK,OAAO6lC,CAAS,GAAG,CAAC;AAAA,0BAEhE7lC,IAAQslC,EACJx9B,EAAM,aAAa,oBAAoB,EACvC,2DACN;AAAA;AAAA;AAAA,QAIR,EAEA,MAAO;AAAA,MACH89B,EAAiCN,CAAS,CAAC;AAAA,MAC3CM,EAAiCL,CAAQ,CAAC;AAAA,qCACX5sB,CAAK,cAAcA,CAAK;AAAA;AAAA,wBAErCA,CAAK,gBAAgBA,CAAK;AAAA,wBAC1BA,CAAK;AAAA,wBACLA,CAAK;AAAA,uBACNA,CAAK;AAAA,oBACR6sB,CAAW,wBAAwBA,CAAW,yBAC5DA,CACF,yBAAyBA,CAAW;AAAA,oBACpBA,CAAW,mBAAmBA,CAAW;AAAA,oBACzCA,CAAW,2BAA2BA,CAAW;AAAA,oBACjDA,CAAW,yBAAyBA,CAAW,0BAC7DA,CACF,0BAA0BA,CAAW;AAAA;AAAA;AAAA;AAAA,qCAIJ7sB,CAAK,sBAAsBA,CAAK,YAAYA,CAAK;AAAA,oBAClEA,CAAK;AAAA;AAAA;AAAA;AAAA,4CAImB5T,EAAO,KAAK,OAAO,QAAQ4T,CAAK;AAAA,yBACnD7Q,EAAM,KAAK,OAAO;AAAA;AAAA;AAAA,KAI3C,EAEM87B,GAAyB,CAC7B97B,EACA/C,EACA8C,EACAo9B,EACAI,IACW,CAEX,GAAM,CAACF,EAAUW,EAAUR,EAAWC,EAAUL,CAAU,EACxDr9B,EAAW,SAAW,EAAI,CAAC,GAAI,EAAG,EAAG,EAAG,EAAE,EAAa,CAAC,EAAG,EAAG,EAAG,EAAG,CAAC,EACjE8Q,EAAQ7Q,EAAM,KAAK,MACzB,MAAO;AAAA,wFAC+E6Q,CAAK;AAAA,2BAClE7Q,EAAM,KAAK,OAAO;AAAA,QACrCA,EAAM,WAAW,gBAAiBg+B,EAAU,qBAAqBj+B,EAAWi+B,CAAQ,CAAC,QAAQ,CAAC;AAAA,QAC9Fh+B,EAAM,WAAW,gBAAiBw9B,EAAW,sBAAsBz9B,EAAWy9B,CAAS,CAAC,QAAQ,CAAC;AAAA,QACjGx9B,EAAM,WAAW,gBAAiBy9B,EAAU,qBAAqB19B,EAAW09B,CAAQ,CAAC,QAAQ,CAAC;AAAA,QAC9F9B,GAA0B37B,EAAOo9B,EAAYC,EAAU,CAAC,CAAC;AAAA,eAClDr9B,EAAM,aAAa,eAAe,CAAC;AAAA;AAAA;AAAA,gDAGF/C,EAAO,KAAK,OAAO,QAAQ4T,CAAK;AAAA;AAAA,kBAE9DA,CAAK,sBAAsBmtB,CAAQ;AAAA,mBAClCntB,CAAK,sBAAsB2sB,CAAS;AAAA,kBACrC3sB,CAAK,sBAAsB4sB,CAAQ;AAAA,QAE7CN,EACI,6BAA6Bp9B,EAAWi+B,CAAQ,CAAC,oCAC/Cj+B,EAAWy9B,CAAS,CACtB,kCAAkCz9B,EAAW09B,CAAQ,CAAC;AAAA,eACnDF,CAAkB;AAAA,WAErB,EACN;AAAA;AAAA,gCAE0Bx9B,EAAWi+B,CAAQ,CAAC;AAAA,oCAChBj+B,EAAWy9B,CAAS,CAAC;AAAA,kCACvBz9B,EAAW09B,CAAQ,CAAC;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,2BAO3B19B,EAAW,OAAS,EAAI,uBAAuBq9B,CAAU,KAAO,GAAG;AAAA,0BACpEr9B,EAAW,OAAS,EAAI,uBAAuBs9B,CAAQ,KAAO,GAAG;AAAA;AAAA,kBAEzExsB,CAAK;AAAA,kBACLA,CAAK;AAAA,kBACLA,CAAK;AAAA,kBACLA,CAAK;AAAA,kBACLA,CAAK;AAAA,kBACLA,CAAK;AAAA,kBACLA,CAAK;AAAA,kBACLA,CAAK;AAAA,iBACNA,CAAK,kBAAkBA,CAAK;AAAA,iBAC5BA,CAAK,UAAUA,CAAK;AAAA,iBACpBA,CAAK,mBAAmBA,CAAK;AAAA,iBAC7BA,CAAK,UAAUA,CAAK;AAAA,iBACpBA,CAAK,kBAAkBA,CAAK;AAAA,iBAC5BA,CAAK,UAAUA,CAAK;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,MAgBrC,EAEMkrB,GAA0B,CAC9Bz7B,EACAa,EACAk7B,EACA4B,EACA3B,EACA4B,IACgB,CAChB,IAAMn+B,EAAaO,EAAY,KACzBi8B,EAAMlB,GAAU6C,EAAU/8B,EAAW,KAAMpB,EAAW,MAAM,EAE9DU,EAAc66B,GAAgBv7B,EAAYk+B,EAAa3B,EAAOn7B,EAAW,IAAI,EAC7EoqB,EAAS0S,EAAY,MAAM,EAC3BA,EAAY,SAAW,IACzB1S,EAASxrB,EAAW,IAAI,CAACpjB,EAAOgZ,IAAWhZ,IAAU,EAAI,EAAM8jB,EAAY9K,CAAK,EAAIhZ,CAAM,EACtFwkB,EAAW,wBAA0B,YACvCV,EAAc86B,GAAkBx7B,EAAYwrB,EAAQpqB,CAAU,IAGlE,IAAMlE,EAASjC,EAAe,SAAUsF,EAAY,SAAUG,EAAY,MAAM,EAC1ET,EAAQjF,EAAc,QAASuF,EAAY,SAAUP,EAAW,MAAM,EACtEgB,EAAapR,EAAU,KAAK8Q,CAAW,EACvC09B,EAAUp+B,EAAW,SAAWU,EAAY,QAAUV,EAAW,MAAM,CAAC2F,EAAGrqB,IAAMqqB,IAAMjF,EAAYplB,CAAC,CAAC,EACrG8hD,EAAmBh8B,EAAW,0BAA4B,qBAC1Do8B,EAAqBp8B,EAAW,mBAChC1gB,EAAWuf,EAAM,KAAK,MACtBa,EAAmBC,GAA+B;AAAA,QAElDq9B,EACI,GACA;AAAA,QACJhD,GAA2Ch6B,EAAW,wBAAyB1gB,CAAQ,CAAC;AAAA,SACvF,IAAM,CACP,OAAQ0gB,EAAW,KAAM,CACvB,IAAK,UACH,MAAO;AAAA,gBACHu6B,GAAkB17B,EAAOD,CAAU,CAAC;AAAA,gBACpCq7B,GAA4Bj6B,EAAW,YAAak7B,EAAc57C,CAAQ,CAAC;AAAA,gBAC3Eg7C,GACAz7B,EACA/C,EACA8C,EACAU,EACA8qB,EAAO,OACPgR,EAAI,OACJY,CACF,CAAC;AAAA,gBAEL,IAAK,SACH,MAAO;AAAA,gBACH3B,GAA0Cv+B,EAAQ8C,EAAYU,EAAa8qB,EAAO,OAAQgR,EAAI,MAAM,CAAC;AAAA,iBACpG,IAAM,CACP,GAAIx8B,EAAW,SAAW,GAAKA,EAAW,SAAW,EACnD,MAAO,GAAG67B,GAAsB57B,EAAO/C,EAAQ8C,EAAYo9B,EAAkBI,CAAkB,CAAC,GAC3F,GAAIx9B,EAAW,SAAW,GAAKA,EAAW,SAAW,EAC1D,MAAO,GAAG+7B,GAAuB97B,EAAO/C,EAAQ8C,EAAYo9B,EAAkBI,CAAkB,CAAC,GAEjG,MAAM,MAAM,kFAAkF,CAElG,GAAG,CAAC;AAAA,cAER,IAAK,QACH,MAAO;AAAA,eACJ,IAAM,CACP,GAAIx9B,EAAW,SAAW,GAAKA,EAAW,SAAW,EACnD,MAAO,GAAG87B,GACR77B,EACA/C,EACA8C,EACAU,EACA8qB,EACAgR,EACAp7B,EAAW,YACXg8B,EACAh8B,EAAW,mBACXA,EAAW,cACb,CAAC,GAED,MAAM,MAAM,2EAA2E,CAE3F,GAAG,CAAC;AAAA,cAEN,QACE,MAAM,MAAM,qBAAqB,CACrC,CACF,GAAG,CAAC;AAAA,OAEJ;AAAA,QACEL,EACC,gBAAgB,cAAe,KAAK,EACpC,gBAAgB,SAAU,MAAOyqB,EAAO,MAAM,EAC9C,gBAAgB,MAAO,MAAOgR,EAAI,MAAM,EACxC,iBAAiBv8B,EAAO/C,CAAM,CAAC;AAAA,QAChC6D,EAAa,UAAU,CAAC;AAAA,UACtBA,EAAa,sCAAsC,sBAAsB,CAAC;AAAA,UAE1Eq9B,EACI,0CACA;AAAA,+BACiBlhC,EAAO,gBAAgB,YAAY,CAAC;AAAA,6BACtC+C,EAAM,KAAK,OAAO;AAAA,WACpC,IAAM,CACP,OAAQmB,EAAW,KAAM,CACvB,IAAK,UACH,MAAO;AAAA;AAAA,yCAEoBnB,EAAM,aAAa,eAAe,CAAC;AAAA;AAAA,yCAEnCmB,EAAW,kBAAkB;AAAA,mBAE1D,IAAK,SACH,MAAO,wBACLpB,EAAW,SAAW,GAAKA,EAAW,SAAW,EAAI,wBAA0B,wBACjF,oBACF,IAAK,QACH,MAAO,6DACT,QACE,MAAM,MAAM,4BAA4BoB,EAAW,IAAI,EAAE,CAC7D,CACF,GAAG,CAAC;AAAA,CAEJ;AAAA,SAGN,MAAO,CACL,KAAM,SACN,YAAa,CACX,KAAM,GAAGA,EAAW,QAAQ,IAAIk7B,CAAY,IAC1C9Q,EAAO,OAAS,EAAKpqB,EAAW,OAAS,QAAUoqB,EAASA,EAAO,OAAU,EAC/E,IAAI+Q,EAAM,OAAS,EAAIA,EAAQ,EAAE,IAAIC,EAAI,OAAS,EAAIA,EAAM,EAAE,IAAI4B,CAAO,IACvEh9B,EAAW,OAAS,UAAYpB,EAAW,OAASA,CACtD,GACA,kBAAmB,CAAC,MAAM,CAC5B,EACA,gBAAAc,EACA,WAAY,KAAO,CACjB,QAAS,CAAC,CAAE,KAAMJ,EAAa,SAAUH,EAAY,QAAS,CAAC,EAC/D,cAAe,CAAE,EAAG,KAAK,KAAKS,EAAa,EAAuB,CAAE,EACpE,gBAAiB,CACf,CAAE,QAAuB,KAAMA,CAAW,EAC1C,CAAE,OAAsB,KAAMwqB,CAAO,EACrC,CAAE,OAAsB,KAAMgR,CAAI,EAClC,GAAG/hC,EAA2BuF,EAAYU,CAAW,CACvD,CACF,EACF,CACF,EAEMu7B,GAAuC/7C,GAAoC,CAC/E,IAAMm+C,EAAmBn+C,EAAQ,iBAGjC,OAF2B,IAAI,YAAYm+C,EAAkBA,EAAiB,WAAY,CAAC,EACnD,CAAC,CAE3C,EAEanC,GAAS,CAACh8C,EAAyBkhB,IAAuC,CACrF,IAAMoqB,EAAmB,CAAC,EACpB+Q,EAAkB,CAAC,EACnBC,EAAgB,CAAC,EAKjBF,EAAeL,GAAoC/7C,CAAO,EAChE,GAAIkhB,EAAW,YAAc,EAC3B,MAAM,MAAM,6DAA6D,EAE3E9B,GAAepf,EAAQ,OAAQkhB,EAAYk7B,EAAc9Q,EAAQ+Q,EAAOC,CAAG,EAC3Et8C,EAAQ,QAAQ87C,GAAwB97C,EAAQ,OAAO,CAAC,EAAGkhB,EAAYk7B,EAAc9Q,EAAQ+Q,EAAOC,CAAG,EAAG,CACxG,OAAQ,CAAC,CAAC,CACZ,CAAC,CACH,EAEaL,GAAyB/6B,GAA0D,CAC9F,IAAMk9B,EAAYl9B,EAAW,UACvB3P,EAAO2P,EAAW,KAClBm9B,EACJn9B,EAAW,wBACPu8B,EAAcv8B,EAAW,YACzBw8B,EAAkBx8B,EAAW,iBAA8B,EAC3Do8B,EAAqBp8B,EAAW,mBAChCo9B,EAA+Cp9B,EAAW,sBAC1Dq9B,EAAar9B,EAAW,KAExBy7B,EAA4Bz7B,EAAW,cAAgB,GAAK,SAAWA,EAAW,YACxF,OAAOlH,EAA4B,CACjC,UAAAokC,EACA,KAAA7sC,EACA,wBAAA8sC,EACA,YAAAZ,EACA,eAAAC,EACA,mBAAAJ,EACA,sBAAAgB,EACA,KAAAC,EACA,YAAA5B,CACF,CAAC,CACH,ICv0BA,IAkBMv9B,GA2DAo/B,GAuGOC,GApLbC,GAAA3jD,EAAA,kBAGAkS,IAEA8C,IACAkK,KAGAmB,IASMgE,GAAiB,CAACpZ,EAA+Bkb,IAAgD,CACrG,GAAM,CAACnB,EAAO4+B,EAAaC,EAAUC,CAAQ,EAAI74C,EAC3C,CAAE,SAAAmiB,EAAU,mBAAA22B,CAAmB,EAAI59B,EAEzC,GAAInB,EAAM,KAAK,SAAW,GAAKA,EAAM,KAAK,SAAW,EACnD,MAAM,IAAI,MAAM,wDAAwDA,EAAM,KAAK,MAAM,EAAE,EAE7F,GACE,CAACrQ,EAAU,SAASivC,EAAY,KAAM,CAAC,CAAC,GACxC,CAACjvC,EAAU,SAASivC,EAAY,KAAM,CAAC,CAAC,CAAC,GACzCA,EAAY,KAAK,SAAW,EAE5B,MAAM,IAAI,MAAM,uEAAuEA,EAAY,KAAK,MAAM,EAAE,EAElH,GAAIC,EAAS,KAAK,SAAW,EAC3B,MAAM,IAAI,MAAM,2DAA2DA,EAAS,KAAK,MAAM,EAAE,EAEnG,GAAIC,EAAS,KAAK,SAAW,EAC3B,MAAM,IAAI,MAAM,2DAA2DA,EAAS,KAAK,MAAM,EAAE,EAEnG,GAAI,CAACnvC,EAAU,SAASkvC,EAAS,KAAMC,EAAS,IAAI,EAClD,MAAM,IAAI,MAAM,wEAAwE,EAG1F,GAAIC,EAAqB,GAAK32B,IAAa,EACzC,MAAM,IAAI,MAAM,iEAAiE,EAGnF,IAAMf,EAAYrH,EAAM,KAAK,CAAC,EACxBsH,EAAiBtH,EAAM,KAAKA,EAAM,KAAK,OAAS,CAAC,EACjD+H,EAAoB82B,EAAS,KAAK,CAAC,EACnCpQ,EAAa9+B,EAAU,kBAAkBqQ,EAAM,KAAM,CAAC,EAAIsH,EAC1DonB,EAAWqQ,IAAuB,EAAIF,EAAS,KAAK,CAAC,EAAI,EAAIpQ,EAAarmB,EAChF,GAAI22B,EAAqBrQ,EACvB,MAAM,IAAI,MAAM,8DAA8D,EAGhF,GAAIkQ,EAAY,KAAK,SAAW,EAAG,CACjC,GAAIv3B,IAAcu3B,EAAY,KAAK,CAAC,EAClC,MAAM,IAAI,MAAM,sEAAsEA,EAAY,KAAK,CAAC,CAAC,EAAE,EAE7G,GAAIt3B,IAAmBs3B,EAAY,KAAK,CAAC,EACvC,MAAM,IAAI,MAAM,2EAA2EA,EAAY,KAAK,CAAC,CAAC,EAAE,CAEpH,CAEA,GAAIlQ,EAAW,IAAMmQ,EAAS,KAAK,CAAC,GAAKE,EAAqB,IAAMF,EAAS,KAAK,CAAC,EACjF,MAAM,IAAI,MACR,kGACEA,EAAS,KAAK,CAAC,CACjB,EACF,EAGF,GAAIv3B,EAAiBS,EACnB,MAAM,IAAI,MAAM,gFAAgF,CAEpG,EAEM02B,GAAmC,CACvCx4C,EACAkb,IACgB,CAChB,GAAM,CAAE,YAAA69B,EAAa,SAAA52B,EAAU,mBAAA22B,EAAoB,MAAAzyB,CAAM,EAAInL,EACvDkG,EAAYphB,EAAO,CAAC,EAAE,KAAK,CAAC,EAC5Bg5C,EAActvC,EAAU,kBAAkB1J,EAAO,CAAC,EAAE,KAAM,CAAC,EAC3DqhB,EAAiBrhB,EAAO,CAAC,EAAE,KAAKA,EAAO,CAAC,EAAE,KAAK,OAAS,CAAC,EACzDwoC,EAAawQ,EAAc33B,EAC3B43B,EAAyBj5C,EAAO,CAAC,EAAE,KAAK,CAAC,EACzCyoC,EAAWqQ,IAAuB,EAAIG,EAAyB,EAAIzQ,EAAarmB,EAKhF+2B,EAAc,IAAI,MACtB93B,EACAC,EACAmnB,EAAaC,EACbA,EAAWwQ,CACb,EACME,EAAgBzvC,EAAU,eAAewvC,CAAW,EAEpD5jC,EAAoC,CACxC,CAAE,OAAsB,KAAM+Q,CAAM,EACpC,CAAE,QAAuB,KAAM6yB,CAAY,EAC3C,CAAE,QAAuB,KAAMC,CAAc,EAI7C,GAAIn5C,EAAO,CAAC,EAAE,KAAK,SAAW,EAC1B,IAAI,MAAsB,CAAE,QAAuB,KAAM,CAACg5C,EAAaxQ,EAAYC,EAAU,CAAC,CAAE,CAAC,EACjG,CAAC,EACL,GAAIzoC,EAAO,CAAC,EAAE,KAAK,SAAW,EAC1B,IAAI,MAAsB,CACxB,QACA,KAAM,CAACg5C,EAAavQ,EAAUpnB,EAAiBonB,EAAU,CAAC,CAC5D,CAAC,EACD,CAAC,EAEL,GAAGl0B,EAA2BvU,EAAO,CAAC,EAAE,KAAMA,EAAO,CAAC,EAAE,KAAMA,EAAO,CAAC,EAAE,KAAMA,EAAO,CAAC,EAAE,KAAMA,EAAO,CAAC,EAAE,IAAI,CAC9G,EAEM4a,EAAmBC,GAA+B,CACtD,IAAMd,EAAQjF,EAAc,QAAS9U,EAAO,CAAC,EAAE,SAAUA,EAAO,CAAC,EAAE,KAAK,MAAM,EACxE24C,EAAc7jC,EAAc,eAAgB9U,EAAO,CAAC,EAAE,SAAUA,EAAO,CAAC,EAAE,KAAK,MAAM,EACrF44C,EAAW9jC,EAAc,YAAa9U,EAAO,CAAC,EAAE,SAAUA,EAAO,CAAC,EAAE,KAAK,MAAM,EAC/E64C,EAAW/jC,EAAc,YAAa9U,EAAO,CAAC,EAAE,SAAUA,EAAO,CAAC,EAAE,KAAK,MAAM,EAC/EgX,EAASjC,EAAe,SAAU/U,EAAO,CAAC,EAAE,SAAUA,EAAO,CAAC,EAAE,KAAK,MAAM,EAEjF,OAAA6a,EAAa,iBAAiB,CAC5B,CAAE,KAAM,QAAS,KAAM,KAAM,EAC7B,CAAE,KAAM,eAAgB,KAAM,MAAO,OAAQq+B,EAAY,MAAO,EAChE,CAAE,KAAM,iBAAkB,KAAM,MAAO,OAAQC,EAAc,MAAO,EACpE,CAAE,KAAM,uBAAwB,KAAM,MAAO,OAAQA,EAAc,MAAO,CAC5E,CAAC,EAEM;AAAA,UACDt+B,EAAa,iBAAiBd,EAAO4+B,EAAaC,EAAUC,EAAU7hC,CAAM,CAAC;AAAA;AAAA,UAE7E6D,EAAa,UAAU1G,EAAc,CAAC;AAAA,+CACDykC,EAAS,IAAI;AAAA;AAAA;AAAA,YAGhD/9B,EAAa,sCAAsC,MAAM,CAAC;AAAA;AAAA;AAAA;AAAA,kBAIpD89B,EAAY,2BAA2B,UAAW5jC,EAAe,GAAI4jC,EAAY,KAAK,OAAQ,CAAC,CAAC,CAAC;AAAA;AAAA,sBAE7FA,EAAY,YAAY,kBAAkB,CAAC;AAAA,oFACmBI,CAAW;AAAA,yDACtCA,CAAW;AAAA,uBAC7Ch/B,EAAM,YAAY,GAAG,CAAC,MAAM6+B,EAAS,IAAI,cAAe,SAAS,CAAC;AAAA,kBACvE7+B,EAAM,YAAY,GAAG,CAAC,MAAM8+B,EAAS,IAAI,cAAe,SAAS,CAAC;AAAA,cACtE7hC,EAAO,YAAY,IAAK,IAAI,CAAC;AAAA,uBACpB+C,EAAM,YAAY,GAAG,CAAC,MAAM8+B,EAAS,IAAI,cAAe,SAAS,CAAC;AAAA,kBACvE9+B,EAAM,YAAY,GAAG,CAAC,MAAM6+B,EAAS,IAAI,cAAe,SAAS,CAAC;AAAA,cACtE5hC,EAAO,YAAY,IAAK,IAAI,CAAC;AAAA;AAAA;AAAA,cAG7BA,EAAO,YAAY,IAAK+C,EAAM,YAAY,GAAG,CAAC,CAAC;AAAA;AAAA,UAG3D,EAEA,MAAO,CACL,KAAM,kBACN,YAAa,CACX,KAAM/F,EAA4B,CAChC,YAAA+kC,CACF,CAAC,EAAE,SACH,kBAAmB,CAAC,OAAQ,OAAQ,OAAQ,MAAM,CACpD,EACA,gBAAAn+B,EACA,WAAY,KAAO,CACjB,QAAS,CAAC,CAAE,KAAM5a,EAAO,CAAC,EAAE,KAAM,SAAUA,EAAO,CAAC,EAAE,QAAS,CAAC,EAChE,cAAe,CAAE,EAAG,KAAK,KAAK0J,EAAU,KAAKwvC,CAAW,EAAI/kC,EAAc,CAAE,EAC5E,gBAAAmB,CACF,EACF,CACF,EAEamjC,GAAkB,CAACz+C,EAAyBkhB,IAAgD,CACvG9B,GAAepf,EAAQ,OAAQkhB,CAAU,EACzClhB,EAAQ,QAAQw+C,GAAiCx+C,EAAQ,OAAQkhB,CAAU,CAAC,CAC9E,ICvLA,IAwBM9B,GAwDAggC,GA8IOC,GA9NbC,GAAAvkD,EAAA,kBAGAkS,IAEA8C,IAGAqL,IAgBMgE,GAAkBpZ,GAAwC,CAC9D,GAAI,CAACA,GAAUA,EAAO,OAAS,EAC7B,MAAM,IAAI,MAAM,uCAAuC,EAGzD,IAAM+Z,EAAoB/Z,EAAO,CAAC,EAC5Bu5C,EAAmBv5C,EAAO,CAAC,EAC3Bw5C,EAAoBx5C,EAAO,CAAC,EAElC,GAAI+Z,EAAM,WAAaw/B,EAAK,UAAYx/B,EAAM,WAAay/B,EAAM,SAC/D,MAAM,IAAI,MAAM,yCAAyC,EAG3D,GAAIz/B,EAAM,KAAK,SAAW,GAAKA,EAAM,KAAK,SAAW,EACnD,MAAM,IAAI,MAAM,wBAAwB,EAG1C,GAAIw/B,EAAK,KAAK,SAAW,GAAKA,EAAK,KAAK,SAAW,EACjD,MAAM,IAAI,MAAM,uBAAuB,EAGzC,IAAM/Q,EAAazuB,EAAM,KAAKA,EAAM,KAAK,OAAS,CAAC,EAC7CsH,EAAiBtH,EAAM,KAAKA,EAAM,KAAK,OAAS,CAAC,EACvD,GAAIw/B,EAAK,KAAKA,EAAK,KAAK,OAAS,CAAC,IAAM/Q,EACtC,MAAM,IAAI,MAAM,8CAA8C,EAEhE,GAAI+Q,EAAK,KAAKA,EAAK,KAAK,OAAS,CAAC,IAAMl4B,EACtC,MAAM,IAAI,MAAM,kDAAkD,EAGpE,GAAIm4B,EAAM,KAAK,SAAW,EACxB,MAAM,IAAI,MAAM,kBAAkB,EAEpC,GAAIA,EAAM,KAAKA,EAAM,KAAK,OAAS,CAAC,IAAMhR,EACxC,MAAM,IAAI,MAAM,+CAA+C,EAEjE,GAAIxoC,EAAO,OAAS,EAAG,CACrB,IAAMuvB,EAAmBvvB,EAAO,CAAC,EACjC,GAAIuvB,EAAK,KAAK,SAAW,EACvB,MAAM,IAAI,MAAM,iBAAiB,EAEnC,GAAIA,EAAK,KAAKA,EAAK,KAAK,OAAS,CAAC,IAAMiZ,EACtC,MAAM,IAAI,MAAM,8CAA8C,CAElE,CACA,GAAIxoC,EAAO,OAAS,EAAG,CACrB,IAAMghB,EAAmBhhB,EAAO,CAAC,EACjC,GAAIghB,EAAK,KAAK,SAAW,EACvB,MAAM,IAAI,MAAM,iBAAiB,EAEnC,GAAIA,EAAK,KAAKA,EAAK,KAAK,OAAS,CAAC,IAAMwnB,EACtC,MAAM,IAAI,MAAM,8CAA8C,CAElE,CACF,EAEM4Q,GAAiC,CACrCp5C,EACAkb,EACA8H,EACAy2B,IACgB,CAChB,IAAMvN,EAAahxB,EAAW,WAExBpB,EAAa9Z,EAAO,CAAC,EAAE,KACvB8pC,EAAYpgC,EAAU,KAAKoQ,CAAU,EACrCU,EAAcV,EACdgB,EAAagvB,EACbtB,EAAa1uB,EAAW,MAAM,EAAE,EAAE,CAAC,EACnCyyB,EAAmBkN,EAAa3/B,EAAW,MAAM,EAAG,EAAE,EAAE,OAAO,CAAC,EAAI,CAAC,EACrE4/B,EAAe,CAACxN,GAAclsC,EAAO,OAAS,EAC9C25C,EAAe35C,EAAO,OAAS,EAC/B45C,EAAgBH,GAAcz2B,EAAc,EAC5C62B,EAAqBJ,GAAcz2B,EAAc,EACjD82B,EAA4B92B,EAAc,EAC1C7K,EAAgB,GAEhB9C,EAAab,EAAiBg0B,CAAU,EAExClzB,EAAoC,CACxC,CAAE,QAAuB,KAAMwF,CAAW,EAC1C,CAAE,QAAuB,KAAMzF,CAAW,EAC1C,CAAE,QAAuB,KAAMmzB,CAAW,EAC1C,CAAE,OAAsB,KAAMttB,EAAW,OAAQ,CACnD,EACMN,EAAmBC,GAA+B,CACtD,IAAMk/B,EAAmC,CACvC,CAAE,KAAM,cAAe,KAAM,KAAM,EACnC,CAAE,KAAM,aAAc,KAAM,KAAM,EAClC,CAAE,KAAM,cAAe,KAAM,KAAM,EACnC,CAAE,KAAM,UAAW,KAAM,KAAM,CACjC,EACMlhC,EAAY,CAChB/D,EAAc,IAAK9U,EAAO,CAAC,EAAE,SAAUA,EAAO,CAAC,EAAE,KAAMqV,CAAU,EACjEP,EAAc,OAAQ9U,EAAO,CAAC,EAAE,SAAUA,EAAO,CAAC,EAAE,KAAMqV,CAAU,EACpEP,EAAc,QAAS9U,EAAO,CAAC,EAAE,SAAUA,EAAO,CAAC,EAAE,KAAMqV,CAAU,CACvE,EACIqkC,GACF7gC,EAAU,KAAK/D,EAAc,OAAQ9U,EAAO,CAAC,EAAE,SAAUA,EAAO,CAAC,EAAE,KAAMqV,CAAU,CAAC,EAElFskC,GACF9gC,EAAU,KAAK/D,EAAc,OAAQ9U,EAAO,CAAC,EAAE,SAAUA,EAAO,CAAC,EAAE,KAAMqV,CAAU,CAAC,EAEtFwD,EAAU,KAAK9D,EAAe,SAAU/U,EAAO,CAAC,EAAE,SAAUwa,EAAanF,CAAU,CAAC,EAChFukC,GACF/gC,EAAU,KAAK9D,EAAe,gBAA+Bw3B,CAAgB,CAAC,EAE5EsN,GACFhhC,EAAU,KAAK9D,EAAe,mBAAkCw3B,CAAgB,CAAC,EAE/EuN,GACFjhC,EAAU,KAAK9D,EAAe,sBAAuB/U,EAAO,CAAC,EAAE,SAAUwa,EAAanF,CAAU,CAAC,EAEnG,IAAM7a,EAAW6Z,GAA4BrU,EAAO,CAAC,EAAE,QAAQ,EACzDg6C,EAAc3lC,KAA4CgB,CAAU,EAC1E,MAAO;AAAA;AAAA,QAEHwF,EAAa,iBAAiBk/B,CAAa,EAAE,iBAAiB,GAAGlhC,CAAS,CAAC;AAAA,0CACzCmhC,CAAW,KAAK7hC,CAAa;AAAA,kDACrB6hC,CAAW,KAAK7hC,CAAa;AAAA;AAAA,QAEvE0C,EAAa,UAAU,CAAC1C,EAAe,EAAG,CAAC,CAAC,CAAC;AAAA;AAAA,iCAEpBA,CAAa;AAAA;AAAA;AAAA,gDAGEA,CAAa;AAAA;AAAA;AAAA,oBAGzCA,EAAgB,CAAC;AAAA;AAAA;AAAA;AAAA;AAAA,6BAKRwhC,EAAe,qBAAuBn/C,EAAW,OAAO;AAAA;AAAA;AAAA,YAGzEs/C,EAA4B,2CAA6C,EAAE;AAAA;AAAA,4BAE3DplC,GAAUla,EAAU6a,EAAY,OAAO,CAAC;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,kCAMlC8C,CAAa;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,qBAY1BxD,GAAU,MAAOU,CAAU,CAAC;AAAA,wCACTV,GAAU,aAAcU,CAAU,CAAC,gCACjE62B,EAAa,GAAK,eACpB;AAAA,UACE0N,EAAgB,kCAAoC,EAAE;AAAA,UACtDC,EAAqB,4CAA8C,EAAE;AAAA;AAAA;AAAA,qDAG1B3N,EAAa,GAAK,KAAK1xC,CAAQ,QAAQ;AAAA,cAC9EA,CAAQ;AAAA,cACRk/C,EAAe,uBAAyB,EAAE;AAAA;AAAA,QAGtD,EACMv5C,EAAU,CAAC,CAAE,KAAMqa,EAAa,SAAUxa,EAAO,CAAC,EAAE,QAAS,CAAC,EACpE,OAAIgjB,EAAc,GAChB7iB,EAAQ,KAAK,CAAE,KAAMosC,EAAkB,UAAyB,CAAC,EAE/DvpB,EAAc,GAChB7iB,EAAQ,KAAK,CAAE,KAAMosC,EAAkB,UAAyB,CAAC,EAE/DvpB,EAAc,GAChB7iB,EAAQ,KAAK,CAAE,KAAM2Z,EAAY,SAAU9Z,EAAO,CAAC,EAAE,QAAS,CAAC,EAE1D,CACL,KAAM,yBACN,YAAa,CACX,KAAM,GAAGqV,CAAU,IAAIukC,CAAa,IAAIC,CAAkB,IAAIC,CAAyB,GACvF,kBAAmB95C,EAAO,IAAI,CAACi6C,EAAQC,IAAW,MAAM,CAC1D,EACA,gBAAAt/B,EACA,WAAY,KAAO,CACjB,QAAAza,EACA,cAAe,CACb,EAAG,KAAK,KAAK2a,EAAa0tB,CAAU,CACtC,EACA,gBAAAlzB,CACF,EACF,CACF,EAEa+jC,GAAgB,CAACr/C,EAAyBkhB,IAA8C,CAGnG9B,GAAepf,EAAQ,MAAM,EAG7B,IAAMmG,EAAU,CAAC,CAAC,EACdnG,EAAQ,YAAc,GACxBmG,EAAQ,KAAsB,EAAE,EAE9BnG,EAAQ,YAAc,GACxBmG,EAAQ,KAAsB,EAAE,EAE9BnG,EAAQ,YAAc,GACxBmG,EAAQ,KAAK,CAAC,EAEhBnG,EAAQ,QAAQo/C,GAA+Bp/C,EAAQ,OAAQkhB,EAAYlhB,EAAQ,YAAa,EAAU,EAAG,CAC3G,QAAAmG,CACF,CAAC,CACH,ICjPA,IAyBMiZ,GAkBA+gC,GAcAC,GAiBAC,GAkBAC,GAyBAC,GA6FOC,GAYAC,GA9NbC,GAAA3lD,EAAA,kBAGAkS,IAEA8C,IACAkK,KAGAmB,IAgBMgE,GAAiB,CAACpZ,EAA+Bkb,IAAsC,CAC3F,GAAI,CAAClb,GAAUA,EAAO,OAAS,EAC7B,MAAM,IAAI,MAAM,gBAAgB,EAElC,GAAIkb,EAAW,KAAK,SAAW,GAC7B,GAAIA,EAAW,KAAK,SAAWA,EAAW,OAAO,QAAUA,EAAW,KAAK,SAAWA,EAAW,KAAK,OACpG,MAAM,IAAI,MAAM,iDAAiD,UAE1DA,EAAW,OAAO,SAAWA,EAAW,KAAK,OACtD,MAAM,IAAI,MAAM,2CAA2C,EAE7Dlb,EAAO,MAAM,CAAC,EAAE,QAAQ,CAAC0wB,EAAGze,IAAQ,CAClC,GAAIjS,EAAOiS,EAAM,CAAC,EAAE,WAAa,GAAkBjS,EAAOiS,EAAM,CAAC,EAAE,WAAa,EAC9E,MAAM,IAAI,MAAM,SAASA,CAAG,qCAAqC,CAErE,CAAC,CACH,EAEMkoC,GAAY,CAACn6C,EAA+BiS,IAA0B,CAC1E,IAAM8H,EAAkB,CAAC,EACzB,GAAI/Z,EAAO,OAASiS,EAClB,GAAIjS,EAAOiS,CAAG,EAAE,WAAa,EAC3BjS,EAAOiS,CAAG,EAAE,iBAAiB,EAAE,QAAS1U,GAAMwc,EAAM,KAAK,OAAOxc,CAAC,CAAC,CAAC,UAC1DyC,EAAOiS,CAAG,EAAE,WAAa,EAClCjS,EAAOiS,CAAG,EAAE,cAAc,EAAE,QAAS1U,GAAMwc,EAAM,KAAK,OAAOxc,CAAC,CAAC,CAAC,MAEhE,OAAM,IAAI,MAAM,SAAS0U,CAAG,qCAAqC,EAGrE,OAAO8H,CACT,EAEMqgC,GAAkC,CACtCp6C,EACAkb,IACoB,CACpB,GAAIlb,EAAO,OAAS,EAAG,CACrB,IAAM26C,EAAmBR,GAAUn6C,EAAQ,CAAC,EACtC46C,EAAiBT,GAAUn6C,EAAQ,CAAC,EACtCuL,EAAiB4uC,GAAUn6C,EAAQ,CAAC,EACxC,OAAIuL,EAAK,SAAW,IAClBA,EAAO,CAAC,GAAG,MAAMvL,EAAO,CAAC,EAAE,KAAK,MAAM,EAAE,KAAK,CAAC,GAEzCgU,EAA4B,CAAE,OAAA2mC,EAAQ,KAAAC,EAAM,KAAArvC,CAAK,CAAC,CAC3D,KACE,QAAO2P,CAEX,EAEMm/B,GAAoB,CACxB3jD,EACAgZ,EACAoK,EACAvO,EACAsvC,IACW,CACX,IAAIC,EAAWpkD,EAIf,OAHIA,EAAQ,IACVokD,GAAYhhC,EAAWvO,EAAKmE,CAAK,CAAC,GAEhCmrC,EAAMnrC,CAAK,EAAI,EACV,KAAK,IAAI,EAAG,KAAK,IAAIorC,EAAUhhC,EAAWvO,EAAKmE,CAAK,CAAC,EAAI,CAAC,CAAC,EAE3D,KAAK,IAAI,EAAG,KAAK,IAAIorC,EAAUhhC,EAAWvO,EAAKmE,CAAK,CAAC,CAAC,CAAC,CAElE,EAEM4qC,GAA4B,CAChCvgC,EACA/C,EACA8C,IAEA,4CAA4C9C,EAAO,KAAK,OAAO,QAAQ+C,EAAM,KAAK,OAAO;AAAA,+BAC5DA,EAAM,KAAK,OAAO;AAAA;AAAA,yBAExBD,EAAW,MAAM;AAAA,kCACRlF,EAAa,uBAAwB,IAAKkF,EAAW,MAAM,CAAC;AAAA,4BAClElF,EAAa,iBAAkB,IAAKkF,EAAW,MAAM,CAAC;AAAA,4BACtDlF,EAAa,iBAAkB,IAAKkF,EAAW,MAAM,CAAC;AAAA,6BACrDlF,EAAa,kBAAmB,IAAKkF,EAAW,MAAM,CAAC;AAAA,iCACnD9C,EAAO,WAAW,iBAAkB,GAAG,CAAC;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,cAO3D+C,EAAM,WAAW,gBAAiB,IAAK,aAAa,CAAC;AAAA;AAAA;AAAA,SAK7DwgC,GAAyB,CAACv6C,EAA+Bkb,IAA6C,CAC1G,IAAMpB,EAAa9Z,EAAO,CAAC,EAAE,KACvB8pC,EAAYpgC,EAAU,KAAKoQ,CAAU,EACrCvO,EACJ2P,EAAW,KAAK,OAAS,EACrBxR,EAAU,cAAcwR,EAAW,KAAMpB,EAAW,MAAM,EAC1D,CAAC,GAAG,MAAMA,EAAW,MAAM,EAAE,KAAK,CAAC,EACrC+gC,EAAQV,GAAUn6C,EAAQ,CAAC,EAC/B66C,EAAM,QACHziD,GACCA,IAAS,IACR,IAAM,CACL,MAAM,IAAI,MAAM,kBAAkB,CACpC,EACJ,EACIyiD,EAAM,SAAW,IACnBA,EAAQ,MAAMtvC,EAAK,MAAM,EAAE,KAAK,CAAC,GAEnC,IAAMovC,EAASz/B,EAAW,OAAO,IAAI,CAAC/P,EAAO/V,IAAMilD,GAAkBlvC,EAAO/V,EAAG0kB,EAAYvO,EAAMsvC,CAAK,CAAC,EAEjGD,EAAO1/B,EAAW,KAAK,IAAI,CAAC9P,EAAKhW,IAAMilD,GAAkBjvC,EAAKhW,EAAG0kB,EAAYvO,EAAMsvC,CAAK,CAAC,EAE/F,GAAItvC,EAAK,SAAWovC,EAAO,QAAUpvC,EAAK,SAAWqvC,EAAK,OACxD,MAAM,IAAI,MAAM,8DAA8D,EAGhF,GAAIrvC,EAAK,SAAWuO,EAAW,OAC7B,QAAS1kB,EAAI,EAAGA,EAAI0kB,EAAW,OAAQ,EAAE1kB,EAClCmW,EAAK,SAASnW,CAAC,IAClBulD,EAAO,OAAOvlD,EAAG,EAAG,CAAC,EACrBwlD,EAAK,OAAOxlD,EAAG,EAAG0kB,EAAW1kB,CAAC,CAAC,EAC/BylD,EAAM,OAAOzlD,EAAG,EAAG,CAAC,GAI1B,IAAM2lD,EAAQF,EAAM,IAAKziD,GAAS,KAAK,KAAKA,CAAI,CAAC,EAEjDyiD,EAAM,QAAQ,CAACziD,EAAMhD,EAAG4lD,IAAU,CAChC,GAAI5iD,EAAO,EAAG,CACZ,IAAM6iD,GAAYL,EAAKxlD,CAAC,EAAIulD,EAAOvlD,CAAC,GAAKgD,EACnC8iD,EAASP,EAAOvlD,CAAC,EACjB+lD,EAAWD,EAASD,EAAWJ,EAAMzlD,CAAC,EAC5CulD,EAAOvlD,CAAC,EAAI+lD,EACZP,EAAKxlD,CAAC,EAAI8lD,EACVF,EAAM5lD,CAAC,EAAI,CAACgD,CACd,CACF,CAAC,EAED,IAAMoiB,EAAcV,EAAW,MAAM,CAAC,EACtCvO,EAAK,QAAQ,CAACL,EAAMwlB,IAAM,CACxBlW,EAAYtP,CAAI,EAAI,KAAK,MAAM0vC,EAAK1vC,CAAI,EAAIyvC,EAAOzvC,CAAI,GAAK2vC,EAAM3vC,CAAI,CAAC,CACzE,CAAC,EACD,IAAMkwC,EAA+B,CAAE,KAAM5gC,EAAa,SAAUxa,EAAO,CAAC,EAAE,QAAS,EAEjFgX,EAASjC,EAAe,SAAU/U,EAAO,CAAC,EAAE,SAAUwa,EAAY,MAAM,EACxET,EAAQjF,EAAc,QAAS9U,EAAO,CAAC,EAAE,SAAUA,EAAO,CAAC,EAAE,KAAK,MAAM,EACxE8a,EAAapR,EAAU,KAAK8Q,CAAW,EACvCuI,EAA8B,CAClC,CAAE,KAAM,aAAc,KAAM,KAAM,EAClC,CAAE,KAAM,SAAU,KAAM,MAAO,OAAQ43B,EAAO,MAAO,EACrD,CAAE,KAAM,QAAS,KAAM,MAAO,OAAQI,EAAM,MAAO,EACnD,CAAE,KAAM,QAAS,KAAM,MAAO,OAAQF,EAAM,MAAO,CACrD,EAEMvlC,EAAoC,CACxC,CAAE,QAAuB,KAAMwF,CAAW,EAC1C,CAAE,QAAuB,KAAM6/B,CAAO,EACtC,CAAE,OAAsB,KAAMI,CAAM,EACpC,CAAE,QAAuB,KAAMF,CAAM,EACrC,GAAGtmC,EAA2BvU,EAAO,CAAC,EAAE,KAAMwa,CAAW,CAC3D,EAEMI,EAAmBC,GAA+B;AAAA,QAClDA,EAAa,iBAAiBkI,CAAQ,EAAE,iBAAiBhJ,EAAO/C,CAAM,CAAC;AAAA,UACrEsjC,GAA0BvgC,EAAO/C,EAAQ8C,CAAU,CAAC;AAAA,UACpDe,EAAa,UAAU,CAAC;AAAA,YACtBA,EAAa,sCAAsC,qBAAqB,CAAC;AAAA,iCACpD7D,EAAO,gBAAgB,YAAY,CAAC;AAAA;AAAA,YAEzDA,EAAO,YAAY,aAAc+C,EAAM,aAAa,eAAe,CAAC,CAAC;AAAA,SAE/E,MAAO,CACL,KAAM,QACN,YAAa,CAAE,KAAM,GAAGghC,EAAM,MAAM,IAAIJ,EAAO,MAAM,IAAIE,EAAM,MAAM,GAAI,kBAAmB,CAAC,MAAM,CAAE,EACrG,gBAAAjgC,EACA,WAAY,KAAO,CACjB,QAAS,CAACwgC,CAAgB,EAC1B,cAAe,CAAE,EAAG,KAAK,KAAKtR,EAAY,EAAuB,CAAE,EACnE,gBAAAx0B,CACF,EACF,CACF,EAEaklC,GAAQ,CAACxgD,EAAyBkhB,IAAsC,CACnF9B,GAAepf,EAAQ,OAAQkhB,CAAU,EACzC,IAAMkC,EAAoBg9B,GAAgCpgD,EAAQ,OAAQkhB,CAAU,EACpFlhB,EAAQ,QAAQugD,GAAuBvgD,EAAQ,OAAQojB,CAAiB,EAAG,CAAE,OAAQ,CAAC,CAAC,CAAE,CAAC,CAO5F,EAEaq9B,GAAwBv/B,GAAyD,CAC5F,IAAMy/B,EAASz/B,EAAW,OACpB0/B,EAAO1/B,EAAW,KAClB3P,EAAO2P,EAAW,KACxB,OAAOlH,EAA4B,CAAE,OAAA2mC,EAAQ,KAAAC,EAAM,KAAArvC,CAAK,CAAC,CAC3D,ICnOA,IAuBM6N,GAUAiiC,GAsJOC,GAKAC,GA5LbC,GAAAzmD,EAAA,kBAOAkS,IAEA8C,IACAkK,KAEA4F,KAEAzE,IASMgE,GAAkBpZ,GAAwC,CAC9D,GAAI,CAACA,GAAUA,EAAO,SAAW,EAC/B,MAAM,IAAI,MAAM,8BAA8B,CAElD,EAMMq7C,GAA2B,CAACrhD,EAAyBkhB,IAAkC,CAC3F,IAAMnB,EAAQ/f,EAAQ,OAAO,CAAC,EACxB8f,EAAaC,EAAM,KACnBe,EAAapR,EAAU,KAAKoQ,CAAU,EACtCjP,EAAYiP,EAAW,OACvB5O,EAAOxB,EAAU,cAAcwR,EAAW,KAAMrQ,CAAS,EACzD4wC,EAAsBvwC,EAAO4O,EAAW,OAAS,EACnD4hC,EACAjwC,EAAiB,CAAC,EAElBgwC,GACFhwC,EAAO,MAAM,KAAK,CAAE,OAAQZ,CAAU,EAAG,CAAC6lB,EAAGt7B,IAAMA,CAAC,EACpDqW,EAAKP,CAAI,EAAIL,EAAY,EACzBY,EAAKZ,EAAY,CAAC,EAAIK,EAEtBwwC,EAAkB1hD,EAAQ,QAAQ0f,GAA2BK,EAAOtO,CAAI,EAAG,CACzE,OAAQ,CAACsO,CAAK,EACd,QAAS,CAAC,EAAE,CACd,CAAC,EAAE,CAAC,GAEJ2hC,EAAkB3hC,EAGpB,IAAM4hC,EAAuBD,EAAgB,KACvCE,EAAOD,EAAqB9wC,EAAY,CAAC,EACzCgxC,EAAO/gC,EAAa8gC,EACpBvmC,EAAab,EAAiBonC,CAAI,EAClCE,EAAaF,EAAOvmC,EACtBgN,EAAK,GAELw5B,IAAS,IACXx5B,EAAK,KAEP,IAAM05B,EAAY,CAAC/mD,EAAcqgB,IAC3BA,IAAe,EACV,WAAWrgB,CAAI,OAAOA,CAAI,YAAYA,CAAI,OAAOA,CAAI,OACnDqgB,IAAe,EACjB,OAAOrgB,CAAI,OAAOA,CAAI,MACpBqgB,IAAe,EACjB,WAAWrgB,CAAI,OAAOA,CAAI,QAAQA,CAAI,MAGxCA,EAEHwW,EAAIsJ,EAAc,IAAK4mC,EAAgB,SAAUA,EAAgB,KAAMrmC,CAAU,EACjF2B,EAASjC,EAAe,SAAU2mC,EAAgB,SAAUA,EAAgB,KAAMrmC,CAAU,EAC5FQ,EAAYrK,EAAE,KAAK,MAEnBwwC,EACJ3nC,GAA4BqnC,EAAgB,QAAQ,IAAM,MACtD,mBAAmB7lC,CAAS,oBAC5B,mBAAmBA,CAAS,eAC5B+E,EAAmBC,GAA+B;AAAA,sCACpBhF,CAAS;AAAA,sCACTA,CAAS;AAAA,4CACHA,CAAS,KAAKwM,CAAE;AAAA;AAAA,4DAEAxM,CAAS;AAAA;AAAA;AAAA;AAAA;AAAA,gEAKLA,CAAS;AAAA;AAAA;AAAA;AAAA,QAIjEgF,EAAa,gBAAgB,aAAc,KAAK,EAAE,iBAAiBrP,EAAGwL,CAAM,CAAC;AAAA,QAC7E6D,EAAa,UAAUwH,CAAE,CAAC;AAAA;AAAA;AAAA,qBAGbA,CAAE;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,UAMb25B,CAAa;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,2BAmBInmC,CAAS,IAAIkmC,EAAU,kBAAmB1mC,CAAU,CAAC;AAAA;AAAA;AAAA;AAAA;AAAA,0BAKtDQ,CAAS;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,2BAeRA,CAAS,IAAIlB,GAAU,kBAAmBU,CAAU,CAAC;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,SAUxE1X,EAAS3D,EAAQ,QACrB,CACE,KAAM,UAEN,YAAa,CAAE,KAAM,GAAGqb,CAAU,IAAIgN,CAAE,GAAI,kBAAmB,CAAC,MAAM,CAAE,EACxE,WAAY,KAAO,CACjB,QAAS,CAAC,CAAE,KAAMs5B,EAAsB,SAAUD,EAAgB,QAAS,CAAC,EAC5E,cAAe,CAAE,EAAGG,CAAK,EACzB,gBAAiB,CAAC,CAAE,OAAsB,KAAMC,CAAW,CAAC,CAC9D,GACA,gBAAAlhC,CACF,EACA,CACE,OAAQ,CAAC8gC,CAAe,EACxB,QAAS,CAACD,EAAsB,GAAK,CAAC,CACxC,CACF,EAAE,CAAC,EAECA,GACFzhD,EAAQ,QAAQ0f,GAA2B/b,EAAQ8N,CAAI,EAAG,CACxD,OAAQ,CAAC9N,CAAM,CACjB,CAAC,CAEL,EAEa29C,GAAU,CAACthD,EAAyBkhB,IAAwC,CACvF9B,GAAepf,EAAQ,MAAM,EAC7BqhD,GAAyBrhD,EAASkhB,CAAU,CAC9C,EAEaqgC,GAA0BrgC,GACrClH,EAA4B,CAAE,KAAMkH,EAAW,IAAe,CAAC,IC7LjE,IAUM+gC,GAGA7iC,GA6BAE,GAUO4iC,GAyCAC,GA7FbC,GAAArnD,EAAA,kBAGAkS,IAEA8C,IAGAqL,IAEM6mC,GAAcI,GAClB,MAAM,KAAKA,EAAkB,iBAAiB,EAAG,MAAM,EAEnDjjC,GAAkBpZ,GAAwC,CAC9D,GAAI,CAACA,GAAUA,EAAO,SAAW,EAC/B,MAAM,IAAI,MAAM,yBAAyB,EAG3C,GACEA,EAAO,CAAC,EAAE,WAAa,GACvBA,EAAO,CAAC,EAAE,WAAa,IACvBA,EAAO,CAAC,EAAE,WAAa,GACvBA,EAAO,CAAC,EAAE,WAAa,GAEvB,MAAM,IAAI,MAAM,gEAAgE,EAGlF,GAAIA,EAAO,CAAC,EAAE,WAAa,EACzB,MAAM,IAAI,MAAM,mDAAmD,EAGrE,GAAIA,EAAO,CAAC,EAAE,KAAK,SAAW,EAC5B,MAAM,IAAI,MAAM,oCAAoC,EAKtD,GAFmCi8C,GAAWj8C,EAAO,CAAC,CAAC,EAE3C,SAAWA,EAAO,CAAC,EAAE,KAAK,OACpC,MAAM,IAAI,MAAM,uFAAuF,CAE3G,EAEMsZ,GAAiB,CAACQ,EAA+BwiC,IAAkD,CACvG,IAAM9hC,EAAwB,CAAC,EAE/B,QAASplB,EAAI,EAAGA,EAAI0kB,EAAW,OAAQ,EAAE1kB,EACvColB,EAAY,KAAKV,EAAW1kB,CAAC,EAAIknD,EAAQlnD,CAAC,CAAC,EAG7C,OAAOolB,CACT,EAEa0hC,GAAwB,CAACl8C,EAA+B2K,IAAkC,CACrG,IAAMmP,EAAa9Z,EAAO,CAAC,EAAE,KACvBs8C,EAA6B3xC,GAAgBsxC,GAAWj8C,EAAO,CAAC,CAAC,EACjEwa,EAAclB,GAAeQ,EAAYwiC,CAAO,EAChDxhC,EAAapR,EAAU,KAAK8Q,CAAW,EAEvChgB,EAAWwF,EAAO,CAAC,EAAE,SACrB+Z,EAAQjF,EAAc,QAASta,EAAUsf,EAAW,MAAM,EAC1D9C,EAASjC,EAAe,SAAUva,EAAUggB,EAAY,MAAM,EAE9DI,EAAmBC,GAA+B;AAAA,2BAC/Bd,EAAM,QAAQ,GAAGD,CAAU,CAAC;AAAA,QAC/Ce,EAAa,gBAAgB,cAAe,KAAK,EAAE,iBAAiBd,EAAO/C,CAAM,CAAC;AAAA,QAClF6D,EAAa,UAAU,CAAC;AAAA,QACxBA,EAAa,sCAAsC,sBAAsB,CAAC;AAAA,6BACrD7D,EAAO,gBAAgB,YAAY,CAAC;AAAA,2BACtC+C,EAAM,KAAK,OAAO;AAAA,4BACjBD,EAAW,MAAM;AAAA,4BACjBC,EAAM,WAAW,uBAAwB,GAAG,CAAC;AAAA,gCACzC/C,EAAO,WAAW,iBAAkB,GAAG,CAAC;AAAA;AAAA,UAE9D+C,EAAM,WAAW,gBAAiB,IAAK,iBAAiB,CAAC;AAAA;AAAA,QAE3D/C,EAAO,YAAY,aAAc+C,EAAM,aAAa,eAAe,CAAC,CAAC;AAAA,OAG3E,MAAO,CACL,KAAM,OACN,YAAa,CAAE,KAAM,GAAGuiC,CAAO,GAAI,kBAAmB,CAAC,MAAM,CAAE,EAC/D,WAAY,KAAO,CACjB,QAAS,CAAC,CAAE,KAAM9hC,EAAa,SAAUxa,EAAO,CAAC,EAAE,QAAS,CAAC,EAC7D,cAAe,CAAE,EAAG,KAAK,KAAK8a,EAAa,EAAuB,CAAE,EACpE,gBAAiB,CACf,CAAE,QAAuB,KAAMA,CAAW,EAC1C,GAAGvG,EAA2BvU,EAAO,CAAC,EAAE,KAAMwa,CAAW,CAC3D,CACF,GACA,gBAAAI,CACF,CACF,EAEauhC,GAAQniD,GAAkC,CACrDof,GAAepf,EAAQ,MAAM,EAC7BA,EAAQ,QAAQkiD,GAAsBliD,EAAQ,MAAM,EAAG,CAAE,OAAQ,CAAC,CAAC,CAAE,CAAC,CACxE,IChGA,IAUMuiD,GAiEAC,GAsCOC,GAjHbC,GAAA3nD,EAAA,kBAGAkS,IAEA8C,IAGAqL,IAEMmnC,GAA6B,CACjC1hC,EACA7a,EACAgsB,EACAqB,EACAf,IACG,CACH,IAAMtV,EAASjC,EAAe,cAAeuX,EAAYN,EAAW,OAAQ,CAAC,EACvE1kB,EAAIwN,EAAc,SAAU9U,EAAO,CAAC,EAAE,SAAUA,EAAO,CAAC,EAAE,KAAK,OAAQ,CAAC,EACxEuH,EAAIuN,EAAc,SAAU9U,EAAO,CAAC,EAAE,SAAUA,EAAO,CAAC,EAAE,KAAK,OAAQ,CAAC,EACxE88B,EAAIhoB,EAAc,SAAU9U,EAAO,CAAC,EAAE,SAAUA,EAAO,CAAC,EAAE,KAAK,OAAQ,CAAC,EAE1EysB,EACErC,EAAa,CAAC9iB,EAAWC,EAAWu1B,IAAc,UAAUv1B,CAAC,KAAKD,CAAC,KAAKw1B,CAAC,IAC/E,GAAI,CAACzP,EACHZ,EAAazV,EAAO,YAClB,aACAoT,EAAW9iB,EAAE,YAAY,YAAY,EAAGC,EAAE,YAAY,YAAY,EAAGu1B,EAAE,YAAY,YAAY,CAAC,CAClG,MACK,CACL,IAAMhQ,EAAmB,CAACC,EAAgBvhB,EAAWwhB,EAAW,KAAO,CACrE,IAAMC,EAAc,iBAAiBzhB,CAAC,gBAAgBA,CAAC,IACjD0hB,EAAc,iBAAiB1hB,CAAC,gBAAgBA,CAAC,IAEjDmxC,EAAc,sBAAsBnxC,CAAC,6BAA6BA,CAAC,UACzE,MAAO;AAAA,gCACmBA,CAAC,MAAMwL,EAAO,gBAAgB,qBAAqBxL,CAAC,GAAG,CAAC;AAAA,0BAC9DA,CAAC,MAAMlE,EAAE,2BAA2B,iBAAiBkE,CAAC,GAAIwL,CAAM,CAAC;AAAA,0BACjExL,CAAC,MAAMjE,EAAE,2BAA2B,iBAAiBiE,CAAC,GAAIwL,CAAM,CAAC;AAAA,0BACjExL,CAAC,MAAMsxB,EAAE,2BAA2B,iBAAiBtxB,CAAC,GAAIwL,CAAM,CAAC;AAAA,yBAClExL,CAAC,cAAcA,CAAC;AAAA,yBAChBA,CAAC,cAAcA,CAAC;AAAA,yBAChBA,CAAC,cAAcA,CAAC;AAAA,6BACZA,CAAC,cAAcA,CAAC;AAAA,6BAChBA,CAAC,cAAcA,CAAC;AAAA,6BAChBA,CAAC,cAAcA,CAAC;AAAA,cAC/BuhB,CAAM,IAAIvhB,CAAC,OAAOwhB,CAAQ,IAAI5C,EAAW6C,EAAaC,EAAayvB,CAAW,CAAC;AAAA,WAEzF,EACIrwB,IAAe,EACjBG,EAAa;AAAA;AAAA,cAELK,EAAiB,OAAQ,EAAG,KAAK,CAAC;AAAA,cAClCA,EAAiB,OAAQ,EAAG,KAAK,CAAC;AAAA,cAClCA,EAAiB,OAAQ,EAAG,KAAK,CAAC;AAAA,cAClCA,EAAiB,OAAQ,EAAG,KAAK,CAAC;AAAA,wGAG1CL,EAAa;AAAA,cACLK,EAAiB,0BAA2B,CAAC,CAAC;AAAA,cAC9CA,EAAiB,0BAA2B,CAAC,CAAC;AAAA,cAC9CA,EAAiB,0BAA2B,CAAC,CAAC;AAAA,cAC9CA,EAAiB,0BAA2B,CAAC,CAAC;AAAA,WAG1D,CAEA,MAAO;AAAA,UACCjS,EAAa,gBAAgB,WAAY,KAAK,EAAE,iBAAiBiiB,EAAGx1B,EAAGC,EAAGyP,CAAM,CAAC;AAAA,UACjF6D,EAAa,UAAU,CAAC;AAAA,UACxBA,EAAa,sCAAsC,mBAAmB,CAAC;AAAA,UACvE4R,CAAU;AAAA,QAEpB,EAEM+vB,GAA4Bx8C,GAA+C,CAC/E,IAAM8rB,EAAQ9rB,EAAO,CAAC,EAAE,KAClB+rB,EAAQ/rB,EAAO,CAAC,EAAE,KAClB48C,EAAQ58C,EAAO,CAAC,EAAE,KAClBid,EAAiBjd,EAAO,CAAC,EAAE,SAE3BqtB,EAAc,EAAE3jB,EAAU,SAASoiB,EAAOC,CAAK,GAAKriB,EAAU,SAASqiB,EAAO6wB,CAAK,GACrFpiC,EAAcsR,EACdhR,EAAapR,EAAU,KAAKoiB,CAAK,EAGrC,GAAIuB,EAAa,CACf,IAAME,EAAkB9jB,GAAc,UAAUA,GAAc,UAAUqiB,EAAOC,EAAO,EAAK,EAAI6wB,EAAO,EAAK,EAC3G,GAAI,CAACrvB,EACH,MAAM,IAAI,MAAM,6CAA6C,EAE/D/S,EAAc+S,EACdzS,EAAapR,EAAU,KAAK8Q,CAAW,CACzC,CAEA,IAAM2P,EAAU,KAAK,KAAKrP,EAAa,CAAC,EAExC,MAAO,CACL,KAAM,QACN,YAAa,CAAE,kBAAmB,CAAC,OAAQ,OAAQ,MAAM,CAAE,EAC3D,gBAAkBD,GAChB0hC,GAA2B1hC,EAAc7a,EAAQwa,EAAa6S,EAAapQ,CAAc,EAC3F,WAAY,KAAO,CACjB,QAAS,CAAC,CAAE,KAAMzC,EAAa,SAAUyC,CAAe,CAAC,EACzD,cAAe,CAAE,EAAG,KAAK,KAAKnC,EAAa,GAA0B,CAAgB,CAAE,EACvF,gBAAiB,CACf,CAAE,QAAuB,KAAMqP,CAAQ,EACvC,GAAG5V,EAA2BqoC,EAAO9wB,EAAOC,EAAOvR,CAAW,CAChE,CACF,EACF,CACF,EAEaiiC,GAASziD,GAAkC,CACtDA,EAAQ,QAAQwiD,GAAyBxiD,EAAQ,MAAM,CAAC,CAC1D,ICnHA,IA8Da6iD,GA9DbC,GAAA/nD,EAAA,kBAGAqrB,KACAU,KACA4E,KACAqB,KACAgE,KACAc,KACAmC,KACAwM,KACAiD,KACAe,KACAU,KACAqB,KACAqC,KACAO,KACAQ,KACAQ,KACAgB,KACAa,KACAM,KACAuB,KACAuC,KACAW,KACAkB,KACAU,KACAS,KACA/E,KACAyG,KACA0B,KACAsC,KACAc,KACAW,KACA93B,KAYAy5B,KACAwC,KACAY,KACAoB,KACAc,KACA7R,KACAyS,KACAviC,KACAiQ,KACA4yB,KAOaG,GAA+D,IAAI,IAAI,CAClF,CAAC,MAAO,CAAU11B,EAAG,CAAC,EACtB,CAAC,OAAQ,CAAUC,EAAI,CAAC,EACxB,CAAC,QAAS,CAAUC,EAAK,CAAC,EAC1B,CAAC,MAAO,CAAW8D,EAAG,CAAC,EACvB,CAAC,SAAU,CAACjL,GAAQC,EAAwB,CAAC,EAC7C,CAAC,SAAU,CAACF,GAAQE,EAAwB,CAAC,EAC7C,CAAC,OAAQ,CAAUmH,EAAI,CAAC,EACxB,CAAC,QAAS,CAAUC,EAAK,CAAC,EAC1B,CAAC,OAAQ,CAAUC,EAAI,CAAC,EACxB,CAAC,QAAS,CAAUC,EAAK,CAAC,EAC1B,CAAC,YAAa,CAAC5G,EAAS,CAAC,EAEzB,CAAC,cAAe,CAAMkvB,GAAkBD,EAA0B,CAAC,EACnE,CAAC,qBAAsB,CAACrqB,EAAS,CAAC,EAClC,CAAC,UAAW,CAACqB,EAAO,CAAC,EACrB,CAAC,gBAAiB,CAACgE,EAAa,CAAC,EACjC,CAAC,OAAQ,CAAUnD,GAAeD,EAAmB,CAAC,EACtD,CAAC,OAAQ,CAAUI,EAAI,CAAC,EACxB,CAAC,OAAQ,CAAUD,EAAI,CAAC,EACxB,CAAC,SAAU,CAACiG,GAAQC,EAAqB,CAAC,EAC1C,CAAC,OAAQ,CAACwM,GAAMJ,EAAmB,CAAC,EACpC,CAAC,gBAAiB,CAACqD,GAAeH,EAA4B,CAAC,EAC/D,CAAC,MAAO,CAAUtV,EAAG,CAAC,EACtB,CAAC,OAAQ,CAAUC,EAAI,CAAC,EACxB,CAAC,SAAU,CAACsW,GAAQC,EAAqB,CAAC,EAC1C,CAAC,eAAgB,CAACS,GAAcC,EAA2B,CAAC,EAC5D,CAAC,mBAAoB,CAAC2T,GAAkBC,EAA+B,CAAC,EACxE,CAAC,MAAO,CAAWznB,EAAG,CAAC,EACvB,CAAC,SAAU,CAACiV,GAAQC,EAAqB,CAAC,EAC1C,CAAC,MAAO,CAAUpY,GAAcD,EAAoB,CAAC,EACrD,CAAC,QAAS,CAAWoD,EAAK,CAAC,EAC3B,CAAC,MAAO,CAAUjD,EAAG,CAAC,EACtB,CAAC,MAAO,CAAUC,EAAG,CAAC,EACtB,CAAC,SAAU,CAACsa,EAAM,CAAC,EACnB,CAAC,WAAY,CAACnZ,EAAQ,CAAC,EACvB,CAAC,QAAS,CAAUlB,EAAK,CAAC,EAC1B,CAAC,YAAa,CAACiS,GAAMJ,EAAmB,CAAC,EACzC,CAAC,SAAU,CAACuJ,GAAQD,EAAqB,CAAC,EAC1C,CAAC,iBAAkB,CAACsC,GAAgBD,EAA6B,CAAC,EAClE,CAAC,uBAAwB,CAACb,GAAsBC,EAAmC,CAAC,EACpF,CAAC,WAAY,CAACjB,GAAUC,EAAuB,CAAC,EAChD,CAAC,OAAQ,CAAU3b,EAAI,CAAC,EACxB,CAAC,OAAQ,CAAC8d,GAAMD,EAAmB,CAAC,EACpC,CAAC,oBAAqB,CAAM8J,GAAwBD,EAAgC,CAAC,EACrF,CAAC,gBAAiB,CAAMM,GAAoBD,EAA4B,CAAC,EACzE,CAAC,UAAW,CAAW7kB,EAAO,CAAC,EAC/B,CAAC,iBAAkB,CAAWE,EAAc,CAAC,EAC7C,CAAC,aAAc,CAACgc,GAAYC,EAAyB,CAAC,EACtD,CAAC,sBAAuB,CAACuC,EAAmB,CAAC,EAC7C,CAAC,cAAe,CAAUphB,GAAsBD,EAA0B,CAAC,EAC3E,CAAC,wBAAyB,CAACgiB,EAAY,CAAC,EACxC,CAAC,qBAAsB,CAACkB,EAAS,CAAC,EAClC,CAAC,YAAa,CAAUxjB,GAAoBP,EAAoB,CAAC,EACjE,CAAC,OAAQ,CAAWyD,EAAI,CAAC,EACzB,CAAC,cAAe,CAAWE,EAAW,CAAC,EACvC,CAAC,MAAO,CAAUlC,EAAG,CAAC,EACtB,CAAC,SAAU,CAACgjB,EAAM,CAAC,EACnB,CAAC,cAAe,CAACQ,GAAaC,EAA0B,CAAC,EAEzD,CAAC,UAAW,CAAMiD,GAAcC,EAAsB,CAAC,EACvD,CAAC,MAAO,CAAW/kB,EAAG,CAAC,EACvB,CAAC,qBAAsB,CAAC8c,GAAoBH,EAAiC,CAAC,EAC9E,CAAC,MAAO,CAAUvf,EAAG,CAAC,EACtB,CAAC,MAAO,CAAUD,EAAG,CAAC,EACtB,CAAC,MAAO,CAAC/c,EAAG,CAAC,EACb,CAAC,MAAO,CAAW6f,EAAG,CAAC,EACvB,CAAC,YAAa,CAAU1B,GAAoB5B,EAAoB,CAAC,EACjE,CAAC,QAAS,CAAC0rB,EAAK,CAAC,EACjB,CAAC,aAAc,CAAUhrB,EAAU,CAAC,EACpC,CAAC,YAAa,CAAC7J,EAAS,CAAC,EACzB,CAAC,aAAc,CAACL,EAAU,CAAC,EAC3B,CAAC,YAAa,CAACI,EAAS,CAAC,EACzB,CAAC,YAAa,CAACG,EAAS,CAAC,EACzB,CAAC,aAAc,CAACD,EAAU,CAAC,EAC3B,CAAC,WAAY,CAACL,EAAQ,CAAC,EACvB,CAAC,WAAY,CAACC,EAAQ,CAAC,EACvB,CAAC,eAAgB,CAACO,EAAY,CAAC,EAC/B,CAAC,kBAAmB,CAACN,EAAe,CAAC,EACrC,CAAC,kBAAmB,CAACK,EAAe,CAAC,EACrC,CAAC,OAAQ,CAAU2J,EAAI,CAAC,EACxB,CAAC,SAAU,CAACotB,GAAQC,EAAqB,CAAC,EAC1C,CAAC,kBAAmB,CAACwC,EAAe,CAAC,EACrC,CAAC,YAAa,CAACnE,GAAWD,EAAwB,CAAC,EACnD,CAAC,UAAW,CAAUxrB,EAAO,CAAC,EAC9B,CAAC,MAAO,CAAUG,EAAG,CAAC,EACtB,CAAC,OAAQ,CAAUC,EAAI,CAAC,EACxB,CAAC,QAAS,CAACuxB,GAAOC,EAAoB,CAAC,EACvC,CAAC,yBAA0B,CAACpB,EAAa,CAAC,EAC1C,CAAC,QAAS,CAAC5P,GAAOC,EAAoB,CAAC,EACvC,CAAC,OAAQ,CAAUxgB,EAAI,CAAC,EACxB,CAAC,UAAW,CAACoyB,GAASC,EAAsB,CAAC,EAC7C,CAAC,MAAO,CAAW/vB,EAAG,CAAC,EACvB,CAAC,MAAO,CAAUrC,EAAG,CAAC,EACtB,CAAC,OAAQ,CAAUE,EAAI,CAAC,EACxB,CAAC,kBAAmB,CAAUI,GAA0BxB,EAAoB,CAAC,EAC7E,CAAC,OAAQ,CAACk0B,EAAI,CAAC,EACf,CAAC,YAAa,CAACxiC,GAAWC,EAAwB,CAAC,EACnD,CAAC,QAAS,CAAC6iC,EAAK,CAAC,CACnB,CAAC,ICjKD,IAoBaM,GApBbC,GAAAjoD,EAAA,kBAGAyJ,KAGAyK,KAEAmM,IAYa2nC,GAAN,KAAqB,CAI1B,YAAoB9nD,EAAwB,CAAxB,aAAAA,EAClB,KAAK,KAAO,IAAI,IAChB,KAAK,gBAAkB,EACzB,CACA,YAAYyI,EAAoC,CAC9C,OAAO,KAAK,KAAK,IAAIA,CAAG,CAC1B,CACA,YAAYA,EAAcu/C,EAA0B,CAClD,KAAK,KAAK,IAAIv/C,EAAKu/C,CAAQ,CAC7B,CACA,IACEC,EACAl9C,EACAG,EACAgZ,EACAgkC,EACM,CACN9gD,GAAiB6gD,EAAc,YAAY,IAAI,EAC/C,IAAME,EAAS,KAAK,QAAQ,OACtBC,EAAqB,KAAK,QAAQ,sBAAsB,EAC9D,KAAK,QAAQ,eAAe,KAAK,QAAQ,sBAAwB,CAAC,EAClE,IAAMC,EAAU,CAAC,EACjB,QAAWvjC,KAAS/Z,EAClBs9C,EAAQ,KAAK,CAAE,QAASA,EAAQ,OAAQ,SAAU,CAAE,OAAQvjC,EAAM,MAAO,CAAE,CAAC,EAE9E,QAAW/C,KAAU7W,EACnBm9C,EAAQ,KAAK,CAAE,QAASA,EAAQ,OAAQ,SAAU,CAAE,OAAQtmC,EAAO,MAAO,CAAE,CAAC,EAE3EmmC,GACFG,EAAQ,KAAK,CAAE,QAASA,EAAQ,OAAQ,SAAUH,CAAqB,CAAC,EAE1E,IAAMI,EAAYH,EAAO,gBAAgB,CACvC,OAAQF,EAAc,gBAAgB,mBAAmB,CAAC,EAC1D,QAAAI,EACA,MAAOJ,EAAc,YAAY,IACnC,CAAC,EAED,GAAI,KAAK,QAAQ,gBAAkB,YAAa,CAC9C,IAAMM,EAAc,CAClB,SAAU,KAAK,QAAQ,gBACvB,gBAAiBN,EAAc,gBAC/B,UAAAK,EACA,cAAApkC,CACF,EAC2B,KAAK,QAAQ,oBAAoB,IAAI,KAAK,QAAQ,gBAAiB,EAC1E,KAAKqkC,CAAW,CACtC,CAEAH,EAAmB,YAAYH,EAAc,eAAe,EAC5DG,EAAmB,aAAa,EAAGE,CAAS,EAC5CF,EAAmB,mBAAmB,GAAGlkC,CAAa,EACtD,KAAK,QAAQ,eAAe,KAAK,QAAQ,sBAAwB,EAAI,CAAC,EACtE,KAAK,QAAQ,yBAGX,KAAK,QAAQ,uBAAyB,KAAK,QAAQ,mBACnD,KAAK,QAAQ,YAAc,cAE3B,KAAK,QAAQ,eAAe,EAE1B,KAAK,QAAQ,uBAAyB,KAAK,QAAQ,mBACrD,KAAK,QAAQ,MAAM,EAErB7c,GAAe4gD,EAAc,YAAY,IAAI,CAC/C,CACA,SAAgB,CAEhB,CACA,MAAMO,EAA0BC,EAAiE,CAC/FrhD,GAAiBohD,EAAY,IAAI,EACjC,IAAML,EAAS,KAAK,QAAQ,OACtBO,EAA6B,CAAC,EAG0C,CAC5E,CAAE,QAAS,aAAc,UAAW,KAAM,EAC1C,CAAE,QAAS,YAA+B,UAAW,WAAY,CACnE,EACe,QAAS3c,GAAS,CAC3Boc,EAAO,SAAS,IAAIpc,EAAK,OAAO,GAClC2c,EAAiB,KAAK,UAAU3c,EAAK,SAAS,GAAG,CAErD,CAAC,EAED,IAAMnmB,EAAe1F,GAAmBuoC,EAA6B,KAAK,QAAQ,OAAO,MAAM,EACzFE,EAAWH,EAAY,gBAAgB5iC,CAAY,EACnDgjC,EAAO,GAAGF,EAAiB,KAAK;AAAA,CAAI,CAAC;AAAA,EAAK9iC,EAAa,yBAAyB;AAAA,EAAK+iC,CAAQ,GAC7FE,EAAeV,EAAO,mBAAmB,CAAE,KAAAS,EAAM,MAAOJ,EAAY,IAAK,CAAC,EAChFz0C,EAAU,UAAW,IAAM,YAAYy0C,EAAY,IAAI,iBAAiBI,CAAI,EAAE,EAE9E,IAAME,EAAkBX,EAAO,sBAAsB,CACnD,QAAS,CAAE,OAAQU,EAAc,WAAY,MAAO,EACpD,OAAQ,OACR,MAAOL,EAAY,IACrB,CAAC,EAED,OAAAnhD,GAAemhD,EAAY,IAAI,EACxB,CAAE,YAAAA,EAAa,gBAAAM,EAAiB,qBAAsBljC,EAAa,aAAc,CAC1F,CAEA,2BACE1B,EAC0B,CAC1B,IAAM3N,EAAI,OAAO2N,GAAkB,SAAWA,EAAgBA,EAAc,EACtEqN,EAAI,OAAOrN,GAAkB,SAAW,EAAIA,EAAc,GAAK,EAC/D6kC,EAAI,OAAO7kC,GAAkB,SAAW,EAAIA,EAAc,GAAK,EAC/D8kC,EAAoB,KAAK,QAAQ,OAAO,OAAO,iCACrD,GAAIzyC,GAAKyyC,GAAqBz3B,GAAKy3B,GAAqBD,GAAKC,EAC3D,MAAO,CAACzyC,EAAGgb,EAAGw3B,CAAC,EAEjB,IAAMziD,EAAOiQ,EAAIgb,EAAIw3B,EACjBE,EAAkB,KAAK,KAAK,KAAK,KAAK3iD,CAAI,CAAC,EAC/C,GAAI2iD,EAAkBD,EAAmB,CAEvC,GADAC,EAAkB,KAAK,KAAK,KAAK,KAAK3iD,CAAI,CAAC,EACvC2iD,EAAkBD,EACpB,MAAM,IAAI,MAAM,6CAA6C,EAE/D,MAAO,CAACC,EAAiBA,EAAiBA,CAAe,CAC3D,KACE,OAAO,CAACA,EAAiBA,EAAiB,CAAC,CAE/C,CACF,IClJA,IAAAC,GAAA,GAAA5/C,GAAA4/C,GAAA,mBAAAC,KAAA,IA6CMC,GAiDAC,GAsBAC,GAwBOH,GA5IbI,GAAAzpD,EAAA,kBAGAyJ,KAEAyI,IAEAgC,KACAuE,KACAwE,KACA8qC,KACAE,KAkCMqB,GAAyC,CAC7Ch0B,EACA5H,IACW,CACX,GAAIA,EAAkB,SAAW4H,EAAa,OAC5C,MAAM,IAAI,MACR,4BAA4B5H,EAAkB,MAAM,wCAClD4H,EAAa,MACf,GACF,EAGF,IAAMo0B,EAAuB,CAAC,EAC9B,QAASrpD,EAAI,EAAGA,EAAIi1B,EAAa,OAAQ,EAAEj1B,EAAG,CAC5C,IAAMsF,EAAO2vB,EAAaj1B,CAAC,EAAE,SAC7B,OAAQqtB,EAAkBrtB,CAAC,EAAG,CAC5B,IAAK,OAAQ,CACXqpD,EAAW,KAAK,EAAE,EAClB,KACF,CACA,IAAK,OAAQ,CACXA,EAAW,KAAK,GAAG/jD,CAAI,EAAE,EACzB,KACF,CACA,IAAK,OAAQ,CACX,IAAMsQ,EAAOqf,EAAaj1B,CAAC,EAAE,KAAK,OAClCqpD,EAAW,KAAK,GAAG/jD,CAAI,IAAIsQ,CAAI,EAAE,EACjC,KACF,CACA,IAAK,OAAQ,CACX,IAAM1Q,EAAO+vB,EAAaj1B,CAAC,EAAE,KAAK,KAAK,GAAG,EAC1CqpD,EAAW,KAAK,GAAG/jD,CAAI,IAAIJ,CAAI,EAAE,EACjC,KACF,CACA,QACE,MAAM,IAAI,MAAM,iCAAiCmoB,EAAkBrtB,CAAC,CAAC,EAAE,CAC3E,CACF,CAEA,OAAOqpD,EAAW,KAAK,GAAG,CAC5B,EASMH,GAA0B,CAC9Bb,EACApzB,EACA9R,IACW,CAGX,IAAI7a,EAAM+/C,EAAY,KACtB,OAAIA,EAAY,aAAa,OAC3B//C,GAAO,IAAM+/C,EAAY,YAAY,KAAO,KAE9C//C,GACE,IACA6a,EACA,IAAI8lC,GACFh0B,EACAozB,EAAY,aAAa,mBACvB,IAAI,MAAwCpzB,EAAa,MAAM,EAAE,KAAK,MAAM,CAChF,CAAC,GACI3sB,CACT,EAEM6gD,GAAN,KAA6C,CAI3C,YAAYG,EAA6B,CACnCA,IACF,KAAK,aAAeA,EAAY,aAChC,KAAK,OAASA,EAAY,OAE9B,CAEA,eAAeC,EAAwC,CACrD,OAAO,KAAK,eAAiBA,CAC/B,CAEA,SAASC,EAA4B,CACnC,OAAO,KAAK,SAAWA,CACzB,CACF,EAMaR,GAAN,KAAoB,CAApB,cAkBL,sBAAkC,KAOlC,qBAAiC,KAgCjC,KAAQ,eAA2C,KACnD,KAAQ,mBAAmD,KAC3D,uBAAoB,GACpB,2BAAwB,EAGxB,KAAQ,eAAsC,CAAC,EAE/C,KAAQ,eAAsD,IAAI,IAOlE,mBAA8B,UAI9B,yBAAkD,IAAI,IAKtD,KAAQ,uBAA2D,IAAI,IAKvE,gCAA4E,IAAI,IA7ChF,IAAI,yBAAsD,CACxD,GAAI,KAAK,kBAAoB,KAC3B,MAAM,IAAI,MAAM,yEAAyE,EAG3F,IAAI3kD,EAAO,KAAK,iBAAiB,IAAI,KAAK,eAAe,EACzD,OAAKA,IACHA,EAAO,CAAC,EACR,KAAK,iBAAiB,IAAI,KAAK,gBAAiBA,CAAI,GAG/CA,CACT,CAmCA,MAAM,WAAWjD,EAAUqoD,EAAoC,CAC7D,KAAK,IAAMroD,EACX,IAAMsoD,EAAqC,CAAC,EACtCC,EAAwC,CAC5C,eAAgB,CACd,+BAAgCF,EAAQ,OAAO,+BAC/C,iCAAkCA,EAAQ,OAAO,iCACjD,4BAA6BA,EAAQ,OAAO,4BAC5C,cAAeA,EAAQ,OAAO,cAC9B,kCAAmCA,EAAQ,OAAO,kCAClD,yBAA0BA,EAAQ,OAAO,yBACzC,yBAA0BA,EAAQ,OAAO,yBACzC,yBAA0BA,EAAQ,OAAO,wBAC3C,EACA,iBAAAC,CACF,EAGME,EAA6BC,GACjCJ,EAAQ,SAAS,IAAII,CAAO,GAAKH,EAAiB,KAAKG,CAAO,GAAK,GAEhED,EAA0B,qDAAuE,GACpGA,EAA0B,iBAAiB,EAE7CA,EAA0B,YAAY,EAEtCA,EAA0B,WAA6B,EAEvD,KAAK,OAAS,MAAMH,EAAQ,cAAcE,CAAgB,EAC1D,KAAK,YAAc,IAAIR,GAAgBM,EAAQ,MAAS,MAAMA,EAAQ,mBAAmB,CAAE,EAC3F,KAAK,eAAiB9sC,GAAqB,IAAI,EAC/C,KAAK,eAAiB,IAAIgrC,GAAe,IAAI,EAC7C,KAAK,QAAU,IAAI,IACnB,KAAK,qBAAuB,IAAI,IAChC,KAAK,iBAAmB,IAAI,IAG5Bj0C,GAAgBtS,EAAI,SAAW,CAAC,CAACA,EAAI,KAAK,EAI1C,KAAK,OAAO,kBAAqB0I,GAAO,CAClCA,EAAG,iBAAiB,oBAEtB,QAAQ,MAAM,mDAAmDA,EAAG,MAAM,OAAO,EAAE,CAEvF,EAEA,OAAO,eAAe,KAAK,IAAI,OAAQ,SAAU,CAC/C,MAAO,KAAK,OACZ,SAAU,GACV,WAAY,GACZ,aAAc,EAChB,CAAC,EACD,OAAO,eAAe,KAAK,IAAI,OAAQ,UAAW,CAChD,MAAO2/C,EACP,SAAU,GACV,WAAY,GACZ,aAAc,EAChB,CAAC,EAGD,KAAK,aAAa,CACpB,CAEA,SAAgB,CACV,OAAO,KAAK,SAAa,KAC3B,KAAK,SAAS,QAAQ,EAExB,KAAK,eAAe,QAAQ,CAC9B,CAEA,mBAAuC,CACrC,OAAK,KAAK,iBACR,KAAK,eAAiB,KAAK,OAAO,qBAAqB,GAElD,KAAK,cACd,CAEA,uBAA+C,CAC7C,GAAI,CAAC,KAAK,mBAAoB,CAC5B,IAAMtsC,EAAiB,KAAK,kBAAkB,EACxC2sC,EAAkD,CAAC,EAErD,KAAK,YAAc,cACrBA,EAAsB,gBAAkB,CACtC,SAAU,KAAK,SACf,0BAA2B,KAAK,sBAAwB,EACxD,oBAAqB,KAAK,sBAAwB,EAAI,CACxD,GAGF,KAAK,mBAAqB3sC,EAAe,iBAAiB2sC,CAAqB,CACjF,CACA,OAAO,KAAK,kBACd,CAEA,gBAAuB,CACjB,KAAK,qBACP,KAAK,mBAAmB,IAAI,EAC5B,KAAK,mBAAqB,KAE9B,CAEA,OAAc,CACZ,GAAI,CAAC,KAAK,eACR,OAGF7iD,GAAiB,EAEjB,KAAK,eAAe,EACpB,IAAI8iD,EACA,KAAK,YAAc,SACrB,KAAK,eAAe,gBAClB,KAAK,SACL,EACA,KAAK,sBAAwB,EAC7B,KAAK,mBACL,CACF,EAEAA,EAAkB,KAAK,OAAO,aAE5B,CAAE,KAAM,KAAK,sBAAwB,EAAI,EAAG,MAAO,eAAe,SAAW,eAAe,QAAS,CACvG,EAEA,KAAK,eAAe,IAAIA,EAAiB,KAAK,cAAc,EAC5D,KAAK,eAAiB,CAAC,EACvB,KAAK,eAAe,mBAClB,KAAK,mBACL,EACAA,EACA,EACA,KAAK,sBAAwB,EAAI,CACnC,GAGF,KAAK,OAAO,MAAM,OAAO,CAAC,KAAK,eAAe,OAAO,CAAC,CAAC,EACvD,KAAK,eAAe,sBAAsB,EAC1C,KAAK,eAAiB,KACtB,KAAK,sBAAwB,EAEzB,KAAK,YAAc,QAChBA,EAAiB,SAAS,WAAW,IAAI,EAAE,KAAK,IAAM,CACzD,IAAMC,EAAa,IAAI,eAAeD,EAAgB,eAAe,CAAC,EAChEE,EAAiB,KAAK,eAAe,IAAIF,CAAe,EAC9D,QAAS/pD,EAAI,EAAGA,EAAIgqD,EAAW,OAAS,EAAGhqD,IAAK,CAC9C,IAAMkqD,EAAoBD,EAAejqD,CAAC,EACpCmqD,EAAWD,EAAkB,SAC7BE,EAAa,KAAK,QAAQ,IAAID,CAAQ,EACtCE,EAAaD,EAAW,WACxBE,EAAaF,EAAW,WACxBG,EAAcL,EAAkB,YAChCM,EAAmBN,EAAkB,iBACrCO,EAAoBP,EAAkB,kBACtCQ,EAAeV,EAAWhqD,EAAI,CAAC,EAC/B2qD,EAAaX,EAAWhqD,EAAI,EAAI,CAAC,EAEnC,OAAO,KAAK,cAAkB,MAChC,KAAK,cAAgB0qD,GAGvB,IAAME,EAAY,OAAOF,EAAe,KAAK,aAAa,EACpDG,EAAU,OAAOF,EAAa,KAAK,aAAa,EAEtD,GAAI,CAAC,OAAO,cAAcC,CAAS,GAAK,CAAC,OAAO,cAAcC,CAAO,EACnE,MAAM,IAAI,WAAW,2BAA2B,EAGlD,GAAI,KAAK,IAAI,OAAO,WAAW,OAC7B,KAAK,IAAI,OAAO,UAAU,OAAO,CAC/B,QAAS,EACT,eAAgBL,EAAiB,IAAKlpD,IAAW,CAC/C,KAAMA,EAAM,KACZ,SAAUgQ,GAA2BhQ,EAAM,QAAQ,CACrD,EAAE,EACF,gBAAiBmpD,EAAkB,IAAKnpD,IAAW,CACjD,KAAMA,EAAM,KACZ,SAAUgQ,GAA2BhQ,EAAM,QAAQ,CACrD,EAAE,EACF,SAAA6oD,EACA,WAAAE,EACA,WAAAC,EACA,YAAAC,EACA,UAAAK,EACA,QAAAC,CACF,CAAC,MACI,CAEL,IAAIxe,EAAc,GAClBme,EAAiB,QAAQ,CAAClpD,EAAOtB,IAAM,CACrCqsC,GAAe,SAASrsC,CAAC,OAAOsB,EAAM,IAAI,OAAOgQ,GAA2BhQ,EAAM,QAAQ,CAAC,IAC7F,CAAC,EACD,IAAIuzC,EAAe,GACnB4V,EAAkB,QAAQ,CAACnpD,EAAOtB,IAAM,CACtC60C,GAAgB,UAAU70C,CAAC,OAAOsB,EAAM,IAAI,OAAOgQ,GAA2BhQ,EAAM,QAAQ,CAAC,IAC/F,CAAC,EAED,QAAQ,IACN,uBAAuB6oD,CAAQ,IAAIE,CAAU,IAAIC,CAAU,IAAIC,CAAW,KAAKle,CAAW,GACxFwI,CACF,mBAAmBgW,EAAUD,CAAS,KACxC,CACF,CACA7jD,GAAM,MAAO,GAAGwjD,CAAW,KAAKG,CAAY,KAAKC,CAAU,EAAE,CAC/D,CACAZ,EAAgB,MAAM,EACtB,KAAK,eAAe,OAAOA,CAAe,CAC5C,CAAC,EAEH7iD,GAAe,CACjB,CAaA,IACE4jD,EACAN,EACA3/C,EACAkgD,EACAC,EACAp9B,EACc,CACd3mB,GAAiB6jD,EAAQ,IAAI,EAE7B,IAAMG,EAAwB,CAAC,EAC/B,QAASjrD,EAAI,EAAGA,EAAIwqD,EAAiB,OAAQ,EAAExqD,EAAG,CAChD,IAAMqE,EAAOmmD,EAAiBxqD,CAAC,EAAE,KAEjC,GAAIqE,IAAS,EACX,SAEF,IAAM8Z,EAAU,KAAK,eAAe,IAAI9Z,CAAI,EAC5C,GAAI,CAAC8Z,EACH,MAAM,IAAI,MAAM,0BAA0B9Z,CAAI,EAAE,EAElD4mD,EAAW,KAAK9sC,CAAO,CACzB,CAEA,GAAM,CAAE,QAAApT,EAAS,cAAAgZ,EAAe,gBAAA7D,CAAgB,EAAI4qC,EAAQ,WAAWN,CAAgB,EAGjFU,EAAyBrgD,EAAc,SAAW,EAAIE,EAAQ,IAAI,CAAC,EAAG/K,IAAMA,CAAC,EAAI6K,EACvF,GAAIqgD,EAAuB,SAAWngD,EAAQ,OAC5C,MAAM,IAAI,MAAM,eAAemgD,EAAuB,MAAM,qBAAqBngD,EAAQ,MAAM,GAAG,EAIpG,IAAM0/C,EAAkC,CAAC,EACnCU,EAAyB,CAAC,EAChC,QAASnrD,EAAI,EAAGA,EAAI+K,EAAQ,OAAQ,EAAE/K,EAAG,CAIvC,GACE,CAAC,OAAO,UAAUkrD,EAAuBlrD,CAAC,CAAC,GAC3CkrD,EAAuBlrD,CAAC,EAAI,IAC5BkrD,EAAuBlrD,CAAC,GAAK4tB,EAE7B,MAAM,IAAI,MAAM,yBAAyBs9B,EAAuBlrD,CAAC,CAAC,EAAE,EAEtE,GAAIkrD,EAAuBlrD,CAAC,IAAM,GAChC,SAEF,IAAMorD,EAAcF,EAAuBlrD,CAAC,IAAM,GAC5CqrD,EAAeH,EAAuBlrD,CAAC,IAAM,GAC7CsrD,EACJF,GAAeC,EACXL,EAAyBjgD,EAAQ/K,CAAC,EAAE,SAAU+K,EAAQ/K,CAAC,EAAE,IAAI,EAC7D+qD,EAAmBG,EAAuBlrD,CAAC,EAAG+K,EAAQ/K,CAAC,EAAE,SAAU+K,EAAQ/K,CAAC,EAAE,IAAI,EAGxF,GAFAyqD,EAAkB,KAAKa,CAAU,EAE7BA,EAAW,OAAS,EACtB,SAEF,IAAMntC,EAAU,KAAK,eAAe,IAAImtC,EAAW,IAAI,EACvD,GAAI,CAACntC,EACH,MAAM,IAAI,MAAM,2BAA2BmtC,EAAW,IAAI,EAAE,EAK9D,GAHIF,GACF,KAAK,cAAc,KAAKjtC,CAAO,EAE7BktC,EAAc,CAChB,IAAIE,EAAiB,KAAK,qBAAqB,IAAI,KAAK,eAAgB,EACnEA,IACHA,EAAiB,CAAC,EAClB,KAAK,qBAAqB,IAAI,KAAK,gBAAkBA,CAAc,GAErEA,EAAe,KAAKptC,CAAO,CAC7B,CACAgtC,EAAY,KAAKhtC,CAAO,CAC1B,CAIA,GAAI8sC,EAAW,SAAWT,EAAiB,QAAUW,EAAY,SAAWV,EAAkB,OAAQ,CAEpG,GAAIU,EAAY,SAAW,EACzB,OAAAjkD,GAAe4jD,EAAQ,IAAI,EACpBL,EAMT,MAAM,IAAI,MACR,WAAWK,EAAQ,IAAI,4EACzB,CACF,CAKA,IAAI/C,EACJ,GAAI7nC,EAAiB,CACnB,IAAIsrC,EAAgB,EACdtqC,EAAoB,CAAC,EAE3BhB,EAAgB,QAAS/X,GAAM,CAC7B,IAAM9D,EAAO,OAAO8D,EAAE,MAAS,SAAW,CAACA,EAAE,IAAI,EAAIA,EAAE,KACvD,GAAI9D,EAAK,SAAW,EAClB,OAGF,IAAMonD,EAAgBtjD,EAAE,OAAS,GAAmB,EAAI,EACpDujD,EACAC,EACAxjD,EAAE,OAAS,IACbwjD,EAAgBtnD,EAAK,OAAS,EAAI,GAAKA,EAAK,OAAS,EAAI,EAAIA,EAAK,OAASonD,EAC3EC,EAAiBrnD,EAAK,OAAS,EAAI,GAAKonD,EAAgBpnD,EAAK,SAE7DsnD,EAAgBtnD,EAAK,QAAU,EAAIA,EAAK,OAASonD,EAAgB,GACjEC,EAAiB,IAEnBF,EAAgB,KAAK,KAAKA,EAAgBG,CAAa,EAAIA,EAC3DzqC,EAAQ,KAAKsqC,CAAa,EAM1B,IAAMI,EAAqBzjD,EAAE,OAAS,GAAmB,EAAI,EAC7DqjD,GACEnnD,EAAK,OAAS,EAAI,KAAK,KAAKA,EAAK,OAASunD,CAAkB,EAAIF,EAAiBrnD,EAAK,OAASonD,CACnG,CAAC,EAID,IAAMI,EAAsB,GAC5BL,EAAgB,KAAK,KAAKA,EAAgBK,CAAmB,EAAIA,EACjE,IAAMzuC,EAAc,IAAI,YAAYouC,CAAa,EACjDtrC,EAAgB,QAAQ,CAAC/X,EAAGnI,IAAM,CAChC,IAAMmT,EAAS+N,EAAQlhB,CAAC,EAClBqE,EAAO,OAAO8D,EAAE,MAAS,SAAW,CAACA,EAAE,IAAI,EAAIA,EAAE,KACvD,GAAIA,EAAE,OAAS,EACb,IAAI,WAAWiV,EAAajK,EAAQ9O,EAAK,MAAM,EAAE,IAAIA,CAAI,UAChD8D,EAAE,OAAS,GACpB,IAAI,YAAYiV,EAAajK,EAAQ9O,EAAK,MAAM,EAAE,IAAIA,CAAI,UACjD8D,EAAE,OAAS,GACpB,IAAI,YAAYiV,EAAajK,EAAQ9O,EAAK,MAAM,EAAE,IAAIA,CAAI,UACjD8D,EAAE,OAAS,EACpB,IAAI,aAAaiV,EAAajK,EAAQ9O,EAAK,MAAM,EAAE,IAAIA,CAAI,MAE3D,OAAM,IAAI,MAAM,6BAA6BiN,GAA2BnJ,EAAE,IAAI,CAAC,EAAE,CAErF,CAAC,EAED,IAAM2jD,EAEJ,KAAK,eAAe,OAAON,EAAe,eAAe,SAAW,eAAe,OAAO,EAC5F,KAAK,OAAO,MAAM,YAAYM,EAAkB,OAAQ,EAAG1uC,EAAa,EAAGouC,CAAa,EACxF,KAAK,eAAe,QAAQM,EAAkB,EAAE,EAChD/D,EAAuB,CAAE,OAAQ,EAAG,KAAMyD,EAAe,OAAQM,EAAkB,MAAO,CAC5F,CAEA,IAAMjpC,EAA0B,KAAK,eAAe,2BAA2BkB,CAAa,EACtFZ,EAAuBN,EAAwB,CAAC,IAAM,GAAKA,EAAwB,CAAC,IAAM,EAE1Fva,EAAM4gD,GAAwB4B,EAASN,EAAkBrnC,CAAoB,EAC/E0kC,EAAW,KAAK,eAAe,YAAYv/C,CAAG,EAQlD,GAPKu/C,IACHA,EAAW,KAAK,eAAe,MAAMiD,EAASjoC,CAAuB,EACrE,KAAK,eAAe,YAAYva,EAAKu/C,CAAQ,EAC7Cj0C,EAAU,OAAQ,IAAM,mBAAmBtL,CAAG,kBAAkBwiD,EAAQ,IAAI,EAAE,GAI5E5qC,GAAmB2nC,EAAS,qBAAsB,CACpD,GAAI3nC,EAAgB,SAAW2nC,EAAS,qBAAqB,OAC3D,MAAM,IAAI,MACR,4CAA4CA,EAAS,qBAAqB,MAAM,SAC9E3nC,EAAgB,MAClB,gBAAgB2nC,EAAS,YAAY,IAAI,IAC3C,EAEF,QAAS7nD,EAAI,EAAGA,EAAIkgB,EAAgB,OAAQlgB,IAAK,CAC/C,IAAM+rD,EAAU7rC,EAAgBlgB,CAAC,EAC3BgsD,EAAaD,EAAQ,KACrBE,EAAe,OAAOF,EAAQ,MAAS,SAAW,EAAIA,EAAQ,KAAK,OACnE,CAACzmD,EAAM6a,CAAM,EAAI0nC,EAAS,qBAAqB7nD,CAAC,EACtD,GAAIgsD,IAAe1mD,GAAQ2mD,IAAiB9rC,EAC1C,MAAM,IAAI,MACR,oBAAoBngB,CAAC,0BAA0BsF,CAAI,cAAc6a,CAAM,cACrE6rC,CACF,cAAcC,CAAY,gBAAgBpE,EAAS,YAAY,IAAI,IACrE,CAEJ,CACF,CAUA,GARAj0C,EACE,OACA,IACE,yBAAyBk3C,EAAQ,IAAI,UAAUxiD,CAAG,UAAUua,EAAwB,CAAC,CAAC,IACpFA,EAAwB,CAAC,CAC3B,IAAIA,EAAwB,CAAC,CAAC,EAClC,EAEI,KAAK,YAAc,QAAU,KAAK,gBAAkB,YAAa,CACnE,IAAMqnC,EAAuC,CAC3C,SAAU,KAAK,gBACf,YAAarC,EAAS,YAAY,KAClC,iBAAA2C,EACA,kBAAAC,CACF,EACA,KAAK,eAAe,KAAKP,CAAiB,EAEtC,KAAK,gBAAkB,aACK,KAAK,uBAAuB,IAAI,KAAK,gBAAiB,EAC7D,KAAKA,CAAiB,CAEjD,CAEA,YAAK,eAAe,IAAIrC,EAAUoD,EAAYE,EAAatoC,EAAyBklC,CAAoB,EAExG7gD,GAAe4jD,EAAQ,IAAI,EACpBL,CACT,CAEA,OAAOyB,EAAmB7nD,EAAwB,CAChD,KAAK,eAAe,OAAO6nD,EAAW7nD,CAAI,CAC5C,CAEA,OAAO8nD,EAAaC,EAAmB,CACrC,KAAK,eAAe,OAAOD,EAAKC,CAAG,CACrC,CAEA,MAAM,SAASF,EAAmBlvC,EAAkD,CAGlF,MAAM,KAAK,eAAe,SAASkvC,EAAWlvC,CAAe,CAC/D,CAEA,MAAM7W,EAAsB,CAC1B,OAAO,KAAK,eAAe,OAAOA,CAAI,EAAE,EAC1C,CAEA,KAAKk5C,EAAqB,CACxB,OAAO,KAAK,eAAe,QAAQA,CAAG,CACxC,CAEA,aAAagL,EAAoBF,EAAkBrrC,EAAoBwrC,EAA0B,CAC/F,IAAM+B,EAAK5E,GAAwB,IAAI4C,CAAU,EACjD,GAAI,CAACgC,EACH,MAAM,IAAI,MAAM,2BAA2BhC,CAAU,EAAE,EAGzD,IAAMD,EAAyB,CAC7B,WAAAC,EACA,WAAAC,EACA,YAAa+B,EAAG,CAAC,EACjB,WAAY,CAACA,EAAG,CAAC,EAAGvtC,CAAS,CAC/B,EACA,KAAK,QAAQ,IAAIqrC,EAAUC,CAAU,CACvC,CAEA,cAAcD,EAAwB,CACpC,IAAMoB,EAAiB,KAAK,qBAAqB,IAAIpB,CAAQ,EAC7D,GAAIoB,EAAgB,CAClB,QAAWlnD,KAAQknD,EACjB,KAAK,eAAe,QAAQlnD,EAAK,EAAE,EAErC,KAAK,qBAAqB,OAAO8lD,CAAQ,CAC3C,CAEA,KAAK,iBAAiB,OAAOA,CAAQ,EACrC,KAAK,QAAQ,OAAOA,CAAQ,CAC9B,CAEA,cAAcA,EAAkBvlD,EAAyBnE,EAA+C,CACtG,IAAM4W,EAAS,KAAK,QAAQ,IAAI8yC,CAAQ,EACxC,GAAI,CAAC9yC,EACH,MAAM,IAAI,MAAM,uBAAuB8yC,CAAQ,EAAE,EAEnD,IAAME,EAAahzC,EAAO,WACpBizC,EAAajzC,EAAO,WACpBi1C,EAAcj1C,EAAO,YACrByO,EAAazO,EAAO,WAC1B,GAAI,KAAK,kBAAoB,KAC3B,MAAM,IAAI,MAAM,YAAYgzC,CAAU,KAAKC,CAAU,2CAA2C,EAElG,KAAK,gBAAkBH,EAGnBrkC,EAAW,CAAC,IACdA,EAAW,CAAC,EAAIA,EAAW,CAAC,EAAEA,EAAW,CAAC,CAAC,EAC3CA,EAAW,CAAC,EAAI,QAGlBlS,EAAU,OAAQ,IAAM,kCAAkCy2C,CAAU,KAAKC,CAAU,MAAM,EAEzF,IAAMiC,EAAgB,KAAK,IAAI,MAE/B,KAAK,cAAgB,CAAC,EACtB,GAAI,CACF,OAAIA,GACF,KAAK,OAAO,eAAe,YAAY,EAGzCD,EAAY1nD,EAASkhB,EAAW,CAAC,CAAC,EAC3B,CACT,OAAS1lB,EAAG,CACV,OAAAK,EAAO,KAAK,QAAQ,QAAQ,qBAAqB4pD,CAAU,KAAKC,CAAU,aAAalqD,CAAC,EAAE,CAAC,EACpF,CACT,QAAE,CACImsD,GACF9rD,EAAO,KACL,KAAK,OACF,cAAc,EACd,KAAMG,GACLA,EAAM,qCAAqCypD,CAAU,KAAKC,CAAU,MAAM1pD,EAAI,OAAO,GAAK,IAC5F,CACJ,EAGF,QAAWyD,KAAQ,KAAK,cACtB,KAAK,eAAe,QAAQA,EAAK,EAAE,EAErC,KAAK,cAAgB,CAAC,EACtB,KAAK,gBAAkB,IACzB,CACF,CAGA,eAAeqG,EAAmB4P,EAAezW,EAAmBsC,EAAsB,CACxF,IAAIqmD,EAA4B,KAAK,2BAA2B,IAAI9hD,CAAS,EACxE8hD,IACHA,EAA4B,IAAI,IAChC,KAAK,2BAA2B,IAAI9hD,EAAW8hD,CAAyB,GAQ1E,IAAMC,EAAiBD,EAA0B,IAAIlyC,CAAK,EACpDiB,EAAK,KAAK,eAAe,uBAAuB1X,EAAQsC,EAAMsmD,CAAc,EAClF,OAAAD,EAA0B,IAAIlyC,EAAO,CAACiB,EAAI1X,CAAM,CAAC,EAC1C0X,CACT,CACA,kBAAkB7Q,EAAyB,CACzC,IAAM8hD,EAA4B,KAAK,2BAA2B,IAAI9hD,CAAS,EAC3E8hD,IACFA,EAA0B,QAASE,GAAe,KAAK,eAAe,yBAAyBA,EAAW,CAAC,CAAC,CAAC,EAC7G,KAAK,2BAA2B,OAAOhiD,CAAS,EAEpD,CACA,UAAUwhD,EAA8B,CACtC,IAAM/tC,EAAU,KAAK,eAAe,IAAI+tC,CAAS,EACjD,GAAI,CAAC/tC,EACH,MAAM,IAAI,MAAM,2BAA2B+tC,CAAS,EAAE,EAExD,OAAO/tC,EAAQ,MACjB,CACA,iBACEhZ,EACAgB,EACAb,EACgC,CAChC,MAAO,UAAY,CACjB,IAAMjB,EAAO,MAAMoY,GAAgB,KAAMtX,EAAWgB,CAAI,EACxD,OAAOgS,GAAW9T,EAAK,OAAQiB,CAAI,CACrC,CACF,CAEA,eAAegV,EAAqB,CAC9B,KAAK,YAAc,iBAKtB,KAAK,mBAA2B,eAAe,KAAK,SAAUA,CAAK,CACtE,CACA,cAAqB,CACnB,KAAK,UAAY,QAEf,KAAK,IAAI,OAAO,WAAW,OAAS,YACnC,OAAO,KAAK,IAAI,MAAU,IAAc,KAAK,IAAI,KAAK,MAAQ,KAAK,IAAI,UAEpE,KAAK,OAAO,SAAS,IAAI,qDAAqD,EAChF,KAAK,UAAY,gBACR,KAAK,OAAO,SAAS,IAAI,iBAAiB,IACnD,KAAK,UAAY,aAGf,KAAK,YAAc,QAAU,OAAO,KAAK,SAAa,MACxD,KAAK,SAAW,KAAK,OAAO,eAAe,CACzC,KAAM,YACN,MAAO,KAAK,kBAAoB,CAClC,CAAC,EACD,KAAK,mBAAqB,KAAK,OAAO,aAEpC,CAAE,KAAM,KAAK,kBAAoB,EAAI,EAAG,MAAO,eAAe,SAAW,eAAe,aAAc,CACxG,GAGN,CAEA,cAAqB,CACnB1G,EAAU,OAAQ,cAAc,EAC3B,KAAK,oBAAoB,IAAI,KAAK,gBAAiB,GACtD,KAAK,oBAAoB,IAAI,KAAK,iBAAmB,CAAC,CAAC,EAEpD,KAAK,uBAAuB,IAAI,KAAK,gBAAiB,GACzD,KAAK,uBAAuB,IAAI,KAAK,iBAAmB,CAAC,CAAC,EAG5D,KAAK,MAAM,EACX,KAAK,cAAgB,WACvB,CACA,YAAmB,CACjBA,EAAU,OAAQ,YAAY,EAE9B,KAAK,MAAM,EACX,KAAK,cAAgB,SACvB,CACA,QAAe,CACbA,EAAU,OAAQ,QAAQ,EAC1B,KAAK,cAAgB,YACrB,IAAM+4C,EAAqB,KAAK,oBAAoB,IAAI,KAAK,gBAAiB,EACxEC,EAAwB,KAAK,uBAAuB,IAAI,KAAK,gBAAiB,EAC9EzsC,EAASwsC,EAAoB,OACnC,KAAK,eAAiB,CAAC,EACvB,QAAS3sD,EAAI,EAAGA,EAAImgB,EAAQngB,IAAK,CAC/B,IAAMioD,EAAqB,KAAK,sBAAsB,EAChD4E,EAAUF,EAAoB3sD,CAAC,EACrC,KAAK,eAAe,KAAK,sBAAwB,CAAC,EAClDioD,EAAmB,YAAY4E,EAAQ,eAAe,EACtD5E,EAAmB,aAAa,EAAG4E,EAAQ,SAAS,EACpD5E,EAAmB,mBAAmB,GAAG4E,EAAQ,aAAa,EAC9D,KAAK,eAAe,KAAK,sBAAwB,EAAI,CAAC,EACtD,KAAK,wBACD,KAAK,YAAc,QACrB,KAAK,eAAe,KAAKD,EAAuB5sD,CAAC,CAAC,GAEhD,KAAK,uBAAyB,KAAK,mBAAqB,KAAK,YAAc,cAC7E,KAAK,eAAe,EAElB,KAAK,uBAAyB,KAAK,mBACrC,KAAK,MAAM,CAEf,CAEA,KAAK,MAAM,EACX,KAAK,cAAgB,SACvB,CAEA,iBAAwB,CACtB,KAAK,eAAe,gBAAgB,CACtC,CAEA,iBAAiB0K,EAAyB,CACxC,KAAK,kBAAkBA,CAAS,EAC5B,KAAK,oBAAoB,IAAIA,CAAS,GACxC,KAAK,oBAAoB,OAAOA,CAAS,EAEvC,KAAK,uBAAuB,IAAIA,CAAS,GAC3C,KAAK,uBAAuB,OAAOA,CAAS,EAE9C,KAAK,eAAe,iBAAiBA,CAAS,CAChD,CAEA,WAAWA,EAAyB,CAClC,KAAK,iBAAmBA,EACxB,KAAK,aAAa,CACpB,CACF,IC75BA,IAAAoiD,GAAA,GAAA3jD,GAAA2jD,GAAA,UAAAvrC,KAAA,IAkBMwrC,GAoDAC,GAqHOzrC,GA3Lb0rC,GAAAttD,EAAA,kBAKAkS,IAKAgC,KAEAc,IAEAgG,KAIMoyC,GAAN,MAAMG,CAAqC,CACzC,YACU9+C,EACQhJ,EACAf,EACAa,EAChB,CAJQ,YAAAkJ,EACQ,cAAAhJ,EACA,UAAAf,EACA,UAAAa,CACf,CAEH,iBAAgC,CAC9B,GAAI,KAAK,WAAa,EACpB,MAAM,IAAI,MAAM,mBAAmB,EAErC,IAAMioD,EAAe74C,EAAU,KAAK,KAAK,IAAI,EAC7C,OAAO64C,IAAiB,EACpB,IAAI,aACJ,IAAI,aAAa,KAAK,OAAO,MAAM,OAAQ,KAAK,KAAMA,CAAY,CACxE,CAEA,kBAAkC,CAChC,GAAI,KAAK,WAAa,EACpB,MAAM,IAAI,MAAM,mBAAmB,EAErC,IAAMA,EAAe74C,EAAU,KAAK,KAAK,IAAI,EAC7C,OAAO64C,IAAiB,EACpB,IAAI,cACJ,IAAI,cAAc,KAAK,OAAO,MAAM,OAAQ,KAAK,KAAMA,CAAY,CACzE,CAEA,eAA4B,CAC1B,GAAI,KAAK,WAAa,EACpB,MAAM,IAAI,MAAM,mBAAmB,EAErC,IAAMA,EAAe74C,EAAU,KAAK,KAAK,IAAI,EAC7C,OAAO64C,IAAiB,EAAI,IAAI,WAAe,IAAI,WAAW,KAAK,OAAO,MAAM,OAAQ,KAAK,KAAMA,CAAY,CACjH,CAEA,gBAA8B,CAC5B,GAAI,KAAK,WAAa,IAAoB,KAAK,WAAa,EAC1D,MAAM,IAAI,MAAM,mBAAmB,EAErC,IAAMA,EAAe74C,EAAU,KAAK,KAAK,IAAI,EAC7C,OAAO64C,IAAiB,EAAI,IAAI,YAAgB,IAAI,YAAY,KAAK,OAAO,MAAM,OAAQ,KAAK,KAAMA,CAAY,CACnH,CAEA,QAAQt3C,EAAwC,CAC9C,GAAIvB,EAAU,KAAKuB,CAAO,IAAMvB,EAAU,KAAK,KAAK,IAAI,EACtD,MAAM,IAAI,MAAM,mBAAmB,EAErC,OAAO,IAAI44C,EAAe,KAAK,OAAQ,KAAK,SAAU,KAAK,KAAMr3C,CAAO,CAC1E,CACF,EAEMm3C,GAAN,KAAmD,CAajD,YACU5+C,EACAvO,EACRutD,EACA,CAHQ,YAAAh/C,EACA,aAAAvO,EAJV,KAAQ,iBAAmB,EAC3B,KAAQ,eAAiB,EAMvB,KAAK,YAAcA,EAAQ,YAG3B,IAAMkP,EAAUX,EAAO,SACnBi/C,EAAYD,EAAoBh/C,EAAO,SACrC9I,EAAOyJ,IAAY,EAAI,MAAQ,MACrC,KAAK,gBAAkB,OAAOX,EAAO,SAASW,EAAUs+C,IAAa/nD,CAAI,CAAC,EAC1E,IAAMgoD,EAAa,OAAOl/C,EAAO,SAASW,EAAUs+C,IAAa/nD,CAAI,CAAC,EACtE,KAAK,YAAc,OAAO8I,EAAO,SAASW,EAAUs+C,IAAa/nD,CAAI,CAAC,EACtE,KAAK,iBAAmB,OAAO8I,EAAO,SAASW,EAAUs+C,IAAa,GAAG,CAAC,EAC1E,KAAK,eAAiB,OAAOj/C,EAAO,SAASW,EAAUs+C,IAAa/nD,CAAI,CAAC,EAEzE,IAAMsF,EAAuB,CAAC,EAC9B,QAAS5K,EAAI,EAAGA,EAAIstD,EAAYttD,IAAK,CACnC,IAAMoF,EAAW,OAAOgJ,EAAO,SAASW,EAAUs+C,IAAa/nD,CAAI,CAAC,EAC9DjB,EAAO,OAAO+J,EAAO,SAASW,EAAUs+C,IAAa,GAAG,CAAC,EACzDjnD,EAAM,OAAOgI,EAAO,SAASW,EAAUs+C,IAAa/nD,CAAI,CAAC,EACzDJ,EAAiB,CAAC,EACxB,QAASmlB,EAAI,EAAGA,EAAIjkB,EAAKikB,IACvBnlB,EAAK,KAAK,OAAOkJ,EAAO,SAASW,EAAUs+C,IAAa/nD,CAAI,CAAC,CAAC,EAEhEsF,EAAO,KAAK,IAAImiD,GAAe3+C,EAAQhJ,EAAUf,EAAMa,CAAI,CAAC,CAC9D,CACA,KAAK,OAAS0F,CAChB,CArCA,IAAI,kBAA+C,CACjD,OAAO,KAAK,QAAQ,uBACtB,CACA,IAAI,kBAA+B,CACjC,OAAO,KAAK,OAAO,OAAO,SAAS,KAAK,iBAAkB,KAAK,iBAAmB,KAAK,cAAc,CACvG,CAkCA,QAAQkgD,EAAsByC,EAAyE,CAErG,IAAMC,EACJD,GAAsB,QAAQ,IAAKvtD,GAAO,OAAOA,GAAM,SAAW,KAAK,OAAOA,CAAC,EAAIA,CAAE,GAAK,KAAK,OAE3F6K,EAAgB0iD,GAAsB,SAAW,CAAC,EAClDxC,EAAqB,CAACzwC,EAAelV,EAAkBF,IAC3D,IAAI6nD,GAAe,KAAK,OAAQ3nD,EAAU,KAAK,OAAOkV,EAAOpV,CAAI,EAAGA,CAAI,EACpEuoD,EAAwB,CAACroD,EAAkBF,IAAwC,CACvF,IAAM+X,EAAa1L,GAA2BnM,EAAUF,CAAI,EAC5D,GAAI,CAAC+X,EACH,MAAM,IAAI,MAAM,0BAA0B7X,CAAQ,EAAE,EAEtD,IAAM8mD,EAAYjvC,EAAa,EAAI,KAAK,QAAQ,eAAe,OAAOA,CAAU,EAAE,GAAK,EACvF,OAAO,IAAI8vC,GAAe,KAAK,OAAQ3nD,EAAU8mD,EAAWhnD,CAAI,CAClE,EACA,OAAO,KAAK,QAAQ,IAClB4lD,EACA0C,EACA3iD,EACAkgD,EACA0C,EACA,KAAK,WACP,CACF,CAEA,OAAOnzC,EAAepV,EAAiC,CACrD,IAAMsC,EAAQ,KAAK,OAAO,UAAU,EACpC,GAAI,CACF,IAAMuH,EAAU,KAAK,OAAO,SACtBzJ,EAAOyJ,IAAY,EAAI,MAAQ,MAC/B1K,EAAO,KAAK,OAAO,YAAY,EAAIa,EAAK,QAAU6J,CAA4B,EACpF,KAAK,OAAO,SAAS1K,EAAMa,EAAK,OAAQI,CAAI,EAC5C,QAAStF,EAAI,EAAGA,EAAIkF,EAAK,OAAQlF,IAC/B,KAAK,OAAO,SAASqE,EAAO0K,GAAW/O,EAAI,GAAIkF,EAAKlF,CAAC,EAAGsF,CAAI,EAE9D,OAAO,KAAK,OAAO,YAAa,KAAK,gBAAiBgV,EAAOjW,CAAI,CACnE,OAASjE,EAAG,CACV,MAAM,IAAI,MACR,sCAAsCka,CAAK,gBAAgBpV,CAAI,8GAEnD9E,CAAC,EACf,CACF,QAAE,CACA,KAAK,OAAO,aAAaoH,CAAK,CAChC,CACF,CACF,EA0Ba+Z,GAAO,MAClB3hB,EACAwO,EACAhN,EACAssD,IACkB,CAClB,IAAMC,EAAWv/C,EAAO,SACxB,GAAI,CAACu/C,EACH,MAAM,IAAI,MAAM,mFAAmF,EAGrG,GAAI/tD,IAAS,SACoB,CAE7B,IAAMguD,EAAoB,cAA4B,cAChD/tD,EAAU,IAAI+tD,EACpB,MAAM/tD,EAAQ,WAAWuB,EAAKssD,CAAW,EAEzCC,EAAS,SAAU,CAEjB9tD,EAGCsG,GAAiBtG,EAAQ,MAAM,OAAOsG,CAAI,CAAC,EAG3Ck5C,GAAgBx/C,EAAQ,KAAKw/C,CAAG,EAGjC,CAAC8M,EAAaC,EAAajmD,EAAc0nD,EAAc,KAAU,CAC/D,GAAIA,EACFj6C,EACE,UACA,IAAM,kCAAkC,OAAOu4C,CAAG,CAAC,SAAS,OAAOC,CAAG,CAAC,UAAU,OAAOjmD,CAAI,CAAC,EAC/F,EACAtG,EAAQ,OAAO,OAAOssD,CAAG,EAAG,OAAOC,CAAG,CAAC,MAClC,CACLx4C,EACE,UACA,IACE,yCAAyC,OAAOu4C,CAAG,CAAC,eAAe,OAAOC,CAAG,CAAC,UAAU,OAAOjmD,CAAI,CAAC,EACxG,EACA,IAAM9B,EAAO+J,EAAO,OAAO,SAAS,OAAO+9C,IAAQ,CAAC,EAAG,OAAOA,IAAQ,CAAC,EAAI,OAAOhmD,CAAI,CAAC,EACvFtG,EAAQ,OAAO,OAAOusD,CAAG,EAAG/nD,CAAI,CAClC,CACF,EAGA,MAAO6nD,EAAmBt9C,EAAoBzI,IAAgC,CAC5EyN,EACE,UACA,IAAM,wCAAwCs4C,CAAS,gBAAgBt9C,CAAU,UAAUzI,CAAI,EACjG,EAEA,MAAMtG,EAAQ,SAAS,OAAOqsD,CAAS,EAAG,IACxC99C,EAAO,OAAO,SAAS,OAAOQ,CAAU,IAAM,EAAG,OAAOA,EAAazI,CAAI,IAAM,CAAC,CAClF,CACF,EAGA,CAACkkD,EAAoBF,EAAkBrrC,IACrCjf,EAAQ,aACNwqD,EACA,OAAOF,CAAQ,EACfrrC,EACA1Q,EAAO,aAAaA,EAAO,iBAAkB,OAAO+7C,CAAQ,CAAC,CAAC,CAChE,EAGD9yC,GAAmBxX,EAAQ,cAAcwX,CAAM,EAGhD,CAACA,EAAgB+1C,EAA2BU,EAAuBrtD,IAA0C,CAC3GmT,EACE,UACA,IACE,mCAAmCk6C,CAAa,YAAYz2C,CAAM,uBAAuB+1C,CAAiB,EAC9G,EACA,IAAMxoD,EAAU,IAAIooD,GAAmB5+C,EAAQvO,EAAS,OAAOutD,CAAiB,CAAC,EACjF,OAAOvtD,EAAQ,cAAc,OAAOwX,CAAM,EAAGzS,EAASnE,CAAM,CAC9D,EAEA,IAAMZ,EAAQ,aAAa,EAE3B,IAAMA,EAAQ,WAAW,EAEzB,IAAMA,EAAQ,OAAO,CACvB,CAAC,CACH,KACK,CACL,IAAMA,EAAU,IAAI6a,GAAatZ,CAAG,EACpCusD,EAAS,QAAS,CAChB9tD,EAEA,IAAMA,EAAQ,gBAAgB,EAE7Bqa,GAAqBra,EAAQ,gBAAgBqa,CAAQ,EAEtD,MAAOxP,EAA+BwP,EAAkBkB,EAAsB7F,EAAiBsE,IAC7Fha,EAAQ,aAAa6K,EAAWwP,EAAUkB,EAAc7F,EAAOsE,CAAO,EAExE,CAACK,EAAkB7V,IAAqB,CACtCxE,EAAQ,aAAaqa,EAAU7V,CAAI,CACrC,EAEA,MAAO6V,EAAkBV,IAA6C3Z,EAAQ,eAAeqa,EAAUV,CAAS,CAClH,CAAC,CACH,CACF,ICvSA,IAiFMu0C,GAWO9jD,GAWAE,GAwGP6jD,GAOAC,GAuBO5jD,GAkBAE,GAqLAE,GA8BAyjD,GAoIApjD,GA8WAI,GAgBAD,GAp9BbtB,GAAAhK,EAAA,kBAgBA0P,KACAa,KACA2B,IAUAjI,KACA6E,KACA8D,KAmDMw7C,GAAU,CAAC3gD,EAAoB+gD,IAA+B,CAChDlhD,GAAY,EAAE,SAASG,EAAY+gD,CAAY,IAC/C,GAChB3/C,EAAe,+BAA+B,CAElD,EAMavE,GAAc,MAAO7I,GAA4B,CAE5D2sD,GAAQ3sD,EAAI,KAAK,WAAaqQ,GAAqBrQ,EAAI,QAAQ,CAAC,CAClE,EAQa+I,GAAS,MAAO/I,EAAU8I,IAAkC,CAEvE+C,GAAY,EAAE,YAAY,EAQI,CAE5B,IAAMmhD,EAAW,cAAuB,KAExC,GAAIlkD,IAAW,SAAuC,CAEpD,GAAI,OAAO,UAAc,KAAe,CAAC,UAAU,IACjD,MAAM,IAAI,MAAM,gDAAgD,EAGlE,IAAIu/C,EAAUroD,EAAI,OAAO,QACzB,GAAKqoD,GAuBH,GACE,OAAOA,EAAQ,QAAW,UAC1B,OAAOA,EAAQ,UAAa,UAC5B,OAAOA,EAAQ,eAAkB,WAEjC,MAAM,IAAI,MAAM,kFAAkF,MA5BxF,CAEZ,IAAM4E,EAAkBjtD,EAAI,OAAO,gBACnC,GACEitD,IAAoB,QACpBA,IAAoB,aACpBA,IAAoB,mBAEpB,MAAM,IAAI,MAAM,qCAAqCA,CAAe,GAAG,EAEzE,IAAMC,EAAuBltD,EAAI,OAAO,qBACxC,GAAIktD,IAAyB,QAAa,OAAOA,GAAyB,UACxE,MAAM,IAAI,MAAM,0CAA0CA,CAAoB,GAAG,EAGnF,GADA7E,EAAU,MAAM,UAAU,IAAI,eAAe,CAAE,gBAAA4E,EAAiB,qBAAAC,CAAqB,CAAC,EAClF,CAAC7E,EACH,MAAM,IAAI,MACR,0GAEF,CAEJ,CAWA,MAAM2E,EAAS,SAAUnhD,GAAY,EAAG7L,EAAKqoD,CAAO,CACtD,CACA,GAAIv/C,IAAW,QAAS,CAEtB,GAAI,OAAO,UAAc,KAAe,CAAE,UAAyC,GACjF,MAAM,IAAI,MAAM,+CAA+C,EAGjE,MAAMkkD,EAAS,QAASnhD,GAAY,EAAG7L,CAAG,CAC5C,CACF,CACF,EAwCM4sD,GAAiB,IAAI,IAOrBC,GAA8BH,GAA4C,CAC9E,IAAMnhD,EAAOM,GAAY,EACnBzF,EAAQmF,EAAK,UAAU,EAC7B,GAAI,CACF,IAAMoC,EAAUpC,EAAK,SACfiC,EAAajC,EAAK,WAAW,EAAIoC,CAAO,EAC5BpC,EAAK,wBAAwBmhD,EAAel/C,EAAYA,EAAaG,CAAO,IAC5E,GAChBP,EAAe,uCAAuC,EAExD,IAAMlJ,EAAOyJ,IAAY,EAAI,MAAQ,MACrC,MAAO,CAAC,OAAOpC,EAAK,SAASiC,EAAYtJ,CAAI,CAAC,EAAG,OAAOqH,EAAK,SAASiC,EAAaG,EAASzJ,CAAI,CAAC,CAAC,CACpG,QAAE,CACAqH,EAAK,aAAanF,CAAK,CACzB,CACF,EAQa6C,GAA0BC,GAAwC,CAC7E,IAAMqC,EAAOM,GAAY,EACnBshD,EAAkB5hD,EAAK,QAAQrC,EAAM,UAAU,EACrD,GAAIikD,IAAoB,EACtB,MAAM,IAAI,MAAM,+DAA+DjkD,EAAM,UAAU,GAAG,EAEpG,OAAAqC,EAAK,OAAO,IAAIrC,EAAOikD,CAAe,EAC/B,CAACA,EAAiBjkD,EAAM,UAAU,CAC3C,EAUaC,GAAgB,MAC3BikD,EACAnuD,IACyC,CACzC,IAAIkuD,EAAyBE,EACvB9hD,EAAOM,GAAY,EAErB,MAAM,QAAQuhD,CAAS,EAEzB,CAACD,EAAiBE,CAAe,EAAID,EAC5BA,EAAU,SAAW7hD,EAAK,OAAO,OAE1C,CAAC4hD,EAAiBE,CAAe,EAAI,CAACD,EAAU,WAAYA,EAAU,UAAU,EAGhF,CAACD,EAAiBE,CAAe,EAAIpkD,GAAuBmkD,CAAS,EAGvE,IAAIV,EAAgB,EAChBv9C,EAAuB,EACvBm+C,EAAkB,EAClBhgD,EAAmB,CAAC,EAClBigD,EAAwB,CAAC,EACzBC,EAAyB,CAAC,EAEhC,GAAI,CAGF,GAFA,CAACr+C,EAAsB7B,CAAM,EAAI,MAAMuB,GAAkB5P,CAAO,EAE5DA,GAAS,cAAgBsM,EAAK,kBAAmB,CACnD,IAAMkiD,EAAkB,CAAC,EACzB,QAAWr8C,KAAQnS,EAAQ,aAAc,CACvC,IAAMyuD,EAAO,OAAOt8C,GAAS,SAAWA,EAAOA,EAAK,KACpDq8C,EAAgB,KACdv8C,GAAS,OAAOE,GAAS,SAAWA,EAAOA,EAAK,IAAI,EAAE,KAAMnO,GAAS,CACnEsI,EAAK,kBAAkBmiD,EAAMzqD,CAAI,CACnC,CAAC,CACH,CACF,CAGA,MAAM,QAAQ,IAAIwqD,CAAe,CACnC,CAEA,QAAWE,KAAY1uD,GAAS,oBAAsB,CAAC,EAErD,IADqB,OAAO0uD,GAAa,SAAWA,EAAWA,EAAS,QACnD,QAAS,CAE5B,GADApiD,EAAK,yBAA2B,GAC5B,OAAOoiD,GAAa,SAAU,CAChC,IAAMC,EAAeD,EACfnqD,EAAWoqD,GAA6D,QACxEC,EAAaD,GAAsD,UACnE5nD,EAAc4nD,GAAuD,WACrEX,EAAmBW,GAAuD,gBAC5EpqD,EACF+H,EAAK,eAAiB/H,EACbqqD,EACTtiD,EAAK,eAAiB,MAAMA,EAAK,oBAAqBsiD,CAAS,EAE/DtiD,EAAK,eAAiB,MAAMA,EAAK,oBAAqB,CAAE,WAAAvF,EAAY,gBAAAinD,CAAgB,CAAC,CAEzF,MACE1hD,EAAK,eAAiB,MAAMA,EAAK,oBAAqB,EAExD,KACF,CAGFmhD,EAAgB,MAAMnhD,EAAK,kBAAkB4hD,EAAiBE,EAAiBl+C,CAAoB,EACnG5D,EAAK,wBAAwBmhD,CAAa,EACtCA,IAAkB,GACpBt/C,EAAe,yBAAyB,EAG1C7B,EAAK,sBAAsB,EAGvBA,EAAK,iBACPA,EAAK,sBAAuBmhD,EAAenhD,EAAK,cAAc,EAC9DA,EAAK,eAAiB,OACtBA,EAAK,yBAA2B,IAGlC,GAAM,CAAC2gD,EAAY1/B,CAAW,EAAIqgC,GAA2BH,CAAa,EAEpEoB,EAAqB,CAAC,CAAC7uD,GAAS,mBAEhC4b,EAAa,CAAC,EACdkzC,EAAc,CAAC,EACfC,EAAwE,CAAC,EAC/E,QAASpvD,EAAI,EAAGA,EAAIstD,EAAYttD,IAAK,CACnC,IAAMJ,EAAO+M,EAAK,iBAAiBmhD,EAAe9tD,CAAC,EAC/CJ,IAAS,GACX4O,EAAe,0BAA0B,EAE3CmgD,EAAsB,KAAK/uD,CAAI,EAC/Bqc,EAAW,KAAKtP,EAAK,aAAa/M,CAAI,CAAC,CACzC,CACA,QAASI,EAAI,EAAGA,EAAI4tB,EAAa5tB,IAAK,CACpC,IAAMJ,EAAO+M,EAAK,kBAAkBmhD,EAAe9tD,CAAC,EAChDJ,IAAS,GACX4O,EAAe,2BAA2B,EAE5CogD,EAAuB,KAAKhvD,CAAI,EAChC,IAAMyvD,EAAa1iD,EAAK,aAAa/M,CAAI,EACzCuvD,EAAY,KAAKE,CAAU,EAEG,CAC5B,GAAIH,GAAsB7uD,GAAS,0BAA4B,OAAW,CACxE+uD,EAAyB,KAAK,YAAY,EAC1C,QACF,CACA,IAAM/8C,EACJ,OAAOhS,GAAS,yBAA4B,SACxCA,EAAQ,wBACPA,GAAS,0BAA0BgvD,CAAU,GAAK,MACzD,GAAIh9C,IAAa,OAASA,IAAa,cAAgBA,IAAa,cAAgBA,IAAa,YAC/F,MAAM,IAAI,MAAM,4CAA4CA,CAAQ,GAAG,EAEzE,GAAI68C,GAAsB78C,IAAa,aACrC,MAAM,IAAI,MACR,4CAA4CA,CAAQ,4EACtD,EAEF+8C,EAAyB,KAAK/8C,CAAQ,CACxC,CACF,CAGA,IAAIi9C,EAAsC,KAC1C,OAAgCF,EAAyB,KAAM1kC,GAAMA,IAAM,cAAgBA,IAAM,WAAW,IAC1GgkC,EAAkB/hD,EAAK,kBAAkBmhD,CAAa,EAClDY,IAAoB,GACtBlgD,EAAe,0BAA0B,EAG3C8gD,EAAe,CACb,OAAQZ,EACR,yBAAAU,EACA,gCAAiCA,EAAyB,IAAK1kC,GAAM9Y,GAAyB8Y,CAAC,CAAC,CAClG,GAGFsjC,GAAe,IAAIF,EAAe,CAChCA,EACAa,EACAC,EACAU,EACAJ,EACA,EACF,CAAC,EACM,CAACpB,EAAe7xC,EAAYkzC,CAAW,CAChD,OAAS/uD,EAAG,CACV,MAAAuuD,EAAsB,QAASY,GAAQ5iD,EAAK,SAAS4iD,CAAG,CAAC,EACzDX,EAAuB,QAASW,GAAQ5iD,EAAK,SAAS4iD,CAAG,CAAC,EAEtDb,IAAoB,GAClB/hD,EAAK,mBAAmB+hD,CAAe,IAAM,GAC/ClgD,EAAe,2BAA2B,EAI1Cs/C,IAAkB,GAChBnhD,EAAK,mBAAmBmhD,CAAa,IAAM,GAC7Ct/C,EAAe,wBAAwB,EAGrCpO,CACR,QAAE,CACAuM,EAAK,MAAM4hD,CAAe,EACtBh+C,IAAyB,GACvB5D,EAAK,0BAA0B4D,CAAoB,IAAM,GAC3D/B,EAAe,gCAAgC,EAGnDE,EAAO,QAASiB,GAAUhD,EAAK,MAAMgD,CAAK,CAAC,EAG3ChD,EAAK,sBAAsB,CAC7B,CACF,EAEalC,GAAkBC,GAA4B,CACzD,IAAMiC,EAAOM,GAAY,EACnBoD,EAAU29C,GAAe,IAAItjD,CAAS,EAC5C,GAAI,CAAC2F,EACH,MAAM,IAAI,MAAM,+CAA+C3F,CAAS,EAAE,EAE5E,GAAM,CAACojD,EAAea,EAAuBC,EAAwBY,EAAgBN,CAAkB,EAAI7+C,EAEvGm/C,IACEN,GACEviD,EAAK,sBAAsB6iD,EAAe,MAAM,IAAM,GACxDhhD,EAAe,4BAA4B,EAG3C7B,EAAK,mBAAmB6iD,EAAe,MAAM,IAAM,GACrDhhD,EAAe,2BAA2B,GAI9C7B,EAAK,uBAAuBjC,CAAS,EACrCiC,EAAK,yBAAyBjC,CAAS,EAEvCikD,EAAsB,QAASY,GAAQ5iD,EAAK,SAAS4iD,CAAG,CAAC,EACzDX,EAAuB,QAASW,GAAQ5iD,EAAK,SAAS4iD,CAAG,CAAC,EACtD5iD,EAAK,mBAAmBmhD,CAAa,IAAM,GAC7Ct/C,EAAe,wBAAwB,EAEzCw/C,GAAe,OAAOtjD,CAAS,CACjC,EAEawjD,GAA2B,MACtCvsD,EACA8tD,EACA/gD,EACAhE,EACA4P,EACA40C,EAAqB,KACH,CAClB,GAAI,CAACvtD,EAAQ,CACX8tD,EAAc,KAAK,CAAC,EACpB,MACF,CAEA,IAAM9iD,EAAOM,GAAY,EACnB8B,EAAUpC,EAAK,SAEfvH,EAAWzD,EAAO,CAAC,EACnBuD,EAAOvD,EAAO,CAAC,EACf0Q,EAAW1Q,EAAO,CAAC,EACrB+tD,EAAiBr9C,EAEjBs9C,EACAC,EAEJ,GAAIxqD,IAAa,WAAaiN,IAAa,cAAgBA,IAAa,aACtE,MAAM,IAAI,MAAM,wCAAwC,EAG1D,GAAI68C,GAAsB78C,IAAa,aACrC,MAAM,IAAI,MACR,2DAA2DiI,CAAK,mCAClE,EAGF,GAAIjI,IAAa,aAAc,CAC7B,IAAMlN,EAAYxD,EAAO,CAAC,EAAE,UAC5BiuD,EAAiBr+C,GAA2BF,GAA2BjM,CAAQ,EAAGF,CAAI,EAS/E,CACL,IAAM2qD,EAAiBljD,EAAK,mBAC5B,GAAI,CAACkjD,EACH,MAAM,IAAI,MAAM,qEAAqE,EAEvFF,EAAUE,EAAenlD,EAAW4P,EAAOnV,EAAWyqD,CAAc,CACtE,CACF,SAAWv9C,IAAa,YAAa,CACnC,IAAMhN,EAAW1D,EAAO,CAAC,EAAE,SAC3BiuD,EAAiBr+C,GAA2BF,GAA2BjM,CAAQ,EAAGF,CAAI,EAEtF,IAAM4qD,EAAmBnjD,EAAK,qBAC9B,GAAI,CAACmjD,EACH,MAAM,IAAI,MAAM,mEAAmE,EAErFH,EAAUG,EAAiBplD,EAAWrF,EAAUgM,GAA2BjM,CAAQ,EAAGF,CAAI,CAC5F,KAAO,CACL,IAAMb,EAAO1C,EAAO,CAAC,EAErB,GAAI,MAAM,QAAQ0C,CAAI,EAAG,CAEvBurD,EAAiB7gD,EAAU1K,EAAK,OAChCsrD,EAAUhjD,EAAK,QAAQijD,CAAc,EACrClhD,EAAO,KAAKihD,CAAO,EACnB,QAAS3vD,EAAI,EAAGA,EAAIqE,EAAK,OAAQrE,IAAK,CACpC,GAAI,OAAOqE,EAAKrE,CAAC,GAAM,SACrB,MAAM,IAAI,UAAU,wBAAwBA,CAAC,kBAAkB,EAEjE2M,EAAK,SAASgjD,EAAU3vD,EAAI+O,EAAST,GAAgBjK,EAAKrE,CAAC,EAAG0O,CAAM,EAAG,GAAG,CAC5E,CACF,KAAO,CACL,IAAMqhD,EAAepjD,EAAK,iBAC1B,GAAIvH,IAAa,UAAY2qD,EAAc,CACzC,IAAMC,EAAiBrjD,EAAK,iBAAiBjC,EAAW4P,CAAK,EACvD21C,EAAatjD,EAAK,aAAaqjD,CAAc,EAEnD,GAAID,EAAarlD,EAAWulD,CAAU,EAAG,CACvC,IAAMC,EAAe7+C,GAA2BjM,CAAQ,EACxDwqD,EAAiBr+C,GAA2B2+C,EAAchrD,CAAI,EAC9DwqD,EAAiB,YACjB,IAAMS,EAAwBxjD,EAAK,0BAC7ByjD,EAAezjD,EAAK,iBAC1B,GAAI,CAACwjD,GAAyB,CAACC,EAC7B,MAAM,IAAI,MAAM,mEAAmE,EAErF,IAAMl2C,EAAW,MAAMi2C,EAAsBzlD,EAAWwlD,EAAchrD,CAAgB,EACtFkrD,EAAal2C,EAAU,IAAI,WAAW7V,EAAK,OAAQA,EAAK,WAAYA,EAAK,UAAU,CAAC,EACpFsrD,EAAUz1C,CACZ,MACE01C,EAAiBvrD,EAAK,WACtBsrD,EAAUhjD,EAAK,QAAQijD,CAAc,EACrClhD,EAAO,KAAKihD,CAAO,EACnBhjD,EAAK,OAAO,IAAI,IAAI,WAAWtI,EAAK,OAAQA,EAAK,WAAYurD,CAAc,EAAGD,CAAO,CAEzF,MACEC,EAAiBvrD,EAAK,WACtBsrD,EAAUhjD,EAAK,QAAQijD,CAAc,EACrClhD,EAAO,KAAKihD,CAAO,EACnBhjD,EAAK,OAAO,IAAI,IAAI,WAAWtI,EAAK,OAAQA,EAAK,WAAYurD,CAAc,EAAGD,CAAO,CAEzF,CACF,CAEA,IAAMnoD,EAAQmF,EAAK,UAAU,EACvB0jD,EAAa1jD,EAAK,WAAW,EAAIzH,EAAK,MAAM,EAClD,GAAI,CACFA,EAAK,QAAQ,CAACmlB,EAAG/P,IAAU3N,EAAK,SAAS0jD,EAAa/1C,EAAQvL,EAASsb,EAAGtb,IAAY,EAAI,MAAQ,KAAK,CAAC,EACxG,IAAMpN,EAASgL,EAAK,iBAClB0E,GAA2BjM,CAAQ,EACnCuqD,EACAC,EACAS,EACAnrD,EAAK,OACL0M,GAAyB89C,CAAc,CACzC,EACI/tD,IAAW,GACb6M,EAAe,iDAAiD9D,CAAS,WAAW4P,CAAK,GAAG,EAE9Fm1C,EAAc,KAAK9tD,CAAM,CAC3B,QAAE,CACAgL,EAAK,aAAanF,CAAK,CACzB,CACF,EAKasD,GAAM,MACjBJ,EACAC,EACAsqB,EACApqB,EACAylD,EACAjwD,IAC8B,CAC9B,IAAMsM,EAAOM,GAAY,EACnB8B,EAAUpC,EAAK,SACf0D,EAAU29C,GAAe,IAAItjD,CAAS,EAC5C,GAAI,CAAC2F,EACH,MAAM,IAAI,MAAM,6CAA6C3F,CAAS,EAAE,EAE1E,IAAMojD,EAAgBz9C,EAAQ,CAAC,EACzBs+C,EAAwBt+C,EAAQ,CAAC,EACjCu+C,EAAyBv+C,EAAQ,CAAC,EAClCm/C,EAAiBn/C,EAAQ,CAAC,EAC1B6+C,EAAqB7+C,EAAQ,CAAC,EAC9BkgD,EAAmBlgD,EAAQ,CAAC,EAE5Bi9C,EAAa3iD,EAAa,OAC1BijB,EAAc/iB,EAAc,OAE9ByE,EAAmB,EACnBkhD,EAA6B,CAAC,EAE5BC,EAA+B,CAAC,EAChCC,EAAgC,CAAC,EACjCC,EAA8B,CAAC,EAE/BC,EAAiBjkD,EAAK,UAAU,EAChCkkD,EAAoBlkD,EAAK,WAAW2gD,EAAav+C,CAAO,EACxD+hD,EAAmBnkD,EAAK,WAAW2gD,EAAav+C,CAAO,EACvDgiD,EAAqBpkD,EAAK,WAAWihB,EAAc7e,CAAO,EAC1DiiD,EAAoBrkD,EAAK,WAAWihB,EAAc7e,CAAO,EAE/D,GAAI,CACF,CAACO,EAAkBkhD,CAAgB,EAAIphD,GAAc/O,CAAO,EAG5D,QAASL,EAAI,EAAGA,EAAIstD,EAAYttD,IAC9B,MAAMkuD,GACJj5B,EAAaj1B,CAAC,EACdywD,EACAE,EACAjmD,EACAC,EAAa3K,CAAC,EACdkvD,CACF,EAIF,QAASlvD,EAAI,EAAGA,EAAI4tB,EAAa5tB,IAC/B,MAAMkuD,GACJoC,EAActwD,CAAC,EACf0wD,EACAC,EACAjmD,EACA4iD,EAAaziD,EAAc7K,CAAC,EAC5BkvD,CACF,EAGF,QAASlvD,EAAI,EAAGA,EAAIstD,EAAYttD,IAC9B2M,EAAK,SAASkkD,EAAoB7wD,EAAI+O,EAAS0hD,EAAmBzwD,CAAC,EAAG,GAAG,EACzE2M,EAAK,SAASmkD,EAAmB9wD,EAAI+O,EAAS4/C,EAAsBhkD,EAAa3K,CAAC,CAAC,EAAG,GAAG,EAE3F,QAASA,EAAI,EAAGA,EAAI4tB,EAAa5tB,IAC/B2M,EAAK,SAASokD,EAAqB/wD,EAAI+O,EAAS2hD,EAAoB1wD,CAAC,EAAG,GAAG,EAC3E2M,EAAK,SAASqkD,EAAoBhxD,EAAI+O,EAAS6/C,EAAuB/jD,EAAc7K,CAAC,CAAC,EAAG,GAAG,EAG9F,GAAgCwvD,GAAkB,CAACe,EAAkB,CACnE,GAAM,CAAE,OAAAU,EAAQ,yBAAA7B,EAA0B,gCAAA8B,EAAgC,EAAI1B,EAE9E,GAAIb,EAAsB,SAAWrB,EACnC,MAAM,IAAI,MACR,2BAA2BA,CAAU,4DAA4DqB,EAAsB,MAAM,IAC/H,EAIF,QAAS3uD,EAAI,EAAGA,EAAIstD,EAAYttD,IAAK,CACnC,IAAMsa,EAAQ3P,EAAa3K,CAAC,EACV,MAAM2M,EAAK,cAAcskD,EAAQtC,EAAsBr0C,CAAK,EAAGm2C,EAAmBzwD,CAAC,CAAC,IACpF,GAChBwO,EAAe,oBAAoBxO,CAAC,iBAAiB0K,CAAS,GAAG,CAErE,CAGA,QAAS1K,EAAI,EAAGA,EAAI4tB,EAAa5tB,IAAK,CACpC,IAAMsa,EAAQzP,EAAc7K,CAAC,EACZswD,EAActwD,CAAC,IAAI,CAAC,EAIjB2M,EAAK,eAAeskD,EAAQrC,EAAuBt0C,CAAK,EAAGo2C,EAAoB1wD,CAAC,EAAG,CAAC,IACpF,GAChBwO,EAAe,mCAAmCxO,CAAC,iBAAiB0K,CAAS,GAAG,EAIhEiC,EAAK,eACrBskD,EACArC,EAAuBt0C,CAAK,EAC5B,EACA42C,GAAgC52C,CAAK,CACvC,IACkB,GAChB9L,EAAe,qBAAqBxO,CAAC,QAAQovD,EAAyBpvD,CAAC,CAAC,gBAAgB0K,CAAS,GAAG,CAG1G,CACAsjD,GAAe,IAAItjD,EAAW,CAC5BojD,EACAa,EACAC,EACAY,EACAN,EACA,EACF,CAAC,CACH,CAEAviD,EAAK,iBAAiBmhD,CAAa,EAEnC,IAAI7+C,EAC4BugD,EAC9BvgD,EAAY,MAAMtC,EAAK,mBACrBmhD,EACA0B,EAAe,OACf5hC,EACAmjC,EACAzhD,CACF,EAEAL,EAAY,MAAMtC,EAAK,QACrBmhD,EACAgD,EACAD,EACAvD,EACA0D,EACApjC,EACAmjC,EACAzhD,CACF,EAGEL,IAAc,GAChBT,EAAe,0BAA0B,EAG3C,IAAMoT,EAA2B,CAAC,EAElC,QAAS5hB,EAAI,EAAGA,EAAI4tB,EAAa5tB,IAAK,CACpC,IAAM2B,EAAS,OAAOgL,EAAK,SAASokD,EAAqB/wD,EAAI+O,EAAS,GAAG,CAAC,EAC1E,GAAIpN,IAAW+uD,EAAoB1wD,CAAC,EAAG,CAErC4hB,EAAO,KAAK0uC,EAActwD,CAAC,CAAE,EAC7B,QACF,CAEA,IAAMmxD,GAA2BxkD,EAAK,UAAU,EAE1CykD,EAAmBzkD,EAAK,WAAW,EAAIoC,CAAO,EAEhDsiD,EAAmB,GACnB/rD,EACFsJ,EAAa,EACf,GAAI,CACgBjC,EAAK,kBACrBhL,EACAyvD,EACAA,EAAmBriD,EACnBqiD,EAAmB,EAAIriD,EAEvBqiD,EAAmB,EAAIriD,CACzB,IACkB,GAChBP,EAAe,4CAA4CxO,CAAC,GAAG,EAEjE,IAAMygB,GAAY1R,IAAY,EAAI,MAAQ,MACpC3J,GAAW,OAAOuH,EAAK,SAASykD,EAAkB3wC,EAAS,CAAC,EAClE7R,EAAajC,EAAK,SAASykD,EAAmBriD,EAAS,GAAG,EAC1D,IAAMshD,EAAa1jD,EAAK,SAASykD,EAAmBriD,EAAU,EAAG,GAAG,EAC9DuiD,EAAa,OAAO3kD,EAAK,SAASykD,EAAmBriD,EAAU,EAAG0R,EAAS,CAAC,EAC5Evb,EAAO,CAAC,EACd,QAASlF,GAAI,EAAGA,GAAIsxD,EAAYtxD,KAC9BkF,EAAK,KAAK,OAAOyH,EAAK,SAAS0jD,EAAarwD,GAAI+O,EAAS0R,EAAS,CAAC,CAAC,EAElE9T,EAAK,SAAS0jD,CAAU,IAAM,GAChC7hD,EAAe,oCAAoC,EAErD,IAAMrI,GAAOjB,EAAK,OAAO,CAACgN,GAAGC,KAAMD,GAAIC,GAAG,CAAC,EAC3C7M,EAAOgM,GAA2BlM,EAAQ,EAE1C,IAAMmsD,GAAoB/B,GAAgB,yBAAyB3kD,EAAc7K,CAAC,CAAC,EAEnF,GAAIsF,IAAS,SAAU,CACrB,GAAIisD,KAAsB,cAAgBA,KAAsB,YAC9D,MAAM,IAAI,MAAM,wCAAwC,EAE1D,IAAMC,GAAuB,CAAC,EAC9B,QAASxxD,GAAI,EAAGA,GAAImG,GAAMnG,KAAK,CAC7B,IAAMmT,GAASxG,EAAK,SAASiC,EAAa5O,GAAI+O,EAAS,GAAG,EACpD0iD,GAAa9kD,EAAK,SAASiC,GAAc5O,GAAI,GAAK+O,EAAS,GAAG,EAC9D2iD,GAAiB1xD,KAAMmG,GAAO,EAAI,OAAYsrD,GAAat+C,GACjEq+C,GAAW,KAAK7kD,EAAK,aAAawG,GAAQu+C,EAAc,CAAC,CAC3D,CACA9vC,EAAO,KAAK,CAACtc,EAAMJ,EAAMssD,GAAY,KAAK,CAAC,CAC7C,SAGMD,KAAsB,cAAgBprD,GAAO,EAAG,CAClD,IAAMwrD,GAA8DhlD,EAAK,cACzE,GAAI,CAACglD,GACH,MAAM,IAAI,MAAM,uEAAuE,EAEzF,IAAMxsD,GAAYwsD,GAAU/iD,CAAU,EAChCqO,GAAa1L,GAA2BnM,GAAUe,EAAI,EAC5D,GAAI8W,KAAe,QAAa,CAACvL,GAAyBpM,CAAI,EAC5D,MAAM,IAAI,MAAM,0BAA0BA,CAAI,EAAE,EAIlD+rD,EAAmB,GAwBjBzvC,EAAO,KAAK,CACVtc,EACAJ,EACA,CACE,UAAAC,GACA,SAAUwH,EAAK,qBAAsBxH,GAAW8X,GAAY3X,CAAI,EAChE,QAAS,IAAM,CACTqH,EAAK,kBAAkBhL,CAAM,IAAM,GACrC6M,EAAe,uBAAuB,CAE1C,CACF,EACA,YACF,CAAC,CAEL,SAAW+iD,KAAsB,aAAeprD,GAAO,EAAG,CACxD,IAAMyrD,GAAejlD,EAAK,iBACpBklD,GAAmBllD,EAAK,qBAC9B,GAAI,CAACilD,IAAgB,CAACC,GACpB,MAAM,IAAI,MAAM,qEAAqE,EAGvF,GADmBtgD,GAA2BnM,GAAUe,EAAI,IACzC,QAAa,CAACwL,GAAwBrM,CAAI,EAC3D,MAAM,IAAI,MAAM,0BAA0BA,CAAI,EAAE,EAElD,GAAIA,IAAS,SAAW,CAACusD,GAAiBnnD,CAAS,EACjD,MAAM,IAAI,MACR,2FACF,EAMF,IAAMrF,GAAW,MAAMusD,GAAalnD,EAAWkE,EAAYxJ,GAAUF,EAAM,EAAK,EAGhFmsD,EAAmB,GAEnBzvC,EAAO,KAAK,CACVtc,EACAJ,EACA,CACE,SAAAG,GACA,SAAUsH,EAAK,6BAA8BiC,EAAYtJ,CAAI,EAC7D,QAAS,IAAM,CACbqH,EAAK,oBAAqBiC,CAAU,EACpCjC,EAAK,kBAAkBhL,CAAM,CAC/B,CACF,EACA,WACF,CAAC,CACH,KAAO,CACL,IAAM+E,GAAwB8K,GAAkClM,CAAI,EAC9DjB,GAAO,IAAIqC,GAAsBP,EAAI,EAC3C,IAAI,WAAW9B,GAAK,OAAQA,GAAK,WAAYA,GAAK,UAAU,EAAE,IAC5DsI,EAAK,OAAO,SAASiC,EAAYA,EAAavK,GAAK,UAAU,CAC/D,EACAud,EAAO,KAAK,CAACtc,EAAMJ,EAAMb,GAAM,KAAK,CAAC,CACvC,CAEJ,QAAE,CACAsI,EAAK,aAAawkD,EAAwB,EACtC7rD,IAAS,UAAYsJ,GACvBjC,EAAK,MAAMiC,CAAU,EAElByiD,GACH1kD,EAAK,kBAAkBhL,CAAM,EAE/BgL,EAAK,eAAemhD,CAAa,CACnC,CACF,CAEA,OAAI0B,GAAkB,CAACN,IACjBviD,EAAK,sBAAsB6iD,EAAe,MAAM,IAAM,GACxDhhD,EAAe,4BAA4B,EAE7Cw/C,GAAe,IAAItjD,EAAW,CAC5BojD,EACAa,EACAC,EACAY,EACAN,EACA,EACF,CAAC,GAEIttC,CACT,QAAE,CACAjV,EAAK,aAAaikD,CAAc,EAchCH,EAAmB,QAAStoD,GAAMwE,EAAK,kBAAkBxE,CAAC,CAAC,EAC3DuoD,EAAoB,QAASvoD,GAAMwE,EAAK,kBAAkBxE,CAAC,CAAC,EAC5DwoD,EAAkB,QAASmB,GAAMnlD,EAAK,MAAMmlD,CAAC,CAAC,EAE1CxiD,IAAqB,GACvB3C,EAAK,sBAAsB2C,CAAgB,EAE7CkhD,EAAiB,QAASsB,GAAMnlD,EAAK,MAAMmlD,CAAC,CAAC,CAC/C,CACF,EAKa5mD,GAAgBR,GAA4B,CACvD,IAAMiC,EAAOM,GAAY,EACnBoD,EAAU29C,GAAe,IAAItjD,CAAS,EAC5C,GAAI,CAAC2F,EACH,MAAM,IAAI,MAAM,oBAAoB,EAEtC,IAAMy9C,EAAgBz9C,EAAQ,CAAC,EAGzB0hD,EAAkBplD,EAAK,iBAAiBmhD,CAAa,EACvDiE,IAAoB,GACtBvjD,EAAe,iCAAiC,EAElD7B,EAAK,SAASolD,CAAe,CAC/B,EAEa9mD,GAA8B+mD,GAAsE,CAC/G,IAAM9zC,EAA6B,CAAC,EACpC,QAAWvc,KAAUqwD,EAAS,CAC5B,IAAM3tD,EAAO1C,EAAO,CAAC,EACjB,CAAC,MAAM,QAAQ0C,CAAI,GAAK,WAAYA,GACtC6Z,EAAQ,KAAK7Z,EAAK,MAAM,CAE5B,CACA,OAAO6Z,CACT,IC79BA,IAoBM+zC,GACFC,GACArlD,GACAD,GACAE,GACAqlD,GAGAC,GACEC,GAEAC,GASAC,GAMAC,GAkCOC,GA+EAC,GAaAroD,GAaAE,GAwBAE,GAaAK,GAgCAI,GA9PbynD,GAAAhzD,EAAA,kBAGAyJ,KASAO,KACAC,KACAC,KAMMooD,GAAU,IAAe,CAAC,CAAC7wD,EAAI,KAAK,OAAS,OAAO,SAAa,IAEnEyL,GAAe,GACfD,GAAc,GACdE,GAAU,GAKRulD,GAAiF,IAAI,IAErFC,GAAmB,CAAChtD,EAA8BstD,IAA+C,CACrG,IAAMC,EAAQR,GAAgB,IAAI/sD,CAAI,EAClCutD,EACFA,EAAM,KAAKD,CAAS,EAEpBP,GAAgB,IAAI/sD,EAAM,CAACstD,CAAS,CAAC,CAEzC,EAEML,GAAe,IAAY,CAC/B,GAAI1lD,IAAgB,CAACD,IAAeE,IAAW,CAAColD,GAC9C,MAAM,IAAI,MAAM,kBAAkB,CAEtC,EAEMM,GAAwB1oD,GAA2C,CACvE,OAAQA,EAAG,KAAK,KAAM,CACpB,IAAK,YACH+C,GAAe,GACX/C,EAAG,KAAK,KACVgD,GAAU,GACVslD,GAAkB,CAAC,EAAEtoD,EAAG,KAAK,GAAG,IAEhC8C,GAAc,GACdwlD,GAAkB,CAAC,EAAE,GAEnBD,KACF,IAAI,gBAAgBA,EAAkB,EACtCA,GAAqB,QAEvB,MACF,IAAK,UACL,IAAK,YACL,IAAK,SACL,IAAK,UACL,IAAK,MACL,IAAK,gBAAiB,CACpB,IAAMS,EAAYP,GAAgB,IAAIvoD,EAAG,KAAK,IAAI,EAC9CA,EAAG,KAAK,IACV8oD,EAAU,MAAM,EAAG,CAAC,EAAE9oD,EAAG,KAAK,GAAG,EAEjC8oD,EAAU,MAAM,EAAG,CAAC,EAAE9oD,EAAG,KAAK,GAAI,EAEpC,KACF,CACA,QACF,CACF,EAEa2oD,GAAqC,SAA2B,CAC3E,GAAI,CAAA7lD,GAGJ,IAAIC,GACF,MAAM,IAAI,MAAM,0CAA0C,EAE5D,GAAIC,GACF,MAAM,IAAI,MAAM,uCAAuC,EAKzD,GAFAD,GAAe,GAEuBolD,GAAQ,EAC5C,OAAO,IAAI,QAAc,CAACvtD,EAASC,IAAW,CAC5CutD,IAAa,UAAU,EAElBpmD,GAAkB,EAAE,KAAK,CAAC,CAAC+B,EAAWilD,CAAM,IAAM,CACrD,GAAI,CACFZ,GAAcY,EACdZ,GAAY,QAAWpoD,GAAmBnF,EAAOmF,CAAE,EACnDooD,GAAY,UAAYM,GACxBJ,GAAoB,CAAC1tD,EAASC,CAAM,EACpC,IAAMoF,EAA0B,CAAE,KAAM,YAAa,GAAI3I,CAAI,EAM7D,GAAyC,CAAC2I,EAAQ,GAAI,KAAK,WAAa8D,EAAW,CAGjF,IAAMM,EAAyB5C,GAAiC,EAC5D4C,IACFpE,EAAQ,GAAI,KAAK,UAAYoE,EAEjC,CAsBA+jD,GAAY,YAAYnoD,CAAO,EAC/BooD,GAAqBtkD,CACvB,OAASzN,EAAG,CACVuE,EAAOvE,CAAC,CACV,CACF,EAAGuE,CAAM,CACX,CAAC,EAED,GAAI,CACF,MAAMqF,GAAsB5I,EAAI,IAAI,EACpC,MAAW6I,GAAY7I,CAAG,EAC1BwL,GAAc,EAChB,OAAS,EAAG,CACV,MAAAE,GAAU,GACJ,CACR,QAAE,CACAD,GAAe,EACjB,EAEJ,EAEa6lD,GAAkB,MAAOxoD,GAAkC,CACtE,GAAsC+nD,GAAQ,EAC5C,OAAAM,GAAa,EACN,IAAI,QAAc,CAAC7tD,EAASC,IAAW,CAC5C2tD,GAAiB,UAAW,CAAC5tD,EAASC,CAAM,CAAC,EAC7C,IAAMoF,EAA0B,CAAE,KAAM,UAAW,GAAI,CAAE,OAAAG,EAAQ,IAAA9I,CAAI,CAAE,EACvE8wD,GAAa,YAAYnoD,CAAO,CAClC,CAAC,EAED,MAAWI,GAAO/I,EAAK8I,CAAM,CAEjC,EAEaG,GAAyB,MAAOxG,GACLouD,GAAQ,GAC5CM,GAAa,EACN,IAAI,QAAoC,CAAC7tD,EAASC,IAAW,CAClE2tD,GAAiB,YAAa,CAAC5tD,EAASC,CAAM,CAAC,EAC/C,IAAMoF,EAA0B,CAAE,KAAM,YAAa,GAAI,CAAE,OAAAlG,CAAO,CAAE,EACpEquD,GAAa,YAAYnoD,EAAS,CAAClG,EAAO,MAAM,CAAC,CACnD,CAAC,GAEWwG,GAAuBxG,CAAM,EAIhC0G,GAAgB,MAC3BD,EACAjK,IACyC,CACzC,GAAsC4xD,GAAQ,EAAG,CAE/C,GAAI5xD,GAAS,wBACX,MAAM,IAAI,MAAM,sEAAsE,EAExF,OAAAkyD,GAAa,EACN,IAAI,QAAqC,CAAC7tD,EAASC,IAAW,CACnE2tD,GAAiB,SAAU,CAAC5tD,EAASC,CAAM,CAAC,EAC5C,IAAMoF,EAA0B,CAAE,KAAM,SAAU,GAAI,CAAE,MAAAO,EAAO,QAAS,CAAE,GAAGjK,CAAQ,CAAE,CAAE,EACnF0yD,EAA+B,CAAC,EAClCzoD,aAAiB,YACnByoD,EAAa,KAAKzoD,EAAM,MAAM,EAEhC4nD,GAAa,YAAYnoD,EAASgpD,CAAY,CAChD,CAAC,CACH,KACE,QAAYxoD,GAAcD,EAAOjK,CAAO,CAE5C,EAEaoK,GAAiB,MAAOC,GAAqC,CACxE,GAAsCunD,GAAQ,EAC5C,OAAAM,GAAa,EACN,IAAI,QAAc,CAAC7tD,EAASC,IAAW,CAC5C2tD,GAAiB,UAAW,CAAC5tD,EAASC,CAAM,CAAC,EAC7C,IAAMoF,EAA0B,CAAE,KAAM,UAAW,GAAIW,CAAU,EACjEwnD,GAAa,YAAYnoD,CAAO,CAClC,CAAC,EAEIU,GAAeC,CAAS,CAEjC,EAEaI,GAAM,MACjBJ,EACAC,EACAC,EACAC,EACAE,EACA1K,IAC8B,CAC9B,GAAsC4xD,GAAQ,EAAG,CAE/C,GAAIrnD,EAAO,KAAMm2B,GAAMA,EAAE,CAAC,IAAM,KAAK,EACnC,MAAM,IAAI,MAAM,iDAAiD,EAGnE,GAAIh2B,EAAQ,KAAMg2B,GAAMA,CAAC,EACvB,MAAM,IAAI,MAAM,yDAAyD,EAE3E,OAAAwxB,GAAa,EACN,IAAI,QAAsC,CAAC7tD,EAASC,IAAW,CACpE2tD,GAAiB,MAAO,CAAC5tD,EAASC,CAAM,CAAC,EACzC,IAAMquD,EAAqBpoD,EACrBb,EAA0B,CAC9B,KAAM,MACN,GAAI,CAAE,UAAAW,EAAW,aAAAC,EAAc,OAAQqoD,EAAoB,cAAAnoD,EAAe,QAAAxK,CAAQ,CACpF,EACA6xD,GAAa,YAAYnoD,EAAckB,GAA2B+nD,CAAkB,CAAC,CACvF,CAAC,CACH,KACE,QAAYloD,GAAIJ,EAAWC,EAAcC,EAAQC,EAAeE,EAAS1K,CAAO,CAEpF,EAEa6K,GAAe,MAAOR,GAAqC,CACtE,GAAsCunD,GAAQ,EAC5C,OAAAM,GAAa,EACN,IAAI,QAAc,CAAC7tD,EAASC,IAAW,CAC5C2tD,GAAiB,gBAAiB,CAAC5tD,EAASC,CAAM,CAAC,EACnD,IAAMoF,EAA0B,CAAE,KAAM,gBAAiB,GAAIW,CAAU,EACvEwnD,GAAa,YAAYnoD,CAAO,CAClC,CAAC,EAEImB,GAAaR,CAAS,CAE/B,ICzQA,IAkBauoD,GAaAC,GAyBAC,GAxDbC,GAAAzzD,EAAA,kBAGAyJ,KAUAupD,KACA9gD,IACAxI,KACAkJ,KAEa0gD,GAAuB,CAACtxD,EAAgB0xD,IAA0C,CAC7F,OAAQ1xD,EAAO,SAAU,CACvB,IAAK,MACH,MAAO,CAACA,EAAO,KAAMA,EAAO,KAAMA,EAAO,KAAM,KAAK,EACtD,IAAK,aACH,MAAO,CAACA,EAAO,KAAMA,EAAO,KAAM,CAAE,UAAWA,EAAO,SAAU,EAAG,YAAY,EACjF,IAAK,YACH,MAAO,CAACA,EAAO,KAAMA,EAAO,KAAM,CAAE,SAAUA,EAAO,QAAS,EAAG,WAAW,EAC9E,QACE,MAAM,IAAI,MAAM,0BAA0BA,EAAO,QAAQ,QAAQ0xD,EAAQ,CAAC,EAAE,CAChF,CACF,EAEaH,GAAwBvxD,GAAmC,CACtE,OAAQA,EAAO,CAAC,EAAG,CACjB,IAAK,MACH,OAAO,IAAIqC,GAAOrC,EAAO,CAAC,EAAGA,EAAO,CAAC,EAAGA,EAAO,CAAC,CAAC,EACnD,IAAK,aAAc,CACjB,IAAMyD,EAAWzD,EAAO,CAAC,EACzB,GAAI,CAAC+P,GAAyBtM,CAAQ,EACpC,MAAM,IAAI,MAAM,4BAA4BA,CAAQ,+BAA+B,EAErF,GAAM,CAAE,UAAAD,EAAW,SAAAH,EAAU,QAAAC,CAAQ,EAAItD,EAAO,CAAC,EACjD,OAAOqC,GAAO,cAAcmB,EAAW,CAAE,SAAAC,EAAU,KAAMzD,EAAO,CAAC,EAAG,SAAAqD,EAAU,QAAAC,CAAQ,CAAC,CACzF,CACA,IAAK,YAAa,CAChB,IAAMG,EAAWzD,EAAO,CAAC,EACzB,GAAI,CAACgQ,GAAwBvM,CAAQ,EACnC,MAAM,IAAI,MAAM,4BAA4BA,CAAQ,oCAAoC,EAE1F,GAAM,CAAE,SAAAC,EAAU,SAAAL,EAAU,QAAAC,CAAQ,EAAItD,EAAO,CAAC,EAChD,OAAOqC,GAAO,aAAaqB,EAAU,CAAE,SAAAD,EAAU,KAAMzD,EAAO,CAAC,EAAG,SAAAqD,EAAU,QAAAC,CAAQ,CAAC,CACvF,CACA,QACE,MAAM,IAAI,MAAM,0BAA0BtD,EAAO,CAAC,CAAC,EAAE,CACzD,CACF,EAEawxD,GAAN,KAA8E,CAMnF,MAAM,8BAA8BrE,EAAmD,CAErF,OAAOzkD,GAAuB,MAAMiI,GAASw8C,CAAI,CAAC,CACpD,CAEA,MAAM,UAAUwE,EAAmCjzD,EAA0D,CAC3G4G,GAAiB,EACjB,IAAIqD,EAEA,OAAOgpD,GAAiB,SAOxBhpD,EAAQ,MAAM,KAAK,8BAA8BgpD,CAAY,EAG/DhpD,EAAQgpD,EAGV,CAAC,KAAK,UAAW,KAAK,WAAY,KAAK,WAAW,EAAI,MAAM/oD,GAAcD,EAAOjK,CAAO,EACxF6G,GAAe,CACjB,CAEA,MAAM,SAAyB,CAC7B,OAAOuD,GAAe,KAAK,SAAS,CACtC,CAEA,MAAM,IACJ3C,EACAC,EACA1H,EACoC,CACpC4G,GAAiB,EACjB,IAAMssD,EAAuB,CAAC,EACxB5oD,EAAyB,CAAC,EAChC,OAAO,QAAQ7C,CAAK,EAAE,QAAS0rD,GAAQ,CACrC,IAAM5zD,EAAO4zD,EAAI,CAAC,EACZ7xD,EAAS6xD,EAAI,CAAC,EACdl5C,EAAQ,KAAK,WAAW,QAAQ1a,CAAI,EAC1C,GAAI0a,IAAU,GACZ,MAAM,IAAI,MAAM,kBAAkB1a,CAAI,GAAG,EAE3C2zD,EAAW,KAAK5xD,CAAM,EACtBgJ,EAAa,KAAK2P,CAAK,CACzB,CAAC,EAED,IAAMm5C,EAAoC,CAAC,EACrC5oD,EAA0B,CAAC,EACjC,OAAO,QAAQ9C,CAAO,EAAE,QAASyrD,GAAQ,CACvC,IAAM5zD,EAAO4zD,EAAI,CAAC,EACZ7xD,EAAS6xD,EAAI,CAAC,EACdl5C,EAAQ,KAAK,YAAY,QAAQ1a,CAAI,EAC3C,GAAI0a,IAAU,GACZ,MAAM,IAAI,MAAM,mBAAmB1a,CAAI,GAAG,EAE5C6zD,EAAY,KAAK9xD,CAAM,EACvBkJ,EAAc,KAAKyP,CAAK,CAC1B,CAAC,EAED,IAAM1P,EAAS2oD,EAAW,IAAI,CAACxyB,EAAG/gC,IAChCizD,GAAqBlyB,EAAG,IAAM,UAAU,KAAK,WAAWp2B,EAAa3K,CAAC,CAAC,CAAC,GAAG,CAC7E,EACM+K,EAAU0oD,EAAY,IAAI,CAAC1yB,EAAG/gC,IAClC+gC,EAAIkyB,GAAqBlyB,EAAG,IAAM,WAAW,KAAK,YAAYl2B,EAAc7K,CAAC,CAAC,CAAC,GAAG,EAAI,IACxF,EAEMoI,EAAU,MAAM0C,GAAI,KAAK,UAAWH,EAAcC,EAAQC,EAAeE,EAAS1K,CAAO,EAEzFqzD,EAAuC,CAAC,EAC9C,QAAS1zD,EAAI,EAAGA,EAAIoI,EAAQ,OAAQpI,IAClC0zD,EAAU,KAAK,YAAY7oD,EAAc7K,CAAC,CAAC,CAAC,EAAIyzD,EAAYzzD,CAAC,GAAKkzD,GAAqB9qD,EAAQpI,CAAC,CAAC,EAEnG,OAAAkH,GAAe,EACRwsD,CACT,CAEA,gBAAuB,CAEvB,CAEA,cAAqB,CACdxoD,GAAa,KAAK,SAAS,CAClC,CACF,ICpJA,IAAAyoD,GAAA,GAAAxqD,GAAAwqD,GAAA,mCAAAC,GAAA,oBAAAC,GAAA,gBAAAC,KAAA,IAcaD,GA2CAD,GAqCAE,GA9FbC,GAAAp0D,EAAA,kBAGAyJ,KAEAupD,KACAS,KAQaS,GAAkB,IAAY,CAqBzC,IApBI,OAAOzyD,EAAI,KAAK,aAAgB,UAAYA,EAAI,KAAK,YAAc,KACrEA,EAAI,KAAK,YAAc,GAGrBA,EAAI,KAAK,OAAS,IAEpB,QAAQ,KACN,8HAEF,EAGE,OAAOA,EAAI,KAAK,OAAU,YAC5BA,EAAI,KAAK,MAAQ,IAGf,OAAOA,EAAI,KAAK,OAAU,YAC5BA,EAAI,KAAK,MAAQ,IAGf,OAAOA,EAAI,KAAK,YAAe,UAAY,CAAC,OAAO,UAAUA,EAAI,KAAK,UAAU,GAAKA,EAAI,KAAK,YAAc,EAY9G,GAAI,OAAO,KAAS,KAAe,CAAC,KAAK,oBACvCA,EAAI,KAAK,WAAa,MACjB,CACL,IAAM4yD,EACJ,OAAO,UAAc,IAAc,GAAQ,SAAS,EAAE,KAAK,EAAE,OAAS,UAAU,oBAClF5yD,EAAI,KAAK,WAAa,KAAK,IAAI,EAAG,KAAK,MAAM4yD,GAAsB,GAAK,CAAC,CAAC,CAC5E,CAEJ,EAEaJ,GAAN,KAAuD,CAS5D,MAAM,KAAK3zD,EAAoC,CAE7C4zD,GAAgB,EAGhB,MAAMpB,GAAmC,EAGzC,MAAMC,GAAgBzyD,CAAW,CACnC,CASA,MAAM,8BACJqzD,EACAjzD,EACkC,CAClC,IAAMwH,EAAU,IAAIsrD,GACpB,aAAMtrD,EAAQ,UAAUyrD,EAAcjzD,CAAO,EACtC,QAAQ,QAAQwH,CAAO,CAChC,CACF,EAEaisD,GAAc,IAAIF,KC9F/B,IAAAK,GAAA,GAAA9qD,GAAA8qD,GAAA,sBAAAvsD,GAAA,UAAAX,GAAA,qBAAAE,GAAA,mBAAAC,GAAA,WAAAlD,GAAA,YAAAkwD,GAAA,QAAA9yD,EAAA,oBAAA7B,KASA6J,KACAA,KAGAA,KCPO,IAAMnI,GAAU,SDKvB,IAAOizD,GAAQhrD,GAUe,CAC5B,IAAM4qD,EAAc,cAA0B,YAE5Cv0D,GAAgB,SAAUu0D,EAAa,CAAC,EACxCv0D,GAAgB,QAASu0D,EAAa,CAAC,EAEzCv0D,GAAgB,MAAOu0D,EAAa,EAAE,EACtCv0D,GAAgB,OAAQu0D,EAAa,EAAE,CACzC,CAEA,OAAO,eAAe1yD,EAAI,SAAU,MAAO,CAAE,MAAOH,GAAS,WAAY,EAAK,CAAC","sourcesContent":["// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport { Backend } from './backend.js';\nimport { InferenceSession } from './inference-session.js';\n\ninterface BackendInfo {\n  backend: Backend;\n  priority: number;\n\n  initPromise?: Promise<void>;\n  initialized?: boolean;\n  aborted?: boolean;\n  error?: string;\n}\n\nconst backends: Map<string, BackendInfo> = new Map();\nconst backendsSortedByPriority: string[] = [];\n\n/**\n * Register a backend.\n *\n * @param name - the name as a key to lookup as an execution provider.\n * @param backend - the backend object.\n * @param priority - an integer indicating the priority of the backend. Higher number means higher priority. if priority\n * < 0, it will be considered as a 'beta' version and will not be used as a fallback backend by default.\n *\n * @ignore\n */\nexport const registerBackend = (name: string, backend: Backend, priority: number): void => {\n  if (backend && typeof backend.init === 'function' && typeof backend.createInferenceSessionHandler === 'function') {\n    const currentBackend = backends.get(name);\n    if (currentBackend === undefined) {\n      backends.set(name, { backend, priority });\n    } else if (currentBackend.priority > priority) {\n      // same name is already registered with a higher priority. skip registeration.\n      return;\n    } else if (currentBackend.priority === priority) {\n      if (currentBackend.backend !== backend) {\n        throw new Error(`cannot register backend \"${name}\" using priority ${priority}`);\n      }\n    }\n\n    if (priority >= 0) {\n      const i = backendsSortedByPriority.indexOf(name);\n      if (i !== -1) {\n        backendsSortedByPriority.splice(i, 1);\n      }\n\n      for (let i = 0; i < backendsSortedByPriority.length; i++) {\n        if (backends.get(backendsSortedByPriority[i])!.priority <= priority) {\n          backendsSortedByPriority.splice(i, 0, name);\n          return;\n        }\n      }\n      backendsSortedByPriority.push(name);\n    }\n    return;\n  }\n\n  throw new TypeError('not a valid backend');\n};\n\n/**\n * Try to resolve and initialize a backend.\n *\n * @param backendName - the name of the backend.\n * @returns the backend instance if resolved and initialized successfully, or an error message if failed.\n */\nconst tryResolveAndInitializeBackend = async (backendName: string): Promise<Backend | string> => {\n  const backendInfo = backends.get(backendName);\n  if (!backendInfo) {\n    return 'backend not found.';\n  }\n\n  if (backendInfo.initialized) {\n    return backendInfo.backend;\n  } else if (backendInfo.aborted) {\n    return backendInfo.error!;\n  } else {\n    const isInitializing = !!backendInfo.initPromise;\n    try {\n      if (!isInitializing) {\n        backendInfo.initPromise = backendInfo.backend.init(backendName);\n      }\n      await backendInfo.initPromise;\n      backendInfo.initialized = true;\n      return backendInfo.backend;\n    } catch (e) {\n      if (!isInitializing) {\n        backendInfo.error = `${e}`;\n        backendInfo.aborted = true;\n      }\n      return backendInfo.error!;\n    } finally {\n      delete backendInfo.initPromise;\n    }\n  }\n};\n\n/**\n * Resolve execution providers from the specific session options.\n *\n * @param options - the session options object.\n * @returns a promise that resolves to a tuple of an initialized backend instance and a session options object with\n * filtered EP list.\n *\n * @ignore\n */\nexport const resolveBackendAndExecutionProviders = async (\n  options: InferenceSession.SessionOptions,\n): Promise<[backend: Backend, options: InferenceSession.SessionOptions]> => {\n  // extract backend hints from session options\n  const eps = options.executionProviders || [];\n  const backendHints = eps.map((i) => (typeof i === 'string' ? i : i.name));\n  const backendNames = backendHints.length === 0 ? backendsSortedByPriority : backendHints;\n\n  // try to resolve and initialize all requested backends\n  let backend: Backend | undefined;\n  const errors = [];\n  const availableBackendNames = new Set<string>();\n  for (const backendName of backendNames) {\n    const resolveResult = await tryResolveAndInitializeBackend(backendName);\n    if (typeof resolveResult === 'string') {\n      errors.push({ name: backendName, err: resolveResult });\n    } else {\n      if (!backend) {\n        backend = resolveResult;\n      }\n      if (backend === resolveResult) {\n        availableBackendNames.add(backendName);\n      }\n    }\n  }\n\n  // if no backend is available, throw error.\n  if (!backend) {\n    throw new Error(`no available backend found. ERR: ${errors.map((e) => `[${e.name}] ${e.err}`).join(', ')}`);\n  }\n\n  // for each explicitly requested backend, if it's not available, output warning message.\n  for (const { name, err } of errors) {\n    if (backendHints.includes(name)) {\n      // eslint-disable-next-line no-console\n      console.warn(\n        `removing requested execution provider \"${name}\" from session options because it is not available: ${err}`,\n      );\n    }\n  }\n\n  const filteredEps = eps.filter((i) => availableBackendNames.has(typeof i === 'string' ? i : i.name));\n\n  return [\n    backend,\n    new Proxy(options, {\n      get: (target, prop) => {\n        if (prop === 'executionProviders') {\n          return filteredEps;\n        }\n        return Reflect.get(target, prop);\n      },\n    }),\n  ];\n};\n","// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport { InferenceSession } from './inference-session.js';\nimport { OnnxValue } from './onnx-value.js';\n\n/**\n * @ignore\n */\nexport declare namespace SessionHandler {\n  type FeedsType = { [name: string]: OnnxValue };\n  type FetchesType = { [name: string]: OnnxValue | null };\n  type ReturnType = { [name: string]: OnnxValue };\n}\n\n/**\n * Represents shared SessionHandler functionality\n *\n * @ignore\n */\ninterface SessionHandler {\n  dispose(): Promise<void>;\n\n  readonly inputNames: readonly string[];\n  readonly outputNames: readonly string[];\n}\n\n/**\n * Represent a handler instance of an inference session.\n *\n * @ignore\n */\nexport interface InferenceSessionHandler extends SessionHandler {\n  startProfiling(): void;\n  endProfiling(): void;\n\n  run(\n    feeds: SessionHandler.FeedsType,\n    fetches: SessionHandler.FetchesType,\n    options: InferenceSession.RunOptions,\n  ): Promise<SessionHandler.ReturnType>;\n}\n\n/**\n * Represent a backend that provides implementation of model inferencing.\n *\n * @ignore\n */\nexport interface Backend {\n  /**\n   * Initialize the backend asynchronously. Should throw when failed.\n   */\n  init(backendName: string): Promise<void>;\n\n  createInferenceSessionHandler(\n    uriOrBuffer: string | Uint8Array,\n    options?: InferenceSession.SessionOptions,\n  ): Promise<InferenceSessionHandler>;\n}\n\nexport { registerBackend } from './backend-impl.js';\n","// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\n// This file is generated by /js/scripts/update-version.ts\n// Do not modify file content manually.\n\nexport const version = '1.22.0';\n","// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport { Env } from './env.js';\nimport { version } from './version.js';\n\ntype LogLevelType = Env['logLevel'];\n\nlet logLevelValue: Required<LogLevelType> = 'warning';\n\nexport const env: Env = {\n  wasm: {} as Env.WebAssemblyFlags,\n  webgl: {} as Env.WebGLFlags,\n  webgpu: {} as Env.WebGpuFlags,\n  versions: { common: version },\n\n  set logLevel(value: LogLevelType) {\n    if (value === undefined) {\n      return;\n    }\n    if (typeof value !== 'string' || ['verbose', 'info', 'warning', 'error', 'fatal'].indexOf(value) === -1) {\n      throw new Error(`Unsupported logging level: ${value}`);\n    }\n    logLevelValue = value;\n  },\n  get logLevel(): Required<LogLevelType> {\n    return logLevelValue;\n  },\n};\n\n// set property 'logLevel' so that they can be correctly transferred to worker by `postMessage()`.\nObject.defineProperty(env, 'logLevel', { enumerable: true });\n","// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport { env as envImpl } from './env-impl.js';\nimport { TryGetGlobalType } from './type-helper.js';\n\nexport declare namespace Env {\n  export type WasmPathPrefix = string;\n  export interface WasmFilePaths {\n    /**\n     * Specify the override path for the main .wasm file.\n     *\n     * This path should be an absolute path.\n     *\n     * If not modified, the filename of the .wasm file is:\n     * - `ort-wasm-simd-threaded.wasm` for default build\n     * - `ort-wasm-simd-threaded.jsep.wasm` for JSEP build (with WebGPU and WebNN)\n     */\n    wasm?: URL | string;\n    /**\n     * Specify the override path for the main .mjs file.\n     *\n     * This path should be an absolute path.\n     *\n     * If not modified, the filename of the .mjs file is:\n     * - `ort-wasm-simd-threaded.mjs` for default build\n     * - `ort-wasm-simd-threaded.jsep.mjs` for JSEP build (with WebGPU and WebNN)\n     */\n    mjs?: URL | string;\n  }\n  export type WasmPrefixOrFilePaths = WasmPathPrefix | WasmFilePaths;\n  export interface WebAssemblyFlags {\n    /**\n     * set or get number of thread(s). If omitted or set to 0, number of thread(s) will be determined by system. If set\n     * to 1, no worker thread will be spawned.\n     *\n     * This setting is available only when WebAssembly multithread feature is available in current context.\n     *\n     * @defaultValue `0`\n     */\n    numThreads?: number;\n\n    /**\n     * set or get a boolean value indicating whether to enable SIMD. If set to false, SIMD will be forcely disabled.\n     *\n     * This setting is available only when WebAssembly SIMD feature is available in current context.\n     *\n     * @defaultValue `true`\n     *\n     * @deprecated This property is deprecated. Since SIMD is supported by all major JavaScript engines, non-SIMD\n     * build is no longer provided. This property will be removed in future release.\n     */\n    simd?: boolean;\n\n    /**\n     * set or get a boolean value indicating whether to enable trace.\n     *\n     * @defaultValue `false`\n     *\n     * @deprecated Use `env.trace` instead. If `env.trace` is set, this property will be ignored.\n     */\n    trace?: boolean;\n\n    /**\n     * Set or get a number specifying the timeout for initialization of WebAssembly backend, in milliseconds. A zero\n     * value indicates no timeout is set.\n     *\n     * @defaultValue `0`\n     */\n    initTimeout?: number;\n\n    /**\n     * Set a custom URL prefix to the .wasm/.mjs files, or an object of overrides for both .wasm/.mjs file. The override\n     * path should be an absolute path.\n     */\n    wasmPaths?: WasmPrefixOrFilePaths;\n\n    /**\n     * Set a custom buffer which contains the WebAssembly binary. If this property is set, the `wasmPaths` property will\n     * be ignored.\n     */\n    wasmBinary?: ArrayBufferLike | Uint8Array;\n\n    /**\n     * Set or get a boolean value indicating whether to proxy the execution of main thread to a worker thread.\n     *\n     * @defaultValue `false`\n     */\n    proxy?: boolean;\n  }\n\n  export interface WebGLFlags {\n    /**\n     * Set or get the WebGL Context ID (webgl or webgl2).\n     *\n     * @defaultValue `'webgl2'`\n     */\n    contextId?: 'webgl' | 'webgl2';\n    /**\n     * Get the WebGL rendering context.\n     */\n    readonly context: WebGLRenderingContext;\n    /**\n     * Set or get the maximum batch size for matmul. 0 means to disable batching.\n     *\n     * @deprecated\n     */\n    matmulMaxBatchSize?: number;\n    /**\n     * Set or get the texture cache mode.\n     *\n     * @defaultValue `'full'`\n     */\n    textureCacheMode?: 'initializerOnly' | 'full';\n    /**\n     * Set or get the packed texture mode\n     *\n     * @defaultValue `false`\n     */\n    pack?: boolean;\n    /**\n     * Set or get whether enable async download.\n     *\n     * @defaultValue `false`\n     */\n    async?: boolean;\n  }\n\n  export interface WebGpuProfilingDataV1TensorMetadata {\n    dims: readonly number[];\n    dataType: string;\n  }\n  export interface WebGpuProfilingDataV1 {\n    version: 1;\n    inputsMetadata: readonly WebGpuProfilingDataV1TensorMetadata[];\n    outputsMetadata: readonly WebGpuProfilingDataV1TensorMetadata[];\n    kernelId: number;\n    kernelType: string;\n    kernelName: string;\n    programName: string;\n    startTime: number;\n    endTime: number;\n  }\n\n  export type WebGpuProfilingData = WebGpuProfilingDataV1;\n\n  export interface WebGpuFlags {\n    /**\n     * Set or get the profiling mode.\n     *\n     * @deprecated Use `env.webgpu.profiling.mode` instead. If `env.webgpu.profiling.mode` is set, this property will be\n     * ignored.\n     */\n    profilingMode?: 'off' | 'default';\n    /**\n     * Set or get the profiling configuration.\n     */\n    profiling: {\n      /**\n       * Set or get the profiling mode.\n       *\n       * @defaultValue `'off'`\n       */\n      mode?: 'off' | 'default';\n\n      /**\n       * Set or get a callback function when a profiling data is received. If not set, the profiling data will be\n       * printed to console.\n       */\n      ondata?: (data: WebGpuProfilingData) => void;\n    };\n    /**\n     * Set or get the power preference.\n     *\n     * Setting this property only has effect before the first WebGPU inference session is created. The value will be\n     * used as options for `navigator.gpu.requestAdapter()`.\n     *\n     * See {@link https://gpuweb.github.io/gpuweb/#dictdef-gpurequestadapteroptions} for more details.\n     *\n     * @defaultValue `undefined`\n     *\n     * @deprecated Create your own GPUAdapter, use it to create a GPUDevice instance and set {@link device} property if\n     * you want to use a specific power preference.\n     */\n    powerPreference?: 'low-power' | 'high-performance';\n    /**\n     * Set or get the force fallback adapter flag.\n     *\n     * Setting this property only has effect before the first WebGPU inference session is created. The value will be\n     * used as options for `navigator.gpu.requestAdapter()`.\n     *\n     * See {@link https://gpuweb.github.io/gpuweb/#dictdef-gpurequestadapteroptions} for more details.\n     *\n     * @defaultValue `undefined`\n     *\n     * @deprecated Create your own GPUAdapter, use it to create a GPUDevice instance and set {@link device} property if\n     * you want to use a specific fallback option.\n     */\n    forceFallbackAdapter?: boolean;\n    /**\n     * Set or get the adapter for WebGPU.\n     *\n     * Setting this property only has effect before the first WebGPU inference session is created. The value will be\n     * used as the GPU adapter for the underlying WebGPU backend to create GPU device.\n     *\n     * If this property is not set, it will be available to get after the first WebGPU inference session is created. The\n     * value will be the GPU adapter that created by the underlying WebGPU backend.\n     *\n     * When use with TypeScript, the type of this property is `GPUAdapter` defined in \"@webgpu/types\".\n     *\n     * @deprecated It is no longer recommended to use this property. The latest WebGPU spec adds `GPUDevice.adapterInfo`\n     * (https://www.w3.org/TR/webgpu/#dom-gpudevice-adapterinfo), which allows to get the adapter information from the\n     * device. When it's available, there is no need to set/get the {@link adapter} property.\n     */\n    adapter: TryGetGlobalType<'GPUAdapter'>;\n    /**\n     * Set or get the GPU device for WebGPU.\n     *\n     * There are 3 valid scenarios of accessing this property:\n     * - Set a value before the first WebGPU inference session is created. The value will be used by the WebGPU backend\n     * to perform calculations. If the value is not a `GPUDevice` object, an error will be thrown.\n     * - Get the value before the first WebGPU inference session is created. This will try to create a new GPUDevice\n     * instance. Returns a `Promise` that resolves to a `GPUDevice` object.\n     * - Get the value after the first WebGPU inference session is created. Returns a resolved `Promise` to the\n     * `GPUDevice` object used by the WebGPU backend.\n     */\n    get device(): Promise<TryGetGlobalType<'GPUDevice'>>;\n    set device(value: TryGetGlobalType<'GPUDevice'>);\n    /**\n     * Set or get whether validate input content.\n     *\n     * @defaultValue `false`\n     */\n    validateInputContent?: boolean;\n  }\n}\n\nexport interface Env {\n  /**\n   * set the severity level for logging.\n   *\n   * @defaultValue `'warning'`\n   */\n  logLevel?: 'verbose' | 'info' | 'warning' | 'error' | 'fatal';\n\n  /**\n   * Indicate whether run in debug mode.\n   *\n   * @defaultValue `false`\n   */\n  debug?: boolean;\n\n  /**\n   * set or get a boolean value indicating whether to enable trace.\n   *\n   * @defaultValue `false`\n   */\n  trace?: boolean;\n\n  /**\n   * Get version of the current package.\n   */\n  readonly versions: {\n    readonly common: string;\n    readonly web?: string;\n    readonly node?: string;\n    // eslint-disable-next-line @typescript-eslint/naming-convention\n    readonly 'react-native'?: string;\n  };\n\n  /**\n   * Represent a set of flags for WebAssembly\n   */\n  readonly wasm: Env.WebAssemblyFlags;\n\n  /**\n   * Represent a set of flags for WebGL\n   */\n  readonly webgl: Env.WebGLFlags;\n\n  /**\n   * Represent a set of flags for WebGPU\n   */\n  readonly webgpu: Env.WebGpuFlags;\n\n  [name: string]: unknown;\n}\n\n/**\n * Represent a set of flags as a global singleton.\n */\nexport const env: Env = envImpl;\n","// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport { TensorToDataUrlOptions, TensorToImageDataOptions } from './tensor-conversion.js';\nimport { Tensor } from './tensor.js';\n\n/**\n * implementation of Tensor.toDataURL()\n */\nexport const tensorToDataURL = (tensor: Tensor, options?: TensorToDataUrlOptions): string => {\n  const canvas = typeof document !== 'undefined' ? document.createElement('canvas') : new OffscreenCanvas(1, 1);\n  canvas.width = tensor.dims[3];\n  canvas.height = tensor.dims[2];\n  const pixels2DContext = canvas.getContext('2d') as\n    | CanvasRenderingContext2D\n    | OffscreenCanvasRenderingContext2D\n    | null;\n\n  if (pixels2DContext != null) {\n    // Default values for height and width & format\n    let width: number;\n    let height: number;\n    if (options?.tensorLayout !== undefined && options.tensorLayout === 'NHWC') {\n      width = tensor.dims[2];\n      height = tensor.dims[3];\n    } else {\n      // Default layout is NCWH\n      width = tensor.dims[3];\n      height = tensor.dims[2];\n    }\n\n    const inputformat = options?.format !== undefined ? options.format : 'RGB';\n\n    const norm = options?.norm;\n    let normMean: [number, number, number, number];\n    let normBias: [number, number, number, number];\n    if (norm === undefined || norm.mean === undefined) {\n      normMean = [255, 255, 255, 255];\n    } else {\n      if (typeof norm.mean === 'number') {\n        normMean = [norm.mean, norm.mean, norm.mean, norm.mean];\n      } else {\n        normMean = [norm.mean[0], norm.mean[1], norm.mean[2], 0];\n        if (norm.mean[3] !== undefined) {\n          normMean[3] = norm.mean[3];\n        }\n      }\n    }\n    if (norm === undefined || norm.bias === undefined) {\n      normBias = [0, 0, 0, 0];\n    } else {\n      if (typeof norm.bias === 'number') {\n        normBias = [norm.bias, norm.bias, norm.bias, norm.bias];\n      } else {\n        normBias = [norm.bias[0], norm.bias[1], norm.bias[2], 0];\n        if (norm.bias[3] !== undefined) {\n          normBias[3] = norm.bias[3];\n        }\n      }\n    }\n\n    const stride = height * width;\n    // Default pointer assignments\n    let rTensorPointer = 0,\n      gTensorPointer = stride,\n      bTensorPointer = stride * 2,\n      aTensorPointer = -1;\n\n    // Updating the pointer assignments based on the input image format\n    if (inputformat === 'RGBA') {\n      rTensorPointer = 0;\n      gTensorPointer = stride;\n      bTensorPointer = stride * 2;\n      aTensorPointer = stride * 3;\n    } else if (inputformat === 'RGB') {\n      rTensorPointer = 0;\n      gTensorPointer = stride;\n      bTensorPointer = stride * 2;\n    } else if (inputformat === 'RBG') {\n      rTensorPointer = 0;\n      bTensorPointer = stride;\n      gTensorPointer = stride * 2;\n    }\n\n    for (let i = 0; i < height; i++) {\n      for (let j = 0; j < width; j++) {\n        const R = ((tensor.data[rTensorPointer++] as number) - normBias[0]) * normMean[0]; // R value\n        const G = ((tensor.data[gTensorPointer++] as number) - normBias[1]) * normMean[1]; // G value\n        const B = ((tensor.data[bTensorPointer++] as number) - normBias[2]) * normMean[2]; // B value\n        const A = aTensorPointer === -1 ? 255 : ((tensor.data[aTensorPointer++] as number) - normBias[3]) * normMean[3]; // A value\n        // eslint-disable-next-line @typescript-eslint/restrict-plus-operands\n        pixels2DContext.fillStyle = 'rgba(' + R + ',' + G + ',' + B + ',' + A + ')';\n        pixels2DContext.fillRect(j, i, 1, 1);\n      }\n    }\n    if ('toDataURL' in canvas) {\n      return canvas.toDataURL();\n    } else {\n      throw new Error('toDataURL is not supported');\n    }\n  } else {\n    throw new Error('Can not access image data');\n  }\n};\n\n/**\n * implementation of Tensor.toImageData()\n */\nexport const tensorToImageData = (tensor: Tensor, options?: TensorToImageDataOptions): ImageData => {\n  const pixels2DContext =\n    typeof document !== 'undefined'\n      ? document.createElement('canvas').getContext('2d')\n      : (new OffscreenCanvas(1, 1).getContext('2d') as OffscreenCanvasRenderingContext2D);\n  let image: ImageData;\n  if (pixels2DContext != null) {\n    // Default values for height and width & format\n    let width: number;\n    let height: number;\n    let channels: number;\n    if (options?.tensorLayout !== undefined && options.tensorLayout === 'NHWC') {\n      width = tensor.dims[2];\n      height = tensor.dims[1];\n      channels = tensor.dims[3];\n    } else {\n      // Default layout is NCWH\n      width = tensor.dims[3];\n      height = tensor.dims[2];\n      channels = tensor.dims[1];\n    }\n    const inputformat = options !== undefined ? (options.format !== undefined ? options.format : 'RGB') : 'RGB';\n\n    const norm = options?.norm;\n    let normMean: [number, number, number, number];\n    let normBias: [number, number, number, number];\n    if (norm === undefined || norm.mean === undefined) {\n      normMean = [255, 255, 255, 255];\n    } else {\n      if (typeof norm.mean === 'number') {\n        normMean = [norm.mean, norm.mean, norm.mean, norm.mean];\n      } else {\n        normMean = [norm.mean[0], norm.mean[1], norm.mean[2], 255];\n        if (norm.mean[3] !== undefined) {\n          normMean[3] = norm.mean[3];\n        }\n      }\n    }\n    if (norm === undefined || norm.bias === undefined) {\n      normBias = [0, 0, 0, 0];\n    } else {\n      if (typeof norm.bias === 'number') {\n        normBias = [norm.bias, norm.bias, norm.bias, norm.bias];\n      } else {\n        normBias = [norm.bias[0], norm.bias[1], norm.bias[2], 0];\n        if (norm.bias[3] !== undefined) {\n          normBias[3] = norm.bias[3];\n        }\n      }\n    }\n\n    const stride = height * width;\n    if (options !== undefined) {\n      if (\n        (options.format !== undefined && channels === 4 && options.format !== 'RGBA') ||\n        (channels === 3 && options.format !== 'RGB' && options.format !== 'BGR')\n      ) {\n        throw new Error(\"Tensor format doesn't match input tensor dims\");\n      }\n    }\n\n    // Default pointer assignments\n    const step = 4;\n    let rImagePointer = 0,\n      gImagePointer = 1,\n      bImagePointer = 2,\n      aImagePointer = 3;\n    let rTensorPointer = 0,\n      gTensorPointer = stride,\n      bTensorPointer = stride * 2,\n      aTensorPointer = -1;\n\n    // Updating the pointer assignments based on the input image format\n    if (inputformat === 'RGBA') {\n      rTensorPointer = 0;\n      gTensorPointer = stride;\n      bTensorPointer = stride * 2;\n      aTensorPointer = stride * 3;\n    } else if (inputformat === 'RGB') {\n      rTensorPointer = 0;\n      gTensorPointer = stride;\n      bTensorPointer = stride * 2;\n    } else if (inputformat === 'RBG') {\n      rTensorPointer = 0;\n      bTensorPointer = stride;\n      gTensorPointer = stride * 2;\n    }\n\n    image = pixels2DContext.createImageData(width, height);\n\n    for (\n      let i = 0;\n      i < height * width;\n      rImagePointer += step, gImagePointer += step, bImagePointer += step, aImagePointer += step, i++\n    ) {\n      image.data[rImagePointer] = ((tensor.data[rTensorPointer++] as number) - normBias[0]) * normMean[0]; // R value\n      image.data[gImagePointer] = ((tensor.data[gTensorPointer++] as number) - normBias[1]) * normMean[1]; // G value\n      image.data[bImagePointer] = ((tensor.data[bTensorPointer++] as number) - normBias[2]) * normMean[2]; // B value\n      image.data[aImagePointer] =\n        aTensorPointer === -1 ? 255 : ((tensor.data[aTensorPointer++] as number) - normBias[3]) * normMean[3]; // A value\n    }\n  } else {\n    throw new Error('Can not access image data');\n  }\n  return image;\n};\n","// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {\n  OptionsDimensions,\n  OptionsFormat,\n  OptionsNormalizationParameters,\n  OptionsTensorFormat,\n  OptionsTensorLayout,\n  TensorFromGpuBufferOptions,\n  TensorFromImageBitmapOptions,\n  TensorFromImageDataOptions,\n  TensorFromImageElementOptions,\n  TensorFromMLTensorOptions,\n  TensorFromTextureOptions,\n  TensorFromUrlOptions,\n} from './tensor-factory.js';\nimport { Tensor } from './tensor-impl.js';\nimport { Tensor as TensorInterface } from './tensor.js';\n\ninterface BufferToTensorOptions\n  extends OptionsDimensions,\n    OptionsTensorLayout,\n    OptionsNormalizationParameters,\n    OptionsFormat,\n    OptionsTensorFormat {}\n\n/**\n * Create a new tensor object from image object\n *\n * @param buffer - Extracted image buffer data - assuming RGBA format\n * @param imageFormat - input image configuration - required configurations height, width, format\n * @param tensorFormat - output tensor configuration - Default is RGB format\n */\nexport const bufferToTensor = (buffer: Uint8ClampedArray | undefined, options: BufferToTensorOptions): Tensor => {\n  if (buffer === undefined) {\n    throw new Error('Image buffer must be defined');\n  }\n  if (options.height === undefined || options.width === undefined) {\n    throw new Error('Image height and width must be defined');\n  }\n  if (options.tensorLayout === 'NHWC') {\n    throw new Error('NHWC Tensor layout is not supported yet');\n  }\n\n  const { height, width } = options;\n\n  const norm = options.norm ?? { mean: 255, bias: 0 };\n  let normMean: [number, number, number, number];\n  let normBias: [number, number, number, number];\n\n  if (typeof norm.mean === 'number') {\n    normMean = [norm.mean, norm.mean, norm.mean, norm.mean];\n  } else {\n    normMean = [norm.mean![0], norm.mean![1], norm.mean![2], norm.mean![3] ?? 255];\n  }\n\n  if (typeof norm.bias === 'number') {\n    normBias = [norm.bias, norm.bias, norm.bias, norm.bias];\n  } else {\n    normBias = [norm.bias![0], norm.bias![1], norm.bias![2], norm.bias![3] ?? 0];\n  }\n\n  const inputformat = options.format !== undefined ? options.format : 'RGBA';\n  // default value is RGBA since imagedata and HTMLImageElement uses it\n\n  const outputformat =\n    options.tensorFormat !== undefined ? (options.tensorFormat !== undefined ? options.tensorFormat : 'RGB') : 'RGB';\n  const stride = height * width;\n  const float32Data = outputformat === 'RGBA' ? new Float32Array(stride * 4) : new Float32Array(stride * 3);\n\n  // Default pointer assignments\n  let step = 4,\n    rImagePointer = 0,\n    gImagePointer = 1,\n    bImagePointer = 2,\n    aImagePointer = 3;\n  let rTensorPointer = 0,\n    gTensorPointer = stride,\n    bTensorPointer = stride * 2,\n    aTensorPointer = -1;\n\n  // Updating the pointer assignments based on the input image format\n  if (inputformat === 'RGB') {\n    step = 3;\n    rImagePointer = 0;\n    gImagePointer = 1;\n    bImagePointer = 2;\n    aImagePointer = -1;\n  }\n\n  // Updating the pointer assignments based on the output tensor format\n  if (outputformat === 'RGBA') {\n    aTensorPointer = stride * 3;\n  } else if (outputformat === 'RBG') {\n    rTensorPointer = 0;\n    bTensorPointer = stride;\n    gTensorPointer = stride * 2;\n  } else if (outputformat === 'BGR') {\n    bTensorPointer = 0;\n    gTensorPointer = stride;\n    rTensorPointer = stride * 2;\n  }\n\n  for (\n    let i = 0;\n    i < stride;\n    i++, rImagePointer += step, bImagePointer += step, gImagePointer += step, aImagePointer += step\n  ) {\n    float32Data[rTensorPointer++] = (buffer[rImagePointer] + normBias[0]) / normMean[0];\n    float32Data[gTensorPointer++] = (buffer[gImagePointer] + normBias[1]) / normMean[1];\n    float32Data[bTensorPointer++] = (buffer[bImagePointer] + normBias[2]) / normMean[2];\n    if (aTensorPointer !== -1 && aImagePointer !== -1) {\n      float32Data[aTensorPointer++] = (buffer[aImagePointer] + normBias[3]) / normMean[3];\n    }\n  }\n\n  // Float32Array -> ort.Tensor\n  const outputTensor =\n    outputformat === 'RGBA'\n      ? new Tensor('float32', float32Data, [1, 4, height, width])\n      : new Tensor('float32', float32Data, [1, 3, height, width]);\n  return outputTensor;\n};\n\n/**\n * implementation of Tensor.fromImage().\n */\nexport const tensorFromImage = async (\n  image: ImageData | HTMLImageElement | ImageBitmap | string,\n  options?:\n    | TensorFromImageDataOptions\n    | TensorFromImageElementOptions\n    | TensorFromImageBitmapOptions\n    | TensorFromUrlOptions,\n): Promise<Tensor> => {\n  // checking the type of image object\n  const isHTMLImageEle = typeof HTMLImageElement !== 'undefined' && image instanceof HTMLImageElement;\n  const isImageDataEle = typeof ImageData !== 'undefined' && image instanceof ImageData;\n  const isImageBitmap = typeof ImageBitmap !== 'undefined' && image instanceof ImageBitmap;\n  const isString = typeof image === 'string';\n\n  let data: Uint8ClampedArray | undefined;\n  let bufferToTensorOptions: BufferToTensorOptions = options ?? {};\n\n  const createCanvas = () => {\n    if (typeof document !== 'undefined') {\n      return document.createElement('canvas');\n    } else if (typeof OffscreenCanvas !== 'undefined') {\n      return new OffscreenCanvas(1, 1);\n    } else {\n      throw new Error('Canvas is not supported');\n    }\n  };\n  const createCanvasContext = (canvas: HTMLCanvasElement | OffscreenCanvas) => {\n    if (typeof HTMLCanvasElement !== 'undefined' && canvas instanceof HTMLCanvasElement) {\n      return canvas.getContext('2d');\n    } else if (canvas instanceof OffscreenCanvas) {\n      return canvas.getContext('2d') as OffscreenCanvasRenderingContext2D;\n    } else {\n      return null;\n    }\n  };\n  // filling and checking image configuration options\n  if (isHTMLImageEle) {\n    // HTMLImageElement - image object - format is RGBA by default\n    const canvas = createCanvas();\n    canvas.width = image.width;\n    canvas.height = image.height;\n    const pixels2DContext = createCanvasContext(canvas);\n\n    if (pixels2DContext != null) {\n      let height = image.height;\n      let width = image.width;\n      if (options !== undefined && options.resizedHeight !== undefined && options.resizedWidth !== undefined) {\n        height = options.resizedHeight;\n        width = options.resizedWidth;\n      }\n\n      if (options !== undefined) {\n        bufferToTensorOptions = options;\n        if (options.tensorFormat !== undefined) {\n          throw new Error('Image input config format must be RGBA for HTMLImageElement');\n        } else {\n          bufferToTensorOptions.tensorFormat = 'RGBA';\n        }\n        bufferToTensorOptions.height = height;\n        bufferToTensorOptions.width = width;\n      } else {\n        bufferToTensorOptions.tensorFormat = 'RGBA';\n        bufferToTensorOptions.height = height;\n        bufferToTensorOptions.width = width;\n      }\n\n      pixels2DContext.drawImage(image, 0, 0);\n      data = pixels2DContext.getImageData(0, 0, width, height).data;\n    } else {\n      throw new Error('Can not access image data');\n    }\n  } else if (isImageDataEle) {\n    let height: number;\n    let width: number;\n\n    if (options !== undefined && options.resizedWidth !== undefined && options.resizedHeight !== undefined) {\n      height = options.resizedHeight;\n      width = options.resizedWidth;\n    } else {\n      height = image.height;\n      width = image.width;\n    }\n\n    if (options !== undefined) {\n      bufferToTensorOptions = options;\n    }\n    bufferToTensorOptions.format = 'RGBA';\n    bufferToTensorOptions.height = height;\n    bufferToTensorOptions.width = width;\n\n    if (options !== undefined) {\n      const tempCanvas = createCanvas();\n\n      tempCanvas.width = width;\n      tempCanvas.height = height;\n\n      const pixels2DContext = createCanvasContext(tempCanvas);\n\n      if (pixels2DContext != null) {\n        pixels2DContext.putImageData(image, 0, 0);\n        data = pixels2DContext.getImageData(0, 0, width, height).data;\n      } else {\n        throw new Error('Can not access image data');\n      }\n    } else {\n      data = image.data;\n    }\n  } else if (isImageBitmap) {\n    // ImageBitmap - image object - format must be provided by user\n    if (options === undefined) {\n      throw new Error('Please provide image config with format for Imagebitmap');\n    }\n\n    const canvas = createCanvas();\n    canvas.width = image.width;\n    canvas.height = image.height;\n    const pixels2DContext = createCanvasContext(canvas);\n\n    if (pixels2DContext != null) {\n      const height = image.height;\n      const width = image.width;\n      pixels2DContext.drawImage(image, 0, 0, width, height);\n      data = pixels2DContext.getImageData(0, 0, width, height).data;\n      bufferToTensorOptions.height = height;\n      bufferToTensorOptions.width = width;\n      return bufferToTensor(data, bufferToTensorOptions);\n    } else {\n      throw new Error('Can not access image data');\n    }\n  } else if (isString) {\n    return new Promise((resolve, reject) => {\n      const canvas = createCanvas();\n      const context = createCanvasContext(canvas);\n      if (!image || !context) {\n        return reject();\n      }\n      const newImage = new Image();\n      newImage.crossOrigin = 'Anonymous';\n      newImage.src = image;\n      newImage.onload = () => {\n        canvas.width = newImage.width;\n        canvas.height = newImage.height;\n        context.drawImage(newImage, 0, 0, canvas.width, canvas.height);\n        const img = context.getImageData(0, 0, canvas.width, canvas.height);\n\n        bufferToTensorOptions.height = canvas.height;\n        bufferToTensorOptions.width = canvas.width;\n        resolve(bufferToTensor(img.data, bufferToTensorOptions));\n      };\n    });\n  } else {\n    throw new Error('Input data provided is not supported - aborted tensor creation');\n  }\n\n  if (data !== undefined) {\n    return bufferToTensor(data, bufferToTensorOptions);\n  } else {\n    throw new Error('Input data provided is not supported - aborted tensor creation');\n  }\n};\n\n/**\n * implementation of Tensor.fromTexture().\n */\nexport const tensorFromTexture = <T extends TensorInterface.TextureDataTypes>(\n  texture: TensorInterface.TextureType,\n  options: TensorFromTextureOptions<T>,\n): Tensor => {\n  const { width, height, download, dispose } = options;\n  // Always assume RGBAF32. TODO: support different texture format\n  const dims = [1, height, width, 4];\n  return new Tensor({ location: 'texture', type: 'float32', texture, dims, download, dispose });\n};\n\n/**\n * implementation of Tensor.fromGpuBuffer().\n */\nexport const tensorFromGpuBuffer = <T extends TensorInterface.GpuBufferDataTypes>(\n  gpuBuffer: TensorInterface.GpuBufferType,\n  options: TensorFromGpuBufferOptions<T>,\n): Tensor => {\n  const { dataType, dims, download, dispose } = options;\n  return new Tensor({ location: 'gpu-buffer', type: dataType ?? 'float32', gpuBuffer, dims, download, dispose });\n};\n\n/**\n * implementation of Tensor.fromMLTensor().\n */\nexport const tensorFromMLTensor = <T extends TensorInterface.MLTensorDataTypes>(\n  mlTensor: TensorInterface.MLTensorType,\n  options: TensorFromMLTensorOptions<T>,\n): Tensor => {\n  const { dataType, dims, download, dispose } = options;\n  return new Tensor({ location: 'ml-tensor', type: dataType ?? 'float32', mlTensor, dims, download, dispose });\n};\n\n/**\n * implementation of Tensor.fromPinnedBuffer().\n */\nexport const tensorFromPinnedBuffer = <T extends TensorInterface.CpuPinnedDataTypes>(\n  type: T,\n  buffer: TensorInterface.DataTypeMap[T],\n  dims?: readonly number[],\n): Tensor => new Tensor({ location: 'cpu-pinned', type, data: buffer, dims: dims ?? [buffer.length] });\n","// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport { Tensor } from './tensor.js';\n\nexport type SupportedTypedArrayConstructors =\n  | Float32ArrayConstructor\n  | Uint8ArrayConstructor\n  | Int8ArrayConstructor\n  | Uint16ArrayConstructor\n  | Int16ArrayConstructor\n  | Int32ArrayConstructor\n  | BigInt64ArrayConstructor\n  | Uint8ArrayConstructor\n  | Float64ArrayConstructor\n  | Uint32ArrayConstructor\n  | BigUint64ArrayConstructor;\nexport type SupportedTypedArray = InstanceType<SupportedTypedArrayConstructors>;\n\n// a runtime map that maps type string to TypedArray constructor. Should match Tensor.DataTypeMap.\nexport const NUMERIC_TENSOR_TYPE_TO_TYPEDARRAY_MAP = new Map<string, SupportedTypedArrayConstructors>([\n  ['float32', Float32Array],\n  ['uint8', Uint8Array],\n  ['int8', Int8Array],\n  ['uint16', Uint16Array],\n  ['int16', Int16Array],\n  ['int32', Int32Array],\n  ['bool', Uint8Array],\n  ['float64', Float64Array],\n  ['uint32', Uint32Array],\n  ['int4', Uint8Array],\n  ['uint4', Uint8Array],\n]);\n\n// a runtime map that maps type string to TypedArray constructor. Should match Tensor.DataTypeMap.\nexport const NUMERIC_TENSOR_TYPEDARRAY_TO_TYPE_MAP = new Map<SupportedTypedArrayConstructors, Tensor.Type>([\n  [Float32Array, 'float32'],\n  [Uint8Array, 'uint8'],\n  [Int8Array, 'int8'],\n  [Uint16Array, 'uint16'],\n  [Int16Array, 'int16'],\n  [Int32Array, 'int32'],\n  [Float64Array, 'float64'],\n  [Uint32Array, 'uint32'],\n]);\n\n// the following code allows delaying execution of BigInt/Float16Array checking. This allows lazy initialization for\n// NUMERIC_TENSOR_TYPE_TO_TYPEDARRAY_MAP and NUMERIC_TENSOR_TYPEDARRAY_TO_TYPE_MAP, which allows BigInt/Float16Array\n// polyfill if available.\nlet isTypedArrayChecked = false;\nexport const checkTypedArray = () => {\n  if (!isTypedArrayChecked) {\n    isTypedArrayChecked = true;\n    const isBigInt64ArrayAvailable = typeof BigInt64Array !== 'undefined' && BigInt64Array.from;\n    const isBigUint64ArrayAvailable = typeof BigUint64Array !== 'undefined' && BigUint64Array.from;\n\n    // eslint-disable-next-line @typescript-eslint/naming-convention, @typescript-eslint/no-explicit-any\n    const Float16Array = (globalThis as any).Float16Array;\n    const isFloat16ArrayAvailable = typeof Float16Array !== 'undefined' && Float16Array.from;\n\n    if (isBigInt64ArrayAvailable) {\n      NUMERIC_TENSOR_TYPE_TO_TYPEDARRAY_MAP.set('int64', BigInt64Array);\n      NUMERIC_TENSOR_TYPEDARRAY_TO_TYPE_MAP.set(BigInt64Array, 'int64');\n    }\n    if (isBigUint64ArrayAvailable) {\n      NUMERIC_TENSOR_TYPE_TO_TYPEDARRAY_MAP.set('uint64', BigUint64Array);\n      NUMERIC_TENSOR_TYPEDARRAY_TO_TYPE_MAP.set(BigUint64Array, 'uint64');\n    }\n    if (isFloat16ArrayAvailable) {\n      NUMERIC_TENSOR_TYPE_TO_TYPEDARRAY_MAP.set('float16', Float16Array);\n      NUMERIC_TENSOR_TYPEDARRAY_TO_TYPE_MAP.set(Float16Array, 'float16');\n    } else {\n      // if Float16Array is not available, use 'Uint16Array' to store the data.\n      NUMERIC_TENSOR_TYPE_TO_TYPEDARRAY_MAP.set('float16', Uint16Array);\n    }\n  }\n};\n","// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {\n  CpuPinnedConstructorParameters,\n  GpuBufferConstructorParameters,\n  MLTensorConstructorParameters,\n  TextureConstructorParameters,\n} from './tensor-factory.js';\nimport { Tensor } from './tensor-impl.js';\n\n/**\n * calculate size from dims.\n *\n * @param dims the dims array. May be an illegal input.\n */\nexport const calculateSize = (dims: readonly unknown[]): number => {\n  let size = 1;\n  for (let i = 0; i < dims.length; i++) {\n    const dim = dims[i];\n    if (typeof dim !== 'number' || !Number.isSafeInteger(dim)) {\n      throw new TypeError(`dims[${i}] must be an integer, got: ${dim}`);\n    }\n    if (dim < 0) {\n      throw new RangeError(`dims[${i}] must be a non-negative integer, got: ${dim}`);\n    }\n    size *= dim;\n  }\n  return size;\n};\n\n/**\n * implementation of Tensor.reshape()\n */\nexport const tensorReshape = (tensor: Tensor, dims: readonly number[]): Tensor => {\n  switch (tensor.location) {\n    case 'cpu':\n      return new Tensor(tensor.type, tensor.data, dims);\n    case 'cpu-pinned':\n      return new Tensor({\n        location: 'cpu-pinned',\n        data: tensor.data as CpuPinnedConstructorParameters['data'],\n        type: tensor.type as CpuPinnedConstructorParameters['type'],\n        dims,\n      });\n    case 'texture':\n      return new Tensor({\n        location: 'texture',\n        texture: tensor.texture,\n        type: tensor.type as TextureConstructorParameters['type'],\n        dims,\n      });\n    case 'gpu-buffer':\n      return new Tensor({\n        location: 'gpu-buffer',\n        gpuBuffer: tensor.gpuBuffer,\n        type: tensor.type as GpuBufferConstructorParameters['type'],\n        dims,\n      });\n    case 'ml-tensor':\n      return new Tensor({\n        location: 'ml-tensor',\n        mlTensor: tensor.mlTensor,\n        type: tensor.type as MLTensorConstructorParameters['type'],\n        dims,\n      });\n    default:\n      throw new Error(`tensorReshape: tensor location ${tensor.location} is not supported`);\n  }\n};\n","// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport { tensorToDataURL, tensorToImageData } from './tensor-conversion-impl.js';\nimport { TensorToDataUrlOptions, TensorToImageDataOptions } from './tensor-conversion.js';\nimport {\n  tensorFromGpuBuffer,\n  tensorFromImage,\n  tensorFromMLTensor,\n  tensorFromPinnedBuffer,\n  tensorFromTexture,\n} from './tensor-factory-impl.js';\nimport {\n  CpuPinnedConstructorParameters,\n  GpuBufferConstructorParameters,\n  MLTensorConstructorParameters,\n  TensorFromGpuBufferOptions,\n  TensorFromImageBitmapOptions,\n  TensorFromImageDataOptions,\n  TensorFromImageElementOptions,\n  TensorFromMLTensorOptions,\n  TensorFromTextureOptions,\n  TensorFromUrlOptions,\n  TextureConstructorParameters,\n} from './tensor-factory.js';\nimport {\n  checkTypedArray,\n  NUMERIC_TENSOR_TYPE_TO_TYPEDARRAY_MAP,\n  NUMERIC_TENSOR_TYPEDARRAY_TO_TYPE_MAP,\n  SupportedTypedArray,\n  SupportedTypedArrayConstructors,\n} from './tensor-impl-type-mapping.js';\nimport { calculateSize, tensorReshape } from './tensor-utils-impl.js';\nimport { Tensor as TensorInterface } from './tensor.js';\n\n// type aliases for those exported from Tensor interface\n\ntype TensorType = TensorInterface.Type;\ntype TensorDataType = TensorInterface.DataType;\ntype TensorDataLocation = TensorInterface.DataLocation;\ntype TensorTextureType = TensorInterface.TextureType;\ntype TensorGpuBufferType = TensorInterface.GpuBufferType;\ntype TensorMLTensorType = TensorInterface.MLTensorType;\n\n/**\n * the implementation of Tensor interface.\n *\n * @ignore\n */\nexport class Tensor implements TensorInterface {\n  // #region constructors\n\n  /**\n   * Construct a new CPU tensor object from the given type, data and dims.\n   */\n  constructor(\n    type: TensorType,\n    data: TensorDataType | Uint8ClampedArray | readonly string[] | readonly number[] | readonly boolean[],\n    dims?: readonly number[],\n  );\n  /**\n   * Construct a new CPU tensor object from the given data and dims. Type is inferred from data.\n   */\n  constructor(\n    data: TensorDataType | Uint8ClampedArray | readonly string[] | readonly boolean[],\n    dims?: readonly number[],\n  );\n  /**\n   * Construct a new tensor object from the pinned CPU data with the given type and dims.\n   *\n   * Tensor's location will be set to 'cpu-pinned'.\n   *\n   * @param params - Specify the parameters to construct the tensor.\n   */\n  constructor(params: CpuPinnedConstructorParameters);\n  /**\n   * Construct a new tensor object from the WebGL texture with the given type and dims.\n   *\n   * Tensor's location will be set to 'texture'.\n   *\n   * @param params - Specify the parameters to construct the tensor.\n   */\n  constructor(params: TextureConstructorParameters);\n  /**\n   * Construct a new tensor object from the WebGPU buffer with the given type and dims.\n   *\n   * Tensor's location will be set to 'gpu-buffer'.\n   *\n   * @param params - Specify the parameters to construct the tensor.\n   */\n  constructor(params: GpuBufferConstructorParameters);\n\n  /**\n   * Construct a new tensor object from the WebNN MLTensor with the given type and dims.\n   *\n   * Tensor's location will be set to 'ml-tensor'.\n   *\n   * @param params - Specify the parameters to construct the tensor.\n   */\n  constructor(params: MLTensorConstructorParameters);\n\n  /**\n   * implementation.\n   */\n  constructor(\n    arg0:\n      | TensorType\n      | TensorDataType\n      | Uint8ClampedArray\n      | readonly string[]\n      | readonly boolean[]\n      | CpuPinnedConstructorParameters\n      | TextureConstructorParameters\n      | GpuBufferConstructorParameters\n      | MLTensorConstructorParameters,\n    arg1?: TensorDataType | Uint8ClampedArray | readonly number[] | readonly string[] | readonly boolean[],\n    arg2?: readonly number[],\n  ) {\n    // perform one-time check for BigInt/Float16Array support\n    checkTypedArray();\n\n    let type: TensorType;\n    let dims: readonly number[];\n\n    if (typeof arg0 === 'object' && 'location' in arg0) {\n      //\n      // constructing tensor from specific location\n      //\n      this.dataLocation = arg0.location;\n      type = arg0.type;\n      dims = arg0.dims;\n      switch (arg0.location) {\n        case 'cpu-pinned': {\n          const expectedTypedArrayConstructor = NUMERIC_TENSOR_TYPE_TO_TYPEDARRAY_MAP.get(type);\n          if (!expectedTypedArrayConstructor) {\n            throw new TypeError(`unsupported type \"${type}\" to create tensor from pinned buffer`);\n          }\n          if (!(arg0.data instanceof expectedTypedArrayConstructor)) {\n            throw new TypeError(`buffer should be of type ${expectedTypedArrayConstructor.name}`);\n          }\n          this.cpuData = arg0.data;\n          break;\n        }\n        case 'texture': {\n          if (type !== 'float32') {\n            throw new TypeError(`unsupported type \"${type}\" to create tensor from texture`);\n          }\n          this.gpuTextureData = arg0.texture;\n          this.downloader = arg0.download;\n          this.disposer = arg0.dispose;\n          break;\n        }\n        case 'gpu-buffer': {\n          if (\n            type !== 'float32' &&\n            type !== 'float16' &&\n            type !== 'int32' &&\n            type !== 'int64' &&\n            type !== 'uint32' &&\n            type !== 'uint8' &&\n            type !== 'bool' &&\n            type !== 'uint4' &&\n            type !== 'int4'\n          ) {\n            throw new TypeError(`unsupported type \"${type}\" to create tensor from gpu buffer`);\n          }\n          this.gpuBufferData = arg0.gpuBuffer;\n          this.downloader = arg0.download;\n          this.disposer = arg0.dispose;\n          break;\n        }\n        case 'ml-tensor': {\n          if (\n            type !== 'float32' &&\n            type !== 'float16' &&\n            type !== 'int32' &&\n            type !== 'int64' &&\n            type !== 'uint32' &&\n            type !== 'uint64' &&\n            type !== 'int8' &&\n            type !== 'uint8' &&\n            type !== 'bool' &&\n            type !== 'uint4' &&\n            type !== 'int4'\n          ) {\n            throw new TypeError(`unsupported type \"${type}\" to create tensor from MLTensor`);\n          }\n          this.mlTensorData = arg0.mlTensor;\n          this.downloader = arg0.download;\n          this.disposer = arg0.dispose;\n          break;\n        }\n        default:\n          throw new Error(`Tensor constructor: unsupported location '${this.dataLocation}'`);\n      }\n    } else {\n      //\n      // constructing tensor of location 'cpu'\n      //\n      let data: TensorDataType;\n      let maybeDims: typeof arg1 | typeof arg2;\n      // check whether arg0 is type or data\n      if (typeof arg0 === 'string') {\n        //\n        // Override: constructor(type, data, ...)\n        //\n        type = arg0;\n        maybeDims = arg2;\n        if (arg0 === 'string') {\n          // string tensor\n          if (!Array.isArray(arg1)) {\n            throw new TypeError(\"A string tensor's data must be a string array.\");\n          }\n          // we don't check whether every element in the array is string; this is too slow. we assume it's correct and\n          // error will be populated at inference\n          data = arg1;\n        } else {\n          // numeric tensor\n          const typedArrayConstructor = NUMERIC_TENSOR_TYPE_TO_TYPEDARRAY_MAP.get(arg0);\n          if (typedArrayConstructor === undefined) {\n            throw new TypeError(`Unsupported tensor type: ${arg0}.`);\n          }\n          if (Array.isArray(arg1)) {\n            if ((arg0 === 'float16' && typedArrayConstructor === Uint16Array) || arg0 === 'uint4' || arg0 === 'int4') {\n              // - 'float16':\n              //   When no Float16Array polyfill is used, we cannot create 'float16' tensor from number array.\n              //\n              //   Throw error here because when user try to use number array as data,\n              //   e.g. new Tensor('float16', [1, 2, 3, 4], dims)), it will actually call\n              //   Uint16Array.from(arg1) which generates wrong data.\n              //\n              // - 'uint4' and 'int4':\n              //   Uint8Array.from(arg1) will generate wrong data for 'uint4' and 'int4' tensor.\n              //\n              throw new TypeError(\n                `Creating a ${arg0} tensor from number array is not supported. Please use ${typedArrayConstructor.name} as data.`,\n              );\n            } else if (arg0 === 'uint64' || arg0 === 'int64') {\n              // use 'as any' here because:\n              // 1. TypeScript's check on type of 'Array.isArray()' does not work with readonly arrays.\n              // see https://github.com/microsoft/TypeScript/issues/17002\n              // 2. TypeScript's check on union type of '(BigInt64ArrayConstructor|BigUint64ArrayConstructor).from()'\n              // does not accept parameter mapFn.\n              // 3. parameters of 'SupportedTypedArrayConstructors.from()' does not match the requirement of the union\n              // type.\n\n              // assume 'arg1' is of type \"readonly number[]|readonly bigint[]\" here.\n\n              // eslint-disable-next-line @typescript-eslint/no-explicit-any\n              data = (typedArrayConstructor as any).from(arg1, BigInt);\n            } else {\n              // assume 'arg1' is of type \"readonly number[]\" here.\n              // eslint-disable-next-line @typescript-eslint/no-explicit-any\n              data = (typedArrayConstructor as any).from(arg1);\n            }\n          } else if (arg1 instanceof typedArrayConstructor) {\n            data = arg1;\n          } else if (arg1 instanceof Uint8ClampedArray) {\n            if (arg0 === 'uint8') {\n              data = Uint8Array.from(arg1);\n            } else {\n              throw new TypeError(`A Uint8ClampedArray tensor's data must be type of uint8`);\n            }\n          } else if (arg0 === 'float16' && arg1 instanceof Uint16Array && typedArrayConstructor !== Uint16Array) {\n            // when Float16Array is available and data is of type Uint16Array.\n            // We allow Uint16Array to be passed in as data for 'float16' tensor until Float16Array is generally\n            // supported in JavaScript environment.\n\n            // eslint-disable-next-line @typescript-eslint/no-explicit-any\n            data = new (globalThis as any).Float16Array(arg1.buffer, arg1.byteOffset, arg1.length);\n          } else {\n            throw new TypeError(`A ${type} tensor's data must be type of ${typedArrayConstructor}`);\n          }\n        }\n      } else {\n        //\n        // Override: constructor(data, ...)\n        //\n        maybeDims = arg1;\n        if (Array.isArray(arg0)) {\n          // only boolean[] and string[] is supported\n          if (arg0.length === 0) {\n            throw new TypeError('Tensor type cannot be inferred from an empty array.');\n          }\n          const firstElementType = typeof arg0[0];\n          if (firstElementType === 'string') {\n            type = 'string';\n            data = arg0;\n          } else if (firstElementType === 'boolean') {\n            type = 'bool';\n            // 'arg0' is of type 'boolean[]'. Uint8Array.from(boolean[]) actually works, but typescript thinks this is\n            // wrong type. We use 'as any' to make it happy.\n            // eslint-disable-next-line @typescript-eslint/no-explicit-any\n            data = Uint8Array.from(arg0 as any[]);\n          } else {\n            throw new TypeError(`Invalid element type of data array: ${firstElementType}.`);\n          }\n        } else if (arg0 instanceof Uint8ClampedArray) {\n          type = 'uint8';\n          data = Uint8Array.from(arg0);\n        } else {\n          // get tensor type from TypedArray\n          const mappedType = NUMERIC_TENSOR_TYPEDARRAY_TO_TYPE_MAP.get(\n            arg0.constructor as SupportedTypedArrayConstructors,\n          );\n          if (mappedType === undefined) {\n            throw new TypeError(`Unsupported type for tensor data: ${arg0.constructor}.`);\n          }\n          type = mappedType;\n          data = arg0 as SupportedTypedArray;\n        }\n      }\n\n      // type and data is processed, now processing dims\n      if (maybeDims === undefined) {\n        // assume 1-D tensor if dims omitted\n        maybeDims = [data.length];\n      } else if (!Array.isArray(maybeDims)) {\n        throw new TypeError(\"A tensor's dims must be a number array\");\n      }\n      dims = maybeDims as readonly number[];\n\n      this.cpuData = data;\n      this.dataLocation = 'cpu';\n    }\n\n    // perform check on dims\n    const size = calculateSize(dims);\n    // if data is on CPU, check whether data length matches tensor size\n    if (this.cpuData && size !== this.cpuData.length) {\n      if ((type === 'uint4' || type === 'int4') && Math.ceil(size / 2) === this.cpuData.length) {\n        // for (u)int4, the data length is half of the tensor size. So we check this special case when size is odd.\n      } else {\n        throw new Error(`Tensor's size(${size}) does not match data length(${this.cpuData.length}).`);\n      }\n    }\n\n    this.type = type;\n    this.dims = dims;\n    this.size = size;\n  }\n  // #endregion\n\n  // #region factory\n  static async fromImage(\n    image: ImageData | HTMLImageElement | ImageBitmap | string,\n    options?:\n      | TensorFromImageDataOptions\n      | TensorFromImageElementOptions\n      | TensorFromImageBitmapOptions\n      | TensorFromUrlOptions,\n  ): Promise<TensorInterface> {\n    return tensorFromImage(image, options);\n  }\n\n  static fromTexture<T extends TensorInterface.TextureDataTypes>(\n    texture: TensorTextureType,\n    options: TensorFromTextureOptions<T>,\n  ): TensorInterface {\n    return tensorFromTexture(texture, options);\n  }\n\n  static fromGpuBuffer<T extends TensorInterface.GpuBufferDataTypes>(\n    gpuBuffer: TensorGpuBufferType,\n    options: TensorFromGpuBufferOptions<T>,\n  ): TensorInterface {\n    return tensorFromGpuBuffer(gpuBuffer, options);\n  }\n\n  static fromMLTensor<T extends TensorInterface.MLTensorDataTypes>(\n    mlTensor: TensorMLTensorType,\n    options: TensorFromMLTensorOptions<T>,\n  ): TensorInterface {\n    return tensorFromMLTensor(mlTensor, options);\n  }\n\n  static fromPinnedBuffer<T extends TensorInterface.CpuPinnedDataTypes>(\n    type: T,\n    buffer: TensorInterface.DataTypeMap[T],\n    dims?: readonly number[],\n  ): Tensor {\n    return tensorFromPinnedBuffer(type, buffer, dims);\n  }\n\n  // #endregion\n\n  // #region conversions\n  toDataURL(options?: TensorToDataUrlOptions): string {\n    return tensorToDataURL(this, options);\n  }\n\n  toImageData(options?: TensorToImageDataOptions): ImageData {\n    return tensorToImageData(this, options);\n  }\n  // #endregion\n\n  // #region public fields\n  readonly dims: readonly number[];\n  readonly type: TensorType;\n  readonly size: number;\n  // #endregion\n\n  // #region private fields\n\n  /**\n   * stores the location of the data.\n   */\n  private dataLocation: TensorDataLocation;\n\n  /**\n   * stores the data on CPU, if location is 'cpu' or 'cpu-pinned'. otherwise empty.\n   */\n  private cpuData?: TensorDataType;\n\n  /**\n   * stores the underlying texture when location is 'texture'. otherwise empty.\n   */\n  private gpuTextureData?: TensorTextureType;\n\n  /**\n   * stores the underlying GPU buffer when location is 'gpu-buffer'. otherwise empty.\n   */\n  private gpuBufferData?: TensorGpuBufferType;\n\n  /**\n   * stores the underlying WebNN MLTensor when location is 'ml-tensor'. otherwise empty.\n   */\n  private mlTensorData?: TensorMLTensorType;\n\n  /**\n   * stores an optional downloader function to download data from GPU to CPU.\n   */\n  private downloader?(): Promise<TensorDataType>;\n\n  /**\n   * a flag indicating whether the data is being downloaded from GPU to CPU.\n   */\n  private isDownloading?: boolean;\n\n  /**\n   * stores an optional disposer function to dispose the underlying data.\n   */\n  private disposer?(): void;\n  // #endregion\n\n  // #region properties\n  get data(): TensorDataType {\n    this.ensureValid();\n    if (!this.cpuData) {\n      throw new Error(\n        'The data is not on CPU. Use `getData()` to download GPU data to CPU, ' +\n          'or use `texture` or `gpuBuffer` property to access the GPU data directly.',\n      );\n    }\n    return this.cpuData;\n  }\n\n  get location(): TensorDataLocation {\n    return this.dataLocation;\n  }\n\n  get texture(): TensorTextureType {\n    this.ensureValid();\n    if (!this.gpuTextureData) {\n      throw new Error('The data is not stored as a WebGL texture.');\n    }\n    return this.gpuTextureData;\n  }\n\n  get gpuBuffer(): TensorGpuBufferType {\n    this.ensureValid();\n    if (!this.gpuBufferData) {\n      throw new Error('The data is not stored as a WebGPU buffer.');\n    }\n    return this.gpuBufferData;\n  }\n\n  get mlTensor(): TensorMLTensorType {\n    this.ensureValid();\n    if (!this.mlTensorData) {\n      throw new Error('The data is not stored as a WebNN MLTensor.');\n    }\n    return this.mlTensorData;\n  }\n  // #endregion\n\n  // #region methods\n\n  async getData(releaseData?: boolean): Promise<TensorDataType> {\n    this.ensureValid();\n    switch (this.dataLocation) {\n      case 'cpu':\n      case 'cpu-pinned':\n        return this.data;\n      case 'texture':\n      case 'gpu-buffer':\n      case 'ml-tensor': {\n        if (!this.downloader) {\n          throw new Error('The current tensor is not created with a specified data downloader.');\n        }\n        if (this.isDownloading) {\n          throw new Error('The current tensor is being downloaded.');\n        }\n        try {\n          this.isDownloading = true;\n          const data = await this.downloader();\n          this.downloader = undefined;\n          this.dataLocation = 'cpu';\n          this.cpuData = data;\n\n          if (releaseData && this.disposer) {\n            this.disposer();\n            this.disposer = undefined;\n          }\n\n          return data;\n        } finally {\n          this.isDownloading = false;\n        }\n      }\n      default:\n        throw new Error(`cannot get data from location: ${this.dataLocation}`);\n    }\n  }\n\n  dispose(): void {\n    if (this.isDownloading) {\n      throw new Error('The current tensor is being downloaded.');\n    }\n\n    if (this.disposer) {\n      this.disposer();\n      this.disposer = undefined;\n    }\n    this.cpuData = undefined;\n    this.gpuTextureData = undefined;\n    this.gpuBufferData = undefined;\n    this.mlTensorData = undefined;\n    this.downloader = undefined;\n    this.isDownloading = undefined;\n\n    this.dataLocation = 'none';\n  }\n\n  // #endregion\n\n  // #region tensor utilities\n  private ensureValid(): void {\n    if (this.dataLocation === 'none') {\n      throw new Error('The tensor is disposed.');\n    }\n  }\n\n  reshape(dims: readonly number[]): TensorInterface {\n    this.ensureValid();\n    if (this.downloader || this.disposer) {\n      throw new Error('Cannot reshape a tensor that owns GPU resource.');\n    }\n    return tensorReshape(this, dims);\n  }\n  // #endregion\n}\n","// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport { TensorFactory } from './tensor-factory.js';\nimport { Tensor as TensorImpl } from './tensor-impl.js';\nimport { TypedTensorUtils } from './tensor-utils.js';\nimport { TryGetGlobalType } from './type-helper.js';\n\n/* eslint-disable @typescript-eslint/no-redeclare */\n\n/**\n * represent a basic tensor with specified dimensions and data type.\n */\ninterface TypedTensorBase<T extends Tensor.Type> {\n  /**\n   * Get the dimensions of the tensor.\n   */\n  readonly dims: readonly number[];\n  /**\n   * Get the data type of the tensor.\n   */\n  readonly type: T;\n  /**\n   * Get the buffer data of the tensor.\n   *\n   * If the data is not on CPU (eg. it's in the form of WebGL texture or WebGPU buffer), throw error.\n   */\n  readonly data: Tensor.DataTypeMap[T];\n  /**\n   * Get the location of the data.\n   */\n  readonly location: Tensor.DataLocation;\n  /**\n   * Get the WebGL texture that holds the tensor data.\n   *\n   * If the data is not on GPU as WebGL texture, throw error.\n   */\n  readonly texture: Tensor.TextureType;\n  /**\n   * Get the WebGPU buffer that holds the tensor data.\n   *\n   * If the data is not on GPU as WebGPU buffer, throw error.\n   */\n  readonly gpuBuffer: Tensor.GpuBufferType;\n\n  /**\n   * Get the WebNN MLTensor that holds the tensor data.\n   *\n   * If the data is not in a WebNN MLTensor, throw error.\n   */\n  readonly mlTensor: Tensor.MLTensorType;\n\n  /**\n   * Get the buffer data of the tensor.\n   *\n   * If the data is on CPU, returns the data immediately.\n   * If the data is on GPU, downloads the data and returns the promise.\n   *\n   * @param releaseData - whether release the data on GPU. Ignore if data is already on CPU.\n   */\n  getData(releaseData?: boolean): Promise<Tensor.DataTypeMap[T]>;\n\n  /**\n   * Dispose the tensor data.\n   *\n   * If the data is on CPU, remove its internal reference to the underlying data.\n   * If the data is on GPU, release the data on GPU.\n   *\n   * After calling this function, the tensor is considered no longer valid. Its location will be set to 'none'.\n   */\n  dispose(): void;\n}\n\nexport declare namespace Tensor {\n  interface DataTypeMap {\n    float32: Float32Array;\n    uint8: Uint8Array;\n    int8: Int8Array;\n    uint16: Uint16Array;\n    int16: Int16Array;\n    int32: Int32Array;\n    int64: BigInt64Array;\n    string: string[];\n    bool: Uint8Array;\n    float16: Uint16Array; // Keep using Uint16Array until we have a concrete solution for float 16.\n    float64: Float64Array;\n    uint32: Uint32Array;\n    uint64: BigUint64Array;\n    // complex64: never;\n    // complex128: never;\n    // bfloat16: never;\n    uint4: Uint8Array;\n    int4: Int8Array;\n  }\n\n  interface ElementTypeMap {\n    float32: number;\n    uint8: number;\n    int8: number;\n    uint16: number;\n    int16: number;\n    int32: number;\n    int64: bigint;\n    string: string;\n    bool: boolean;\n    float16: number; // Keep using Uint16Array until we have a concrete solution for float 16.\n    float64: number;\n    uint32: number;\n    uint64: bigint;\n    // complex64: never;\n    // complex128: never;\n    // bfloat16: never;\n    uint4: number;\n    int4: number;\n  }\n\n  type DataType = DataTypeMap[Type];\n  type ElementType = ElementTypeMap[Type];\n\n  /**\n   * supported data types for constructing a tensor from a pinned CPU buffer\n   */\n  export type CpuPinnedDataTypes = Exclude<Tensor.Type, 'string'>;\n\n  /**\n   * type alias for WebGL texture\n   */\n  export type TextureType = WebGLTexture;\n\n  /**\n   * supported data types for constructing a tensor from a WebGL texture\n   */\n  export type TextureDataTypes = 'float32';\n\n  type GpuBufferTypeFallback = { size: number; mapState: 'unmapped' | 'pending' | 'mapped' };\n  /**\n   * type alias for WebGPU buffer\n   */\n  export type GpuBufferType = TryGetGlobalType<'GPUBuffer', GpuBufferTypeFallback>;\n\n  type MLTensorTypeFallback = { destroy(): void };\n  /**\n   * type alias for WebNN MLTensor\n   *\n   * The specification for WebNN's MLTensor is currently in flux.\n   */\n  export type MLTensorType = TryGetGlobalType<'MLTensor', MLTensorTypeFallback>;\n\n  /**\n   * supported data types for constructing a tensor from a WebGPU buffer\n   */\n  export type GpuBufferDataTypes = 'float32' | 'float16' | 'int32' | 'int64' | 'uint32' | 'uint8' | 'bool';\n\n  /**\n   * supported data types for constructing a tensor from a WebNN MLTensor\n   */\n  export type MLTensorDataTypes =\n    | 'float32'\n    | 'float16'\n    | 'int8'\n    | 'uint8'\n    | 'int32'\n    | 'uint32'\n    | 'int64'\n    | 'uint64'\n    | 'bool'\n    | 'uint4'\n    | 'int4';\n\n  /**\n   * represent where the tensor data is stored\n   */\n  export type DataLocation = 'none' | 'cpu' | 'cpu-pinned' | 'texture' | 'gpu-buffer' | 'ml-tensor';\n\n  /**\n   * represent the data type of a tensor\n   */\n  export type Type = keyof DataTypeMap;\n}\n\n/**\n * Represent multi-dimensional arrays to feed to or fetch from model inferencing.\n */\nexport interface TypedTensor<T extends Tensor.Type> extends TypedTensorBase<T>, TypedTensorUtils<T> {}\n/**\n * Represent multi-dimensional arrays to feed to or fetch from model inferencing.\n */\nexport interface Tensor extends TypedTensorBase<Tensor.Type>, TypedTensorUtils<Tensor.Type> {}\n\n/**\n * type TensorConstructor defines the constructors of 'Tensor' to create CPU tensor instances.\n */\nexport interface TensorConstructor extends TensorFactory {\n  // #region CPU tensor - specify element type\n  /**\n   * Construct a new string tensor object from the given type, data and dims.\n   *\n   * @param type - Specify the element type.\n   * @param data - Specify the CPU tensor data.\n   * @param dims - Specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\n   */\n  new (\n    type: 'string',\n    data: Tensor.DataTypeMap['string'] | readonly string[],\n    dims?: readonly number[],\n  ): TypedTensor<'string'>;\n\n  /**\n   * Construct a new bool tensor object from the given type, data and dims.\n   *\n   * @param type - Specify the element type.\n   * @param data - Specify the CPU tensor data.\n   * @param dims - Specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\n   */\n  new (\n    type: 'bool',\n    data: Tensor.DataTypeMap['bool'] | readonly boolean[],\n    dims?: readonly number[],\n  ): TypedTensor<'bool'>;\n\n  /**\n   * Construct a new uint8 tensor object from a Uint8ClampedArray, data and dims.\n   *\n   * @param type - Specify the element type.\n   * @param data - Specify the CPU tensor data.\n   * @param dims - Specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\n   */\n  new (type: 'uint8', data: Uint8ClampedArray, dims?: readonly number[]): TypedTensor<'uint8'>;\n\n  /**\n   * Construct a new 64-bit integer typed tensor object from the given type, data and dims.\n   *\n   * @param type - Specify the element type.\n   * @param data - Specify the CPU tensor data.\n   * @param dims - Specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\n   */\n  new <T extends 'uint64' | 'int64'>(\n    type: T,\n    data: Tensor.DataTypeMap[T] | readonly bigint[] | readonly number[],\n    dims?: readonly number[],\n  ): TypedTensor<T>;\n\n  /**\n   * Construct a new numeric tensor object from the given type, data and dims.\n   *\n   * @param type - Specify the element type.\n   * @param data - Specify the CPU tensor data.\n   * @param dims - Specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\n   */\n  new <T extends Exclude<Tensor.Type, 'string' | 'bool' | 'uint64' | 'int64'>>(\n    type: T,\n    data: Tensor.DataTypeMap[T] | readonly number[],\n    dims?: readonly number[],\n  ): TypedTensor<T>;\n  // #endregion\n\n  // #region CPU tensor - infer element types\n\n  /**\n   * Construct a new float32 tensor object from the given data and dims.\n   *\n   * @param data - Specify the CPU tensor data.\n   * @param dims - Specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\n   */\n  new (data: Float32Array, dims?: readonly number[]): TypedTensor<'float32'>;\n\n  /**\n   * Construct a new int8 tensor object from the given data and dims.\n   *\n   * @param data - Specify the CPU tensor data.\n   * @param dims - Specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\n   */\n  new (data: Int8Array, dims?: readonly number[]): TypedTensor<'int8'>;\n\n  /**\n   * Construct a new uint8 tensor object from the given data and dims.\n   *\n   * @param data - Specify the CPU tensor data.\n   * @param dims - Specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\n   */\n  new (data: Uint8Array, dims?: readonly number[]): TypedTensor<'uint8'>;\n\n  /**\n   * Construct a new uint8 tensor object from the given data and dims.\n   *\n   * @param data - Specify the CPU tensor data.\n   * @param dims - Specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\n   */\n  new (data: Uint8ClampedArray, dims?: readonly number[]): TypedTensor<'uint8'>;\n\n  /**\n   * Construct a new uint16 tensor object from the given data and dims.\n   *\n   * @param data - Specify the CPU tensor data.\n   * @param dims - Specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\n   */\n  new (data: Uint16Array, dims?: readonly number[]): TypedTensor<'uint16'>;\n\n  /**\n   * Construct a new int16 tensor object from the given data and dims.\n   *\n   * @param data - Specify the CPU tensor data.\n   * @param dims - Specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\n   */\n  new (data: Int16Array, dims?: readonly number[]): TypedTensor<'int16'>;\n\n  /**\n   * Construct a new int32 tensor object from the given data and dims.\n   *\n   * @param data - Specify the CPU tensor data.\n   * @param dims - Specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\n   */\n  new (data: Int32Array, dims?: readonly number[]): TypedTensor<'int32'>;\n\n  /**\n   * Construct a new int64 tensor object from the given data and dims.\n   *\n   * @param data - Specify the CPU tensor data.\n   * @param dims - Specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\n   */\n  new (data: BigInt64Array, dims?: readonly number[]): TypedTensor<'int64'>;\n\n  /**\n   * Construct a new string tensor object from the given data and dims.\n   *\n   * @param data - Specify the CPU tensor data.\n   * @param dims - Specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\n   */\n  new (data: readonly string[], dims?: readonly number[]): TypedTensor<'string'>;\n\n  /**\n   * Construct a new bool tensor object from the given data and dims.\n   *\n   * @param data - Specify the CPU tensor data.\n   * @param dims - Specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\n   */\n  new (data: readonly boolean[], dims?: readonly number[]): TypedTensor<'bool'>;\n\n  /**\n   * Construct a new float64 tensor object from the given data and dims.\n   *\n   * @param data - Specify the CPU tensor data.\n   * @param dims - Specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\n   */\n  new (data: Float64Array, dims?: readonly number[]): TypedTensor<'float64'>;\n\n  /**\n   * Construct a new uint32 tensor object from the given data and dims.\n   *\n   * @param data - Specify the CPU tensor data.\n   * @param dims - Specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\n   */\n  new (data: Uint32Array, dims?: readonly number[]): TypedTensor<'uint32'>;\n\n  /**\n   * Construct a new uint64 tensor object from the given data and dims.\n   *\n   * @param data - Specify the CPU tensor data.\n   * @param dims - Specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\n   */\n  new (data: BigUint64Array, dims?: readonly number[]): TypedTensor<'uint64'>;\n\n  // #endregion\n\n  // #region CPU tensor - fall back to non-generic tensor type declaration\n\n  /**\n   * Construct a new tensor object from the given type, data and dims.\n   *\n   * @param type - Specify the element type.\n   * @param data - Specify the CPU tensor data.\n   * @param dims - Specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\n   */\n  new (\n    type: Tensor.Type,\n    data: Tensor.DataType | readonly number[] | readonly string[] | readonly bigint[] | readonly boolean[],\n    dims?: readonly number[],\n  ): Tensor;\n\n  /**\n   * Construct a new tensor object from the given data and dims.\n   *\n   * @param data - Specify the CPU tensor data.\n   * @param dims - Specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\n   */\n  new (data: Tensor.DataType, dims?: readonly number[]): Tensor;\n  // #endregion\n}\n\n// eslint-disable-next-line @typescript-eslint/naming-convention\nexport const Tensor = TensorImpl as TensorConstructor;\n","// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport { env } from './env-impl.js';\n\n/**\n * @ignore\n */\nexport const TRACE = (deviceType: string, label: string) => {\n  if (typeof env.trace === 'undefined' ? !env.wasm.trace : !env.trace) {\n    return;\n  }\n  // eslint-disable-next-line no-console\n  console.timeStamp(`${deviceType}::ORT::${label}`);\n};\n\nconst TRACE_FUNC = (msg: string, extraMsg?: string) => {\n  const stack = new Error().stack?.split(/\\r\\n|\\r|\\n/g) || [];\n  let hasTraceFunc = false;\n  for (let i = 0; i < stack.length; i++) {\n    if (hasTraceFunc && !stack[i].includes('TRACE_FUNC')) {\n      let label = `FUNC_${msg}::${stack[i].trim().split(' ')[1]}`;\n      if (extraMsg) {\n        label += `::${extraMsg}`;\n      }\n      TRACE('CPU', label);\n      return;\n    }\n    if (stack[i].includes('TRACE_FUNC')) {\n      hasTraceFunc = true;\n    }\n  }\n};\n\n/**\n * @ignore\n */\nexport const TRACE_FUNC_BEGIN = (extraMsg?: string) => {\n  if (typeof env.trace === 'undefined' ? !env.wasm.trace : !env.trace) {\n    return;\n  }\n  TRACE_FUNC('BEGIN', extraMsg);\n};\n\n/**\n * @ignore\n */\nexport const TRACE_FUNC_END = (extraMsg?: string) => {\n  if (typeof env.trace === 'undefined' ? !env.wasm.trace : !env.trace) {\n    return;\n  }\n  TRACE_FUNC('END', extraMsg);\n};\n","// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport { resolveBackendAndExecutionProviders } from './backend-impl.js';\nimport { InferenceSessionHandler } from './backend.js';\nimport { InferenceSession as InferenceSessionInterface } from './inference-session.js';\nimport { OnnxValue } from './onnx-value.js';\nimport { Tensor } from './tensor.js';\nimport { TRACE_FUNC_BEGIN, TRACE_FUNC_END } from './trace.js';\n\ntype SessionOptions = InferenceSessionInterface.SessionOptions;\ntype RunOptions = InferenceSessionInterface.RunOptions;\ntype FeedsType = InferenceSessionInterface.FeedsType;\ntype FetchesType = InferenceSessionInterface.FetchesType;\ntype ReturnType = InferenceSessionInterface.ReturnType;\n\nexport class InferenceSession implements InferenceSessionInterface {\n  private constructor(handler: InferenceSessionHandler) {\n    this.handler = handler;\n  }\n  run(feeds: FeedsType, options?: RunOptions): Promise<ReturnType>;\n  run(feeds: FeedsType, fetches: FetchesType, options?: RunOptions): Promise<ReturnType>;\n  async run(feeds: FeedsType, arg1?: FetchesType | RunOptions, arg2?: RunOptions): Promise<ReturnType> {\n    TRACE_FUNC_BEGIN();\n    const fetches: { [name: string]: OnnxValue | null } = {};\n    let options: RunOptions = {};\n    // check inputs\n    if (typeof feeds !== 'object' || feeds === null || feeds instanceof Tensor || Array.isArray(feeds)) {\n      throw new TypeError(\n        \"'feeds' must be an object that use input names as keys and OnnxValue as corresponding values.\",\n      );\n    }\n\n    let isFetchesEmpty = true;\n    // determine which override is being used\n    if (typeof arg1 === 'object') {\n      if (arg1 === null) {\n        throw new TypeError('Unexpected argument[1]: cannot be null.');\n      }\n      if (arg1 instanceof Tensor) {\n        throw new TypeError(\"'fetches' cannot be a Tensor\");\n      }\n\n      if (Array.isArray(arg1)) {\n        if (arg1.length === 0) {\n          throw new TypeError(\"'fetches' cannot be an empty array.\");\n        }\n        isFetchesEmpty = false;\n        // output names\n        for (const name of arg1) {\n          if (typeof name !== 'string') {\n            throw new TypeError(\"'fetches' must be a string array or an object.\");\n          }\n          if (this.outputNames.indexOf(name) === -1) {\n            throw new RangeError(`'fetches' contains invalid output name: ${name}.`);\n          }\n          fetches[name] = null;\n        }\n\n        if (typeof arg2 === 'object' && arg2 !== null) {\n          options = arg2;\n        } else if (typeof arg2 !== 'undefined') {\n          throw new TypeError(\"'options' must be an object.\");\n        }\n      } else {\n        // decide whether arg1 is fetches or options\n        // if any output name is present and its value is valid OnnxValue, we consider it fetches\n        let isFetches = false;\n        const arg1Keys = Object.getOwnPropertyNames(arg1);\n        for (const name of this.outputNames) {\n          if (arg1Keys.indexOf(name) !== -1) {\n            const v = (arg1 as InferenceSessionInterface.NullableOnnxValueMapType)[name];\n            if (v === null || v instanceof Tensor) {\n              isFetches = true;\n              isFetchesEmpty = false;\n              fetches[name] = v;\n            }\n          }\n        }\n\n        if (isFetches) {\n          if (typeof arg2 === 'object' && arg2 !== null) {\n            options = arg2;\n          } else if (typeof arg2 !== 'undefined') {\n            throw new TypeError(\"'options' must be an object.\");\n          }\n        } else {\n          options = arg1 as RunOptions;\n        }\n      }\n    } else if (typeof arg1 !== 'undefined') {\n      throw new TypeError(\"Unexpected argument[1]: must be 'fetches' or 'options'.\");\n    }\n\n    // check if all inputs are in feed\n    for (const name of this.inputNames) {\n      if (typeof feeds[name] === 'undefined') {\n        throw new Error(`input '${name}' is missing in 'feeds'.`);\n      }\n    }\n\n    // if no fetches is specified, we use the full output names list\n    if (isFetchesEmpty) {\n      for (const name of this.outputNames) {\n        fetches[name] = null;\n      }\n    }\n\n    // feeds, fetches and options are prepared\n\n    const results = await this.handler.run(feeds, fetches, options);\n    const returnValue: { [name: string]: OnnxValue } = {};\n    for (const key in results) {\n      if (Object.hasOwnProperty.call(results, key)) {\n        const result = results[key];\n        if (result instanceof Tensor) {\n          returnValue[key] = result;\n        } else {\n          returnValue[key] = new Tensor(result.type, result.data, result.dims);\n        }\n      }\n    }\n    TRACE_FUNC_END();\n    return returnValue;\n  }\n\n  async release(): Promise<void> {\n    return this.handler.dispose();\n  }\n\n  static create(path: string, options?: SessionOptions): Promise<InferenceSessionInterface>;\n  static create(buffer: ArrayBufferLike, options?: SessionOptions): Promise<InferenceSessionInterface>;\n  static create(\n    buffer: ArrayBufferLike,\n    byteOffset: number,\n    byteLength?: number,\n    options?: SessionOptions,\n  ): Promise<InferenceSessionInterface>;\n  static create(buffer: Uint8Array, options?: SessionOptions): Promise<InferenceSessionInterface>;\n  static async create(\n    arg0: string | ArrayBufferLike | Uint8Array,\n    arg1?: SessionOptions | number,\n    arg2?: number,\n    arg3?: SessionOptions,\n  ): Promise<InferenceSessionInterface> {\n    TRACE_FUNC_BEGIN();\n    // either load from a file or buffer\n    let filePathOrUint8Array: string | Uint8Array;\n    let options: SessionOptions = {};\n\n    if (typeof arg0 === 'string') {\n      filePathOrUint8Array = arg0;\n      if (typeof arg1 === 'object' && arg1 !== null) {\n        options = arg1;\n      } else if (typeof arg1 !== 'undefined') {\n        throw new TypeError(\"'options' must be an object.\");\n      }\n    } else if (arg0 instanceof Uint8Array) {\n      filePathOrUint8Array = arg0;\n      if (typeof arg1 === 'object' && arg1 !== null) {\n        options = arg1;\n      } else if (typeof arg1 !== 'undefined') {\n        throw new TypeError(\"'options' must be an object.\");\n      }\n    } else if (\n      arg0 instanceof ArrayBuffer ||\n      (typeof SharedArrayBuffer !== 'undefined' && arg0 instanceof SharedArrayBuffer)\n    ) {\n      const buffer = arg0;\n      let byteOffset = 0;\n      let byteLength = arg0.byteLength;\n      if (typeof arg1 === 'object' && arg1 !== null) {\n        options = arg1;\n      } else if (typeof arg1 === 'number') {\n        byteOffset = arg1;\n        if (!Number.isSafeInteger(byteOffset)) {\n          throw new RangeError(\"'byteOffset' must be an integer.\");\n        }\n        if (byteOffset < 0 || byteOffset >= buffer.byteLength) {\n          throw new RangeError(`'byteOffset' is out of range [0, ${buffer.byteLength}).`);\n        }\n        byteLength = arg0.byteLength - byteOffset;\n        if (typeof arg2 === 'number') {\n          byteLength = arg2;\n          if (!Number.isSafeInteger(byteLength)) {\n            throw new RangeError(\"'byteLength' must be an integer.\");\n          }\n          if (byteLength <= 0 || byteOffset + byteLength > buffer.byteLength) {\n            throw new RangeError(`'byteLength' is out of range (0, ${buffer.byteLength - byteOffset}].`);\n          }\n          if (typeof arg3 === 'object' && arg3 !== null) {\n            options = arg3;\n          } else if (typeof arg3 !== 'undefined') {\n            throw new TypeError(\"'options' must be an object.\");\n          }\n        } else if (typeof arg2 !== 'undefined') {\n          throw new TypeError(\"'byteLength' must be a number.\");\n        }\n      } else if (typeof arg1 !== 'undefined') {\n        throw new TypeError(\"'options' must be an object.\");\n      }\n      filePathOrUint8Array = new Uint8Array(buffer, byteOffset, byteLength);\n    } else {\n      throw new TypeError(\"Unexpected argument[0]: must be 'path' or 'buffer'.\");\n    }\n\n    // resolve backend, update session options with validated EPs, and create session handler\n    const [backend, optionsWithValidatedEPs] = await resolveBackendAndExecutionProviders(options);\n    const handler = await backend.createInferenceSessionHandler(filePathOrUint8Array, optionsWithValidatedEPs);\n    TRACE_FUNC_END();\n    return new InferenceSession(handler);\n  }\n\n  startProfiling(): void {\n    this.handler.startProfiling();\n  }\n  endProfiling(): void {\n    this.handler.endProfiling();\n  }\n\n  get inputNames(): readonly string[] {\n    return this.handler.inputNames;\n  }\n  get outputNames(): readonly string[] {\n    return this.handler.outputNames;\n  }\n\n  private handler: InferenceSessionHandler;\n}\n","// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport { InferenceSession as InferenceSessionImpl } from './inference-session-impl.js';\nimport { OnnxModelOptions } from './onnx-model.js';\nimport { OnnxValue, OnnxValueDataLocation } from './onnx-value.js';\nimport { TryGetGlobalType } from './type-helper.js';\n\n/* eslint-disable @typescript-eslint/no-redeclare */\n\nexport declare namespace InferenceSession {\n  // #region input/output types\n\n  type OnnxValueMapType = { readonly [name: string]: OnnxValue };\n  type NullableOnnxValueMapType = { readonly [name: string]: OnnxValue | null };\n\n  /**\n   * A feeds (model inputs) is an object that uses input names as keys and OnnxValue as corresponding values.\n   */\n  type FeedsType = OnnxValueMapType;\n\n  /**\n   * A fetches (model outputs) could be one of the following:\n   *\n   * - Omitted. Use model's output names definition.\n   * - An array of string indicating the output names.\n   * - An object that use output names as keys and OnnxValue or null as corresponding values.\n   *\n   * @remark\n   * different from input argument, in output, OnnxValue is optional. If an OnnxValue is present it will be\n   * used as a pre-allocated value by the inference engine; if omitted, inference engine will allocate buffer\n   * internally.\n   */\n  type FetchesType = readonly string[] | NullableOnnxValueMapType;\n\n  /**\n   * A inferencing return type is an object that uses output names as keys and OnnxValue as corresponding values.\n   */\n  type ReturnType = OnnxValueMapType;\n\n  // #endregion\n\n  // #region session options\n\n  /**\n   * A set of configurations for session behavior.\n   */\n  export interface SessionOptions extends OnnxModelOptions {\n    /**\n     * An array of execution provider options.\n     *\n     * An execution provider option can be a string indicating the name of the execution provider,\n     * or an object of corresponding type.\n     */\n    executionProviders?: readonly ExecutionProviderConfig[];\n\n    /**\n     * The intra OP threads number.\n     *\n     * This setting is available only in ONNXRuntime (Node.js binding and react-native).\n     */\n    intraOpNumThreads?: number;\n\n    /**\n     * The inter OP threads number.\n     *\n     * This setting is available only in ONNXRuntime (Node.js binding and react-native).\n     */\n    interOpNumThreads?: number;\n\n    /**\n     * The free dimension override.\n     *\n     * This setting is available only in ONNXRuntime (Node.js binding and react-native) or WebAssembly backend\n     */\n    freeDimensionOverrides?: { readonly [dimensionName: string]: number };\n\n    /**\n     * The optimization level.\n     *\n     * This setting is available only in ONNXRuntime (Node.js binding and react-native) or WebAssembly backend\n     */\n    graphOptimizationLevel?: 'disabled' | 'basic' | 'extended' | 'all';\n\n    /**\n     * Whether enable CPU memory arena.\n     *\n     * This setting is available only in ONNXRuntime (Node.js binding and react-native) or WebAssembly backend\n     */\n    enableCpuMemArena?: boolean;\n\n    /**\n     * Whether enable memory pattern.\n     *\n     * This setting is available only in ONNXRuntime (Node.js binding and react-native) or WebAssembly backend\n     */\n    enableMemPattern?: boolean;\n\n    /**\n     * Execution mode.\n     *\n     * This setting is available only in ONNXRuntime (Node.js binding and react-native) or WebAssembly backend\n     */\n    executionMode?: 'sequential' | 'parallel';\n\n    /**\n     * Optimized model file path.\n     *\n     * If this setting is specified, the optimized model will be dumped. In browser, a blob will be created\n     * with a pop-up window.\n     */\n    optimizedModelFilePath?: string;\n\n    /**\n     * Whether enable profiling.\n     *\n     * This setting is a placeholder for a future use.\n     */\n    enableProfiling?: boolean;\n\n    /**\n     * File prefix for profiling.\n     *\n     * This setting is a placeholder for a future use.\n     */\n    profileFilePrefix?: string;\n\n    /**\n     * Log ID.\n     *\n     * This setting is available only in ONNXRuntime (Node.js binding and react-native) or WebAssembly backend\n     */\n    logId?: string;\n\n    /**\n     * Log severity level. See\n     * https://github.com/microsoft/onnxruntime/blob/main/include/onnxruntime/core/common/logging/severity.h\n     *\n     * This setting is available only in ONNXRuntime (Node.js binding and react-native) or WebAssembly backend\n     */\n    logSeverityLevel?: 0 | 1 | 2 | 3 | 4;\n\n    /**\n     * Log verbosity level.\n     *\n     * This setting is available only in WebAssembly backend. Will support Node.js binding and react-native later\n     */\n    logVerbosityLevel?: number;\n\n    /**\n     * Specify string as a preferred data location for all outputs, or an object that use output names as keys and a\n     * preferred data location as corresponding values.\n     *\n     * This setting is available only in ONNXRuntime Web for WebGL and WebGPU EP.\n     */\n    preferredOutputLocation?: OnnxValueDataLocation | { readonly [outputName: string]: OnnxValueDataLocation };\n\n    /**\n     * Whether enable graph capture.\n     * This setting is available only in ONNXRuntime Web for WebGPU EP.\n     */\n    enableGraphCapture?: boolean;\n\n    /**\n     * Store configurations for a session. See\n     * https://github.com/microsoft/onnxruntime/blob/main/include/onnxruntime/core/session/\n     * onnxruntime_session_options_config_keys.h\n     *\n     * This setting is available only in WebAssembly backend. Will support Node.js binding and react-native later\n     *\n     * @example\n     * ```js\n     * extra: {\n     *   session: {\n     *     set_denormal_as_zero: \"1\",\n     *     disable_prepacking: \"1\"\n     *   },\n     *   optimization: {\n     *     enable_gelu_approximation: \"1\"\n     *   }\n     * }\n     * ```\n     */\n    extra?: Record<string, unknown>;\n  }\n\n  // #region execution providers\n\n  // Currently, we have the following backends to support execution providers:\n  // Backend Node.js binding: supports 'cpu', 'dml' (win32), 'coreml' (macOS) and 'cuda' (linux).\n  // Backend WebAssembly: supports 'cpu', 'wasm', 'webgpu' and 'webnn'.\n  // Backend ONNX.js: supports 'webgl'.\n  // Backend React Native: supports 'cpu', 'xnnpack', 'coreml' (iOS), 'nnapi' (Android).\n  interface ExecutionProviderOptionMap {\n    coreml: CoreMLExecutionProviderOption;\n    cpu: CpuExecutionProviderOption;\n    cuda: CudaExecutionProviderOption;\n    dml: DmlExecutionProviderOption;\n    nnapi: NnapiExecutionProviderOption;\n    tensorrt: TensorRtExecutionProviderOption;\n    wasm: WebAssemblyExecutionProviderOption;\n    webgl: WebGLExecutionProviderOption;\n    webgpu: WebGpuExecutionProviderOption;\n    webnn: WebNNExecutionProviderOption;\n    qnn: QnnExecutionProviderOption;\n    xnnpack: XnnpackExecutionProviderOption;\n  }\n\n  type ExecutionProviderName = keyof ExecutionProviderOptionMap;\n  type ExecutionProviderConfig =\n    | ExecutionProviderOptionMap[ExecutionProviderName]\n    | ExecutionProviderOption\n    | ExecutionProviderName\n    | string;\n\n  export interface ExecutionProviderOption {\n    readonly name: string;\n  }\n  export interface CpuExecutionProviderOption extends ExecutionProviderOption {\n    readonly name: 'cpu';\n    useArena?: boolean;\n  }\n  export interface CudaExecutionProviderOption extends ExecutionProviderOption {\n    readonly name: 'cuda';\n    deviceId?: number;\n  }\n  export interface DmlExecutionProviderOption extends ExecutionProviderOption {\n    readonly name: 'dml';\n    deviceId?: number;\n  }\n  export interface TensorRtExecutionProviderOption extends ExecutionProviderOption {\n    readonly name: 'tensorrt';\n    deviceId?: number;\n  }\n  export interface WebAssemblyExecutionProviderOption extends ExecutionProviderOption {\n    readonly name: 'wasm';\n  }\n  export interface WebGLExecutionProviderOption extends ExecutionProviderOption {\n    readonly name: 'webgl';\n    // TODO: add flags\n  }\n  export interface XnnpackExecutionProviderOption extends ExecutionProviderOption {\n    readonly name: 'xnnpack';\n  }\n  export interface WebGpuExecutionProviderOption extends ExecutionProviderOption {\n    readonly name: 'webgpu';\n    preferredLayout?: 'NCHW' | 'NHWC';\n  }\n\n  // #region WebNN options\n\n  interface WebNNExecutionProviderName extends ExecutionProviderOption {\n    readonly name: 'webnn';\n  }\n\n  /**\n   * Represents a set of options for creating a WebNN MLContext.\n   *\n   * @see https://www.w3.org/TR/webnn/#dictdef-mlcontextoptions\n   */\n  export interface WebNNContextOptions {\n    deviceType?: 'cpu' | 'gpu' | 'npu';\n    numThreads?: number;\n    powerPreference?: 'default' | 'low-power' | 'high-performance';\n  }\n\n  /**\n   * Represents a set of options for WebNN execution provider without MLContext.\n   */\n  export interface WebNNOptionsWithoutMLContext extends WebNNExecutionProviderName, WebNNContextOptions {\n    context?: never;\n  }\n\n  /**\n   * Represents a set of options for WebNN execution provider with MLContext.\n   *\n   * When MLContext is provided, the deviceType is also required so that the WebNN EP can determine the preferred\n   * channel layout.\n   *\n   * @see https://www.w3.org/TR/webnn/#dom-ml-createcontext\n   */\n  export interface WebNNOptionsWithMLContext\n    extends WebNNExecutionProviderName,\n      Omit<WebNNContextOptions, 'deviceType'>,\n      Required<Pick<WebNNContextOptions, 'deviceType'>> {\n    context: TryGetGlobalType<'MLContext'>;\n  }\n\n  /**\n   * Represents a set of options for WebNN execution provider with MLContext which is created from GPUDevice.\n   *\n   * @see https://www.w3.org/TR/webnn/#dom-ml-createcontext-gpudevice\n   */\n  export interface WebNNOptionsWebGpu extends WebNNExecutionProviderName {\n    context: TryGetGlobalType<'MLContext'>;\n    gpuDevice: TryGetGlobalType<'GPUDevice'>;\n  }\n\n  /**\n   * Options for WebNN execution provider.\n   */\n  export type WebNNExecutionProviderOption =\n    | WebNNOptionsWithoutMLContext\n    | WebNNOptionsWithMLContext\n    | WebNNOptionsWebGpu;\n\n  // #endregion\n\n  export interface QnnExecutionProviderOption extends ExecutionProviderOption {\n    readonly name: 'qnn';\n    /**\n     * Specify a path to the QnnHtp.dll file.\n     *\n     * @default 'QnnHtp.dll'\n     */\n    backendPath?: string;\n    /**\n     * Specify whether to enable HTP FP16 precision.\n     *\n     * @default true\n     */\n    enableFp16Precision?: boolean;\n  }\n  export interface CoreMLExecutionProviderOption extends ExecutionProviderOption {\n    readonly name: 'coreml';\n    /**\n     * The bit flags for CoreML execution provider.\n     *\n     * ```\n     * COREML_FLAG_USE_CPU_ONLY = 0x001\n     * COREML_FLAG_ENABLE_ON_SUBGRAPH = 0x002\n     * COREML_FLAG_ONLY_ENABLE_DEVICE_WITH_ANE = 0x004\n     * COREML_FLAG_ONLY_ALLOW_STATIC_INPUT_SHAPES = 0x008\n     * COREML_FLAG_CREATE_MLPROGRAM = 0x010\n     * COREML_FLAG_USE_CPU_AND_GPU = 0x020\n     * ```\n     *\n     * See include/onnxruntime/core/providers/coreml/coreml_provider_factory.h for more details.\n     *\n     * This flag is available only in ONNXRuntime (Node.js binding).\n     */\n    coreMlFlags?: number;\n    /**\n     * Specify whether to use CPU only in CoreML EP.\n     *\n     * This setting is available only in ONNXRuntime (react-native).\n     */\n    useCPUOnly?: boolean;\n    useCPUAndGPU?: boolean;\n    /**\n     * Specify whether to enable CoreML EP on subgraph.\n     *\n     * This setting is available only in ONNXRuntime (react-native).\n     */\n    enableOnSubgraph?: boolean;\n    /**\n     * Specify whether to only enable CoreML EP for Apple devices with ANE (Apple Neural Engine).\n     *\n     * This setting is available only in ONNXRuntime (react-native).\n     */\n    onlyEnableDeviceWithANE?: boolean;\n  }\n  export interface NnapiExecutionProviderOption extends ExecutionProviderOption {\n    readonly name: 'nnapi';\n    useFP16?: boolean;\n    useNCHW?: boolean;\n    cpuDisabled?: boolean;\n    cpuOnly?: boolean;\n  }\n  // #endregion\n\n  // #endregion\n\n  // #region run options\n\n  /**\n   * A set of configurations for inference run behavior\n   */\n  export interface RunOptions {\n    /**\n     * Log severity level. See\n     * https://github.com/microsoft/onnxruntime/blob/main/include/onnxruntime/core/common/logging/severity.h\n     *\n     * This setting is available only in ONNXRuntime (Node.js binding and react-native) or WebAssembly backend\n     */\n    logSeverityLevel?: 0 | 1 | 2 | 3 | 4;\n\n    /**\n     * Log verbosity level.\n     *\n     * This setting is available only in WebAssembly backend. Will support Node.js binding and react-native later\n     */\n    logVerbosityLevel?: number;\n\n    /**\n     * Terminate all incomplete OrtRun calls as soon as possible if true\n     *\n     * This setting is available only in WebAssembly backend. Will support Node.js binding and react-native later\n     */\n    terminate?: boolean;\n\n    /**\n     * A tag for the Run() calls using this\n     *\n     * This setting is available only in ONNXRuntime (Node.js binding and react-native) or WebAssembly backend\n     */\n    tag?: string;\n\n    /**\n     * Set a single run configuration entry. See\n     * https://github.com/microsoft/onnxruntime/blob/main/include/onnxruntime/core/session/\n     * onnxruntime_run_options_config_keys.h\n     *\n     * This setting is available only in WebAssembly backend. Will support Node.js binding and react-native later\n     *\n     * @example\n     *\n     * ```js\n     * extra: {\n     *   memory: {\n     *     enable_memory_arena_shrinkage: \"1\",\n     *   }\n     * }\n     * ```\n     */\n    extra?: Record<string, unknown>;\n  }\n\n  // #endregion\n\n  // #region value metadata\n\n  // eslint-disable-next-line @typescript-eslint/no-empty-interface\n  interface ValueMetadata {\n    // TBD\n  }\n\n  // #endregion\n}\n\n/**\n * Represent a runtime instance of an ONNX model.\n */\nexport interface InferenceSession {\n  // #region run()\n\n  /**\n   * Execute the model asynchronously with the given feeds and options.\n   *\n   * @param feeds - Representation of the model input. See type description of `InferenceSession.InputType` for detail.\n   * @param options - Optional. A set of options that controls the behavior of model inference.\n   * @returns A promise that resolves to a map, which uses output names as keys and OnnxValue as corresponding values.\n   */\n  run(feeds: InferenceSession.FeedsType, options?: InferenceSession.RunOptions): Promise<InferenceSession.ReturnType>;\n\n  /**\n   * Execute the model asynchronously with the given feeds, fetches and options.\n   *\n   * @param feeds - Representation of the model input. See type description of `InferenceSession.InputType` for detail.\n   * @param fetches - Representation of the model output. See type description of `InferenceSession.OutputType` for\n   * detail.\n   * @param options - Optional. A set of options that controls the behavior of model inference.\n   * @returns A promise that resolves to a map, which uses output names as keys and OnnxValue as corresponding values.\n   */\n  run(\n    feeds: InferenceSession.FeedsType,\n    fetches: InferenceSession.FetchesType,\n    options?: InferenceSession.RunOptions,\n  ): Promise<InferenceSession.ReturnType>;\n\n  // #endregion\n\n  // #region release()\n\n  /**\n   * Release the inference session and the underlying resources.\n   */\n  release(): Promise<void>;\n\n  // #endregion\n\n  // #region profiling\n\n  /**\n   * Start profiling.\n   */\n  startProfiling(): void;\n\n  /**\n   * End profiling.\n   */\n  endProfiling(): void;\n\n  // #endregion\n\n  // #region metadata\n\n  /**\n   * Get input names of the loaded model.\n   */\n  readonly inputNames: readonly string[];\n\n  /**\n   * Get output names of the loaded model.\n   */\n  readonly outputNames: readonly string[];\n\n  // /**\n  //  * Get input metadata of the loaded model.\n  //  */\n  // readonly inputMetadata: ReadonlyArray<Readonly<InferenceSession.ValueMetadata>>;\n\n  // /**\n  //  * Get output metadata of the loaded model.\n  //  */\n  // readonly outputMetadata: ReadonlyArray<Readonly<InferenceSession.ValueMetadata>>;\n\n  // #endregion\n}\n\nexport interface InferenceSessionFactory {\n  // #region create()\n\n  /**\n   * Create a new inference session and load model asynchronously from an ONNX model file.\n   *\n   * @param uri - The URI or file path of the model to load.\n   * @param options - specify configuration for creating a new inference session.\n   * @returns A promise that resolves to an InferenceSession object.\n   */\n  create(uri: string, options?: InferenceSession.SessionOptions): Promise<InferenceSession>;\n\n  /**\n   * Create a new inference session and load model asynchronously from an array bufer.\n   *\n   * @param buffer - An ArrayBuffer representation of an ONNX model.\n   * @param options - specify configuration for creating a new inference session.\n   * @returns A promise that resolves to an InferenceSession object.\n   */\n  create(buffer: ArrayBufferLike, options?: InferenceSession.SessionOptions): Promise<InferenceSession>;\n\n  /**\n   * Create a new inference session and load model asynchronously from segment of an array bufer.\n   *\n   * @param buffer - An ArrayBuffer representation of an ONNX model.\n   * @param byteOffset - The beginning of the specified portion of the array buffer.\n   * @param byteLength - The length in bytes of the array buffer.\n   * @param options - specify configuration for creating a new inference session.\n   * @returns A promise that resolves to an InferenceSession object.\n   */\n  create(\n    buffer: ArrayBufferLike,\n    byteOffset: number,\n    byteLength?: number,\n    options?: InferenceSession.SessionOptions,\n  ): Promise<InferenceSession>;\n\n  /**\n   * Create a new inference session and load model asynchronously from a Uint8Array.\n   *\n   * @param buffer - A Uint8Array representation of an ONNX model.\n   * @param options - specify configuration for creating a new inference session.\n   * @returns A promise that resolves to an InferenceSession object.\n   */\n  create(buffer: Uint8Array, options?: InferenceSession.SessionOptions): Promise<InferenceSession>;\n\n  // #endregion\n}\n\n// eslint-disable-next-line @typescript-eslint/naming-convention\nexport const InferenceSession: InferenceSessionFactory = InferenceSessionImpl;\n","// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport { OptionsFormat, OptionsNormalizationParameters, OptionsTensorLayout } from './tensor-factory.js';\n\nexport interface TensorToDataUrlOptions extends OptionsTensorLayout, OptionsFormat, OptionsNormalizationParameters {}\n\nexport interface TensorToImageDataOptions extends OptionsTensorLayout, OptionsFormat, OptionsNormalizationParameters {}\n\nexport interface ConversionUtils {\n  /**\n   * creates a DataURL instance from tensor\n   *\n   * @param options - An optional object representing options for creating a DataURL instance from the tensor.\n   *\n   * The following default settings will be applied:\n   * - `format`: `'RGB'`\n   * - `tensorLayout`: `'NCHW'`\n   * @returns a DataURL string representing the image converted from tensor data\n   */\n  toDataURL(options?: TensorToDataUrlOptions): string;\n\n  /**\n   * creates an ImageData instance from tensor\n   *\n   * @param options - An optional object representing options for creating an ImageData instance from the tensor.\n   *\n   * The following default settings will be applied:\n   * - `format`: `'RGB'`\n   * - `tensorLayout`: `'NCHW'`\n   * @returns an ImageData instance representing the image converted from tensor data\n   */\n  toImageData(options?: TensorToImageDataOptions): ImageData;\n}\n","// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport { Tensor, TypedTensor } from './tensor.js';\n\nexport type ImageFormat = 'RGB' | 'RGBA' | 'BGR' | 'RBG';\nexport type ImageTensorLayout = 'NHWC' | 'NCHW';\n\n// the following region contains type definitions for constructing tensor from a specific location.\n\n// #region types for constructing a tensor from a specific location\n\n/**\n * represent common properties of the parameter for constructing a tensor from a specific location.\n */\ninterface CommonConstructorParameters<T> extends Pick<Tensor, 'dims'> {\n  /**\n   * Specify the data type of the tensor.\n   */\n  readonly type: T;\n}\n\n/**\n * represent the parameter for constructing a tensor from a GPU resource.\n */\ninterface GpuResourceConstructorParameters<T extends Tensor.Type> {\n  /**\n   * an optional callback function to download data from GPU to CPU.\n   *\n   * If not provided, the tensor treat the GPU data as external resource.\n   */\n  download?(): Promise<Tensor.DataTypeMap[T]>;\n\n  /**\n   * an optional callback function that will be called when the tensor is disposed.\n   *\n   * If not provided, the tensor treat the GPU data as external resource.\n   */\n  dispose?(): void;\n}\n\n/**\n * represent the parameter for constructing a tensor from a pinned CPU buffer\n */\nexport interface CpuPinnedConstructorParameters<T extends Tensor.CpuPinnedDataTypes = Tensor.CpuPinnedDataTypes>\n  extends CommonConstructorParameters<T> {\n  /**\n   * Specify the location of the data to be 'cpu-pinned'.\n   */\n  readonly location: 'cpu-pinned';\n  /**\n   * Specify the CPU pinned buffer that holds the tensor data.\n   */\n  readonly data: Tensor.DataTypeMap[T];\n}\n\n/**\n * represent the parameter for constructing a tensor from a WebGL texture\n */\nexport interface TextureConstructorParameters<T extends Tensor.TextureDataTypes = Tensor.TextureDataTypes>\n  extends CommonConstructorParameters<T>,\n    GpuResourceConstructorParameters<T> {\n  /**\n   * Specify the location of the data to be 'texture'.\n   */\n  readonly location: 'texture';\n  /**\n   * Specify the WebGL texture that holds the tensor data.\n   */\n  readonly texture: Tensor.TextureType;\n}\n\n/**\n * represent the parameter for constructing a tensor from a WebGPU buffer\n */\nexport interface GpuBufferConstructorParameters<T extends Tensor.GpuBufferDataTypes = Tensor.GpuBufferDataTypes>\n  extends CommonConstructorParameters<T>,\n    GpuResourceConstructorParameters<T> {\n  /**\n   * Specify the location of the data to be 'gpu-buffer'.\n   */\n  readonly location: 'gpu-buffer';\n  /**\n   * Specify the WebGPU buffer that holds the tensor data.\n   */\n  readonly gpuBuffer: Tensor.GpuBufferType;\n}\n\nexport interface MLTensorConstructorParameters<T extends Tensor.MLTensorDataTypes = Tensor.MLTensorDataTypes>\n  extends CommonConstructorParameters<T>,\n    GpuResourceConstructorParameters<T> {\n  /**\n   * Specify the location of the data to be 'ml-tensor'.\n   */\n  readonly location: 'ml-tensor';\n\n  /**\n   * Specify the WebNN MLTensor that holds the tensor data.\n   */\n  readonly mlTensor: Tensor.MLTensorType;\n}\n\n// #endregion\n\n// the following region contains type definitions of each individual options.\n// the tensor factory functions use a composition of those options as the parameter type.\n\n// #region Options fields\n\nexport interface OptionsFormat {\n  /**\n   * Describes the image format represented in RGBA color space.\n   */\n  format?: ImageFormat;\n}\n\nexport interface OptionsTensorFormat {\n  /**\n   * Describes the image format of the tensor.\n   *\n   * NOTE: this is different from option 'format'. While option 'format' represents the original image, 'tensorFormat'\n   * represents the target format of the tensor. A transpose will be performed if they are different.\n   */\n  tensorFormat?: ImageFormat;\n}\n\nexport interface OptionsTensorDataType {\n  /**\n   * Describes the data type of the tensor.\n   */\n  dataType?: 'float32' | 'uint8';\n}\n\nexport interface OptionsTensorLayout {\n  /**\n   * Describes the tensor layout when representing data of one or more image(s).\n   */\n  tensorLayout?: ImageTensorLayout;\n}\n\nexport interface OptionsDimensions {\n  /**\n   * Describes the image height in pixel\n   */\n  height?: number;\n  /**\n   * Describes the image width in pixel\n   */\n  width?: number;\n}\n\nexport interface OptionResizedDimensions {\n  /**\n   * Describes the resized height. If omitted, original height will be used.\n   */\n  resizedHeight?: number;\n  /**\n   * Describes resized width - can be accessed via tensor dimensions as well\n   */\n  resizedWidth?: number;\n}\n\nexport interface OptionsNormalizationParameters {\n  /**\n   * Describes normalization parameters when preprocessing the image as model input.\n   *\n   * Data element are ranged from 0 to 255.\n   */\n  norm?: {\n    /**\n     * The 'bias' value for image normalization.\n     * - If omitted, use default value 0.\n     * - If it's a single number, apply to each channel\n     * - If it's an array of 3 or 4 numbers, apply element-wise. Number of elements need to match the number of channels\n     * for the corresponding image format\n     */\n    bias?: number | [number, number, number] | [number, number, number, number];\n    /**\n     * The 'mean' value for image normalization.\n     * - If omitted, use default value 255.\n     * - If it's a single number, apply to each channel\n     * - If it's an array of 3 or 4 numbers, apply element-wise. Number of elements need to match the number of channels\n     * for the corresponding image format\n     */\n    mean?: number | [number, number, number] | [number, number, number, number];\n  };\n}\n\n// #endregion\n\n// #region Options composition\n\nexport interface TensorFromImageDataOptions\n  extends OptionResizedDimensions,\n    OptionsTensorFormat,\n    OptionsTensorLayout,\n    OptionsTensorDataType,\n    OptionsNormalizationParameters {}\n\nexport interface TensorFromImageElementOptions\n  extends OptionResizedDimensions,\n    OptionsTensorFormat,\n    OptionsTensorLayout,\n    OptionsTensorDataType,\n    OptionsNormalizationParameters {}\n\nexport interface TensorFromUrlOptions\n  extends OptionsDimensions,\n    OptionResizedDimensions,\n    OptionsTensorFormat,\n    OptionsTensorLayout,\n    OptionsTensorDataType,\n    OptionsNormalizationParameters {}\n\nexport interface TensorFromImageBitmapOptions\n  extends OptionResizedDimensions,\n    OptionsTensorFormat,\n    OptionsTensorLayout,\n    OptionsTensorDataType,\n    OptionsNormalizationParameters {}\n\nexport interface TensorFromTextureOptions<T extends Tensor.TextureDataTypes>\n  extends Required<OptionsDimensions>,\n    OptionsFormat,\n    GpuResourceConstructorParameters<T> /* TODO: add more */ {}\n\nexport interface TensorFromGpuBufferOptions<T extends Tensor.GpuBufferDataTypes>\n  extends Pick<Tensor, 'dims'>,\n    GpuResourceConstructorParameters<T> {\n  /**\n   * Describes the data type of the tensor.\n   */\n  dataType?: T;\n}\n\nexport interface TensorFromMLTensorOptions<T extends Tensor.MLTensorDataTypes>\n  extends Pick<Tensor, 'dims'>,\n    GpuResourceConstructorParameters<T> {\n  /**\n   * Describes the data type of the tensor.\n   */\n  dataType?: T;\n}\n\n// #endregion\n\n/**\n * type TensorFactory defines the factory functions of 'Tensor' to create tensor instances from existing data or\n * resources.\n */\nexport interface TensorFactory {\n  /**\n   * create a tensor from an ImageData object\n   *\n   * @param imageData - the ImageData object to create tensor from\n   * @param options - An optional object representing options for creating tensor from ImageData.\n   *\n   * The following default settings will be applied:\n   * - `tensorFormat`: `'RGB'`\n   * - `tensorLayout`: `'NCHW'`\n   * - `dataType`: `'float32'`\n   * @returns A promise that resolves to a tensor object\n   */\n  fromImage(\n    imageData: ImageData,\n    options?: TensorFromImageDataOptions,\n  ): Promise<TypedTensor<'float32'> | TypedTensor<'uint8'>>;\n\n  /**\n   * create a tensor from a HTMLImageElement object\n   *\n   * @param imageElement - the HTMLImageElement object to create tensor from\n   * @param options - An optional object representing options for creating tensor from HTMLImageElement.\n   *\n   * The following default settings will be applied:\n   * - `tensorFormat`: `'RGB'`\n   * - `tensorLayout`: `'NCHW'`\n   * - `dataType`: `'float32'`\n   * @returns A promise that resolves to a tensor object\n   */\n  fromImage(\n    imageElement: HTMLImageElement,\n    options?: TensorFromImageElementOptions,\n  ): Promise<TypedTensor<'float32'> | TypedTensor<'uint8'>>;\n\n  /**\n   * create a tensor from URL\n   *\n   * @param urlSource - a string as a URL to the image or a data URL containing the image data.\n   * @param options - An optional object representing options for creating tensor from URL.\n   *\n   * The following default settings will be applied:\n   * - `tensorFormat`: `'RGB'`\n   * - `tensorLayout`: `'NCHW'`\n   * - `dataType`: `'float32'`\n   * @returns A promise that resolves to a tensor object\n   */\n  fromImage(urlSource: string, options?: TensorFromUrlOptions): Promise<TypedTensor<'float32'> | TypedTensor<'uint8'>>;\n\n  /**\n   * create a tensor from an ImageBitmap object\n   *\n   * @param bitmap - the ImageBitmap object to create tensor from\n   * @param options - An optional object representing options for creating tensor from URL.\n   *\n   * The following default settings will be applied:\n   * - `tensorFormat`: `'RGB'`\n   * - `tensorLayout`: `'NCHW'`\n   * - `dataType`: `'float32'`\n   * @returns A promise that resolves to a tensor object\n   */\n  fromImage(\n    bitmap: ImageBitmap,\n    options: TensorFromImageBitmapOptions,\n  ): Promise<TypedTensor<'float32'> | TypedTensor<'uint8'>>;\n\n  /**\n   * create a tensor from a WebGL texture\n   *\n   * @param texture - the WebGLTexture object to create tensor from\n   * @param options - An optional object representing options for creating tensor from WebGL texture.\n   *\n   * The options include following properties:\n   * - `width`: the width of the texture. Required.\n   * - `height`: the height of the texture. Required.\n   * - `format`: the format of the texture. If omitted, assume 'RGBA'.\n   * - `download`: an optional function to download the tensor data from GPU to CPU. If omitted, the GPU data\n   * will not be able to download. Usually, this is provided by a GPU backend for the inference outputs. Users don't\n   * need to provide this function.\n   * - `dispose`: an optional function to dispose the tensor data on GPU. If omitted, the GPU data will not be disposed.\n   * Usually, this is provided by a GPU backend for the inference outputs. Users don't need to provide this function.\n   *\n   * @returns a tensor object\n   */\n  fromTexture<T extends Tensor.TextureDataTypes = 'float32'>(\n    texture: Tensor.TextureType,\n    options: TensorFromTextureOptions<T>,\n  ): TypedTensor<'float32'>;\n\n  /**\n   * create a tensor from a WebGPU buffer\n   *\n   * @param buffer - the GPUBuffer object to create tensor from\n   * @param options - An optional object representing options for creating tensor from WebGPU buffer.\n   *\n   * The options include following properties:\n   * - `dataType`: the data type of the tensor. If omitted, assume 'float32'.\n   * - `dims`: the dimension of the tensor. Required.\n   * - `download`: an optional function to download the tensor data from GPU to CPU. If omitted, the GPU data\n   * will not be able to download. Usually, this is provided by a GPU backend for the inference outputs. Users don't\n   * need to provide this function.\n   * - `dispose`: an optional function to dispose the tensor data on GPU. If omitted, the GPU data will not be disposed.\n   * Usually, this is provided by a GPU backend for the inference outputs. Users don't need to provide this function.\n   *\n   * @returns a tensor object\n   */\n  fromGpuBuffer<T extends Tensor.GpuBufferDataTypes>(\n    buffer: Tensor.GpuBufferType,\n    options: TensorFromGpuBufferOptions<T>,\n  ): TypedTensor<T>;\n\n  /**\n   * create a tensor from a WebNN MLTensor\n   *\n   * @param tensor - the MLTensor object to create tensor from\n   * @param options - An optional object representing options for creating tensor from a WebNN MLTensor.\n   *\n   * The options include following properties:\n   * - `dataType`: the data type of the tensor. If omitted, assume 'float32'.\n   * - `dims`: the dimension of the tensor. Required.\n   * - `download`: an optional function to download the tensor data from the MLTensor to CPU. If omitted, the MLTensor\n   * data will not be able to download. Usually, this is provided by the WebNN backend for the inference outputs.\n   * Users don't need to provide this function.\n   * - `dispose`: an optional function to dispose the tensor data on the WebNN MLTensor. If omitted, the MLTensor will\n   * not be disposed. Usually, this is provided by the WebNN backend for the inference outputs. Users don't need to\n   * provide this function.\n   *\n   * @returns a tensor object\n   */\n  fromMLTensor<T extends Tensor.MLTensorDataTypes>(\n    tensor: Tensor.MLTensorType,\n    options: TensorFromMLTensorOptions<T>,\n  ): TypedTensor<T>;\n\n  /**\n   * create a tensor from a pre-allocated buffer. The buffer will be used as a pinned buffer.\n   *\n   * @param type - the tensor element type.\n   * @param buffer - a TypedArray corresponding to the type.\n   * @param dims - specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\n   *\n   * @returns a tensor object\n   */\n  fromPinnedBuffer<T extends Exclude<Tensor.Type, 'string'>>(\n    type: T,\n    buffer: Tensor.DataTypeMap[T],\n    dims?: readonly number[],\n  ): TypedTensor<T>;\n}\n","// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\n/**\n * A string that represents a file's URL or path.\n *\n * Path is vailable only in onnxruntime-node or onnxruntime-web running in Node.js.\n */\nexport type FileUrlOrPath = string;\n\n/**\n * A Blob object that represents a file.\n */\nexport type FileBlob = Blob;\n\n/**\n * A Uint8Array, ArrayBuffer or SharedArrayBuffer object that represents a file content.\n *\n * When it is an ArrayBuffer or SharedArrayBuffer, the whole buffer is assumed to be the file content.\n */\nexport type FileData = Uint8Array | ArrayBufferLike;\n\n/**\n * Represents a file that can be loaded by the ONNX Runtime JavaScript API.\n */\nexport type FileType = FileUrlOrPath | FileBlob | FileData;\n\n/**\n * Represents an external data file.\n */\nexport interface ExternalDataFileDescription {\n  /**\n   * Specify the external data file.\n   */\n  data: FileType;\n  /**\n   * Specify the file path.\n   */\n  path: string;\n}\n\n/**\n * Represents an external data file.\n *\n * When using a string, it should be a file URL or path that in the same directory as the model file.\n */\nexport type ExternalDataFileType = ExternalDataFileDescription | FileUrlOrPath;\n\n/**\n * Options for model loading.\n */\nexport interface OnnxModelOptions {\n  /**\n   * Specifying a list of files that represents the external data.\n   */\n  externalData?: readonly ExternalDataFileType[];\n}\n","// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport { Tensor } from './tensor.js';\n\nexport type NonTensorType = never;\n\n/**\n * Type OnnxValue Represents both tensors and non-tensors value for model's inputs/outputs.\n *\n * NOTE: currently not support non-tensor\n */\nexport type OnnxValue = Tensor | NonTensorType;\n\n/**\n * Type OnnxValueDataLocation represents the location of the data of an OnnxValue.\n */\nexport type OnnxValueDataLocation = Tensor.DataLocation;\n","// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\n/**\n * # ONNX Runtime JavaScript API\n *\n * ONNX Runtime JavaScript API is a unified API for all JavaScript usages, including the following NPM packages:\n *\n * - [onnxruntime-node](https://www.npmjs.com/package/onnxruntime-node)\n * - [onnxruntime-web](https://www.npmjs.com/package/onnxruntime-web)\n * - [onnxruntime-react-native](https://www.npmjs.com/package/onnxruntime-react-native)\n *\n * See also:\n * - [Get Started](https://onnxruntime.ai/docs/get-started/with-javascript/)\n * - [Inference examples](https://github.com/microsoft/onnxruntime-inference-examples/tree/main/js)\n *\n * @packageDocumentation\n */\n\nexport * from './backend.js';\nexport * from './env.js';\nexport * from './inference-session.js';\nexport * from './tensor.js';\nexport * from './tensor-conversion.js';\nexport * from './tensor-factory.js';\nexport * from './trace.js';\nexport * from './onnx-model.js';\nexport * from './onnx-value.js';\n","// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nexport const isNode = !!(typeof process !== 'undefined' && process.versions && process.versions.node);\n","// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\n/// <reference lib=\"webworker\" />\n\n//\n// * type hack for \"HTMLImageElement\"\n//\n// in typescript, the type of \"HTMLImageElement\" is defined in lib.dom.d.ts, which is conflict with lib.webworker.d.ts.\n// when we use webworker, the lib.webworker.d.ts will be used, which does not have HTMLImageElement defined.\n//\n// we will get the following errors complaining that HTMLImageElement is not defined:\n//\n// ====================================================================================================================\n//\n// ../common/dist/cjs/tensor-factory.d.ts:187:29 - error TS2552: Cannot find name 'HTMLImageElement'. Did you mean\n// 'HTMLLIElement'?\n//\n// 187     fromImage(imageElement: HTMLImageElement, options?: TensorFromImageElementOptions):\n// Promise<TypedTensor<'float32'> | TypedTensor<'uint8'>>;\n//                                 ~~~~~~~~~~~~~~~~\n//\n// node_modules/@webgpu/types/dist/index.d.ts:83:7 - error TS2552: Cannot find name 'HTMLImageElement'. Did you mean\n// 'HTMLLIElement'?\n//\n// 83     | HTMLImageElement\n//          ~~~~~~~~~~~~~~~~\n//\n// ====================================================================================================================\n//\n// `HTMLImageElement` is only used in type declaration and not in real code. So we define it as `unknown` here to\n// bypass the type check.\n\n//\n// * type hack for \"document\"\n//\n// in typescript, the type of \"document\" is defined in lib.dom.d.ts, so it's not available in webworker.\n//\n// we will get the following errors complaining that document is not defined:\n//\n// ====================================================================================================================\n//\n// lib/wasm/wasm-utils-import.ts:7:33 - error TS2584: Cannot find name 'document'. Do you need to change your target\n// library? Try changing the 'lib' compiler option to include 'dom'.\n//\n// 7 export const scriptSrc = typeof document !== 'undefined' ? (document?.currentScript as HTMLScriptElement)?.src :\n//                                   ~~~~~~~~\n//\n// lib/wasm/wasm-utils-import.ts:7:61 - error TS2584: Cannot find name 'document'. Do you need to change your target\n// library? Try changing the 'lib' compiler option to include 'dom'.\n//\n// 7 export const scriptSrc = typeof document !== 'undefined' ? (document?.currentScript as HTMLScriptElement)?.src :\n//                                                               ~~~~~~~~\n//\n// lib/wasm/wasm-utils-import.ts:7:88 - error TS2552: Cannot find name 'HTMLScriptElement'. Did you mean\n// 'HTMLLIElement'?\n//\n// 7 export const scriptSrc = typeof document !== 'undefined' ? (document?.currentScript as HTMLScriptElement)?.src :\n//                                                                                          ~~~~~~~~~~~~~~~~~\n// ====================================================================================================================\n//\n// `document` is used to get the current script URL, which is not available in webworker. This file is served as a\n// \"dual\" file for entries of both webworker and the esm module.\n//\ndeclare global {\n  type HTMLImageElement = unknown;\n  type HTMLScriptElement = { src?: string };\n  const document: undefined | { currentScript?: HTMLScriptElement };\n}\n\n/**\n * @summary\n *\n * This file is served as a \"dual\" file for both entries of the following:\n * - The proxy worker itself.\n *   - When used as a worker, it listens to the messages from the main thread and performs the corresponding operations.\n *   - Should be imported directly using `new Worker()` in the main thread.\n *\n * - The ESM module that creates the proxy worker (as a worker launcher).\n *   - When used as a worker launcher, it creates the proxy worker and returns it.\n *   - Should be imported using `import()` in the main thread, with the query parameter `import=1`.\n *\n * This file will be always compiling into ESM format.\n */\n\nimport type { OrtWasmMessage, SerializableTensorMetadata } from '../proxy-messages.js';\nimport {\n  createSession,\n  copyFromExternalBuffer,\n  endProfiling,\n  extractTransferableBuffers,\n  initEp,\n  initRuntime,\n  releaseSession,\n  run,\n} from '../wasm-core-impl.js';\nimport { initializeWebAssembly } from '../wasm-factory.js';\nimport { scriptSrc } from '../wasm-utils-import.js';\n\nconst WORKER_NAME = 'ort-wasm-proxy-worker';\nconst isProxyWorker = globalThis.self?.name === WORKER_NAME;\n\nif (isProxyWorker) {\n  // Worker thread\n  self.onmessage = (ev: MessageEvent<OrtWasmMessage>): void => {\n    const { type, in: message } = ev.data;\n    try {\n      switch (type) {\n        case 'init-wasm':\n          initializeWebAssembly(message!.wasm).then(\n            () => {\n              initRuntime(message!).then(\n                () => {\n                  postMessage({ type });\n                },\n                (err) => {\n                  postMessage({ type, err });\n                },\n              );\n            },\n            (err) => {\n              postMessage({ type, err });\n            },\n          );\n          break;\n        case 'init-ep': {\n          const { epName, env } = message!;\n          initEp(env, epName).then(\n            () => {\n              postMessage({ type });\n            },\n            (err) => {\n              postMessage({ type, err });\n            },\n          );\n          break;\n        }\n        case 'copy-from': {\n          const { buffer } = message!;\n          const bufferData = copyFromExternalBuffer(buffer);\n          postMessage({ type, out: bufferData } as OrtWasmMessage);\n          break;\n        }\n        case 'create': {\n          const { model, options } = message!;\n          createSession(model, options).then(\n            (sessionMetadata) => {\n              postMessage({ type, out: sessionMetadata } as OrtWasmMessage);\n            },\n            (err) => {\n              postMessage({ type, err });\n            },\n          );\n          break;\n        }\n        case 'release':\n          releaseSession(message!);\n          postMessage({ type });\n          break;\n        case 'run': {\n          const { sessionId, inputIndices, inputs, outputIndices, options } = message!;\n          run(sessionId, inputIndices, inputs, outputIndices, new Array(outputIndices.length).fill(null), options).then(\n            (outputs) => {\n              if (outputs.some((o) => o[3] !== 'cpu')) {\n                postMessage({ type, err: 'Proxy does not support non-cpu tensor location.' });\n              } else {\n                postMessage(\n                  { type, out: outputs } as OrtWasmMessage,\n                  extractTransferableBuffers([...inputs, ...outputs] as SerializableTensorMetadata[]),\n                );\n              }\n            },\n            (err) => {\n              postMessage({ type, err });\n            },\n          );\n          break;\n        }\n        case 'end-profiling':\n          endProfiling(message!);\n          postMessage({ type });\n          break;\n        default:\n      }\n    } catch (err) {\n      postMessage({ type, err } as OrtWasmMessage);\n    }\n  };\n}\n\nexport default isProxyWorker\n  ? null\n  : (urlOverride?: string) =>\n      new Worker(urlOverride ?? scriptSrc!, { type: BUILD_DEFS.IS_ESM ? 'module' : 'classic', name: WORKER_NAME });\n","// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport type { OrtWasmModule } from './wasm-types';\nimport { isNode } from './wasm-utils-env';\n\n/**\n * The origin of the current location.\n *\n * In Node.js, this is undefined.\n */\nconst origin = isNode || typeof location === 'undefined' ? undefined : location.origin;\n\n/**\n * Some bundlers (eg. Webpack) will rewrite `import.meta.url` to a file URL at compile time.\n *\n * This function checks if `import.meta.url` starts with `file:`, but using the `>` and `<` operators instead of\n * `startsWith` function so that code minimizers can remove the dead code correctly.\n *\n * For example, if we use terser to minify the following code:\n * ```js\n * if (\"file://hard-coded-filename\".startsWith(\"file:\")) {\n *   console.log(1)\n * } else {\n *   console.log(2)\n * }\n *\n * if (\"file://hard-coded-filename\" > \"file:\" && \"file://hard-coded-filename\" < \"file;\") {\n *   console.log(3)\n * } else {\n *   console.log(4)\n * }\n * ```\n *\n * The minified code will be:\n * ```js\n * \"file://hard-coded-filename\".startsWith(\"file:\")?console.log(1):console.log(2),console.log(3);\n * ```\n *\n * (use Terser 5.39.0 with default options, https://try.terser.org/)\n *\n * @returns true if the import.meta.url is hardcoded as a file URI.\n */\nexport const isEsmImportMetaUrlHardcodedAsFileUri =\n  BUILD_DEFS.IS_ESM && BUILD_DEFS.ESM_IMPORT_META_URL! > 'file:' && BUILD_DEFS.ESM_IMPORT_META_URL! < 'file;';\n\nconst getScriptSrc = (): string | undefined => {\n  // if Nodejs, return undefined\n  if (isNode) {\n    return undefined;\n  }\n  // if It's ESM, use import.meta.url\n  if (BUILD_DEFS.IS_ESM) {\n    // For ESM, if the import.meta.url is a file URL, this usually means the bundler rewrites `import.meta.url` to\n    // the file path at compile time. In this case, this file path cannot be used to determine the runtime URL.\n    //\n    // We need to use the URL constructor like this:\n    // ```js\n    // new URL('actual-bundle-name.js', import.meta.url).href\n    // ```\n    // So that bundler can preprocess the URL correctly.\n    if (isEsmImportMetaUrlHardcodedAsFileUri) {\n      // if the rewritten URL is a relative path, we need to use the origin to resolve the URL.\n\n      // The following is a workaround for Vite.\n      //\n      // Vite uses a bundler(rollup/rolldown) that does not rewrite `import.meta.url` to a file URL. So in theory, this\n      // code path should not be executed in Vite. However, the bundler does not know it and it still try to load the\n      // following pattern:\n      // - `return new URL('filename', import.meta.url).href`\n      //\n      // By replacing the pattern above with the following code, we can skip the resource loading behavior:\n      // - `const URL2 = URL; return new URL2('filename', import.meta.url).href;`\n      //\n      // And it still works in Webpack.\n      const URL2 = URL;\n      return new URL(new URL2(BUILD_DEFS.BUNDLE_FILENAME, BUILD_DEFS.ESM_IMPORT_META_URL).href, origin).href;\n    }\n\n    return BUILD_DEFS.ESM_IMPORT_META_URL;\n  }\n\n  return typeof document !== 'undefined'\n    ? (document.currentScript as HTMLScriptElement)?.src\n    : // use `self.location.href` if available\n      typeof self !== 'undefined'\n      ? self.location?.href\n      : undefined;\n};\n\n/**\n * The classic script source URL. This is not always available in non ESModule environments.\n *\n * In Node.js, this is undefined.\n */\nexport const scriptSrc = getScriptSrc();\n\n/**\n * Infer the wasm path prefix from the script source URL.\n *\n * @returns The inferred wasm path prefix, or undefined if the script source URL is not available or is a blob URL.\n */\nexport const inferWasmPathPrefixFromScriptSrc = (): string | undefined => {\n  if (scriptSrc && !scriptSrc.startsWith('blob:')) {\n    return scriptSrc.substring(0, scriptSrc.lastIndexOf('/') + 1);\n  }\n  return undefined;\n};\n\n/**\n * Check if the given filename with prefix is from the same origin.\n */\nconst isSameOrigin = (filename: string, prefixOverride?: string) => {\n  try {\n    const baseUrl = prefixOverride ?? scriptSrc;\n    const url = baseUrl ? new URL(filename, baseUrl) : new URL(filename);\n    return url.origin === origin;\n  } catch {\n    return false;\n  }\n};\n\n/**\n * Normalize the inputs to an absolute URL with the given prefix override. If failed, return undefined.\n */\nconst normalizeUrl = (filename: string, prefixOverride?: string) => {\n  const baseUrl = prefixOverride ?? scriptSrc;\n  try {\n    const url = baseUrl ? new URL(filename, baseUrl) : new URL(filename);\n    return url.href;\n  } catch {\n    return undefined;\n  }\n};\n\n/**\n * Create a fallback URL if an absolute URL cannot be created by the normalizeUrl function.\n */\nconst fallbackUrl = (filename: string, prefixOverride?: string) => `${prefixOverride ?? './'}${filename}`;\n\n/**\n * This helper function is used to preload a module from a URL.\n *\n * If the origin of the worker URL is different from the current origin, the worker cannot be loaded directly.\n * See discussions in https://github.com/webpack-contrib/worker-loader/issues/154\n *\n * In this case, we will fetch the worker URL and create a new Blob URL with the same origin as a workaround.\n *\n * @param absoluteUrl - The absolute URL to preload.\n *\n * @returns - A promise that resolves to a new Blob URL\n */\nconst preload = async (absoluteUrl: string): Promise<string> => {\n  const response = await fetch(absoluteUrl, { credentials: 'same-origin' });\n  const blob = await response.blob();\n  return URL.createObjectURL(blob);\n};\n\n/**\n * This helper function is used to dynamically import a module from a URL.\n *\n * The build script has special handling for this function to ensure that the URL is not bundled into the final output.\n *\n * @param url - The URL to import.\n *\n * @returns - A promise that resolves to the default export of the module.\n */\nconst dynamicImportDefault = async <T>(url: string): Promise<T> =>\n  (await import(/* webpackIgnore: true */ url)).default;\n\n/**\n * The proxy worker factory imported from the proxy worker module.\n *\n * This is only available when the WebAssembly proxy is not disabled.\n */\nconst createProxyWorker: ((urlOverride?: string) => Worker) | undefined =\n  // eslint-disable-next-line @typescript-eslint/no-require-imports, @typescript-eslint/no-var-requires\n  BUILD_DEFS.DISABLE_WASM_PROXY ? undefined : require('./proxy-worker/main').default;\n\n/**\n * Import the proxy worker.\n *\n * This function will perform the following steps:\n * 1. If a preload is needed, it will preload the module and return the object URL.\n * 2. Use the proxy worker factory to create the proxy worker.\n *\n * @returns - A promise that resolves to a tuple of 2 elements:\n *            - The object URL of the preloaded module, or undefined if no preload is needed.\n *            - The proxy worker.\n */\nexport const importProxyWorker = async (): Promise<[undefined | string, Worker]> => {\n  if (!scriptSrc) {\n    throw new Error('Failed to load proxy worker: cannot determine the script source URL.');\n  }\n\n  // If the script source is from the same origin, we can use the embedded proxy module directly.\n  if (isSameOrigin(scriptSrc)) {\n    return [undefined, createProxyWorker!()];\n  }\n\n  // Otherwise, need to preload\n  const url = await preload(scriptSrc);\n  return [url, createProxyWorker!(url)];\n};\n\n/**\n * The embedded WebAssembly module.\n *\n * This is only available in ESM and when embedding is not disabled.\n */\nconst embeddedWasmModule: EmscriptenModuleFactory<OrtWasmModule> | undefined =\n  BUILD_DEFS.IS_ESM && BUILD_DEFS.ENABLE_BUNDLE_WASM_JS\n    ? // eslint-disable-next-line @typescript-eslint/no-require-imports, @typescript-eslint/no-var-requires\n      require(\n        !BUILD_DEFS.DISABLE_JSEP\n          ? '../../dist/ort-wasm-simd-threaded.jsep.mjs'\n          : '../../dist/ort-wasm-simd-threaded.mjs',\n      ).default\n    : undefined;\n\n/**\n * Import the WebAssembly module.\n *\n * This function will perform the following steps:\n * 1. If the embedded module exists and no custom URL is specified, use the embedded module.\n * 2. If a preload is needed, it will preload the module and return the object URL.\n * 3. Otherwise, it will perform a dynamic import of the module.\n *\n * @returns - A promise that resolves to a tuple of 2 elements:\n *            - The object URL of the preloaded module, or undefined if no preload is needed.\n *            - The default export of the module, which is a factory function to create the WebAssembly module.\n */\nexport const importWasmModule = async (\n  urlOverride: string | undefined,\n  prefixOverride: string | undefined,\n  isMultiThreaded: boolean,\n): Promise<[undefined | string, EmscriptenModuleFactory<OrtWasmModule>]> => {\n  if (!urlOverride && !prefixOverride && embeddedWasmModule && scriptSrc && isSameOrigin(scriptSrc)) {\n    return [undefined, embeddedWasmModule];\n  } else {\n    const wasmModuleFilename = !BUILD_DEFS.DISABLE_JSEP\n      ? 'ort-wasm-simd-threaded.jsep.mjs'\n      : 'ort-wasm-simd-threaded.mjs';\n    const wasmModuleUrl = urlOverride ?? normalizeUrl(wasmModuleFilename, prefixOverride);\n    // need to preload if all of the following conditions are met:\n    // 1. not in Node.js.\n    //    - Node.js does not have the same origin policy for creating workers.\n    // 2. multi-threaded is enabled.\n    //    - If multi-threaded is disabled, no worker will be created. So we don't need to preload the module.\n    // 3. the absolute URL is available.\n    //    - If the absolute URL is failed to be created, the origin cannot be determined. In this case, we will not\n    //    preload the module.\n    // 4. the worker URL is not from the same origin.\n    //    - If the worker URL is from the same origin, we can create the worker directly.\n    const needPreload = !isNode && isMultiThreaded && wasmModuleUrl && !isSameOrigin(wasmModuleUrl, prefixOverride);\n    const url = needPreload\n      ? await preload(wasmModuleUrl)\n      : (wasmModuleUrl ?? fallbackUrl(wasmModuleFilename, prefixOverride));\n    return [needPreload ? url : undefined, await dynamicImportDefault<EmscriptenModuleFactory<OrtWasmModule>>(url)];\n  }\n};\n","// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport { Env } from 'onnxruntime-common';\n\nimport type { OrtWasmModule } from './wasm-types';\nimport { importWasmModule, inferWasmPathPrefixFromScriptSrc } from './wasm-utils-import';\n\nlet wasm: OrtWasmModule | undefined;\nlet initialized = false;\nlet initializing = false;\nlet aborted = false;\n\nconst isMultiThreadSupported = (): boolean => {\n  // If 'SharedArrayBuffer' is not available, WebAssembly threads will not work.\n  if (typeof SharedArrayBuffer === 'undefined') {\n    return false;\n  }\n\n  try {\n    // Test for transferability of SABs (for browsers. needed for Firefox)\n    // https://groups.google.com/forum/#!msg/mozilla.dev.platform/IHkBZlHETpA/dwsMNchWEQAJ\n    if (typeof MessageChannel !== 'undefined') {\n      new MessageChannel().port1.postMessage(new SharedArrayBuffer(1));\n    }\n\n    // Test for WebAssembly threads capability (for both browsers and Node.js)\n    // This typed array is a WebAssembly program containing threaded instructions.\n    return WebAssembly.validate(\n      new Uint8Array([\n        0, 97, 115, 109, 1, 0, 0, 0, 1, 4, 1, 96, 0, 0, 3, 2, 1, 0, 5, 4, 1, 3, 1, 1, 10, 11, 1, 9, 0, 65, 0, 254, 16,\n        2, 0, 26, 11,\n      ]),\n    );\n  } catch (e) {\n    return false;\n  }\n};\n\nconst isSimdSupported = (): boolean => {\n  try {\n    // Test for WebAssembly SIMD capability (for both browsers and Node.js)\n    // This typed array is a WebAssembly program containing SIMD instructions.\n\n    // The binary data is generated from the following code by wat2wasm:\n    //\n    // (module\n    //   (type $t0 (func))\n    //   (func $f0 (type $t0)\n    //     (drop\n    //       (i32x4.dot_i16x8_s\n    //         (i8x16.splat\n    //           (i32.const 0))\n    //         (v128.const i32x4 0x00000000 0x00000000 0x00000000 0x00000000)))))\n\n    return WebAssembly.validate(\n      new Uint8Array([\n        0, 97, 115, 109, 1, 0, 0, 0, 1, 4, 1, 96, 0, 0, 3, 2, 1, 0, 10, 30, 1, 28, 0, 65, 0, 253, 15, 253, 12, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 253, 186, 1, 26, 11,\n      ]),\n    );\n  } catch (e) {\n    return false;\n  }\n};\n\nexport const initializeWebAssembly = async (flags: Env.WebAssemblyFlags): Promise<void> => {\n  if (initialized) {\n    return Promise.resolve();\n  }\n  if (initializing) {\n    throw new Error(\"multiple calls to 'initializeWebAssembly()' detected.\");\n  }\n  if (aborted) {\n    throw new Error(\"previous call to 'initializeWebAssembly()' failed.\");\n  }\n\n  initializing = true;\n\n  // wasm flags are already initialized\n  const timeout = flags.initTimeout!;\n  let numThreads = flags.numThreads!;\n\n  // ensure SIMD is supported\n  if (!isSimdSupported()) {\n    throw new Error('WebAssembly SIMD is not supported in the current environment.');\n  }\n\n  // check if multi-threading is supported\n  const multiThreadSupported = isMultiThreadSupported();\n  if (numThreads > 1 && !multiThreadSupported) {\n    if (typeof self !== 'undefined' && !self.crossOriginIsolated) {\n      // eslint-disable-next-line no-console\n      console.warn(\n        'env.wasm.numThreads is set to ' +\n          numThreads +\n          ', but this will not work unless you enable crossOriginIsolated mode. ' +\n          'See https://web.dev/cross-origin-isolation-guide/ for more info.',\n      );\n    }\n\n    // eslint-disable-next-line no-console\n    console.warn(\n      'WebAssembly multi-threading is not supported in the current environment. ' + 'Falling back to single-threading.',\n    );\n\n    // set flags.numThreads to 1 so that OrtInit() will not create a global thread pool.\n    flags.numThreads = numThreads = 1;\n  }\n\n  const wasmPaths = flags.wasmPaths;\n  const wasmPrefixOverride = typeof wasmPaths === 'string' ? wasmPaths : undefined;\n  const mjsPathOverrideFlag = (wasmPaths as Env.WasmFilePaths)?.mjs;\n  const mjsPathOverride = (mjsPathOverrideFlag as URL)?.href ?? mjsPathOverrideFlag;\n  const wasmPathOverrideFlag = (wasmPaths as Env.WasmFilePaths)?.wasm;\n  const wasmPathOverride = (wasmPathOverrideFlag as URL)?.href ?? wasmPathOverrideFlag;\n  const wasmBinaryOverride = flags.wasmBinary;\n\n  const [objectUrl, ortWasmFactory] = await importWasmModule(mjsPathOverride, wasmPrefixOverride, numThreads > 1);\n\n  let isTimeout = false;\n\n  const tasks: Array<Promise<void>> = [];\n\n  // promise for timeout\n  if (timeout > 0) {\n    tasks.push(\n      new Promise((resolve) => {\n        setTimeout(() => {\n          isTimeout = true;\n          resolve();\n        }, timeout);\n      }),\n    );\n  }\n\n  // promise for module initialization\n  tasks.push(\n    new Promise((resolve, reject) => {\n      const config: Partial<OrtWasmModule> = {\n        /**\n         * The number of threads. WebAssembly will create (Module.numThreads - 1) workers. If it is 1, no worker will be\n         * created.\n         */\n        numThreads,\n      };\n\n      if (wasmBinaryOverride) {\n        // Set a custom buffer which contains the WebAssembly binary. This will skip the wasm file fetching.\n        config.wasmBinary = wasmBinaryOverride;\n      } else if (wasmPathOverride || wasmPrefixOverride) {\n        // A callback function to locate the WebAssembly file. The function should return the full path of the file.\n        //\n        // Since Emscripten 3.1.58, this function is only called for the .wasm file.\n        config.locateFile = (fileName) => wasmPathOverride ?? wasmPrefixOverride + fileName;\n      } else if (mjsPathOverride && mjsPathOverride.indexOf('blob:') !== 0) {\n        // if mjs path is specified, use it as the base path for the .wasm file.\n        config.locateFile = (fileName) => new URL(fileName, mjsPathOverride).href;\n      } else if (objectUrl) {\n        const inferredWasmPathPrefix = inferWasmPathPrefixFromScriptSrc();\n        if (inferredWasmPathPrefix) {\n          // if the wasm module is preloaded, use the inferred wasm path as the base path for the .wasm file.\n          config.locateFile = (fileName) => inferredWasmPathPrefix + fileName;\n        }\n      }\n\n      ortWasmFactory(config).then(\n        // wasm module initialized successfully\n        (module) => {\n          initializing = false;\n          initialized = true;\n          wasm = module;\n          resolve();\n          if (objectUrl) {\n            URL.revokeObjectURL(objectUrl);\n          }\n        },\n        // wasm module failed to initialize\n        (what) => {\n          initializing = false;\n          aborted = true;\n          reject(what);\n        },\n      );\n    }),\n  );\n\n  await Promise.race(tasks);\n\n  if (isTimeout) {\n    throw new Error(`WebAssembly backend initializing failed due to timeout: ${timeout}ms`);\n  }\n};\n\nexport const getInstance = (): OrtWasmModule => {\n  if (initialized && wasm) {\n    return wasm;\n  }\n\n  throw new Error('WebAssembly is not initialized yet.');\n};\n\nexport const dispose = (): void => {\n  if (initialized && !initializing && !aborted) {\n    // TODO: currently \"PThread.terminateAllThreads()\" is not exposed in the wasm module.\n    //       And this function is not yet called by any code.\n    //       If it is needed in the future, we should expose it in the wasm module and uncomment the following line.\n\n    // wasm?.PThread?.terminateAllThreads();\n    wasm = undefined;\n\n    initializing = false;\n    initialized = false;\n    aborted = true;\n  }\n};\n","// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport { getInstance } from './wasm-factory';\n\nexport const allocWasmString = (data: string, allocs: number[]): number => {\n  const wasm = getInstance();\n\n  const dataLength = wasm.lengthBytesUTF8(data) + 1;\n  const dataOffset = wasm._malloc(dataLength);\n  wasm.stringToUTF8(data, dataOffset, dataLength);\n  allocs.push(dataOffset);\n\n  return dataOffset;\n};\n\ninterface ExtraOptionsHandler {\n  (name: string, value: string): void;\n}\n\nexport const iterateExtraOptions = (\n  options: Record<string, unknown>,\n  prefix: string,\n  seen: WeakSet<Record<string, unknown>>,\n  handler: ExtraOptionsHandler,\n): void => {\n  if (typeof options == 'object' && options !== null) {\n    if (seen.has(options)) {\n      throw new Error('Circular reference in options');\n    } else {\n      seen.add(options);\n    }\n  }\n\n  Object.entries(options).forEach(([key, value]) => {\n    const name = prefix ? prefix + key : key;\n    if (typeof value === 'object') {\n      iterateExtraOptions(value as Record<string, unknown>, name + '.', seen, handler);\n    } else if (typeof value === 'string' || typeof value === 'number') {\n      handler(name, value.toString());\n    } else if (typeof value === 'boolean') {\n      handler(name, value ? '1' : '0');\n    } else {\n      throw new Error(`Can't handle extra config type: ${typeof value}`);\n    }\n  });\n};\n\n/**\n * check web assembly API's last error and throw error if any error occurred.\n * @param message a message used when an error occurred.\n */\nexport const checkLastError = (message: string): void => {\n  const wasm = getInstance();\n\n  const stack = wasm.stackSave();\n  try {\n    const ptrSize = wasm.PTR_SIZE;\n    const paramsOffset = wasm.stackAlloc(2 * ptrSize);\n    wasm._OrtGetLastError(paramsOffset, paramsOffset + ptrSize);\n    const errorCode = Number(wasm.getValue(paramsOffset, ptrSize === 4 ? 'i32' : 'i64'));\n    const errorMessagePointer = wasm.getValue(paramsOffset + ptrSize, '*');\n    const errorMessage = errorMessagePointer ? wasm.UTF8ToString(errorMessagePointer) : '';\n    throw new Error(`${message} ERROR_CODE: ${errorCode}, ERROR_MESSAGE: ${errorMessage}`);\n  } finally {\n    wasm.stackRestore(stack);\n  }\n};\n","// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport { InferenceSession } from 'onnxruntime-common';\n\nimport { getInstance } from './wasm-factory';\nimport { allocWasmString, checkLastError, iterateExtraOptions } from './wasm-utils';\n\nexport const setRunOptions = (options: InferenceSession.RunOptions): [number, number[]] => {\n  const wasm = getInstance();\n  let runOptionsHandle = 0;\n  const allocs: number[] = [];\n\n  const runOptions: InferenceSession.RunOptions = options || {};\n\n  try {\n    if (options?.logSeverityLevel === undefined) {\n      runOptions.logSeverityLevel = 2; // Default to warning\n    } else if (\n      typeof options.logSeverityLevel !== 'number' ||\n      !Number.isInteger(options.logSeverityLevel) ||\n      options.logSeverityLevel < 0 ||\n      options.logSeverityLevel > 4\n    ) {\n      throw new Error(`log serverity level is not valid: ${options.logSeverityLevel}`);\n    }\n\n    if (options?.logVerbosityLevel === undefined) {\n      runOptions.logVerbosityLevel = 0; // Default to 0\n    } else if (typeof options.logVerbosityLevel !== 'number' || !Number.isInteger(options.logVerbosityLevel)) {\n      throw new Error(`log verbosity level is not valid: ${options.logVerbosityLevel}`);\n    }\n\n    if (options?.terminate === undefined) {\n      runOptions.terminate = false;\n    }\n\n    let tagDataOffset = 0;\n    if (options?.tag !== undefined) {\n      tagDataOffset = allocWasmString(options.tag, allocs);\n    }\n\n    runOptionsHandle = wasm._OrtCreateRunOptions(\n      runOptions.logSeverityLevel!,\n      runOptions.logVerbosityLevel!,\n      !!runOptions.terminate!,\n      tagDataOffset,\n    );\n    if (runOptionsHandle === 0) {\n      checkLastError(\"Can't create run options.\");\n    }\n\n    if (options?.extra !== undefined) {\n      iterateExtraOptions(options.extra, '', new WeakSet<Record<string, unknown>>(), (key, value) => {\n        const keyDataOffset = allocWasmString(key, allocs);\n        const valueDataOffset = allocWasmString(value, allocs);\n\n        if (wasm._OrtAddRunConfigEntry(runOptionsHandle, keyDataOffset, valueDataOffset) !== 0) {\n          checkLastError(`Can't set a run config entry: ${key} - ${value}.`);\n        }\n      });\n    }\n\n    return [runOptionsHandle, allocs];\n  } catch (e) {\n    if (runOptionsHandle !== 0) {\n      wasm._OrtReleaseRunOptions(runOptionsHandle);\n    }\n    allocs.forEach((alloc) => wasm._free(alloc));\n    throw e;\n  }\n};\n","// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport type { InferenceSession } from 'onnxruntime-common';\n\nimport { getInstance } from './wasm-factory';\nimport { allocWasmString, checkLastError, iterateExtraOptions } from './wasm-utils';\n\nconst getGraphOptimzationLevel = (graphOptimizationLevel: string | unknown): number => {\n  switch (graphOptimizationLevel) {\n    case 'disabled':\n      return 0;\n    case 'basic':\n      return 1;\n    case 'extended':\n      return 2;\n    case 'all':\n      return 99;\n    default:\n      throw new Error(`unsupported graph optimization level: ${graphOptimizationLevel}`);\n  }\n};\n\nconst getExecutionMode = (executionMode: 'sequential' | 'parallel'): number => {\n  switch (executionMode) {\n    case 'sequential':\n      return 0;\n    case 'parallel':\n      return 1;\n    default:\n      throw new Error(`unsupported execution mode: ${executionMode}`);\n  }\n};\n\nconst appendDefaultOptions = (options: InferenceSession.SessionOptions): void => {\n  if (!options.extra) {\n    options.extra = {};\n  }\n  if (!options.extra.session) {\n    options.extra.session = {};\n  }\n  const session = options.extra.session as Record<string, string>;\n  if (!session.use_ort_model_bytes_directly) {\n    // eslint-disable-next-line camelcase\n    session.use_ort_model_bytes_directly = '1';\n  }\n\n  // if using JSEP with WebGPU, always disable memory pattern\n  if (\n    options.executionProviders &&\n    options.executionProviders.some((ep) => (typeof ep === 'string' ? ep : ep.name) === 'webgpu')\n  ) {\n    options.enableMemPattern = false;\n  }\n};\n\nconst appendSessionConfig = (sessionOptionsHandle: number, key: string, value: string, allocs: number[]): void => {\n  const keyDataOffset = allocWasmString(key, allocs);\n  const valueDataOffset = allocWasmString(value, allocs);\n  if (getInstance()._OrtAddSessionConfigEntry(sessionOptionsHandle, keyDataOffset, valueDataOffset) !== 0) {\n    checkLastError(`Can't set a session config entry: ${key} - ${value}.`);\n  }\n};\n\nconst appendEpOption = (epOptions: Array<[number, number]>, key: string, value: string, allocs: number[]): void => {\n  const keyDataOffset = allocWasmString(key, allocs);\n  const valueDataOffset = allocWasmString(value, allocs);\n  epOptions.push([keyDataOffset, valueDataOffset]);\n};\n\nconst setExecutionProviders = async (\n  sessionOptionsHandle: number,\n  executionProviders: readonly InferenceSession.ExecutionProviderConfig[],\n  allocs: number[],\n): Promise<void> => {\n  for (const ep of executionProviders) {\n    let epName = typeof ep === 'string' ? ep : ep.name;\n    const epOptions: Array<[number, number]> = [];\n\n    // check EP name\n    switch (epName) {\n      case 'webnn':\n        epName = 'WEBNN';\n        if (typeof ep !== 'string') {\n          const webnnOptions = ep as InferenceSession.WebNNExecutionProviderOption;\n          // const context = (webnnOptions as InferenceSession.WebNNOptionsWithMLContext)?.context;\n          const deviceType = (webnnOptions as InferenceSession.WebNNContextOptions)?.deviceType;\n          if (deviceType) {\n            appendSessionConfig(sessionOptionsHandle, 'deviceType', deviceType, allocs);\n          }\n        }\n        break;\n      case 'webgpu':\n        if (BUILD_DEFS.USE_WEBGPU_EP) {\n          epName = 'WebGPU';\n          let customDevice: GPUDevice | undefined;\n\n          if (typeof ep !== 'string') {\n            const customOptions = ep as unknown as { device: GPUDevice };\n            if (customOptions.device) {\n              if (typeof GPUDevice !== 'undefined' && customOptions.device instanceof GPUDevice) {\n                customDevice = customOptions.device;\n              } else {\n                throw new Error('Invalid GPU device set in WebGPU EP options.');\n              }\n            }\n\n            // TODO: handle more options\n          }\n\n          const info = getInstance().webgpuRegisterDevice!(customDevice);\n          if (info) {\n            const [deviceId, instanceHandle, deviceHandle] = info;\n            appendEpOption(epOptions, 'deviceId', deviceId.toString(), allocs);\n            appendEpOption(epOptions, 'webgpuInstance', instanceHandle.toString(), allocs);\n            appendEpOption(epOptions, 'webgpuDevice', deviceHandle.toString(), allocs);\n          }\n        } else {\n          epName = 'JS';\n          if (typeof ep !== 'string') {\n            const webgpuOptions = ep as InferenceSession.WebGpuExecutionProviderOption;\n            if (webgpuOptions?.preferredLayout) {\n              if (webgpuOptions.preferredLayout !== 'NCHW' && webgpuOptions.preferredLayout !== 'NHWC') {\n                throw new Error(`preferredLayout must be either 'NCHW' or 'NHWC': ${webgpuOptions.preferredLayout}`);\n              }\n              appendSessionConfig(sessionOptionsHandle, 'preferredLayout', webgpuOptions.preferredLayout, allocs);\n            }\n          }\n        }\n        break;\n      case 'wasm':\n      case 'cpu':\n        continue;\n      default:\n        throw new Error(`not supported execution provider: ${epName}`);\n    }\n\n    const epNameDataOffset = allocWasmString(epName, allocs);\n    const epOptionsCount = epOptions.length;\n    let keysOffset = 0;\n    let valuesOffset = 0;\n    if (epOptionsCount > 0) {\n      keysOffset = getInstance()._malloc(epOptionsCount * getInstance().PTR_SIZE);\n      allocs.push(keysOffset);\n      valuesOffset = getInstance()._malloc(epOptionsCount * getInstance().PTR_SIZE);\n      allocs.push(valuesOffset);\n      for (let i = 0; i < epOptionsCount; i++) {\n        getInstance().setValue(keysOffset + i * getInstance().PTR_SIZE, epOptions[i][0], '*');\n        getInstance().setValue(valuesOffset + i * getInstance().PTR_SIZE, epOptions[i][1], '*');\n      }\n    }\n    if (\n      (await getInstance()._OrtAppendExecutionProvider(\n        sessionOptionsHandle,\n        epNameDataOffset,\n        keysOffset,\n        valuesOffset,\n        epOptionsCount,\n      )) !== 0\n    ) {\n      checkLastError(`Can't append execution provider: ${epName}.`);\n    }\n  }\n};\n\nexport const setSessionOptions = async (options?: InferenceSession.SessionOptions): Promise<[number, number[]]> => {\n  const wasm = getInstance();\n  let sessionOptionsHandle = 0;\n  const allocs: number[] = [];\n\n  const sessionOptions: InferenceSession.SessionOptions = options || {};\n  appendDefaultOptions(sessionOptions);\n\n  try {\n    const graphOptimizationLevel = getGraphOptimzationLevel(sessionOptions.graphOptimizationLevel ?? 'all');\n    const executionMode = getExecutionMode(sessionOptions.executionMode ?? 'sequential');\n    const logIdDataOffset =\n      typeof sessionOptions.logId === 'string' ? allocWasmString(sessionOptions.logId, allocs) : 0;\n\n    const logSeverityLevel = sessionOptions.logSeverityLevel ?? 2; // Default to 2 - warning\n    if (!Number.isInteger(logSeverityLevel) || logSeverityLevel < 0 || logSeverityLevel > 4) {\n      throw new Error(`log serverity level is not valid: ${logSeverityLevel}`);\n    }\n\n    const logVerbosityLevel = sessionOptions.logVerbosityLevel ?? 0; // Default to 0 - verbose\n    if (!Number.isInteger(logVerbosityLevel) || logVerbosityLevel < 0 || logVerbosityLevel > 4) {\n      throw new Error(`log verbosity level is not valid: ${logVerbosityLevel}`);\n    }\n\n    const optimizedModelFilePathOffset =\n      typeof sessionOptions.optimizedModelFilePath === 'string'\n        ? allocWasmString(sessionOptions.optimizedModelFilePath, allocs)\n        : 0;\n\n    sessionOptionsHandle = wasm._OrtCreateSessionOptions(\n      graphOptimizationLevel,\n      !!sessionOptions.enableCpuMemArena,\n      !!sessionOptions.enableMemPattern,\n      executionMode,\n      !!sessionOptions.enableProfiling,\n      0,\n      logIdDataOffset,\n      logSeverityLevel,\n      logVerbosityLevel,\n      optimizedModelFilePathOffset,\n    );\n    if (sessionOptionsHandle === 0) {\n      checkLastError(\"Can't create session options.\");\n    }\n\n    if (sessionOptions.executionProviders) {\n      await setExecutionProviders(sessionOptionsHandle, sessionOptions.executionProviders, allocs);\n    }\n\n    if (sessionOptions.enableGraphCapture !== undefined) {\n      if (typeof sessionOptions.enableGraphCapture !== 'boolean') {\n        throw new Error(`enableGraphCapture must be a boolean value: ${sessionOptions.enableGraphCapture}`);\n      }\n      appendSessionConfig(\n        sessionOptionsHandle,\n        'enableGraphCapture',\n        sessionOptions.enableGraphCapture.toString(),\n        allocs,\n      );\n    }\n\n    if (sessionOptions.freeDimensionOverrides) {\n      for (const [name, value] of Object.entries(sessionOptions.freeDimensionOverrides)) {\n        if (typeof name !== 'string') {\n          throw new Error(`free dimension override name must be a string: ${name}`);\n        }\n        if (typeof value !== 'number' || !Number.isInteger(value) || value < 0) {\n          throw new Error(`free dimension override value must be a non-negative integer: ${value}`);\n        }\n        const nameOffset = allocWasmString(name, allocs);\n        if (wasm._OrtAddFreeDimensionOverride(sessionOptionsHandle, nameOffset, value) !== 0) {\n          checkLastError(`Can't set a free dimension override: ${name} - ${value}.`);\n        }\n      }\n    }\n\n    if (sessionOptions.extra !== undefined) {\n      iterateExtraOptions(sessionOptions.extra, '', new WeakSet<Record<string, unknown>>(), (key, value) => {\n        appendSessionConfig(sessionOptionsHandle, key, value, allocs);\n      });\n    }\n\n    return [sessionOptionsHandle, allocs];\n  } catch (e) {\n    if (sessionOptionsHandle !== 0) {\n      if (wasm._OrtReleaseSessionOptions(sessionOptionsHandle) !== 0) {\n        checkLastError(\"Can't release session options.\");\n      }\n    }\n    allocs.forEach((alloc) => wasm._free(alloc));\n    throw e;\n  }\n};\n","// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport { Tensor } from 'onnxruntime-common';\n\n// a dummy type declaration for Float16Array in case any polyfill is available.\ndeclare global {\n  // eslint-disable-next-line @typescript-eslint/naming-convention, @typescript-eslint/no-explicit-any\n  const Float16Array: any;\n}\n\n// This file includes common definitions. They do NOT have dependency on the WebAssembly instance.\n\n/**\n * Copied from ONNX definition. Use this to drop dependency 'onnx_proto' to decrease compiled .js file size.\n */\nexport const enum DataType {\n  undefined = 0,\n  float = 1,\n  uint8 = 2,\n  int8 = 3,\n  uint16 = 4,\n  int16 = 5,\n  int32 = 6,\n  int64 = 7,\n  string = 8,\n  bool = 9,\n  float16 = 10,\n  double = 11,\n  uint32 = 12,\n  uint64 = 13,\n  complex64 = 14,\n  complex128 = 15,\n  bfloat16 = 16,\n\n  // 4-bit data-types\n  uint4 = 21,\n  int4 = 22,\n}\n\n/**\n * Map string tensor data to enum value\n */\nexport const tensorDataTypeStringToEnum = (type: string): DataType => {\n  switch (type) {\n    case 'int8':\n      return DataType.int8;\n    case 'uint8':\n      return DataType.uint8;\n    case 'bool':\n      return DataType.bool;\n    case 'int16':\n      return DataType.int16;\n    case 'uint16':\n      return DataType.uint16;\n    case 'int32':\n      return DataType.int32;\n    case 'uint32':\n      return DataType.uint32;\n    case 'float16':\n      return DataType.float16;\n    case 'float32':\n      return DataType.float;\n    case 'float64':\n      return DataType.double;\n    case 'string':\n      return DataType.string;\n    case 'int64':\n      return DataType.int64;\n    case 'uint64':\n      return DataType.uint64;\n    case 'int4':\n      return DataType.int4;\n    case 'uint4':\n      return DataType.uint4;\n\n    default:\n      throw new Error(`unsupported data type: ${type}`);\n  }\n};\n\n/**\n * Map enum value to string tensor data\n */\nexport const tensorDataTypeEnumToString = (typeProto: DataType): Tensor.Type => {\n  switch (typeProto) {\n    case DataType.int8:\n      return 'int8';\n    case DataType.uint8:\n      return 'uint8';\n    case DataType.bool:\n      return 'bool';\n    case DataType.int16:\n      return 'int16';\n    case DataType.uint16:\n      return 'uint16';\n    case DataType.int32:\n      return 'int32';\n    case DataType.uint32:\n      return 'uint32';\n    case DataType.float16:\n      return 'float16';\n    case DataType.float:\n      return 'float32';\n    case DataType.double:\n      return 'float64';\n    case DataType.string:\n      return 'string';\n    case DataType.int64:\n      return 'int64';\n    case DataType.uint64:\n      return 'uint64';\n    case DataType.int4:\n      return 'int4';\n    case DataType.uint4:\n      return 'uint4';\n\n    default:\n      throw new Error(`unsupported data type: ${typeProto}`);\n  }\n};\n\n/**\n * get tensor size in bytes by the given data type and dimensions\n * @returns size in integer or undefined if the data type is not supported\n */\nexport const calculateTensorSizeInBytes = (\n  dateType: number,\n  dimsOrSize: readonly number[] | number,\n): number | undefined => {\n  const elementSize = [\n    -1, // undefined = 0\n    4, // float = 1\n    1, // uint8 = 2\n    1, // int8 = 3\n    2, // uint16 = 4\n    2, // int16 = 5\n    4, // int32 = 6\n    8, // int64 = 7\n    -1, // string = 8\n    1, // bool = 9\n    2, // float16 = 10\n    8, // double = 11\n    4, // uint32 = 12\n    8, // uint64 = 13\n    -1, // complex64 = 14\n    -1, // complex128 = 15\n    -1, // bfloat16 = 16\n    -1, // FLOAT8E4M3FN = 17\n    -1, // FLOAT8E4M3FNUZ = 18\n    -1, // FLOAT8E5M2 = 19\n    -1, // FLOAT8E5M2FNUZ = 20\n    0.5, // uint4 = 21\n    0.5, // int4 = 22\n  ][dateType];\n\n  const size = typeof dimsOrSize === 'number' ? dimsOrSize : dimsOrSize.reduce((a, b) => a * b, 1);\n  return elementSize > 0 ? Math.ceil(size * elementSize) : undefined;\n};\n\n/**\n * get typed array constructor by the given tensor type\n */\nexport const tensorTypeToTypedArrayConstructor = (\n  type: Tensor.Type,\n):\n  | Float32ArrayConstructor\n  | Uint8ArrayConstructor\n  | Int8ArrayConstructor\n  | Uint16ArrayConstructor\n  | Int16ArrayConstructor\n  | Int32ArrayConstructor\n  | BigInt64ArrayConstructor\n  | Uint8ArrayConstructor\n  | Float64ArrayConstructor\n  | Uint32ArrayConstructor\n  | BigUint64ArrayConstructor => {\n  switch (type) {\n    case 'float16':\n      // allow Float16Array polyfill.\n      return typeof Float16Array !== 'undefined' && Float16Array.from ? Float16Array : Uint16Array;\n    case 'float32':\n      return Float32Array;\n    case 'uint8':\n      return Uint8Array;\n    case 'int8':\n      return Int8Array;\n    case 'uint16':\n      return Uint16Array;\n    case 'int16':\n      return Int16Array;\n    case 'int32':\n      return Int32Array;\n    case 'bool':\n      return Uint8Array;\n    case 'float64':\n      return Float64Array;\n    case 'uint32':\n      return Uint32Array;\n    case 'int64':\n      return BigInt64Array;\n    case 'uint64':\n      return BigUint64Array;\n    default:\n      throw new Error(`unsupported type: ${type}`);\n  }\n};\n\n/**\n * Map string log level to integer value\n */\nexport const logLevelStringToEnum = (logLevel?: 'verbose' | 'info' | 'warning' | 'error' | 'fatal'): number => {\n  switch (logLevel) {\n    case 'verbose':\n      return 0;\n    case 'info':\n      return 1;\n    case 'warning':\n      return 2;\n    case 'error':\n      return 3;\n    case 'fatal':\n      return 4;\n    default:\n      throw new Error(`unsupported logging level: ${logLevel}`);\n  }\n};\n\n/**\n * Check whether the given tensor type is supported by GPU buffer\n */\nexport const isGpuBufferSupportedType = (type: Tensor.Type): type is Tensor.GpuBufferDataTypes =>\n  type === 'float32' ||\n  type === 'float16' ||\n  type === 'int32' ||\n  type === 'int64' ||\n  type === 'uint32' ||\n  type === 'uint8' ||\n  type === 'bool' ||\n  type === 'uint4' ||\n  type === 'int4';\n\n/**\n * Check whether the given tensor type is supported by WebNN MLTensor\n */\nexport const isMLTensorSupportedType = (type: Tensor.Type): type is Tensor.MLTensorDataTypes =>\n  type === 'float32' ||\n  type === 'float16' ||\n  type === 'int32' ||\n  type === 'int64' ||\n  type === 'uint32' ||\n  type === 'uint64' ||\n  type === 'int8' ||\n  type === 'uint8' ||\n  type === 'bool' ||\n  type === 'uint4' ||\n  type === 'int4';\n\n/**\n * Map string data location to integer value\n */\nexport const dataLocationStringToEnum = (location: Tensor.DataLocation): number => {\n  switch (location) {\n    case 'none':\n      return 0;\n    case 'cpu':\n      return 1;\n    case 'cpu-pinned':\n      return 2;\n    case 'texture':\n      return 3;\n    case 'gpu-buffer':\n      return 4;\n    case 'ml-tensor':\n      return 5;\n    default:\n      throw new Error(`unsupported data location: ${location}`);\n  }\n};\n\n/**\n * Map integer data location to string value\n */\nexport const dataLocationEnumToString = (location: number): Tensor.DataLocation | undefined =>\n  (['none', 'cpu', 'cpu-pinned', 'texture', 'gpu-buffer', 'ml-tensor'] as const)[location];\n","// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport { isNode } from './wasm-utils-env';\n\n/**\n * Load a file into a Uint8Array.\n *\n * @param file - the file to load. Can be a URL/path, a Blob, an ArrayBuffer, or a Uint8Array.\n * @returns a Uint8Array containing the file data.\n */\nexport const loadFile = async (file: string | Blob | ArrayBufferLike | Uint8Array): Promise<Uint8Array> => {\n  if (typeof file === 'string') {\n    if (isNode) {\n      // load file into ArrayBuffer in Node.js\n      try {\n        const { readFile } = require('node:fs/promises');\n        return new Uint8Array(await readFile(file));\n      } catch (e) {\n        if (e.code === 'ERR_FS_FILE_TOO_LARGE') {\n          // file is too large, use fs.createReadStream instead\n          const { createReadStream } = require('node:fs');\n          const stream = createReadStream(file);\n          const chunks: Uint8Array[] = [];\n          for await (const chunk of stream) {\n            chunks.push(chunk);\n          }\n          return new Uint8Array(Buffer.concat(chunks));\n        }\n        throw e;\n      }\n    } else {\n      // load file into ArrayBuffer in browsers\n      const response = await fetch(file);\n      if (!response.ok) {\n        throw new Error(`failed to load external data file: ${file}`);\n      }\n      const contentLengthHeader = response.headers.get('Content-Length');\n      const fileSize = contentLengthHeader ? parseInt(contentLengthHeader, 10) : 0;\n      if (fileSize < 1073741824 /* 1GB */) {\n        // when Content-Length header is not set, we cannot determine the file size. We assume it is small enough to\n        // load into memory.\n        return new Uint8Array(await response.arrayBuffer());\n      } else {\n        // file is too large, use stream instead\n        if (!response.body) {\n          throw new Error(`failed to load external data file: ${file}, no response body.`);\n        }\n        const reader = response.body.getReader();\n\n        let buffer;\n        try {\n          // try to create ArrayBuffer directly\n          buffer = new ArrayBuffer(fileSize);\n        } catch (e) {\n          if (e instanceof RangeError) {\n            // use WebAssembly Memory to allocate larger ArrayBuffer\n            const pages = Math.ceil(fileSize / 65536);\n            buffer = new WebAssembly.Memory({ initial: pages, maximum: pages }).buffer;\n          } else {\n            throw e;\n          }\n        }\n\n        let offset = 0;\n        // eslint-disable-next-line no-constant-condition\n        while (true) {\n          const { done, value } = await reader.read();\n          if (done) {\n            break;\n          }\n          const chunkSize = value.byteLength;\n          const chunk = new Uint8Array(buffer, offset, chunkSize);\n          chunk.set(value);\n          offset += chunkSize;\n        }\n        return new Uint8Array(buffer, 0, fileSize);\n      }\n    }\n  } else if (file instanceof Blob) {\n    return new Uint8Array(await file.arrayBuffer());\n  } else if (file instanceof Uint8Array) {\n    return file;\n  } else {\n    return new Uint8Array(file);\n  }\n};\n","// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport { Env } from 'onnxruntime-common';\n\nimport { logLevelStringToEnum } from '../wasm-common';\n\ntype LogLevel = NonNullable<Env['logLevel']>;\ntype MessageString = string;\ntype MessageFunction = () => string;\ntype Message = MessageString | MessageFunction;\n\nconst logLevelPrefix = ['V', 'I', 'W', 'E', 'F'];\n\nconst doLog = (level: number, message: string): void => {\n  // eslint-disable-next-line no-console\n  console.log(`[${logLevelPrefix[level]},${new Date().toISOString()}]${message}`);\n};\n\nlet configLogLevel: LogLevel | undefined;\nlet debug: boolean | undefined;\n\nexport const configureLogger = ($configLogLevel: LogLevel, $debug: boolean): void => {\n  configLogLevel = $configLogLevel;\n  debug = $debug;\n};\n\n/**\n * A simple logging utility to log messages to the console.\n */\nexport const LOG = (logLevel: LogLevel, msg: Message): void => {\n  const messageLevel = logLevelStringToEnum(logLevel);\n  const configLevel = logLevelStringToEnum(configLogLevel);\n  if (messageLevel >= configLevel) {\n    doLog(messageLevel, typeof msg === 'function' ? msg() : msg);\n  }\n};\n\n/**\n * A simple logging utility to log messages to the console. Only logs when debug is enabled.\n */\nexport const LOG_DEBUG: typeof LOG = (...args: Parameters<typeof LOG>) => {\n  if (debug) {\n    LOG(...args);\n  }\n};\n","// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\n/* eslint-disable no-param-reassign */\n\nexport class MatMulUtil {\n  /**\n   * Calculate the expected shape when matrix multiplication\n   * @param a The shape of tensor A. Should be a tuple of 2 positive integers\n   * @param b The shape of tensor B. Should be a tuple of 2 positive integers\n   * @returns The expected shape of the result, or undefined if N/A\n   */\n  static calcMatMulShape(a: [number, number], b: [number, number]): [number, number] | undefined {\n    return a[1] !== b[0] ? undefined : [a[0], b[1]];\n  }\n}\n\nexport class BroadcastUtil {\n  /**\n   * Calculate the expected shape when broadcasting 2 tensors\n   * @param a The shape of tensor A. Should be an array of positive integers\n   * @param b The shape of tensor B. Should be an array of positive integers\n   * @param isMatMul Whether the operation is MatMul\n   * @returns The expected shape of the result, or undefined if N/A\n   */\n  static calcShape(\n    adims: readonly number[],\n    bdims: readonly number[],\n    isMatMul = false,\n  ): readonly number[] | undefined {\n    const arank = adims.length;\n    const brank = bdims.length;\n    if (arank === 0) {\n      return bdims;\n    }\n    if (brank === 0) {\n      return adims;\n    }\n    const crank = Math.max(adims.length, bdims.length);\n    const cdims = new Array<number>(crank);\n\n    // calculate the last 2 dimension if it is MatMul\n    if (isMatMul) {\n      if (arank < 2 || brank < 2) {\n        return undefined;\n      }\n      const cShapeMatMul = MatMulUtil.calcMatMulShape(\n        [adims[arank - 2], adims[arank - 1]],\n        [bdims[brank - 2], bdims[brank - 1]],\n      );\n      if (cShapeMatMul === undefined) {\n        return undefined;\n      }\n      [cdims[crank - 2], cdims[crank - 1]] = cShapeMatMul;\n    }\n\n    for (let i = isMatMul ? 3 : 1; i <= crank; i++) {\n      const aLen = arank - i < 0 ? 1 : adims[arank - i];\n      const bLen = brank - i < 0 ? 1 : bdims[brank - i];\n\n      if (aLen !== bLen && aLen > 1 && bLen > 1) {\n        return undefined;\n      }\n      const max = Math.max(aLen, bLen);\n      if (aLen && bLen) {\n        cdims[crank - i] = Math.max(aLen, bLen);\n      } else {\n        // when either aLen or bLen is 0, the other should be either 0 or 1, otherwise it is not broadcastable.\n        if (max > 1) {\n          return undefined;\n        }\n        cdims[crank - i] = 0;\n      }\n    }\n\n    return cdims;\n  }\n\n  /**\n   * Determine if a shape is unidirectional broadcastable to another shape\n   * @param shape The input shape\n   * @param finalShape The desired shape after broadcasting\n   */\n  static isValidBroadcast(shape: readonly number[], finalShape: readonly number[]): boolean {\n    // align shape to the right\n    const inputRank = shape.length;\n    const finalRank = finalShape.length;\n    if (inputRank > finalRank) {\n      return false;\n    }\n    for (let i = 1; i <= inputRank; i++) {\n      if (shape[inputRank - i] !== 1 && shape[inputRank - i] !== finalShape[finalRank - i]) {\n        return false;\n      }\n    }\n    return true;\n  }\n}\n\nexport class ShapeUtil {\n  /**\n   * calculate the size (number of elements)\n   */\n  static size(dims: readonly number[]): number {\n    return ShapeUtil.getSizeFromDimensionRange(dims, 0, dims.length);\n  }\n\n  /**\n   * convert dims corresponding to type change to pack. ex. uint8 data to uint32\n   */\n  static convertShape(dims: readonly number[], size = 4): readonly number[] {\n    const rank = dims.length;\n    if (rank === 0) {\n      return [];\n    }\n    const newDims = new Array(rank);\n    let i = rank - 1;\n    while (i >= 0) {\n      if (dims[i] % size === 0) {\n        newDims[i] = dims[i] / size;\n        break;\n      }\n      if (size % dims[i] !== 0) {\n        throw new Error('cannot convert shape');\n      }\n      newDims[i] = 1;\n      size /= dims[i];\n      i--;\n    }\n    for (i--; i >= 0; i--) {\n      newDims[i] = dims[i];\n    }\n    return newDims;\n  }\n\n  /**\n   * calculate the size (number of elements) from the given axis (inclusive)\n   */\n  static sizeFromDimension(dims: readonly number[], axis: number): number {\n    if (axis < 0 || axis > dims.length) {\n      throw new Error(`invalid dimension of ${axis} for sizeFromDimension as Tensor has ${dims.length} dimensions.`);\n    }\n    return ShapeUtil.getSizeFromDimensionRange(dims, axis, dims.length);\n  }\n\n  /**\n   * calculate the size (number of elements) to the given axis (exclusive)\n   */\n  static sizeToDimension(dims: readonly number[], axis: number): number {\n    if (axis < 0 || axis > dims.length) {\n      throw new Error(`invalid dimension of ${axis} for sizeToDimension as Tensor has ${dims.length} dimensions.`);\n    }\n    return ShapeUtil.getSizeFromDimensionRange(dims, 0, axis);\n  }\n\n  /**\n   * calculate the size (number of elements) from and to the given axis [start, end)\n   */\n  static getSizeFromDimensionRange(dims: readonly number[], start: number, end: number): number {\n    let size = 1;\n    for (let i = start; i < end; i++) {\n      // safety check as this method is called by multiple other methods requiring size.\n      // size cannot be negative.\n      if (dims[i] < 0) {\n        throw new Error(\n          // eslint-disable-next-line max-len\n          'cannot get valid size from specified dimension range. Most likely the range contains negative values in them.',\n        );\n      }\n      size *= Number(dims[i]);\n    }\n    return size;\n  }\n\n  static computeStrides(dims: readonly number[]): readonly number[] {\n    const rank = dims.length;\n    if (rank === 0) {\n      return [];\n    } else if (rank === 1) {\n      return [1];\n    }\n    const strides = new Array(rank);\n    strides[rank - 1] = 1;\n    strides[rank - 2] = dims[rank - 1];\n    for (let i = rank - 3; i >= 0; --i) {\n      strides[i] = strides[i + 1] * dims[i + 1];\n    }\n    return strides;\n  }\n\n  /**\n   * normailze axis of range [-r, r) into [0, r).\n   */\n  static normalizeAxis(axis: number, tensorRank: number): number {\n    if (axis < -tensorRank && axis >= tensorRank) {\n      throw new Error('unsupported axis for this operation.');\n    }\n    return axis < 0 ? axis + tensorRank : axis;\n  }\n\n  static normalizeAxes(axes: readonly number[], tensorRank?: number): number[] {\n    return axes.map((x) => this.normalizeAxis(x, tensorRank ?? axes.length));\n  }\n\n  /**\n   * Sorts a given array based on the indices in the Perm array\n   * Used in Transpose\n   * @param a Array to be sorted such as dims or strides\n   * @param perm Perm given; if null a will be reversed\n   */\n  static sortBasedOnPerm(a: readonly number[], perm?: readonly number[]): readonly number[] {\n    if (perm) {\n      return perm.map((v) => a[v]);\n    } else {\n      return a.slice().reverse();\n    }\n  }\n\n  /**\n   * Pads a given shape according to the padding values\n   * @param dims shape of the Tensor to be padded\n   * @param pad pad values\n   */\n  static padShape(dims: readonly number[], pad: readonly number[]): readonly number[] {\n    const rank = dims.length;\n    return dims.map((v, i) => v + pad[i] + pad[i + rank]);\n  }\n\n  /**\n   * Determines if the two shapes are identical\n   * @param shape1\n   * @param shape2\n   */\n  static areEqual(shape1: readonly number[], shape2: readonly number[]): boolean {\n    if (shape1.length !== shape2.length) {\n      return false;\n    }\n    return shape1.every((v, i) => v === shape2[i]);\n  }\n}\n\nexport class PoolConvUtil {\n  /**\n   * Adjust the kernel, strides, pads to correct rank. Set to default value if not present\n   * @param isGlobalOperator If true, perform global pooling.\n   * @param inputDims The input tensor dimension.\n   * @param kernelShape The size of the kernel along each axis.\n   * @param strides Stride along each axis.\n   * @param dilations Dilation along each axis.\n   * @param pads Padding for the beginning and ending along each axis.\n   */\n  static adjustPoolAttributes(\n    isGlobalOperator: boolean,\n    inputDims: readonly number[],\n    kernelShape: number[],\n    strides: number[],\n    dilations: number[],\n    pads: number[],\n  ): void {\n    if (!isGlobalOperator && kernelShape.length !== inputDims.length - 2) {\n      throw new Error('length of specified kernel shapes should be 2 less than length of input dimensions');\n    }\n\n    if (isGlobalOperator) {\n      // adjust kernel shape to cover the input dims\n      for (let dim = 0; dim < inputDims.length - 2; dim++) {\n        if (dim >= kernelShape.length) {\n          kernelShape.push(inputDims[dim + 2]);\n        } else {\n          kernelShape[dim] = inputDims[dim + 2];\n        }\n      }\n    }\n\n    // adjust strides length to match kernel shape length\n    for (let dim = 0; dim < kernelShape.length; dim++) {\n      if (dim < strides.length) {\n        if (strides[dim] < 0) {\n          throw new Error('strides should be greater than or equal to 1');\n        }\n      } else {\n        strides.push(1);\n      }\n    }\n\n    // adjust dilation value\n    for (let dim = 0; dim < kernelShape.length; dim++) {\n      if (dim < dilations.length) {\n        if (dilations[dim] < 0) {\n          throw new Error('dilations should be greater than or equal to 1');\n        }\n      } else {\n        dilations.push(1);\n      }\n    }\n\n    // adjust pads length to match 2 * kernel shape length\n    for (let dim = 0; dim < kernelShape.length * 2; dim++) {\n      if (dim < pads.length) {\n        if (pads[dim] < 0) {\n          throw new Error('pad should be greater than or equal to 1');\n        }\n      } else {\n        pads.push(0);\n      }\n    }\n\n    // sanity checks for values in kernel shapes and pads\n    for (let dim = 0; dim < kernelShape.length; dim++) {\n      if (kernelShape[dim] <= 0) {\n        throw new Error('kernel shapes need to be greater than 0');\n      }\n\n      if (pads[dim] >= kernelShape[dim] || pads[dim + kernelShape.length] >= kernelShape[dim]) {\n        throw new Error('pads should be smaller than kernel');\n      }\n    }\n  }\n\n  // adjust pad values based on 'autoPad' attribute\n  static adjustPadsBasedOnAutoPad(\n    inputDims: readonly number[],\n    strides: readonly number[],\n    dilations: readonly number[],\n    kernelShape: readonly number[],\n    pads: number[],\n    isChannelLast: boolean,\n    autoPad?: string,\n  ): void {\n    if (!autoPad) {\n      return;\n    }\n\n    if (pads.length !== 2 * (inputDims.length - 2)) {\n      throw new Error('length of pads should be twice the length of data dimensions');\n    }\n\n    if (strides.length !== inputDims.length - 2) {\n      throw new Error('length of strides should be the length of data dimensions');\n    }\n\n    if (kernelShape.length !== inputDims.length - 2) {\n      throw new Error('length of kernel shapes should be the length of data dimensions');\n    }\n\n    for (let dim = 0; dim < inputDims.length - 2; dim++) {\n      PoolConvUtil.adjustPadAndReturnShape(\n        inputDims[dim + (isChannelLast ? 1 : 2)],\n        strides[dim],\n        dilations[dim],\n        kernelShape[dim],\n        pads,\n        dim,\n        dim + inputDims.length - 2,\n        autoPad,\n      );\n    }\n  }\n\n  /**\n   * Calculate the output shape for Pool ops based on input attributes. (Should be used only for Pool ops)\n   * @param isGlobalOperator If true, perform global pooling.\n   * @param inputDims The input tensor dimension. (inputs[0].dims)\n   * @param strides Stride along each axis.\n   * @param dilations Dilation along each axis.\n   * @param kernelShape The size of the kernel along each axis.\n   * @param pads Padding for the beginning and ending along each axis.\n   * @param autoPad DEPRECATED attribute supported for legacy models. Specifies how to implicitly calculate pads in each\n   *     dimension. Can take values NOTSET, SAME_UPPER, SAME_LOWER, or VALID.\n   */\n  static computePoolOutputShape(\n    isGlobalOperator: boolean,\n    inputDims: readonly number[],\n    strides: number[],\n    dilations: number[],\n    kernelShape: number[],\n    pads: number[],\n    autoPad?: string,\n  ): number[] {\n    if (inputDims.length <= 0) {\n      throw new Error('input shape must be of size greater than 0');\n    }\n\n    // Add batch size and number of channels of output\n    const outputDims = [inputDims[0], inputDims[1]];\n\n    PoolConvUtil.computeShapeHelper(\n      isGlobalOperator,\n      inputDims,\n      outputDims,\n      strides,\n      dilations,\n      kernelShape,\n      pads,\n      autoPad,\n    );\n    return outputDims;\n  }\n\n  /**\n   * Calculate the output shape for Conv op based on input attributes. (Should be used only for Conv op)\n   * @param inputDims The input tensor dimension. (inputs[0].dims)\n   * @param filterDims The filter tensor dimension. (inputs[1].dims)\n   * @param strides Stride along each axis.\n   * @param kernelShape The size of the kernel along each axis.\n   * @param pads Padding for the beginning and ending along each axis.\n   * @param autoPad DEPRECATED attribute supported for legacy models. Specifies how to implicitly calculate pads in each\n   *     dimension. Can take values NOTSET, SAME_UPPER, SAME_LOWER, or VALID.\n   */\n  static computeConvOutputShape(\n    inputDims: readonly number[],\n    filterDims: readonly number[],\n    strides: number[],\n    dilations: number[],\n    kernelShape: number[],\n    pads: number[],\n    autoPad?: string,\n  ): number[] {\n    if (inputDims.length <= 0 || filterDims.length <= 0) {\n      throw new Error('invalid input tensor dims or invalid filter tensor dims');\n    }\n\n    // Add batch size and number of channels of output\n    const outputDims = [inputDims[0], filterDims[0]];\n\n    PoolConvUtil.computeShapeHelper(false, inputDims, outputDims, strides, dilations, kernelShape, pads, autoPad);\n    return outputDims;\n  }\n\n  // will compute output shapes for data dimensions ONLY (i.e.) no batch size and channels\n  // called by computePoolOutputShape() and computeConvOutputShape()\n  // adjust pads based on 'autoPad' attribute prior to shape computation\n  private static computeShapeHelper(\n    isGlobalOperator: boolean,\n    inputDims: readonly number[],\n    outputDims: number[],\n    strides: readonly number[],\n    dilations: readonly number[],\n    kernelShape: readonly number[],\n    pads: number[],\n    autoPad?: string,\n  ) {\n    if (isGlobalOperator) {\n      for (let dim = 0; dim < inputDims.length - 2; dim++) {\n        outputDims.push(1);\n      }\n    } else {\n      for (let dim = 0; dim < inputDims.length - 2; dim++) {\n        outputDims.push(\n          PoolConvUtil.adjustPadAndReturnShape(\n            inputDims[dim + 2],\n            strides[dim],\n            dilations[dim],\n            kernelShape[dim],\n            pads,\n            dim,\n            dim + inputDims.length - 2,\n            autoPad,\n          ),\n        );\n      }\n    }\n  }\n\n  // helper for computeShapeHelper() and adjustPadsBasedOnAutoPad()\n  // adjusts pad value for given 'autoPad' string and computes output shape along a particular dimension\n  private static adjustPadAndReturnShape(\n    inSize: number,\n    stride: number,\n    dilation: number,\n    kernel: number,\n    pads: number[],\n    padHeadIndex: number,\n    padTailIndex: number,\n    autoPad?: string,\n  ): number {\n    const dkernel = dilation * (kernel - 1) + 1;\n    if (autoPad && autoPad !== 'NOTSET') {\n      switch (autoPad) {\n        case 'VALID':\n          pads[padHeadIndex] = 0;\n          pads[padTailIndex] = 0;\n          return Math.floor((inSize - dkernel) / stride + 1);\n        case 'SAME_LOWER':\n        case 'SAME_UPPER':\n          if (dilation !== 1) {\n            throw new Error('Dilation not supported for SAME_UPPER or SAME_LOWER');\n          } else {\n            const legacyTargetSize = (inSize + stride - 1) / stride;\n            const padNeeded = (legacyTargetSize - 1) * stride + kernel - inSize;\n            pads[padHeadIndex] = autoPad === 'SAME_LOWER' ? Math.floor((padNeeded + 1) / 2) : Math.floor(padNeeded / 2);\n            pads[padTailIndex] = padNeeded - pads[padHeadIndex];\n            return Math.floor((inSize + padNeeded - kernel) / stride + 1);\n          }\n        default:\n          throw new Error('Unsupported AutoPad type');\n      }\n    } else {\n      return Math.floor((inSize + pads[padHeadIndex] + pads[padTailIndex] - dkernel) / stride + 1);\n    }\n  }\n}\n\nexport class GemmUtil {\n  // will make sure input shapes are compatible for this op\n  // and return back the shape of the output in the form of a tuple\n  // will throw exception if the input shapes are not compatible\n  static getShapeOfGemmResult(\n    leftShape: readonly number[],\n    transLeft: boolean,\n    rightShape: readonly number[],\n    transRight: boolean,\n    biasShape?: readonly number[],\n  ): readonly number[] {\n    if (leftShape.length !== 2 || rightShape.length !== 2) {\n      throw new Error('shape need to be of size 2');\n    }\n\n    let M: number;\n    let K: number;\n    let N: number;\n\n    if (transLeft) {\n      M = leftShape[1];\n      K = leftShape[0];\n    } else {\n      M = leftShape[0];\n      K = leftShape[1];\n    }\n\n    let kDim = -1;\n\n    if (transRight) {\n      N = rightShape[0];\n      kDim = 1;\n    } else {\n      N = rightShape[1];\n      kDim = 0;\n    }\n\n    if (rightShape[kDim] !== K) {\n      throw new Error('dimension mismatch');\n    }\n\n    if (M <= 0 || N <= 0 || K <= 0) {\n      throw new Error('invalid shape specified');\n    }\n\n    if (biasShape && !BroadcastUtil.isValidBroadcast(biasShape, [M, N])) {\n      throw new Error('gemm: invalid bias shape for broadcast');\n    }\n\n    return [M, N, K];\n  }\n}\n\nexport const MIN_CLIP = -3.4028234663852886e38;\nexport const MAX_CLIP = 3.4028234663852886e38;\n","// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport { Tensor } from 'onnxruntime-common';\n\nimport { tensorTypeToTypedArrayConstructor } from '../wasm-common';\n\nexport const createView = (\n  dataBuffer: ArrayBuffer,\n  type: Tensor.Type,\n):\n  | Int32Array\n  | Uint32Array\n  | BigInt64Array\n  | BigUint64Array\n  | Uint8Array\n  | Float32Array\n  | Float64Array\n  | Int8Array\n  | Int16Array\n  | Uint16Array => new (tensorTypeToTypedArrayConstructor(type))(dataBuffer);\n\n/**\n * a TensorView does not own the data.\n */\nexport interface TensorView {\n  readonly data: number;\n  readonly dataType: number;\n  readonly dims: readonly number[];\n\n  /**\n   * get a Float16Array data view of the tensor data. tensor data must be on CPU.\n   */\n  getUint16Array(): Uint16Array;\n\n  /**\n   * get a Float32Array data view of the tensor data. tensor data must be on CPU.\n   */\n  getFloat32Array(): Float32Array;\n\n  /**\n   * get a BigInt64Array data view of the tensor data. tensor data must be on CPU.\n   */\n  getBigInt64Array(): BigInt64Array;\n\n  /**\n   * get a Int32Array data view of the tensor data. tensor data must be on CPU.\n   */\n  getInt32Array(): Int32Array;\n\n  /**\n   * get a Uint16Array data view of the tensor data. tensor data must be on CPU.\n   */\n  getUint16Array(): Uint16Array;\n\n  /**\n   * create a new tensor view with the same data but different dimensions.\n   */\n  reshape(newDims: readonly number[]): TensorView;\n}\n","// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport { WebNNBackend } from '../backend-webnn';\nimport { LOG_DEBUG } from '../log';\n\n// WebNN API currently does not have a TypeScript definition file. This file is a workaround with types generated from\n// WebNN API specification.\n// https://github.com/webmachinelearning/webnn/issues/677\n/// <reference path=\"webnn.d.ts\" />\n\n// Convert BigInt64Array buffer data to Int32Array buffer data.\nexport const convertInt64ToInt32 = (data: Uint8Array, returnUint8 = true): Uint8Array | Int32Array => {\n  // Make sure it is a multiple of 8 bytes (BigInt64Array).\n  if (data.byteLength % 8 !== 0) {\n    throw new Error('Invalid Uint8Array length - must be a multiple of 8 (BigInt).');\n  }\n\n  // Convert Uint8Array to BigInt64Array.\n  const numElements = data.byteLength / 8;\n  const bigInt64Array = new BigInt64Array(data.buffer, data.byteOffset, numElements);\n\n  // Convert BigInt64Array to Int32Array (same number of elements).\n  const int32Array = new Int32Array(numElements);\n\n  for (let i = 0; i < numElements; i++) {\n    const value = bigInt64Array[i];\n\n    // Check for overflow.\n    if (value > 2147483647n || value < -2147483648n) {\n      throw new Error(`Overflow occurred when converting BigInt to Int32 at index ${i}: ${value}`);\n    }\n\n    int32Array[i] = Number(value);\n  }\n\n  // Return based on the requested format.\n  return returnUint8 ? new Uint8Array(int32Array.buffer) : int32Array;\n};\n\n// Convert Int32Array buffer data to BigInt64Array buffer data.\nconst convertInt32ToInt64 = (data: Uint8Array, returnUint8 = true): Uint8Array | BigInt64Array => {\n  // Make sure it is a multiple of 4 bytes (Int32Array).\n  if (data.byteLength % 4 !== 0) {\n    throw new Error('Invalid Uint8Array length - must be a multiple of 4 (Int32).');\n  }\n\n  // Convert Uint8Array to Int32Array.\n  const numElements = data.byteLength / 4;\n  const int32Array = new Int32Array(data.buffer, data.byteOffset, numElements);\n\n  // Convert Int32Array to BigInt64Array (same number of elements).\n  const bigInt64Array = BigInt64Array.from(int32Array, BigInt);\n\n  // Return based on the requested format.\n  return returnUint8 ? new Uint8Array(bigInt64Array.buffer) : bigInt64Array;\n};\n\nexport type TensorId = number;\n\n/**\n * Manages TensorId to MLTensor mapping.\n */\nexport interface TensorManager {\n  /**\n   * Reserve a new TensorId.\n   */\n  reserveTensorId(): TensorId;\n  /**\n   * Release a TensorId.\n   */\n  releaseTensorId(tensorId: TensorId): void;\n  /**\n   * Ensure a MLTensor is created for the TensorId.\n   */\n  ensureTensor(\n    sessionId: number,\n    tensorId: TensorId,\n    dataType: MLOperandDataType,\n    shape: readonly number[],\n    copyOld: boolean,\n  ): Promise<MLTensor>;\n  /**\n   * Upload data to a MLTensor.\n   */\n  upload(tensorId: TensorId, data: Uint8Array): void;\n  /**\n   * Download data from a MLTensor.\n   */\n  download(tensorId: TensorId): Promise<ArrayBuffer>;\n  download(tensorId: TensorId, dstTensor: ArrayBufferView | ArrayBuffer): Promise<undefined>;\n  /**\n   * Release all tensors for a given session.\n   */\n  releaseTensorsForSession(session: number): void;\n  /**\n   * Register an externally created MLTensor with a given session id and return a TensorId.\n   */\n  registerTensor(sessionId: number, mlTensor: MLTensor, dataType: MLOperandDataType, shape: number[]): TensorId;\n}\n\nlet tensorGuid = 1;\nconst createNewTensorId = (): TensorId => tensorGuid++;\n\n/**\n * Map from MLOperandDataType to size in bits. Using bits instead of bytes to avoid possible precision loss on int4 and uint4.\n */\nconst webnnDataTypeToSize = new Map<MLOperandDataType, number>([\n  ['float32', 32],\n  ['float16', 16],\n  ['int32', 32],\n  ['uint32', 32],\n  ['int64', 64],\n  ['uint64', 64],\n  ['int8', 8],\n  ['uint8', 8],\n  ['int4', 4],\n  ['uint4', 4],\n]);\n\n/**\n * Calculate the byte length of a tensor with the given data type and shape.\n */\nconst calculateByteLength = (dataType: MLOperandDataType, shape: readonly number[]): number => {\n  const size = webnnDataTypeToSize.get(dataType);\n  if (!size) {\n    throw new Error('Unsupported data type.');\n  }\n  return shape.length > 0 ? Math.ceil((shape.reduce((a, b) => a * b) * size) / 8) : 0;\n};\n\n/**\n * TensorWrapper wraps an MLTensor and provides a way to track the last session that used it.\n */\nclass TensorWrapper {\n  // The id of the last session that used this tensor.\n  public sessionId: number;\n  // This flag is used to indicate whether we should convert data from int64 to int32.\n  public shouldConvertInt64toInt32 = false;\n  public isInt64ToInt32Converted = false;\n\n  private mlContext: MLContext;\n  private mlTensor: MLTensor;\n  private dataType: MLOperandDataType;\n  private tensorShape: readonly number[];\n\n  constructor(descriptor: {\n    sessionId: number;\n    context: MLContext;\n    tensor: MLTensor;\n    dataType: MLOperandDataType;\n    shape: readonly number[];\n    shouldConvertInt64toInt32?: boolean;\n  }) {\n    const { sessionId, context, tensor, dataType, shape, shouldConvertInt64toInt32 = false } = descriptor;\n    this.sessionId = sessionId;\n    this.mlContext = context;\n    this.mlTensor = tensor;\n    this.dataType = dataType;\n    this.tensorShape = shape;\n    this.shouldConvertInt64toInt32 = shouldConvertInt64toInt32;\n  }\n\n  public get tensor(): MLTensor {\n    return this.mlTensor;\n  }\n\n  public get type(): MLOperandDataType {\n    return this.dataType;\n  }\n\n  public get shape(): readonly number[] {\n    return this.tensorShape;\n  }\n\n  public get byteLength(): number {\n    return calculateByteLength(this.dataType, this.tensorShape);\n  }\n\n  public destroy(): void {\n    LOG_DEBUG('verbose', () => '[WebNN] TensorWrapper.destroy');\n    this.mlTensor.destroy();\n  }\n\n  public write(data: Uint8Array): void {\n    this.mlContext.writeTensor(this.mlTensor, data);\n  }\n\n  public async read(shouldConvertInt32ToInt64?: boolean): Promise<ArrayBuffer>;\n  public async read(\n    shouldConvertInt32ToInt64?: boolean,\n    dstBuffer?: ArrayBufferView | ArrayBuffer,\n  ): Promise<ArrayBuffer | undefined>;\n  public async read(\n    shouldConvertInt32ToInt64?: boolean,\n    dstBuffer?: ArrayBufferView | ArrayBuffer,\n  ): Promise<ArrayBuffer | undefined> {\n    if (shouldConvertInt32ToInt64) {\n      // This was an int64 data as saved as int32 as workaround, we need to read it as int64.\n      const data = await this.mlContext.readTensor(this.mlTensor);\n      const int64Data = convertInt32ToInt64(new Uint8Array(data)) as Uint8Array;\n\n      if (dstBuffer) {\n        const targetBuffer =\n          dstBuffer instanceof ArrayBuffer\n            ? new Uint8Array(dstBuffer)\n            : new Uint8Array(dstBuffer.buffer, dstBuffer.byteOffset, dstBuffer.byteLength);\n        targetBuffer.set(int64Data);\n        return undefined;\n      } else {\n        return int64Data.buffer;\n      }\n    } else {\n      return dstBuffer ? this.mlContext.readTensor(this.mlTensor, dstBuffer) : this.mlContext.readTensor(this.mlTensor);\n    }\n  }\n\n  public canReuseTensor(context: MLContext, dataType: MLOperandDataType, shape: readonly number[]): boolean {\n    return (\n      this.mlContext === context &&\n      this.dataType === dataType &&\n      this.tensorShape.length === shape.length &&\n      this.tensorShape.every((v, i) => v === shape[i])\n    );\n  }\n\n  public setIsInt64ToInt32Converted(isConverted: boolean): void {\n    this.isInt64ToInt32Converted = isConverted;\n  }\n}\n\n/**\n * TensorTracker tracks the MLTensor and pending upload data.\n *\n * We need to track the MLTensor and pending upload data because we delay the creation of MLTensor until\n * we know the data type and shape. This is because WebNN only support creating MLTensors with dataTypes and shape.\n */\nclass TensorIdTracker {\n  private activeUpload?: Uint8Array;\n\n  constructor(\n    private tensorManager: TensorManagerImpl,\n    private wrapper?: TensorWrapper,\n  ) {}\n\n  public get tensorWrapper(): TensorWrapper | undefined {\n    return this.wrapper;\n  }\n\n  public releaseTensor(): void {\n    if (this.tensorWrapper) {\n      this.tensorManager.releaseTensor(this.tensorWrapper);\n      this.wrapper = undefined;\n    }\n  }\n\n  public async ensureTensor(\n    sessionId: number,\n    dataType: MLOperandDataType,\n    shape: readonly number[],\n    copyOld: boolean,\n  ): Promise<MLTensor> {\n    let newDataType = dataType;\n    const context = this.tensorManager.getMLContext(sessionId);\n    // If the data type is int64 and the context does not support int64, we need to convert it to int32.\n    const shouldConvertInt64toInt32 =\n      newDataType === 'int64' && !context.opSupportLimits().input.dataTypes.includes('int64');\n    if (shouldConvertInt64toInt32) {\n      newDataType = 'int32';\n      LOG_DEBUG('verbose', () => `[WebNN] TensorIdTracker.ensureTensor: convert dataType from int64 to int32`);\n    }\n\n    if (this.wrapper) {\n      if (this.wrapper.canReuseTensor(context, newDataType, shape)) {\n        return this.wrapper.tensor;\n      } else {\n        if (copyOld) {\n          if (this.wrapper.byteLength !== calculateByteLength(newDataType, shape)) {\n            throw new Error('Unable to copy data to tensor with different size.');\n          }\n          this.activeUpload = new Uint8Array(await this.wrapper.read());\n        }\n        this.tensorManager.releaseTensor(this.wrapper);\n      }\n    }\n\n    // eslint-disable-next-line no-bitwise\n    const usage = typeof MLTensorUsage == 'undefined' ? undefined : MLTensorUsage.READ | MLTensorUsage.WRITE;\n    this.wrapper = await this.tensorManager.getCachedTensor(\n      sessionId,\n      newDataType,\n      shape,\n      usage,\n      true,\n      true,\n      shouldConvertInt64toInt32,\n    );\n\n    if (copyOld && this.activeUpload) {\n      // We don't need to convert the old int64 data to int32,\n      // because it has been converted when it was uploaded.\n      this.wrapper.write(this.activeUpload);\n      this.activeUpload = undefined;\n    }\n\n    return this.wrapper.tensor;\n  }\n\n  public upload(data: Uint8Array): void {\n    let newData = data;\n    if (this.wrapper) {\n      if (this.wrapper.shouldConvertInt64toInt32) {\n        // Convert int64 to int32.\n        newData = convertInt64ToInt32(data, true) as Uint8Array;\n        this.wrapper.setIsInt64ToInt32Converted(true);\n      }\n      if (newData.byteLength === this.wrapper.byteLength) {\n        this.wrapper.write(newData);\n        return;\n      } else {\n        LOG_DEBUG('verbose', () => 'Data size does not match tensor size. Releasing tensor.');\n        this.releaseTensor();\n      }\n    }\n\n    if (this.activeUpload) {\n      this.activeUpload.set(newData);\n    } else {\n      this.activeUpload = new Uint8Array(newData);\n    }\n  }\n\n  public async download(dstBuffer?: ArrayBufferView | ArrayBuffer): Promise<ArrayBuffer | undefined> {\n    if (this.activeUpload) {\n      // If this.activeUpload has been converted to int32, we need to convert it back to int64 data.\n      const dstData = this.wrapper?.isInt64ToInt32Converted\n        ? (convertInt32ToInt64(this.activeUpload) as Uint8Array)\n        : this.activeUpload;\n\n      if (dstBuffer) {\n        if (dstBuffer instanceof ArrayBuffer) {\n          new Uint8Array(dstBuffer).set(dstData);\n        } else {\n          new Uint8Array(dstBuffer.buffer, dstBuffer.byteOffset, dstBuffer.byteLength).set(dstData);\n        }\n        return;\n      } else {\n        return dstData.buffer;\n      }\n    }\n    if (!this.wrapper) {\n      throw new Error('Tensor has not been created.');\n    }\n\n    if (!dstBuffer) {\n      return this.wrapper.read(this.wrapper?.shouldConvertInt64toInt32);\n    }\n    return this.wrapper.read(this.wrapper?.shouldConvertInt64toInt32, dstBuffer);\n  }\n}\n\nclass TensorManagerImpl implements TensorManager {\n  private tensorTrackersById: Map<TensorId, TensorIdTracker> = new Map();\n  private freeTensors: TensorWrapper[] = [];\n  private externalTensors: Set<TensorWrapper> = new Set();\n\n  constructor(private backend: WebNNBackend) {}\n\n  public getMLContext(sessionId: number): MLContext {\n    const context = this.backend.getMLContext(sessionId);\n    if (!context) {\n      throw new Error('MLContext not found for session.');\n    }\n    return context;\n  }\n\n  public reserveTensorId(): TensorId {\n    const tensorId = createNewTensorId();\n    this.tensorTrackersById.set(tensorId, new TensorIdTracker(this));\n    return tensorId;\n  }\n\n  public releaseTensorId(tensorId: TensorId): void {\n    const tensorTracker = this.tensorTrackersById.get(tensorId);\n    if (!tensorTracker) {\n      return;\n    }\n    this.tensorTrackersById.delete(tensorId);\n    if (tensorTracker.tensorWrapper) {\n      this.releaseTensor(tensorTracker.tensorWrapper);\n    }\n  }\n\n  public async ensureTensor(\n    sessionId: number,\n    tensorId: TensorId,\n    dataType: MLOperandDataType,\n    shape: number[],\n    copyOld: boolean,\n  ): Promise<MLTensor> {\n    LOG_DEBUG(\n      'verbose',\n      () =>\n        `[WebNN] TensorManager.ensureTensor {tensorId: ${tensorId}, dataType: ${\n          dataType\n        }, shape: ${shape}, copyOld: ${copyOld}}`,\n    );\n    const tensor = this.tensorTrackersById.get(tensorId);\n    if (!tensor) {\n      throw new Error('Tensor not found.');\n    }\n    return tensor.ensureTensor(sessionId, dataType, shape, copyOld);\n  }\n\n  public upload(tensorId: TensorId, data: Uint8Array): void {\n    const tensor = this.tensorTrackersById.get(tensorId);\n    if (!tensor) {\n      throw new Error('Tensor not found.');\n    }\n    tensor.upload(data);\n  }\n\n  public async download(tensorId: TensorId): Promise<ArrayBuffer>;\n  public async download(tensorId: TensorId, dstBuffer: ArrayBufferView | ArrayBuffer): Promise<undefined>;\n  async download(tensorId: TensorId, dstBuffer?: ArrayBufferView | ArrayBuffer): Promise<ArrayBuffer | undefined> {\n    LOG_DEBUG(\n      'verbose',\n      () => `[WebNN] TensorManager.download {tensorId: ${tensorId}, dstBuffer: ${dstBuffer?.byteLength}}`,\n    );\n    const tensorTracker = this.tensorTrackersById.get(tensorId);\n    if (!tensorTracker) {\n      throw new Error('Tensor not found.');\n    }\n    return tensorTracker.download(dstBuffer);\n  }\n\n  public releaseTensorsForSession(sessionId: number): void {\n    for (const tensor of this.freeTensors) {\n      if (tensor.sessionId === sessionId) {\n        tensor.destroy();\n      }\n    }\n    this.freeTensors = this.freeTensors.filter((tensor) => tensor.sessionId !== sessionId);\n  }\n\n  public registerTensor(\n    sessionId: number,\n    mlTensor: MLTensor,\n    dataType: MLOperandDataType,\n    shape: readonly number[],\n  ): TensorId {\n    const context = this.getMLContext(sessionId);\n    const tensorId = createNewTensorId();\n    // Defaulting to READ | WRITE if usage is not provided.\n    // eslint-disable-next-line no-bitwise\n    const wrapper = new TensorWrapper({\n      sessionId,\n      context,\n      tensor: mlTensor,\n      dataType,\n      shape,\n    });\n    this.tensorTrackersById.set(tensorId, new TensorIdTracker(this, wrapper));\n    this.externalTensors.add(wrapper);\n    return tensorId;\n  }\n\n  /**\n   * Get or create an MLTensor with the given data type and shape.\n   */\n  public async getCachedTensor(\n    sessionId: number,\n    dataType: MLOperandDataType,\n    shape: readonly number[],\n    usage: MLTensorUsageFlags | undefined,\n    writable: boolean,\n    readable: boolean,\n    shouldConvertInt64toInt32 = false,\n  ): Promise<TensorWrapper> {\n    const context = this.getMLContext(sessionId);\n    for (const [index, tensor] of this.freeTensors.entries()) {\n      if (tensor.canReuseTensor(context, dataType, shape)) {\n        LOG_DEBUG('verbose', () => `[WebNN] Reusing tensor {dataType: ${dataType}, shape: ${shape}}`);\n        const wrapper = this.freeTensors.splice(index, 1)[0];\n        wrapper.sessionId = sessionId;\n        return wrapper;\n      }\n    }\n    LOG_DEBUG('verbose', () => `[WebNN] MLContext.createTensor {dataType: ${dataType}, shape: ${shape}}`);\n    const tensor = await context.createTensor({\n      dataType,\n      shape,\n      dimensions: shape,\n      usage,\n      writable,\n      readable,\n    });\n    return new TensorWrapper({ sessionId, context, tensor, dataType, shape, shouldConvertInt64toInt32 });\n  }\n\n  /**\n   * Release tensor for reuse unless external.\n   */\n  public releaseTensor(tensorWrapper: TensorWrapper) {\n    if (this.externalTensors.has(tensorWrapper)) {\n      this.externalTensors.delete(tensorWrapper);\n    }\n    this.freeTensors.push(tensorWrapper);\n  }\n}\n\nexport const createTensorManager = (...args: ConstructorParameters<typeof TensorManagerImpl>): TensorManager =>\n  new TensorManagerImpl(...args);\n","// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\n// WebNN API currently does not have a TypeScript definition file. This file is a workaround with types generated from\n// WebNN API specification.\n// https://github.com/webmachinelearning/webnn/issues/677\n/// <reference path=\"webnn/webnn.d.ts\" />\n\nimport { Env, Tensor } from 'onnxruntime-common';\n\nimport { DataType } from '../wasm-common';\nimport { getInstance } from '../wasm-factory';\n\nimport { createView } from './tensor-view';\nimport { TensorId, createTensorManager, convertInt64ToInt32 } from './webnn/tensor-manager';\nimport { configureLogger, LOG_DEBUG } from './log';\n\n/*\n * TensorProto::data_type to WebNN OperandType mapping.\n */\nconst onnxDataTypeToWebnnDataType = new Map<DataType, MLOperandDataType>([\n  [DataType.float, 'float32'],\n  [DataType.float16, 'float16'],\n  [DataType.int32, 'int32'],\n  [DataType.uint32, 'uint32'],\n  [DataType.int64, 'int64'],\n  [DataType.uint64, 'uint64'],\n  [DataType.int4, 'int4'],\n  [DataType.uint4, 'uint4'],\n  [DataType.int8, 'int8'],\n  [DataType.uint8, 'uint8'],\n  [DataType.bool, 'uint8'],\n]);\n\ntype MLContextEntry = {\n  gpuDevice?: GPUDevice;\n  options?: MLContextOptions;\n  mlContext: MLContext;\n};\n\nconst compareMLContextOptions = (a?: MLContextOptions, b?: MLContextOptions): boolean => {\n  if (a === b) {\n    return true;\n  }\n  if (a === undefined || b === undefined) {\n    return false;\n  }\n  const aKeys = Object.keys(a).sort() as Array<keyof typeof a>;\n  const bKeys = Object.keys(b).sort() as Array<keyof typeof b>;\n  return aKeys.length === bKeys.length && aKeys.every((key, index) => key === bKeys[index] && a[key] === b[key]);\n};\n\n/**\n * WebNN backend implementation. This class is used to keep track of the MLTensors created by the backend and keep track\n * of the current MLContext being used by the sessions.\n */\nexport class WebNNBackend {\n  /**\n   * Tensor managers for each session.\n   */\n  private tensorManager = createTensorManager(this);\n  /**\n   * Maps from session id to MLContexts.\n   */\n  private mlContextBySessionId = new Map<number, MLContext>();\n  /**\n   * Maps from MLContext to session ids.\n   */\n  private sessionIdsByMLContext = new Map<MLContext, Set<number>>();\n  /**\n   * Cache of MLContexts.\n   */\n  private mlContextCache: MLContextEntry[] = [];\n  /**\n   * Current session id.\n   */\n  private activeSessionId?: number;\n  /**\n   * Maps from session id to list of graph inputs.\n   */\n  private sessionGraphInputs: Map<number, string[]> = new Map();\n  /**\n   * Temporary graph inputs for the current session.\n   * These inputs will be registered when the session is created.\n   */\n  private temporaryGraphInputs: string[] = [];\n  /**\n   * Temporary tensors for the current session.\n   */\n  private temporarySessionTensorIds: Map<number, TensorId[]> = new Map();\n\n  constructor(env: Env) {\n    configureLogger(env.logLevel!, !!env.debug);\n  }\n\n  public get currentSessionId(): number {\n    if (this.activeSessionId === undefined) {\n      throw new Error('No active session');\n    }\n    return this.activeSessionId;\n  }\n\n  public onRunStart(sessionId: number): void {\n    LOG_DEBUG('verbose', () => `[WebNN] onRunStart {sessionId: ${sessionId}}`);\n    this.activeSessionId = sessionId;\n  }\n\n  public onRunEnd(sessionId: number): void {\n    LOG_DEBUG('verbose', () => `[WebNN] onRunEnd {sessionId: ${sessionId}}`);\n    const tensorIds = this.temporarySessionTensorIds.get(sessionId);\n    if (!tensorIds) {\n      return;\n    }\n    for (const tensorId of tensorIds) {\n      LOG_DEBUG('verbose', () => `[WebNN] releasing temporary tensor {tensorId: ${tensorId}}`);\n      this.tensorManager.releaseTensorId(tensorId);\n    }\n    this.temporarySessionTensorIds.delete(sessionId);\n    this.activeSessionId = undefined;\n  }\n\n  public async createMLContext(optionsOrDevice?: MLContextOptions | GPUDevice): Promise<MLContext> {\n    if (optionsOrDevice instanceof GPUDevice) {\n      const mlContextIndex = this.mlContextCache.findIndex((entry) => entry.gpuDevice === optionsOrDevice);\n      if (mlContextIndex !== -1) {\n        return this.mlContextCache[mlContextIndex].mlContext;\n      } else {\n        const mlContext = await navigator.ml.createContext(optionsOrDevice);\n        this.mlContextCache.push({ gpuDevice: optionsOrDevice, mlContext });\n        return mlContext;\n      }\n    } else if (optionsOrDevice === undefined) {\n      const mlContextIndex = this.mlContextCache.findIndex(\n        (entry) => entry.options === undefined && entry.gpuDevice === undefined,\n      );\n      if (mlContextIndex !== -1) {\n        return this.mlContextCache[mlContextIndex].mlContext;\n      } else {\n        const mlContext = await navigator.ml.createContext();\n        this.mlContextCache.push({ mlContext });\n        return mlContext;\n      }\n    }\n\n    const mlContextIndex = this.mlContextCache.findIndex((entry) =>\n      compareMLContextOptions(entry.options, optionsOrDevice),\n    );\n    if (mlContextIndex !== -1) {\n      return this.mlContextCache[mlContextIndex].mlContext;\n    } else {\n      const mlContext = await navigator.ml.createContext(optionsOrDevice);\n      this.mlContextCache.push({ options: optionsOrDevice, mlContext });\n      return mlContext;\n    }\n  }\n\n  public registerMLContext(sessionId: number, mlContext: MLContext): void {\n    this.mlContextBySessionId.set(sessionId, mlContext);\n    let sessionIds = this.sessionIdsByMLContext.get(mlContext);\n    if (!sessionIds) {\n      sessionIds = new Set();\n      this.sessionIdsByMLContext.set(mlContext, sessionIds);\n    }\n    sessionIds.add(sessionId);\n\n    if (this.temporaryGraphInputs.length > 0) {\n      this.sessionGraphInputs.set(sessionId, this.temporaryGraphInputs);\n      this.temporaryGraphInputs = [];\n    }\n  }\n\n  public onReleaseSession(sessionId: number): void {\n    this.sessionGraphInputs.delete(sessionId);\n    const mlContext = this.mlContextBySessionId.get(sessionId)!;\n    if (!mlContext) {\n      // Current session is not a WebNN session.\n      return;\n    }\n    this.tensorManager.releaseTensorsForSession(sessionId);\n    this.mlContextBySessionId.delete(sessionId);\n    const sessionIds = this.sessionIdsByMLContext.get(mlContext)!;\n    sessionIds.delete(sessionId);\n    if (sessionIds.size === 0) {\n      this.sessionIdsByMLContext.delete(mlContext);\n      const mlContextIndex = this.mlContextCache.findIndex((entry) => entry.mlContext === mlContext);\n      if (mlContextIndex !== -1) {\n        this.mlContextCache.splice(mlContextIndex, 1);\n      }\n    }\n  }\n\n  public getMLContext(sessionId: number): MLContext | undefined {\n    return this.mlContextBySessionId.get(sessionId);\n  }\n\n  public reserveTensorId(): TensorId {\n    return this.tensorManager.reserveTensorId();\n  }\n\n  public releaseTensorId(tensorId: TensorId): void {\n    LOG_DEBUG('verbose', () => `[WebNN] releaseTensorId {tensorId: ${tensorId}}`);\n    this.tensorManager.releaseTensorId(tensorId);\n  }\n\n  public async ensureTensor(\n    sessionId: number | undefined,\n    tensorId: TensorId,\n    onnxDataType: DataType,\n    dimensions: number[],\n    copyOld: boolean,\n  ): Promise<MLTensor> {\n    const webnnDataType = onnxDataTypeToWebnnDataType.get(onnxDataType);\n    if (!webnnDataType) {\n      throw new Error(`Unsupported ONNX data type: ${onnxDataType}`);\n    }\n    return this.tensorManager.ensureTensor(\n      sessionId ?? this.currentSessionId,\n      tensorId,\n      webnnDataType,\n      dimensions,\n      copyOld,\n    );\n  }\n\n  public async createTemporaryTensor(\n    sessionId: number,\n    onnxDataType: DataType,\n    shape: readonly number[],\n  ): Promise<TensorId> {\n    LOG_DEBUG('verbose', () => `[WebNN] createTemporaryTensor {onnxDataType: ${onnxDataType}, shape: ${shape}}`);\n    const dataType = onnxDataTypeToWebnnDataType.get(onnxDataType);\n    if (!dataType) {\n      throw new Error(`Unsupported ONNX data type: ${onnxDataType}`);\n    }\n    const tensorId = this.tensorManager.reserveTensorId();\n    await this.tensorManager.ensureTensor(sessionId, tensorId, dataType, shape, false);\n    const tensorIds = this.temporarySessionTensorIds.get(sessionId);\n    if (!tensorIds) {\n      this.temporarySessionTensorIds.set(sessionId, [tensorId]);\n    } else {\n      tensorIds.push(tensorId);\n    }\n    return tensorId;\n  }\n\n  public uploadTensor(tensorId: TensorId, data: Uint8Array): void {\n    const wasm = getInstance();\n    if (!wasm.shouldTransferToMLTensor) {\n      throw new Error('Trying to upload to a MLTensor while shouldTransferToMLTensor is false');\n    }\n    LOG_DEBUG('verbose', () => `[WebNN] uploadTensor {tensorId: ${tensorId}, data: ${data.byteLength}}`);\n    this.tensorManager.upload(tensorId, data);\n  }\n\n  public async downloadTensor(tensorId: TensorId, dstBuffer: ArrayBufferView | ArrayBuffer): Promise<undefined> {\n    return this.tensorManager.download(tensorId, dstBuffer);\n  }\n\n  public createMLTensorDownloader(tensorId: TensorId, type: Tensor.MLTensorDataTypes): () => Promise<Tensor.DataType> {\n    return async () => {\n      const data = await this.tensorManager.download(tensorId);\n      return createView(data, type);\n    };\n  }\n\n  public registerMLTensor(sessionId: number, tensor: MLTensor, onnxDataType: DataType, dimensions: number[]): TensorId {\n    const webnnDataType = onnxDataTypeToWebnnDataType.get(onnxDataType);\n    if (!webnnDataType) {\n      throw new Error(`Unsupported ONNX data type: ${onnxDataType}`);\n    }\n\n    const id = this.tensorManager.registerTensor(sessionId, tensor, webnnDataType, dimensions);\n    LOG_DEBUG(\n      'verbose',\n      () =>\n        `[WebNN] registerMLTensor {tensor: ${tensor}, dataType: ${webnnDataType}, dimensions: ${\n          dimensions\n        }} -> {tensorId: ${id}}`,\n    );\n    return id;\n  }\n\n  // Register a WebNN Constant operand from external data.\n  public registerMLConstant(\n    externalFilePath: string,\n    dataOffset: number,\n    dataLength: number,\n    builder: MLGraphBuilder,\n    desc: MLOperandDescriptor,\n    mountedFiles: Map<string, Uint8Array> | undefined,\n    shouldConvertInt64ToInt32 = false,\n  ): MLOperand {\n    // If available, \"Module.MountedFiles\" is a Map for all preloaded files.\n    if (!mountedFiles) {\n      throw new Error('External mounted files are not available.');\n    }\n\n    let filePath = externalFilePath;\n    if (externalFilePath.startsWith('./')) {\n      filePath = externalFilePath.substring(2);\n    }\n    const fileData = mountedFiles.get(filePath);\n    if (!fileData) {\n      throw new Error(`File with name ${filePath} not found in preloaded files.`);\n    }\n\n    if (dataOffset + dataLength > fileData.byteLength) {\n      throw new Error('Out of bounds: data offset and length exceed the external file data size.');\n    }\n\n    const buffer = fileData.slice(dataOffset, dataOffset + dataLength).buffer;\n    let bufferView: ArrayBufferView;\n    switch (desc.dataType) {\n      case 'float32':\n        bufferView = new Float32Array(buffer);\n        break;\n      case 'float16':\n        bufferView =\n          typeof Float16Array !== 'undefined' && Float16Array.from ? new Float16Array(buffer) : new Uint16Array(buffer);\n        break;\n      case 'int32':\n        bufferView = new Int32Array(buffer);\n        break;\n      case 'uint32':\n        bufferView = new Uint32Array(buffer);\n        break;\n      case 'int64':\n        if (shouldConvertInt64ToInt32) {\n          // Int64 is not supported by current context, use int32 instead.\n          bufferView = convertInt64ToInt32(new Uint8Array(buffer), false) as Int32Array;\n          desc.dataType = 'int32';\n        } else {\n          bufferView = new BigInt64Array(buffer);\n        }\n        break;\n      case 'uint64':\n        bufferView = new BigUint64Array(buffer);\n        break;\n      case 'int8':\n        bufferView = new Int8Array(buffer);\n        break;\n      case 'int4':\n      case 'uint4':\n      case 'uint8':\n        bufferView = new Uint8Array(buffer);\n        break;\n      default:\n        throw new Error(`Unsupported data type: ${desc.dataType} in creating WebNN Constant from external data.`);\n    }\n\n    LOG_DEBUG(\n      'verbose',\n      () =>\n        `[WebNN] registerMLConstant {dataType: ${desc.dataType}, shape: ${desc.shape}}} ${\n          shouldConvertInt64ToInt32 ? '(Note: it was int64 data type and registered to int32 as workaround)' : ''\n        }`,\n    );\n\n    return builder.constant(desc, bufferView);\n  }\n\n  public registerGraphInput(inputName: string): void {\n    this.temporaryGraphInputs.push(inputName);\n  }\n\n  public isGraphInput(sessionId: number, inputName: string): boolean {\n    const inputNames = this.sessionGraphInputs.get(sessionId);\n    if (!inputNames) {\n      return false;\n    }\n    return inputNames.includes(inputName);\n  }\n\n  public isInt64Supported(sessionId: number): boolean {\n    const context = this.mlContextBySessionId.get(sessionId);\n    return !!context?.opSupportLimits().input.dataTypes.includes('int64');\n  }\n\n  public flush(): void {\n    // Unlike the WebGPU backend, the WebNN backend does not need to flush any pending operations.\n  }\n}\n","// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport { DataType } from '../../wasm-common';\nimport { TensorView } from '../tensor-view';\n\nimport { ShaderHelper } from './ops/common';\n\nexport type SessionState = 'default' | 'capturing' | 'replaying';\n\nexport enum GpuDataType {\n  default = 0,\n  upload = 1,\n  profile = 2,\n}\nexport type GpuDataId = number;\n\nexport type GpuArchitecture = 'ampere' | 'gen-12lp';\nexport type GpuVendor = 'amd' | 'intel' | 'nvidia';\nexport interface AdapterInfo {\n  isArchitecture: (architecture: GpuArchitecture) => boolean;\n  isVendor: (vendor: GpuVendor) => boolean;\n}\n\nexport interface GpuData {\n  type: GpuDataType;\n  id: GpuDataId;\n  buffer: GPUBuffer;\n}\n\nexport interface TensorInfo {\n  dims: readonly number[];\n  dataType: number;\n}\n\nexport interface ProgramUniform {\n  type: DataType;\n  data: number | readonly number[];\n}\n\nexport type ProgramUniformVariableInfo = [type: DataType, length: number];\n\n/**\n * Represent the dependency of a program on a specific input tensor.\n *\n * - 'none': the shader/uniform does not depend on this input's info\n * - 'type': the shader/uniform depends on data type of this input\n * - 'rank': the shader/uniform depends on data type and the rank of this input\n * - 'dims': the shader/uniform depends on data type and the dims of this input\n * - 'data': the shader/uniform depends on data type, the dims and the data of this input\n */\nexport type ProgramInputTensorInfoDependency = 'none' | 'type' | 'rank' | 'dims' | 'data';\n\n/**\n * Represent information about a program's cache for shader.\n */\nexport interface ProgramShaderCacheInfo {\n  /**\n   * an optional string as a cache hint in the artifact cache. If this is not specified, the cache hint will be empty.\n   *\n   * This hint string should only contains initializing-time information, such as the attributes or any information of\n   * initializers. It should NOT contain any runtime information, such as the shape of inputs.\n   */\n  hint?: string;\n\n  /**\n   * an optional list of dependencies of the program on the input tensors. If this is not specified, the program depends\n   * on 'dims' of all inputs.\n   */\n  inputDependencies?: ProgramInputTensorInfoDependency[];\n}\n\n/**\n * Represent information about a program's cache for uniform.\n */\nexport interface ProgramUniformCacheInfo {\n  /**\n   * an optional string as a cache hint in the uniform cache. If this is not specified, the cache hint will be empty.\n   *\n   * This hint string should only contains runtime information, such as the shape of inputs.\n   */\n  hint?: string;\n\n  /**\n   * an optional list of dependencies of the program on the input tensors. If this is not specified, the program depends\n   * on 'none' of all inputs.\n   */\n  inputDependencies?: ProgramInputTensorInfoDependency[];\n}\n\n/**\n * A set of data that represent a shader program\n */\nexport interface ProgramInfo {\n  /**\n   * the name of the program. used for debugging and profiling\n   */\n  name: string;\n\n  /**\n   * an optional object describing the cache information of the program shader.\n   *\n   * If this is not specified, assume hint is empty and inputDependencies are ['dims'] for all inputs.\n   */\n  shaderCache?: ProgramShaderCacheInfo;\n\n  /**\n   * the shader's processing source code.\n   *\n   * This function will be called when shader cache missed.\n   */\n  getShaderSource: (shaderHelper: ShaderHelper) => string;\n\n  /**\n   * A function to get run data required to run the program.\n   *\n   * This function will be called every time the program is executed. Should keep this function as simple as possible.\n   */\n  getRunData: (inputs: readonly TensorView[]) => {\n    outputs: readonly TensorInfo[];\n    dispatchGroup: { x: number; y?: number; z?: number };\n    programUniforms?: readonly ProgramUniform[];\n  };\n}\n\nexport interface Artifact {\n  programInfo: ProgramInfo;\n  computePipeline: GPUComputePipeline;\n  uniformVariablesInfo: readonly ProgramUniformVariableInfo[] | undefined;\n}\n\nexport interface ComputeContextInputsOutputsMapping {\n  /**\n   * specify the mapping to the program's inputs. the value can be a number or a tensor view.\n   * - if it's a number, it's the index of the kernel's input\n   * - if it's a tensor view, it's an existing tensor view that will be used as the input\n   *\n   * if inputs is not specified, the mapping will be the kernel's inputs in order.\n   */\n  readonly inputs?: ReadonlyArray<TensorView | number>;\n  /**\n   * specify the mapping to the program's outputs. the value must be a number.\n   * - if it's a non-negative number, it's the index of the kernel's output\n   * - if it's -1, it's an output that will be created as a temporary value. this value will be released after\n   * the kernel is executed.\n   * - if it's -2, it's an output that will be created as a persistent value. this value will be released when the\n   * kernel is released.\n   *\n   * if outputs is not specified, the mapping will be the kernel's outputs in order.\n   */\n  readonly outputs?: readonly number[];\n}\n\n/**\n * A ComputeContext instance carries the states that representing the current running of a kernel.\n */\nexport interface ComputeContext {\n  /**\n   * gpu adapter info\n   */\n  readonly adapterInfo: AdapterInfo;\n\n  /**\n   * stores the pointer to OpKernelContext\n   */\n  readonly opKernelContext: number;\n\n  /**\n   * a list of inputs, each input is an instance of TensorView\n   */\n  readonly inputs: readonly TensorView[];\n\n  /**\n   * a custom data object that can be used to store any data that is needed by the kernel\n   */\n  readonly kernelCustomData: { [key: string]: unknown };\n\n  /**\n   * a buffer that can be used to access custom data created each time the kernel is executed\n   */\n  readonly customDataBuffer: Uint8Array;\n\n  /**\n   * a number of outputs for the node\n   */\n  readonly outputCount: number;\n\n  compute(program: ProgramInfo, inputsOutputsMapping?: ComputeContextInputsOutputsMapping): TensorView[];\n  output(index: number, dims: readonly number[]): number;\n}\n\nexport type TimestampQuery = 'none' | 'inside-passes' | 'at-passes';\n","// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport { WebGpuBackend } from '../backend-webgpu';\nimport { LOG_DEBUG } from '../log';\n\nimport { GpuData, GpuDataId, GpuDataType } from './types';\n\n/**\n * manages GpuDataId -> GpuBuffer\n */\nexport interface GpuDataManager {\n  /**\n   * copy data from CPU to GPU.\n   */\n  upload(id: GpuDataId, data: Uint8Array): void;\n  /**\n   * copy data from GPU to GPU.\n   */\n  memcpy(sourceId: GpuDataId, destinationId: GpuDataId): void;\n  /**\n   * create new data on GPU.\n   */\n  create(size: number, usage?: number): GpuData;\n  /**\n   * get GPU data by ID.\n   */\n  get(id: GpuDataId): GpuData | undefined;\n  /**\n   * release the data on GPU by ID.\n   *\n   * @return size of the data released\n   */\n  release(id: GpuDataId): number;\n  /**\n   * copy data from GPU to CPU.\n   */\n  download(id: GpuDataId, getTargetBuffer: () => Uint8Array): Promise<void>;\n\n  /**\n   * refresh the buffers that marked for release.\n   *\n   * when release() is called, the buffer is not released immediately. this is because we need to wait for the commands\n   * to be submitted to the GPU. this function is called after the commands are submitted so that the buffers can be\n   * actually released.\n   */\n  refreshPendingBuffers(): void;\n\n  /**\n   * register an external buffer for IO Binding. If the buffer is already registered, return the existing GPU data ID.\n   *\n   * GPU data manager only manages a mapping between the buffer and the GPU data ID. It will not manage the lifecycle of\n   * the external buffer.\n   */\n  registerExternalBuffer(buffer: GPUBuffer, originalSize: number, previous?: [GpuDataId, GPUBuffer]): number;\n\n  /**\n   * unregister an external buffer for IO Binding.\n   */\n  unregisterExternalBuffer(id: GpuDataId): void;\n\n  /**\n   * destroy all gpu buffers.\n   */\n  dispose(): void;\n\n  /**\n   * create session related data.\n   */\n  onCreateSession(): void;\n\n  /**\n   * release session related data.\n   * @param sessionId - specify the session ID.\n   */\n  onReleaseSession(sessionId: number): void;\n}\n\ninterface StorageCacheValue {\n  gpuData: GpuData;\n  originalSize: number;\n}\n\nconst bucketFreelist: Map<number, number> = new Map([\n  [64, 250],\n  [128, 200],\n  [256, 200],\n  [512, 200],\n  [2048, 230],\n  [4096, 200],\n  [8192, 50],\n  [16384, 50],\n  [32768, 50],\n  [65536, 50],\n  [131072, 50],\n  [262144, 50],\n  [524288, 50],\n  [1048576, 50],\n  [2097152, 30],\n  [4194304, 20],\n  [8388608, 10],\n  [12582912, 10],\n  [16777216, 10],\n  [26214400, 15],\n  [33554432, 22],\n  [44236800, 2],\n  [58982400, 6],\n  // we don't want to cache the bucket sizes below but not caching them\n  // results in some major performance hits for models like sd-turbo.\n  [67108864, 6],\n  [134217728, 6],\n  [167772160, 6],\n]);\n\nconst bucketArr: number[] = [];\n\n/**\n * normalize the buffer size so that it fits the 128-bits (16 bytes) alignment.\n */\nconst calcNormalizedBufferSize = (size: number) => Math.ceil(Number(size) / 16) * 16;\n\n/**\n * calculate the buffer size so that it fits into buckets.\n */\nconst calcBucketBufferSize = (size: number) => {\n  for (let idx = 0; idx < bucketArr.length; idx++) {\n    const sizeForBucket = bucketArr[idx];\n    if (size <= sizeForBucket) {\n      return sizeForBucket;\n    }\n  }\n  // not in bucket list -> caller will not cache, round up to 16.\n  return Math.ceil(size / 16) * 16;\n};\n\nlet guid = 1;\nconst createNewGpuDataId = () => guid++;\n\n/**\n * exported standard download function. This function is used by the session to download the data from GPU, and also by\n * factory to create GPU tensors with the capacity of downloading data from GPU.\n *\n * @param backend - the WebGPU backend\n * @param gpuBuffer - the GPU buffer to download\n * @param originalSize - the original size of the data\n * @param getTargetBuffer - optional. If provided, the data will be copied to the target buffer. Otherwise, a new buffer\n * will be created and returned.\n */\nexport const downloadGpuData = async (\n  backend: WebGpuBackend,\n  gpuBuffer: GPUBuffer,\n  originalSize: number,\n  getTargetBuffer?: () => Uint8Array,\n): Promise<Uint8Array> => {\n  const bufferSize = calcNormalizedBufferSize(originalSize);\n  const gpuReadBuffer = backend.device.createBuffer(\n    // eslint-disable-next-line no-bitwise\n    { size: bufferSize, usage: GPUBufferUsage.COPY_DST | GPUBufferUsage.MAP_READ },\n  );\n  try {\n    const commandEncoder = backend.getCommandEncoder();\n    backend.endComputePass();\n    commandEncoder.copyBufferToBuffer(\n      gpuBuffer /* source buffer */,\n      0 /* source offset */,\n      gpuReadBuffer /* destination buffer */,\n      0 /* destination offset */,\n      bufferSize /* size */,\n    );\n    backend.flush();\n\n    await gpuReadBuffer.mapAsync(GPUMapMode.READ);\n\n    const arrayBuffer = gpuReadBuffer.getMappedRange();\n    if (getTargetBuffer) {\n      // if we already have a CPU buffer to accept the data, no need to clone the ArrayBuffer.\n      const targetBuffer = getTargetBuffer();\n      targetBuffer.set(new Uint8Array(arrayBuffer, 0, originalSize));\n      return targetBuffer;\n    } else {\n      // the mapped ArrayBuffer will be released when the GPU buffer is destroyed. Need to clone the\n      // ArrayBuffer.\n      return new Uint8Array(arrayBuffer.slice(0, originalSize));\n    }\n  } finally {\n    gpuReadBuffer.destroy();\n  }\n};\n\nclass GpuDataManagerImpl implements GpuDataManager {\n  // GPU Data ID => GPU Data ( storage buffer )\n  private storageCache: Map<GpuDataId, StorageCacheValue>;\n\n  // pending buffers for computing\n  private buffersPending: GPUBuffer[];\n\n  // The reusable storage buffers for computing.\n  private freeBuffers: Map<number, GPUBuffer[]>;\n  // The reusable uniform buffers\n  private freeUniformBuffers: Map<number, GPUBuffer[]>;\n\n  // The pendingBuffers for capture graph.\n  // a SessionID -> GPUBuffer[] mapping.\n  private capturedPendingBuffers: Map<number, GPUBuffer[]>;\n\n  // The session count.\n  private sessionCount: number;\n\n  constructor(private backend: WebGpuBackend) {\n    this.storageCache = new Map();\n    this.freeBuffers = new Map();\n    this.freeUniformBuffers = new Map();\n    this.buffersPending = [];\n    this.capturedPendingBuffers = new Map();\n\n    for (const [key] of bucketFreelist) {\n      bucketArr.push(key);\n      this.freeBuffers.set(key, []);\n      this.freeUniformBuffers.set(key, []);\n    }\n\n    this.sessionCount = 0;\n  }\n\n  upload(id: GpuDataId, data: Uint8Array): void {\n    const srcArrayBuffer = data.buffer;\n    const srcOffset = data.byteOffset;\n    const srcLength = data.byteLength;\n    const size = calcNormalizedBufferSize(srcLength);\n\n    // get destination gpu buffer\n    const gpuDataCache = this.storageCache.get(id);\n    if (!gpuDataCache) {\n      throw new Error('gpu data for uploading does not exist');\n    }\n    if (Number(gpuDataCache.originalSize) !== srcLength) {\n      throw new Error(`inconsistent data size. gpu data size=${gpuDataCache.originalSize}, data size=${srcLength}`);\n    }\n\n    // create gpu buffer\n    const gpuBufferForUploading = this.backend.device.createBuffer(\n      // eslint-disable-next-line no-bitwise\n      { mappedAtCreation: true, size, usage: GPUBufferUsage.MAP_WRITE | GPUBufferUsage.COPY_SRC },\n    );\n\n    // copy (upload) data\n    const arrayBuffer = gpuBufferForUploading.getMappedRange();\n    new Uint8Array(arrayBuffer).set(new Uint8Array(srcArrayBuffer, srcOffset, srcLength));\n    gpuBufferForUploading.unmap();\n\n    // GPU copy\n    const commandEncoder = this.backend.device.createCommandEncoder();\n    commandEncoder.copyBufferToBuffer(gpuBufferForUploading, 0, gpuDataCache.gpuData.buffer, 0, size);\n    this.backend.device.queue.submit([commandEncoder.finish()]);\n    gpuBufferForUploading.destroy();\n\n    LOG_DEBUG('verbose', () => `[WebGPU] GpuDataManager.upload(id=${id})`);\n  }\n\n  memcpy(sourceId: GpuDataId, destinationId: GpuDataId): void {\n    // get source gpu buffer\n    const sourceGpuDataCache = this.storageCache.get(sourceId);\n    if (!sourceGpuDataCache) {\n      throw new Error('source gpu data for memcpy does not exist');\n    }\n    // get destination gpu buffer\n    const destinationGpuDataCache = this.storageCache.get(destinationId);\n    if (!destinationGpuDataCache) {\n      throw new Error('destination gpu data for memcpy does not exist');\n    }\n    if (sourceGpuDataCache.originalSize !== destinationGpuDataCache.originalSize) {\n      throw new Error('inconsistent source and destination gpu data size');\n    }\n\n    const size = calcNormalizedBufferSize(sourceGpuDataCache.originalSize);\n\n    // GPU copy\n    const commandEncoder = this.backend.getCommandEncoder();\n    this.backend.endComputePass();\n    commandEncoder.copyBufferToBuffer(\n      sourceGpuDataCache.gpuData.buffer,\n      0,\n      destinationGpuDataCache.gpuData.buffer,\n      0,\n      size,\n    );\n  }\n\n  registerExternalBuffer(buffer: GPUBuffer, originalSize: number, previous?: [GpuDataId, GPUBuffer]): number {\n    let id: number | undefined;\n    if (previous) {\n      id = previous[0];\n      if (buffer === previous[1]) {\n        LOG_DEBUG(\n          'verbose',\n          () =>\n            `[WebGPU] GpuDataManager.registerExternalBuffer(size=${originalSize}) => id=${id}, buffer is the same, skip.`,\n        );\n        return id;\n      } else if (this.backend.capturedCommandList.has(this.backend.currentSessionId!)) {\n        throw new Error(`Registering a different external buffer under graph capture mode is not supported yet.\n             Please use the previous external buffer!`);\n      }\n    } else {\n      id = createNewGpuDataId();\n    }\n\n    this.storageCache.set(id, { gpuData: { id, type: GpuDataType.default, buffer }, originalSize });\n    LOG_DEBUG(\n      'verbose',\n      () => `[WebGPU] GpuDataManager.registerExternalBuffer(size=${originalSize}) => id=${id}, registered.`,\n    );\n    return id;\n  }\n\n  unregisterExternalBuffer(id: GpuDataId): void {\n    if (id !== undefined) {\n      this.storageCache.delete(id);\n      LOG_DEBUG('verbose', () => `[WebGPU] GpuDataManager.unregisterExternalBuffer() => id=${id}`);\n    }\n  }\n\n  // eslint-disable-next-line no-bitwise\n  create(size: number, usage = GPUBufferUsage.STORAGE | GPUBufferUsage.COPY_SRC | GPUBufferUsage.COPY_DST): GpuData {\n    const bufferSize = calcBucketBufferSize(size);\n\n    let gpuBuffer;\n    // Currently, only storage buffers are reused.\n    // eslint-disable-next-line no-bitwise\n    const isStorage = (usage & GPUBufferUsage.STORAGE) === GPUBufferUsage.STORAGE;\n    // eslint-disable-next-line no-bitwise\n    const isUniform = (usage & GPUBufferUsage.UNIFORM) === GPUBufferUsage.UNIFORM;\n    if (isStorage || isUniform) {\n      const freeBuffers = isStorage ? this.freeBuffers : this.freeUniformBuffers;\n      const buffers = freeBuffers.get(bufferSize);\n      if (!buffers) {\n        // no such bucket/freelist - create gpu buffer\n        gpuBuffer = this.backend.device.createBuffer({ size: bufferSize, usage });\n      } else {\n        if (buffers.length > 0) {\n          // in freelist, use it\n          gpuBuffer = buffers.pop() as GPUBuffer;\n        } else {\n          // bucket empty, create gpu buffer\n          gpuBuffer = this.backend.device.createBuffer({ size: bufferSize, usage });\n        }\n      }\n    } else {\n      // create gpu buffer\n      gpuBuffer = this.backend.device.createBuffer({ size: bufferSize, usage });\n    }\n\n    const gpuData = { id: createNewGpuDataId(), type: GpuDataType.default, buffer: gpuBuffer };\n    this.storageCache.set(gpuData.id, { gpuData, originalSize: Number(size) });\n\n    LOG_DEBUG('verbose', () => `[WebGPU] GpuDataManager.create(size=${size}) => id=${gpuData.id}`);\n    return gpuData;\n  }\n\n  get(id: GpuDataId): GpuData | undefined {\n    return this.storageCache.get(id)?.gpuData;\n  }\n\n  release(idInput: GpuDataId): number {\n    const id = typeof idInput === 'bigint' ? Number(idInput) : idInput;\n    const cachedData = this.storageCache.get(id);\n    if (!cachedData) {\n      if (this.storageCache.size === 0) {\n        // cache was previously cleared, no need to release anything.\n        return 0;\n      } else {\n        throw new Error('releasing data does not exist');\n      }\n    }\n\n    LOG_DEBUG('verbose', () => `[WebGPU] GpuDataManager.release(id=${id}), gpuDataId=${cachedData.gpuData.id}`);\n\n    this.storageCache.delete(id);\n    this.buffersPending.push(cachedData.gpuData.buffer);\n    // cachedData.gpuData.buffer.destroy();\n\n    return cachedData.originalSize;\n  }\n\n  async download(id: GpuDataId, getTargetBuffer: () => Uint8Array): Promise<void> {\n    const cachedData = this.storageCache.get(Number(id));\n    if (!cachedData) {\n      throw new Error('data does not exist');\n    }\n    await downloadGpuData(this.backend, cachedData.gpuData.buffer, cachedData.originalSize, getTargetBuffer);\n  }\n\n  refreshPendingBuffers(): void {\n    if (this.buffersPending.length === 0) {\n      return;\n    }\n\n    if (this.backend.sessionStatus === 'default') {\n      for (const buffer of this.buffersPending) {\n        const maxInFreeList = bucketFreelist.get(buffer.size);\n\n        // eslint-disable-next-line no-bitwise\n        if ((buffer.usage & GPUBufferUsage.STORAGE) === GPUBufferUsage.STORAGE) {\n          // Put the pending buffer to freeBuffers list instead of really destroying it for buffer reusing.\n          const freelist = this.freeBuffers.get(buffer.size) || [];\n          if (maxInFreeList === undefined || freelist.length >= maxInFreeList) {\n            buffer.destroy();\n          } else {\n            freelist.push(buffer);\n          }\n          // eslint-disable-next-line no-bitwise\n        } else if ((buffer.usage & GPUBufferUsage.UNIFORM) === GPUBufferUsage.UNIFORM) {\n          // Put the pending buffer to freeUniformBuffers list instead of really destroying it for buffer reusing.\n          const freelist = this.freeUniformBuffers.get(buffer.size) || [];\n          if (maxInFreeList === undefined || freelist.length >= maxInFreeList) {\n            buffer.destroy();\n          } else {\n            freelist.push(buffer);\n          }\n        } else {\n          buffer.destroy();\n        }\n      }\n      this.buffersPending = [];\n    } else {\n      // Don't release intermediate tensors in non-default mode.\n      // TODO: reuse the storage buffers in non-default mode.\n      let capturedBuffers = this.capturedPendingBuffers.get(this.backend.currentSessionId!);\n      if (!capturedBuffers) {\n        capturedBuffers = [];\n        this.capturedPendingBuffers.set(this.backend.currentSessionId!, capturedBuffers);\n      }\n      for (const buffer of this.buffersPending) {\n        capturedBuffers.push(buffer);\n      }\n      this.buffersPending = [];\n    }\n  }\n\n  dispose() {\n    this.freeBuffers.forEach((buffers) => {\n      buffers.forEach((buffer) => {\n        buffer.destroy();\n      });\n    });\n    this.freeUniformBuffers.forEach((buffers) => {\n      buffers.forEach((buffer) => {\n        buffer.destroy();\n      });\n    });\n\n    this.storageCache.forEach((storage) => {\n      storage.gpuData.buffer.destroy();\n    });\n\n    this.capturedPendingBuffers.forEach((buffers) => {\n      buffers.forEach((buffer) => {\n        buffer.destroy();\n      });\n    });\n    this.storageCache = new Map();\n    this.freeBuffers = new Map();\n    this.freeUniformBuffers = new Map();\n    this.capturedPendingBuffers = new Map();\n  }\n\n  onCreateSession() {\n    this.sessionCount += 1;\n  }\n\n  onReleaseSession(sessionId: number) {\n    // release the captured pending buffers.\n    const pendingBuffers = this.capturedPendingBuffers.get(sessionId);\n    if (pendingBuffers) {\n      pendingBuffers.forEach((buffer) => {\n        buffer.destroy();\n      });\n      this.capturedPendingBuffers.delete(sessionId);\n    }\n\n    // release the storage cache if no active sessions.\n    this.sessionCount -= 1;\n    if (this.sessionCount === 0) {\n      LOG_DEBUG('warning', () => '[WebGPU] Clearing webgpu buffer cache');\n      this.storageCache.forEach((storage) => {\n        storage.gpuData.buffer.destroy();\n      });\n      this.storageCache = new Map();\n    }\n  }\n}\n\nexport const createGpuDataManager = (...args: ConstructorParameters<typeof GpuDataManagerImpl>): GpuDataManager =>\n  new GpuDataManagerImpl(...args);\n","// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nclass AttributeWithCacheKeyImpl {\n  constructor(attribute: Record<string, unknown>) {\n    Object.assign(this, attribute);\n  }\n\n  private key: string;\n  public get cacheKey(): string {\n    if (!this.key) {\n      this.key = Object.getOwnPropertyNames(this)\n        .sort()\n        .map((name) => `${(this as Record<string, unknown>)[name]}`)\n        .join(';');\n    }\n    return this.key;\n  }\n}\n\nexport interface AttributeWithCacheKey {\n  readonly cacheKey: string;\n}\n\n/**\n * create a new object from the given attribute, and add a cacheKey property to it\n */\nexport const createAttributeWithCacheKey = <T extends Record<string, unknown>>(\n  attribute: T,\n): T & AttributeWithCacheKey => new AttributeWithCacheKeyImpl(attribute) as unknown as T & AttributeWithCacheKey;\n","// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport { DataType } from '../../../wasm-common';\nimport { ShapeUtil } from '../../util';\nimport { ProgramUniform, ProgramUniformVariableInfo } from '../types';\n\n/**\n * constant value for a workgroup size.\n *\n * We definitely can do further optimization in future, but for now we use 64.\n *\n * rule of thumb: Use [a workgroup size of] 64 unless you know what GPU you are targeting or that your workload\n *                needs something different.\n *\n * from: https://surma.dev/things/webgpu/\n **/\nexport const WORKGROUP_SIZE = 64;\n\ninterface IndicesHelperTypes {\n  /**\n   * WGSL type of indices expression\n   */\n  readonly indices: string;\n\n  /**\n   * WGSL type of a value\n   */\n  readonly value: string;\n\n  /**\n   * WGSL type of storage type representing a value\n   *\n   * This is usually the same to `value`, but for some type (eg. bool), we need to use `u32` as storage type for\n   * value type `vec4<bool>`\n   */\n  readonly storage: string;\n\n  /**\n   * tensor type as represented in TensorView\n   */\n  readonly tensor: number;\n}\n\n/**\n * A helper class for generating WGSL code for manipulating indices and data for a shader's input or output.\n *\n * This class is designed to offer a unified way to generate WGSL code for manipulating indices and data for a shader's\n * input or output.\n *\n * The following is a list of terminologies used in this class:\n * - `offset`: a uint32 value representing the offset of an element in the data buffer.\n * - `indices`: an abstraction of a multi-dimensional array's indices representing the data's index on each dimension.\n * - `value`: a value of a data element.\n *\n * Users are expected to create an instance of this class for each shader's input or output, and use the instance to\n * generate WGSL code for manipulating indices and data. The following 2 exported functions are for users to call to\n * create an instance of an indices helper:\n * - `inputVariable()`: create an indices helper instance for an input.\n * - `outputVariable()`: create an indices helper instance for an output.\n * - `internalVariable()`: create an indices helper instance for an internal variable.\n *\n * An indices helper instance contains helper functions for the following operations:\n * - access readonly basic information, including: `name`(the name of the input or output), `usage`(whether it's an\n * input, an output or an internal variable) and `shape`(the passed in shape).\n * - `type`: access readonly type information, including: `indices`(the type of indices), `value`(the type of value at\n * runtime), `storage`(the type of value at storage) and `tensor`(the tensor type as represented in TensorView).\n * - generate WGSL code for getting indices from offset. Use `offsetToIndices()` for WGSL code snippet to calculate\n * indices from offset, and use `indicesToOffset()` for WGSL code snippet to calculate offset from indices.\n * - to manipulate an instance of indices, use `setIndices()` and `getIndices()` to set and get the indices on an\n * indices variable.\n * - to manipulate data, use `set()`/`get()` to access data at the given indices from parameter list, use\n * `setByIndices()`/`getByIndices()` to access data at the given indices from an indices variable, and use\n * `setByOffset()`/`getByOffset()` to access data at the given offset.\n * - `impl`: get WGSL code of function implementation for the util functions mentioned above.\n */\nexport interface IndicesHelper {\n  /**\n   * get WGSL code of function implementation for the util functions.\n   *\n   */\n  readonly impl: () => string;\n\n  /**\n   * get type info\n   */\n  readonly type: IndicesHelperTypes;\n\n  /**\n   * WGSL code of a expression for getting indices from offset.\n   *\n   * @param varOffset - a u32 expression representing the offset.\n   *\n   * @returns an `type.indices` expression\n   */\n  readonly offsetToIndices: (varOffset: string) => string;\n\n  /**\n   * WGSL code of an `u32` expression for getting offset from indices.\n   *\n   * @param varIndices - a `type.indices` expression representing the indices.\n   *\n   * @returns an `u32` expression\n   */\n  readonly indicesToOffset: (varIndices: string) => string;\n\n  /**\n   * WGSL code of an `u32` expression for getting original offset from broadcasted indices.\n   *\n   * @param varIndices - a `type.indices` expression representing the output indices.\n   * @param output - output IndicesHelper.\n   *\n   * @returns an `u32` expression\n   */\n  readonly broadcastedIndicesToOffset: (varIndices: string, output: IndicesHelper) => string;\n\n  /**\n   * WGSL code of generating an indices literal\n   *\n   * @param init - initial value.\n   */\n  readonly indices: (...init: ReadonlyArray<number | string>) => string;\n\n  /**\n   * WGSL code of a statement for setting indices.\n   *\n   * @param varIndices - a variable name for the indices.\n   * @param idx - the index of the indices to set. can be a number or a string (WGSL `u32` expression).\n   * @param value - the value to set. can be a number or a string (WGSL `u32` expression).\n   *\n   * @returns a WGSL statement\n   */\n  readonly indicesSet: (varIndices: string, idx: number | string, value: number | string) => void;\n\n  /**\n   * WGSL code of an `u32` expression for getting indices.\n   *\n   * @param varIndices - a variable name for the indices.\n   * @param idx - the index of the indices to get. can be a number or a string (WGSL `u32` expression).\n   *\n   * @returns an `u32` expression\n   */\n  readonly indicesGet: (varIndices: string, idx: number | string) => string;\n\n  /**\n   * WGSL code for a statement for setting data at the given indices.\n   *\n   * @param indicesAndValue - an array of numbers or strings (WGSL `u32` expression) representing the indices, followed\n   *     by the value to set. This array should have exactly `shape.length + 1` elements.\n   */\n  readonly set: (...indicesAndValue: ReadonlyArray<number | string>) => string;\n\n  /**\n   * WGSL code for a statement for setting data at the given indices variable.\n   *\n   * @param varIndices - a variable name for the indices.\n   * @param value - the value to set. should be a WGSL expression.\n   */\n  readonly setByIndices: (varIndices: string, value: string) => string;\n\n  /**\n   * WGSL code for a statement for setting data at the given offset.\n   *\n   * @param offset - a number or a string (WGSL `u32` expression) representing the offset.\n   * @param value - the value to set. should be a WGSL expression.\n   */\n  readonly setByOffset: (offset: number | string, value: string) => string;\n\n  /**\n   * WGSL code for an expression for getting data at the given indices.\n   *\n   * @param indices - an array of numbers or strings (WGSL `u32` expression) representing the indices.\n   */\n  readonly get: (...indices: ReadonlyArray<number | string>) => string;\n\n  /**\n   * WGSL code for an expression for getting data at the given indices variable.\n   *\n   * @param varIndices - a variable name for the indices.\n   */\n  readonly getByIndices: (varIndices: string) => string;\n\n  /**\n   * WGSL code for an expression for getting data at the given offset.\n   *\n   * @param offset - a number or a string (WGSL `u32` expression) representing the offset.\n   */\n  readonly getByOffset: (offset: number | string) => string;\n\n  /**\n   * name of the data variable\n   */\n  readonly name: string;\n\n  /**\n   * whether the helper is for an input, an output or an internal variable.\n   */\n  readonly usage: 'input' | 'output' | 'atomicOutput' | 'internal';\n\n  /**\n   * the rank of the input or output.\n   */\n  readonly rank: number;\n\n  /**\n   * a string representing the variable name for the shape of the input or output.\n   */\n  readonly shape: string;\n\n  /**\n   * a string representing the variable name for the strides of the input or output.\n   */\n  readonly strides: string;\n}\n\nconst getWgslMappedType = (type: number, components: 1 | 2 | 3 | 4): string | [string, string] => {\n  if (components === 3) {\n    throw new Error('vec3 has same alignment as vec4, use vec4 instead');\n  }\n\n  // return type is [ storage type, runtime type ] or a single string for both\n  switch (Number(type)) {\n    case DataType.float16:\n      return components > 1 ? `vec${components}<f16>` : 'f16';\n    case DataType.float:\n      return components > 1 ? `vec${components}<f32>` : 'f32';\n    case DataType.int32:\n      return components > 1 ? `vec${components}<i32>` : 'i32';\n    case DataType.uint32:\n      return components > 1 ? `vec${components}<u32>` : 'u32';\n    case DataType.int64:\n      if (components > 1) {\n        throw new Error('currently not supported vecX of uint64 yet');\n      }\n      return ['vec2<u32>', 'i32'];\n    case DataType.uint64:\n      if (components > 1) {\n        throw new Error('currently not supported vecX of uint64 yet');\n      }\n      return ['vec2<u32>', 'u32'];\n    case DataType.bool:\n      if (components !== 4) {\n        throw new Error('bool must be vec4');\n      }\n      return ['u32', 'vec4<bool>'];\n    case DataType.int4:\n      return 'i32';\n    case DataType.uint4:\n      return 'u32';\n    default:\n      throw new Error(`Unknown data type: ${type}`);\n  }\n};\n\nexport const tensorTypeToWsglStorageType = (type: DataType, components: 1 | 2 | 3 | 4 = 1) => {\n  const mappedType = getWgslMappedType(type, components);\n  return typeof mappedType === 'string' ? mappedType : mappedType[0];\n};\n\nexport const tensorTypeToWsglValueType = (type: DataType, components: 1 | 2 | 3 | 4 = 1) => {\n  const mappedType = getWgslMappedType(type, components);\n  return typeof mappedType === 'string' ? mappedType : mappedType[1];\n};\n\nexport const createTensorShapeVariables = (...dims: ReadonlyArray<readonly number[]>): ProgramUniform[] => {\n  const programUniforms: ProgramUniform[] = [];\n  dims.forEach((dim) => {\n    if (dim.length !== 0) {\n      programUniforms.push(\n        { type: DataType.uint32, data: dim },\n        { type: DataType.uint32, data: ShapeUtil.computeStrides(dim) },\n      );\n    }\n  });\n  return programUniforms;\n};\n\n/**\n * A helper function to get maximum vector size for specified data length\n * @param size\n */\nexport const getMaxComponents = (size: number) => {\n  // we cannot use vec3 type since it has alignment of 16 bytes\n  if (size % 4 === 0) {\n    return 4;\n  } else if (size % 2 === 0) {\n    return 2;\n  }\n\n  return 1;\n};\n\n/**\n * A helper function that initializes variable as a scalar or vector. e.g. f32(0) or vec4f(0,0,0,0)\n * @param dataType\n * @param components\n * @param value\n */\nexport const fillVector = (dataType = 'f32', components?: number, value = '0') => {\n  if (!components || components === 1) {\n    return `${dataType}(${value})`;\n  }\n\n  return `vec${components}<${dataType}>(${value})`;\n};\n\n/**\n * A helper function that casts value or vector to f32\n * @param dataType\n * @param components\n * @param value\n */\nexport const castToF32 = (dataType: string, components: number, value: string) => {\n  if (dataType === 'f32') {\n    return value;\n  }\n  if (components === 1) {\n    return `f32(${value})`;\n  }\n\n  return `vec${components}<f32>(${value})`;\n};\n\n/**\n * A helper function that returns scalar or sums all components of a vector\n * @param name\n * @param components\n */\nexport const sumVector = (name: string, components: number) => {\n  if (components === 4) {\n    return `(${name}.x + ${name}.y + ${name}.z + ${name}.w)`;\n  } else if (components === 2) {\n    return `(${name}.x + ${name}.y)`;\n  } else if (components === 3) {\n    return `(${name}.x + ${name}.y + ${name}.z)`;\n  }\n\n  return name;\n};\n\n/**\n * A helper function that returns variable element at index.\n * @param name - the name of variable.\n * @param index - the index of variable element.\n * @param length - the length of variable.\n * @param type - the type of variable, optional.\n */\nexport const getElementAt = (\n  name: string,\n  index: number | string,\n  length: number,\n  type?: UniformDataElementType,\n): string => {\n  if (name.startsWith('uniforms.') && length > 4) {\n    if (typeof index === 'string') {\n      if (type === 'f16') {\n        return `${name}[(${index}) / 8][(${index}) % 8 / 4][(${index}) % 8 % 4]`;\n      } else {\n        return `${name}[(${index}) / 4][(${index}) % 4]`;\n      }\n    } else {\n      if (type === 'f16') {\n        return `${name}[${Math.floor(index / 8)}][${Math.floor((index % 8) / 4)}][${(index % 8) % 4}]`;\n      } else {\n        return `${name}[${Math.floor(index / 4)}][${index % 4}]`;\n      }\n    }\n  } else {\n    return length > 1 ? `${name}[${index}]` : name;\n  }\n};\n\n/**\n * A helper function to get a IndicesHelper for a given input or output.\n *\n * @param name - the name of the input or output.\n * @param tensorType - the tensor type of the input or output.\n * @param shapeOrRank - the tensor shape or the rank of the input or output.\n * @param usage - the usage of the indices helper.\n * @param components - indicates the number of components of each element. 1 for scalar, 2 for vec2, 3 for vec3, 4 for\n *    vec4.\n */\nconst createIndicesHelper = (\n  name: string,\n  tensorType: number,\n  shapeOrRank: number | readonly number[],\n  usage: IndicesHelper['usage'],\n  components: 1 | 2 | 3 | 4,\n): IndicesHelper => {\n  const useUniform = typeof shapeOrRank === 'number';\n  const rank = useUniform ? shapeOrRank : shapeOrRank.length;\n  const rankIdentity = [...new Array(rank).keys()];\n  const indicesType = rank < 2 ? 'u32' : rank <= 4 ? `vec${rank}<u32>` : `array<u32, ${rank}>`;\n  const mappedType = getWgslMappedType(tensorType, components);\n  const valueType = typeof mappedType === 'string' ? mappedType : mappedType[1];\n  const storageType = typeof mappedType === 'string' ? mappedType : mappedType[0];\n  const type = { indices: indicesType, value: valueType, storage: storageType, tensor: tensorType };\n\n  const normalizeDim = (dim: number | string): string => (typeof dim === 'string' ? dim : `${dim}u`);\n\n  const implementationUsed = {\n    offsetToIndices: false,\n    indicesToOffset: false,\n    broadcastedIndicesToOffset: false,\n    set: false,\n    setByIndices: false,\n    get: false,\n    getByIndices: false,\n  };\n\n  const uniformPrefix = useUniform ? 'uniforms.' : '';\n  const shape = `${uniformPrefix}${name}_shape`;\n  const strides = `${uniformPrefix}${name}_strides`;\n\n  let o2iSnippet = '';\n  for (let i = 0; i < rank - 1; i++) {\n    o2iSnippet += `\n    let dim${i} = current / ${getElementAt(strides, i, rank)};\n    let rest${i} = current % ${getElementAt(strides, i, rank)};\n    indices[${i}] = dim${i};\n    current = rest${i};\n    `;\n  }\n  o2iSnippet += `indices[${rank - 1}] = current;`;\n\n  const offsetToIndicesImplementation =\n    rank < 2\n      ? ''\n      : `\n  fn o2i_${name}(offset: u32) -> ${type.indices} {\n    var indices: ${type.indices};\n    var current = offset;\n    ${o2iSnippet}\n    return indices;\n  }`;\n\n  const offsetToIndices = (varOffset: string) => {\n    implementationUsed.offsetToIndices = true;\n    return rank < 2 ? varOffset : `o2i_${name}(${varOffset})`;\n  };\n\n  const offsets: string[] = [];\n  if (rank >= 2) {\n    for (let i = rank - 1; i >= 0; i--) {\n      offsets.push(`${getElementAt(strides, i, rank)} * (indices[${i}])`);\n    }\n  }\n\n  const indicesToOffsetImplementation =\n    rank < 2\n      ? ''\n      : `\n  fn i2o_${name}(indices: ${type.indices}) -> u32 {\n    return ${offsets.join('+')};\n  }`;\n\n  const indicesToOffset = (varIndices: string) => {\n    implementationUsed.indicesToOffset = true;\n    return rank < 2 ? varIndices : `i2o_${name}(${varIndices})`;\n  };\n\n  const indices = (...init: ReadonlyArray<number | string>) =>\n    rank === 0 ? '0u' : `${type.indices}(${init.map(normalizeDim).join(',')})`;\n\n  const indicesGet = (varIndices: string, idx: number | string) => {\n    if (rank < 2) {\n      return `${varIndices}`;\n    } else {\n      return `${getElementAt(varIndices, idx, rank)}`;\n    }\n  };\n\n  const indicesSet = (varIndices: string, idx: number | string, value: string) => {\n    if (rank < 2) {\n      return `${varIndices}=${value};`;\n    } else {\n      return `${getElementAt(varIndices, idx, rank)}=${value};`;\n    }\n  };\n\n  const broadcastedIndicesToOffsetImplementation: { [key: string]: string } = {};\n  const broadcastedIndicesToOffset = (varIndices: string, output: IndicesHelper) => {\n    implementationUsed.broadcastedIndicesToOffset = true;\n    const implKey = `${output.name}broadcastedIndicesTo${name}Offset`;\n    if (implKey in broadcastedIndicesToOffsetImplementation) {\n      return `${implKey}(${varIndices})`;\n    }\n    const offsets = [];\n    for (let i = rank - 1; i >= 0; i--) {\n      const idx = output.indicesGet('outputIndices', i + output.rank - rank);\n      offsets.push(`${indicesGet(strides, i)} * (${idx} % ${indicesGet(shape, i)})`);\n    }\n    broadcastedIndicesToOffsetImplementation[implKey] = `fn ${implKey}(outputIndices: ${output.type.indices}) -> u32 {\n             return ${offsets.length > 0 ? offsets.join('+') : '0u'};\n           }`;\n\n    return `${implKey}(${varIndices})`;\n  };\n\n  const setByOffset = (offset: number | string, value: string) =>\n    (() => {\n      if (type.storage === type.value) {\n        return `${name}[${offset}]=${value};`;\n      } else if (type.storage === 'vec2<u32>' && type.value === 'i32') {\n        // int64, components === 1\n        return `${name}[${offset}]=vec2<u32>(u32(${value}), select(0u, 0xFFFFFFFFu, ${value} < 0));`;\n      } else if (type.storage === 'vec2<u32>' && type.value === 'u32') {\n        // uint64, components === 1\n        return `${name}[${offset}]=vec2<u32>(u32(${value}), 0u);`;\n      } else if (type.storage === 'u32' && type.value === 'vec4<bool>') {\n        // bool, components === 4\n        return `${name}[${offset}]=dot(vec4<u32>(0x1, 0x100, 0x10000, 0x1000000), vec4<u32>(${value}));`;\n      } else {\n        throw new Error(`not supported combination of storage type ${type.storage} and value type ${type.value} yet`);\n      }\n    })();\n\n  const getByOffset = (offset: number | string) =>\n    (() => {\n      if (type.storage === type.value) {\n        return `${name}[${offset}]`;\n      } else if (type.storage === 'vec2<u32>' && type.value === 'i32') {\n        // int64, components === 1\n        return `i32(${name}[${offset}].x)`;\n      } else if (type.storage === 'vec2<u32>' && type.value === 'u32') {\n        // uint64, components === 1\n        return `u32(${name}[${offset}].x)`;\n      } else if (type.storage === 'u32' && type.value === 'vec4<bool>') {\n        // bool, components === 4\n        return `vec4<bool>(bool(${name}[${offset}] & 0xFFu), bool(${name}[${offset}] & 0xFF00u), bool(${name}[${\n          offset\n        }] & 0xFF0000u), bool(${name}[${offset}] & 0xFF000000u))`;\n      } else {\n        throw new Error(`not supported combination of storage type ${type.storage} and value type ${type.value} yet`);\n      }\n    })();\n\n  const getByIndicesImplementation =\n    rank < 2\n      ? ''\n      : `\n  fn get_${name}ByIndices(indices: ${type.indices}) -> ${valueType} {\n    return ${getByOffset(`i2o_${name}(indices)`)};\n  }`;\n\n  const getImplementation =\n    rank < 2\n      ? ''\n      : (() => {\n          const functionParams = rankIdentity.map((i) => `d${i}: u32`).join(', ');\n          const dimsParams = rankIdentity.map((i) => `d${i}`).join(', ');\n          return `\n  fn get_${name}(${functionParams}) -> ${valueType} {\n    return get_${name}ByIndices(${indices(dimsParams)});\n  }`;\n        })();\n\n  const get = (...indices: ReadonlyArray<number | string>) => {\n    if (indices.length !== rank) {\n      throw new Error(`indices length must be ${rank}`);\n    }\n\n    const normalizedIndices = indices.map(normalizeDim).join(',');\n\n    if (rank === 0) {\n      return getByOffset('0u');\n    } else if (rank === 1) {\n      return getByOffset(normalizedIndices[0]);\n    } else {\n      implementationUsed.get = true;\n      implementationUsed.getByIndices = true;\n      implementationUsed.indicesToOffset = true;\n      return `get_${name}(${normalizedIndices})`;\n    }\n  };\n\n  const getByIndices = (varIndices: string) => {\n    if (rank < 2) {\n      return getByOffset(varIndices);\n    } else {\n      implementationUsed.getByIndices = true;\n      implementationUsed.indicesToOffset = true;\n      return `get_${name}ByIndices(${varIndices})`;\n    }\n  };\n\n  const setByIndicesImplementation =\n    rank < 2\n      ? ''\n      : `\n  fn set_${name}ByIndices(indices: ${type.indices}, value: ${valueType}) {\n    ${setByOffset(`i2o_${name}(indices)`, 'value')}\n  }`;\n\n  const setImplementation =\n    rank < 2\n      ? ''\n      : (() => {\n          const functionParams = rankIdentity.map((i) => `d${i}: u32`).join(', ');\n          const dimsParams = rankIdentity.map((i) => `d${i}`).join(', ');\n          return `\n  fn set_${name}(${functionParams}, value: ${valueType}) {\n    set_${name}ByIndices(${indices(dimsParams)}, value);\n  }`;\n        })();\n\n  const set = (...indicesAndValue: ReadonlyArray<number | string>) => {\n    if (indicesAndValue.length !== rank + 1) {\n      throw new Error(`indices length must be ${rank}`);\n    }\n    const value = indicesAndValue[rank];\n    if (typeof value !== 'string') {\n      throw new Error('value must be string');\n    }\n\n    const normalizedIndices = indicesAndValue.slice(0, rank).map(normalizeDim).join(',');\n\n    if (rank === 0) {\n      return setByOffset('0u', value);\n    } else if (rank === 1) {\n      return setByOffset(normalizedIndices[0], value);\n    } else {\n      implementationUsed.set = true;\n      implementationUsed.setByIndices = true;\n      implementationUsed.indicesToOffset = true;\n      return `set_${name}(${normalizedIndices}, ${value})`;\n    }\n  };\n\n  const setByIndices = (varIndices: string, value: string) => {\n    if (rank < 2) {\n      return setByOffset(varIndices, value);\n    } else {\n      implementationUsed.setByIndices = true;\n      implementationUsed.indicesToOffset = true;\n      return `set_${name}ByIndices(${varIndices}, ${value});`;\n    }\n  };\n\n  const impl = () => {\n    const impls = [];\n    let needShapeStrides = false;\n    if (implementationUsed.offsetToIndices) {\n      impls.push(offsetToIndicesImplementation);\n      needShapeStrides = true;\n    }\n    if (implementationUsed.indicesToOffset) {\n      impls.push(indicesToOffsetImplementation);\n      needShapeStrides = true;\n    }\n    if (implementationUsed.broadcastedIndicesToOffset) {\n      Object.values(broadcastedIndicesToOffsetImplementation).forEach((impl) => impls.push(impl));\n      needShapeStrides = true;\n    }\n    if (implementationUsed.set) {\n      impls.push(setImplementation);\n      needShapeStrides = true;\n    }\n    if (implementationUsed.setByIndices) {\n      impls.push(setByIndicesImplementation);\n      needShapeStrides = true;\n    }\n    if (implementationUsed.get) {\n      impls.push(getImplementation);\n      needShapeStrides = true;\n    }\n    if (implementationUsed.getByIndices) {\n      impls.push(getByIndicesImplementation);\n      needShapeStrides = true;\n    }\n    if (!useUniform && needShapeStrides) {\n      impls.unshift(\n        `const ${shape} = ${type.indices}(${shapeOrRank.join(',')});`,\n        `const ${strides} = ${type.indices}(${ShapeUtil.computeStrides(shapeOrRank).join(',')});`,\n      );\n    }\n    return impls.join('\\n');\n  };\n\n  return {\n    impl,\n    type,\n    offsetToIndices,\n    indicesToOffset,\n    broadcastedIndicesToOffset,\n    indices,\n    indicesGet,\n    indicesSet,\n    set,\n    setByOffset,\n    setByIndices,\n    get,\n    getByOffset,\n    getByIndices,\n    // isVec4,\n    usage,\n    name,\n    strides,\n    shape,\n    rank,\n  };\n};\n\n/**\n * Create a IndicesHelper for an input.\n *\n * @param name - the name of the input.\n * @param type - the tensor type of the input.\n * @param shapeOrRank - the tensor shape or the rank of the input.\n * @param components - the number of components of the input. available values are 1, 2, 3, 4. default is 1.\n * @returns an IndicesHelper for the input.\n */\nexport const inputVariable = (\n  name: string,\n  type: number,\n  shapeOrRank: number | readonly number[],\n  components: 1 | 2 | 3 | 4 = 1,\n): IndicesHelper => createIndicesHelper(name, type, shapeOrRank, 'input', components);\n\n/**\n * Create a IndicesHelper for an output.\n *\n * @param name - the name of the output.\n * @param type - the tensor type of the output.\n * @param shapeOrRank - the tensor shape or the rank of the output.\n * @param components - the number of components of the output. available values are 1, 2, 3, 4. default is 1.\n * @returns an IndicesHelper for the output.\n */\nexport const outputVariable = (\n  name: string,\n  type: number,\n  shapeOrRank: number | readonly number[],\n  components: 1 | 2 | 3 | 4 = 1,\n): IndicesHelper => createIndicesHelper(name, type, shapeOrRank, 'output', components);\n\n/**\n * Create a IndicesHelper for an atomic output.\n *\n * @param name - the name of the output.\n * @param type - the tensor type of the output.\n * @param shapeOrRank - the tensor shape or the rank of the output.\n * @returns an IndicesHelper for the output.\n */\nexport const atomicOutputVariable = (\n  name: string,\n  type: number,\n  shapeOrRank: number | readonly number[],\n): IndicesHelper => createIndicesHelper(name, type, shapeOrRank, 'atomicOutput', 1);\n\n/**\n * Create a IndicesHelper for an internal variable.\n *\n * @param name - the name of the variable.\n * @param type - the tensor type of the variable.\n * @param shapeOrRank - the tensor shape or the rank of the variable.\n * @param components - the number of components of the variable. available values are 1, 2, 3, 4. default is 1.\n * @returns an IndicesHelper for the variable.\n */\nexport const internalVariable = (\n  name: string,\n  type: number,\n  shapeOrRank: number | readonly number[],\n  components: 1 | 2 | 3 | 4 = 1,\n): IndicesHelper => createIndicesHelper(name, type, shapeOrRank, 'internal', components);\n\nexport type UniformDataElementType = 'u32' | 'f16' | 'f32' | 'i32';\nexport type UniformsArrayType = Array<{ name: string; type: UniformDataElementType; length?: number }>;\n\n/**\n * A ShaderHelper is a helper class for generating WGSL code.\n */\nexport interface ShaderHelper {\n  /**\n   * A helper function to generate the start of main function in WGSL source code.\n   *\n   * @example\n   * const getShaderSource = (shaderHelper: ShaderHelper) => `\n   *  ...\n   *\n   *  ${shaderHelper.mainStart()}\n   *    // your code here inside main() function\n   *    ...\n   *  }\n   * `;\n   *\n   * @param workgroupSize - an optional workgroup size. default is WORKGROUP_SIZE.\n   */\n  mainStart(workgroupSize?: number | [number, number, number]): string;\n\n  /**\n   * A helper function to generate the code snippet for guarding against out-of-bounds size.\n   *\n   * @example\n   * const getShaderSource = (shaderHelper: ShaderHelper) => `\n   *  ...\n   *\n   *  ${shaderHelper.mainStart()}\n   *    ${shaderHelper.guardAgainstOutOfBoundsWorkgroupSizes(outputSize)}\n   *\n   *    // your code here inside main() function\n   *    ...\n   *  }\n   * `;\n   *\n   * @param size - the size of the data to guard against. can be a number or a string (WGSL `u32` expression).\n   */\n  guardAgainstOutOfBoundsWorkgroupSizes(size: unknown): string;\n\n  /**\n   * A helper function to generate the code snippet for declaring multiple inputs or outputs.\n   *\n   * @param variables - an array of IndicesHelper for the variables.\n   */\n  declareVariables(...variables: IndicesHelper[]): string;\n\n  /**\n   * A helper function to register one uniform. Can be called multiple times to register multiple uniforms.\n   *\n   * @param name - the name of the uniform.\n   * @param type - the type of the uniform.\n   * @param length - the length of the uniform, default to 1 when it is not provided.\n   */\n  registerUniform(name: string, type: string, length?: number): ShaderHelper;\n\n  /**\n   * A helper function to register multiple uniforms. Can be called multiple times to register multiple uniforms.\n   *\n   * @param uniforms - an array of uniforms. Each element of the array is an object with 2 properties: `name` and\n   *     `type`.\n   */\n  registerUniforms(uniforms: UniformsArrayType): ShaderHelper;\n\n  /**\n   * A helper function to register multiple internal variables. Can be called multiple times to register multiple\n   * internal variables.\n   *\n   * @param variables - an array of IndicesHelper for the variables.\n   */\n  registerInternalVariables(...variables: IndicesHelper[]): ShaderHelper;\n}\n\nclass ShaderHelperImpl implements ShaderHelper {\n  constructor(\n    private normalizedDispatchGroup: [number, number, number],\n    private limits: GPUSupportedLimits,\n  ) {}\n\n  guardAgainstOutOfBoundsWorkgroupSizes(size: number | string): string {\n    // Guard against out-of-bounds work group sizes\n    const sizeInCode = typeof size === 'number' ? `${size}u` : size;\n    return `if (global_idx >= ${sizeInCode}) { return; }`;\n  }\n\n  mainStart(workgroupSize: number | [number, number, number] = WORKGROUP_SIZE) {\n    const workgroupSizeX = typeof workgroupSize === 'number' ? workgroupSize : workgroupSize[0];\n    const workgroupSizeY = typeof workgroupSize === 'number' ? 1 : workgroupSize[1];\n    const workgroupSizeZ = typeof workgroupSize === 'number' ? 1 : workgroupSize[2];\n\n    if (\n      workgroupSizeX > this.limits.maxComputeWorkgroupSizeX ||\n      workgroupSizeY > this.limits.maxComputeWorkgroupSizeY ||\n      workgroupSizeZ > this.limits.maxComputeWorkgroupSizeZ\n    ) {\n      throw new Error(\n        `workgroup size [${workgroupSizeX}, ${workgroupSizeY}, ${\n          workgroupSizeZ\n        }] exceeds the maximum workgroup size [${this.limits.maxComputeWorkgroupSizeX}, ${\n          this.limits.maxComputeWorkgroupSizeY\n        }, ${this.limits.maxComputeWorkgroupSizeZ}].`,\n      );\n    }\n\n    if (workgroupSizeX * workgroupSizeY * workgroupSizeZ > this.limits.maxComputeInvocationsPerWorkgroup) {\n      throw new Error(\n        `workgroup size [${workgroupSizeX}, ${workgroupSizeY}, ${\n          workgroupSizeZ\n        }] exceeds the maximum workgroup invocations ${this.limits.maxComputeInvocationsPerWorkgroup}.`,\n      );\n    }\n\n    const is1DimensionDispatch = this.normalizedDispatchGroup[1] === 1 && this.normalizedDispatchGroup[2] === 1;\n    const paramList = is1DimensionDispatch\n      ? `@builtin(global_invocation_id) global_id : vec3<u32>,\n    @builtin(workgroup_id) workgroup_id : vec3<u32>,\n    @builtin(local_invocation_index) local_idx : u32,\n    @builtin(local_invocation_id) local_id : vec3<u32>`\n      : `@builtin(global_invocation_id) global_id : vec3<u32>,\n                                             @builtin(local_invocation_id) local_id : vec3<u32>,\n    @builtin(local_invocation_index) local_idx : u32,\n    @builtin(workgroup_id) workgroup_id : vec3<u32>,\n    @builtin(num_workgroups) num_workgroups : vec3<u32>`;\n    const globalIdxDefinition = is1DimensionDispatch\n      ? `let global_idx = global_id.x;\n         let workgroup_index = workgroup_id.x;`\n      : `let workgroup_index = workgroup_id.z * num_workgroups[0] * num_workgroups[1] +\n             workgroup_id.y * num_workgroups[0] + workgroup_id.x;\n         let global_idx = workgroup_index * ${workgroupSizeX * workgroupSizeY * workgroupSizeZ}u + local_idx;`;\n\n    return `@compute @workgroup_size(${workgroupSizeX}, ${workgroupSizeY}, ${workgroupSizeZ})\n  fn main(${paramList}) {\n    ${globalIdxDefinition}\n  `;\n  }\n\n  private appendVariableUniforms(variable: IndicesHelper): void {\n    if (variable.rank !== 0) {\n      if (variable.shape.startsWith('uniforms.')) {\n        this.uniforms.push({ name: variable.shape.replace('uniforms.', ''), type: 'u32', length: variable.rank });\n      }\n      if (variable.strides.startsWith('uniforms.')) {\n        this.uniforms.push({ name: variable.strides.replace('uniforms.', ''), type: 'u32', length: variable.rank });\n      }\n    }\n  }\n\n  private declareVariable(variable: IndicesHelper, bindingIndex: number): string {\n    if (variable.usage === 'internal') {\n      throw new Error('cannot use internal variable with declareVariable(). use registerInternalVariables() instead.');\n    }\n    this.variables.push(variable);\n    this.appendVariableUniforms(variable);\n    const access = variable.usage === 'input' ? 'read' : 'read_write';\n    const storageType = variable.usage === 'atomicOutput' ? `atomic<i32>` : variable.type.storage;\n    return `@group(0) @binding(${bindingIndex}) var<storage, ${access}> ${variable.name}: array<${storageType}>;`;\n  }\n\n  declareVariables(...variables: IndicesHelper[]): string {\n    return variables.map((v) => this.declareVariable(v, this.variableIndex++)).join('\\n');\n  }\n\n  private registerInternalVariable(variable: IndicesHelper): void {\n    if (variable.usage !== 'internal') {\n      throw new Error(\n        'cannot use input or output variable with registerInternalVariable(). use declareVariables() instead.',\n      );\n    }\n\n    this.internalVariables.push(variable);\n    this.appendVariableUniforms(variable);\n  }\n\n  registerInternalVariables(...variables: IndicesHelper[]): ShaderHelper {\n    variables.forEach((v) => this.registerInternalVariable(v));\n    return this;\n  }\n\n  registerUniform(name: string, type: UniformDataElementType, length = 1): ShaderHelper {\n    this.uniforms.push({ name, type, length });\n    return this;\n  }\n\n  registerUniforms(additionalUniforms: UniformsArrayType): ShaderHelper {\n    this.uniforms = this.uniforms.concat(additionalUniforms);\n    return this;\n  }\n\n  private internalVariables: IndicesHelper[] = [];\n  private variables: IndicesHelper[] = [];\n  private uniforms: UniformsArrayType = [];\n  private uniformDeclaration(): string {\n    if (this.uniforms.length === 0) {\n      return '';\n    }\n\n    const uniformSnippets: string[] = [];\n    for (const { name, type, length } of this.uniforms) {\n      if (length && length > 4) {\n        if (type === 'f16') {\n          uniformSnippets.push(`@align(16) ${name}:array<mat2x4<${type}>, ${Math.ceil(length / 8)}>`);\n        } else {\n          uniformSnippets.push(`${name}:array<vec4<${type}>, ${Math.ceil(length / 4)}>`);\n        }\n      } else {\n        const typeTemp = length == null || length === 1 ? type : `vec${length}<${type}>`;\n        uniformSnippets.push(`${name}:${typeTemp}`);\n      }\n    }\n\n    return `\n      struct Uniforms { ${uniformSnippets.join(', ')} };\n      @group(0) @binding(${this.variableIndex}) var<uniform> uniforms: Uniforms;`;\n  }\n  private variableIndex = 0;\n\n  /**\n   * Get additional implementation that needs to be added to the shader source.\n   */\n  get additionalImplementations(): string {\n    return (\n      this.uniformDeclaration() +\n      this.variables.map((i) => i.impl()).join('\\n') +\n      this.internalVariables.map((i) => i.impl()).join('\\n')\n    );\n  }\n\n  /**\n   * Get the variable info of the shader program.\n   */\n  get variablesInfo(): ProgramUniformVariableInfo[] | undefined {\n    if (this.uniforms.length === 0) {\n      return undefined;\n    }\n\n    const uniformWgslTypeToDataType = (type: UniformDataElementType) =>\n      [DataType.uint32, DataType.float16, DataType.float, DataType.int32][['u32', 'f16', 'f32', 'i32'].indexOf(type)];\n    return this.uniforms.map((u) => [uniformWgslTypeToDataType(u.type), u.length ?? 1]);\n  }\n}\n\nexport const createShaderHelper = (dispatchGroup: [number, number, number], limits: GPUSupportedLimits) =>\n  new ShaderHelperImpl(dispatchGroup, limits);\n","// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport { DataType } from '../../../wasm-common';\nimport { TensorView } from '../../tensor-view';\nimport { ShapeUtil } from '../../util';\nimport { AttributeWithCacheKey, createAttributeWithCacheKey } from '../attribute-with-cache-key';\nimport { ComputeContext, ProgramInfo } from '../types';\n\nimport { createTensorShapeVariables, IndicesHelper, inputVariable, outputVariable, ShaderHelper } from './common';\n\nexport interface TransposeAttributes extends AttributeWithCacheKey {\n  readonly perm: number[];\n}\n\nconst validateInputs = (inputs: readonly TensorView[], perm: readonly number[]): void => {\n  if (!inputs || inputs.length !== 1) {\n    throw new Error('Transpose requires 1 input.');\n  }\n\n  if (perm.length !== 0 && perm.length !== inputs[0].dims.length) {\n    throw new Error(`perm size ${perm.length} does not match input rank ${inputs[0].dims.length}`);\n  }\n};\n\nconst getAdjustedPerm = (inputRank: number, perm: number[]): number[] =>\n  perm.length !== 0 ? perm : [...new Array(inputRank).keys()].reverse();\n\nconst getOutputShape = (inputShape: readonly number[], perm: number[]): readonly number[] =>\n  ShapeUtil.sortBasedOnPerm(inputShape, getAdjustedPerm(inputShape.length, perm));\n\nconst permFunctionBody = (perm: number[], rank: number, input: IndicesHelper, output: IndicesHelper): string => {\n  let reverseFunc = `fn perm(i: ${output.type.indices}) -> ${input.type.indices} {\n    var a: ${input.type.indices};`;\n  for (let i = 0; i < rank; ++i) {\n    // input indices and output indices should always be larger or equal to 2,\n    // so indexer is always valid to be used on `a` and `i`.\n    reverseFunc += `a[${perm[i]}]=i[${i}];`;\n  }\n  return (reverseFunc += 'return a;}');\n};\n\nconst squeezeShape = (shape: readonly number[], adjustedPerm: number[]): { newShape: number[]; newPerm: number[] } => {\n  const newShape: number[] = [];\n  const newPerm: number[] = [];\n  for (let i = 0; i < shape.length; ++i) {\n    if (shape[i] !== 1) {\n      newShape.push(shape[i]);\n    }\n    if (shape[adjustedPerm[i]] !== 1) {\n      newPerm.push(adjustedPerm[i]);\n    }\n  }\n  return { newShape, newPerm };\n};\n\nconst isTransposeReshape = (perm: number[], shape: readonly number[]) => {\n  // As long as the dims with values > 1 stay in the same order, it's a reshape.\n  // Example: Shape=(1,1,1024,4096) -> perm=(2,0,3,1).\n  let lastPermutedAxis = 0;\n  for (let i = 0; i < perm.length; ++i) {\n    if (shape[perm[i]] === 1) {\n      continue;\n    }\n    if (perm[i] < lastPermutedAxis) {\n      return false;\n    }\n    lastPermutedAxis = perm[i];\n  }\n  return true;\n};\n\nexport const createTransposeProgramInfo = (inputTensor: TensorView, permAttr: number[]): ProgramInfo => {\n  const inputDataType = inputTensor.dataType;\n  const inputRank = inputTensor.dims.length;\n  const perm = getAdjustedPerm(inputRank, permAttr);\n  const outputShape = getOutputShape(inputTensor.dims, perm);\n  let newInputShape = inputTensor.dims;\n  let newOutputShape = outputShape;\n  const transposeAsReshape = inputRank < 2 || isTransposeReshape(perm, inputTensor.dims);\n  let getShaderSource;\n  if (transposeAsReshape) {\n    getShaderSource = (shaderHelper: ShaderHelper) => {\n      const input = inputVariable('input', inputDataType, newInputShape, 4);\n      const output = outputVariable('output', inputDataType, newOutputShape, 4);\n      return `\n  ${shaderHelper.registerUniform('output_size', 'u32').declareVariables(input, output)}\n  ${shaderHelper.mainStart()}\n    ${shaderHelper.guardAgainstOutOfBoundsWorkgroupSizes('uniforms.output_size')}\n    output[global_idx] = input[global_idx];\n  }`;\n    };\n\n    return {\n      name: 'TransposeCopy',\n      shaderCache: { inputDependencies: ['type'] },\n      getRunData: () => {\n        const outputSize = ShapeUtil.size(outputShape);\n        return {\n          outputs: [{ dims: outputShape, dataType: inputTensor.dataType }],\n          dispatchGroup: { x: Math.ceil(outputSize / 64 /* workgroup size */ / 4 /* components */) },\n          programUniforms: [{ type: DataType.uint32, data: Math.ceil(outputSize / 4) }],\n        };\n      },\n      getShaderSource,\n    };\n  }\n  const { newShape, newPerm } = squeezeShape(inputTensor.dims, perm);\n  const channelsLast = ShapeUtil.areEqual(newPerm, [2, 3, 1]);\n  const channelsFirst = ShapeUtil.areEqual(newPerm, [3, 1, 2]);\n  const useShared = newShape.length === 2 || channelsLast || channelsFirst;\n  if (useShared) {\n    newInputShape = channelsLast\n      ? [newShape[0], newShape[1] * newShape[2]]\n      : channelsFirst\n        ? [newShape[0] * newShape[1], newShape[2]]\n        : newShape;\n    newOutputShape = [newInputShape[1], newInputShape[0]];\n    const tileSize = 16;\n    getShaderSource = (shaderHelper: ShaderHelper) => {\n      const input = inputVariable('a', inputDataType, newInputShape.length);\n      const output = outputVariable('output', inputDataType, newOutputShape.length);\n      return `\n  ${shaderHelper.registerUniform('output_size', 'u32').declareVariables(input, output)}\n  var<workgroup> tile : array<array<${output.type.value}, ${tileSize + 1}>, ${tileSize}>;\n  ${shaderHelper.mainStart([tileSize, tileSize, 1])}\n    let stride = (uniforms.output_shape[1] - 1) / ${tileSize} + 1;\n    let workgroup_id_x = workgroup_index % stride;\n    let workgroup_id_y = workgroup_index / stride;\n    let input_col = workgroup_id_y * ${tileSize}u + local_id.x;\n    let input_row = workgroup_id_x * ${tileSize}u + local_id.y;\n    if (input_row < uniforms.a_shape[0] && input_col < uniforms.a_shape[1]) {\n      tile[local_id.y][local_id.x] = ${input.getByIndices(`${input.type.indices}(input_row, input_col)`)};\n    }\n    workgroupBarrier();\n\n    let output_col = workgroup_id_x * ${tileSize}u + local_id.x;\n    let output_row = workgroup_id_y * ${tileSize}u + local_id.y;\n    if (output_row < uniforms.output_shape[0] && output_col < uniforms.output_shape[1]) {\n      ${output.setByIndices(`${output.type.indices}(output_row, output_col)`, 'tile[local_id.x][local_id.y]')}\n    }\n  }`;\n    };\n    return {\n      name: 'TransposeShared',\n      shaderCache: { inputDependencies: ['type'] },\n      getRunData: () => {\n        const outputSize = ShapeUtil.size(outputShape);\n        return {\n          outputs: [{ dims: outputShape, dataType: inputTensor.dataType }],\n          dispatchGroup: { x: Math.ceil(newOutputShape[1] / tileSize), y: Math.ceil(newOutputShape[0] / tileSize) },\n          programUniforms: [\n            { type: DataType.uint32, data: outputSize },\n            ...createTensorShapeVariables(newInputShape, newOutputShape),\n          ],\n        };\n      },\n      getShaderSource,\n    };\n  }\n\n  getShaderSource = (shaderHelper: ShaderHelper) => {\n    const input = inputVariable('a', inputDataType, newInputShape.length);\n    const output = outputVariable('output', inputDataType, newOutputShape.length);\n    return `\n  ${shaderHelper.registerUniform('output_size', 'u32').declareVariables(input, output)}\n\n  ${permFunctionBody(perm, inputRank, input, output)}\n\n  ${shaderHelper.mainStart()}\n    ${shaderHelper.guardAgainstOutOfBoundsWorkgroupSizes('uniforms.output_size')}\n\n    let indices = ${output.offsetToIndices('global_idx')};\n    let aIndices = perm(indices);\n\n    ${output.setByOffset('global_idx', input.getByIndices('aIndices'))}\n  }`;\n  };\n  return {\n    name: 'Transpose',\n    shaderCache: { hint: `${permAttr}`, inputDependencies: ['rank'] },\n    getRunData: () => {\n      const outputSize = ShapeUtil.size(outputShape);\n      return {\n        outputs: [{ dims: outputShape, dataType: inputTensor.dataType }],\n        dispatchGroup: { x: Math.ceil(outputSize / 64 /* workgroup size */) },\n        programUniforms: [\n          { type: DataType.uint32, data: outputSize },\n          ...createTensorShapeVariables(newInputShape, newOutputShape),\n        ],\n      };\n    },\n    getShaderSource,\n  };\n};\n\nexport const transpose = (context: ComputeContext, attributes: TransposeAttributes): void => {\n  validateInputs(context.inputs, attributes.perm);\n  context.compute(createTransposeProgramInfo(context.inputs[0], attributes.perm));\n};\n\nexport const parseTransposeAttributes = (attributes: Record<string, unknown>): TransposeAttributes =>\n  createAttributeWithCacheKey({ perm: attributes.perm as number[] });\n","// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport { DataType } from '../../../wasm-common';\nimport { TensorView } from '../../tensor-view';\nimport { ShapeUtil } from '../../util';\nimport { ComputeContext, ProgramInfo } from '../types';\n\nimport { inputVariable, outputVariable, ShaderHelper } from './common';\nimport { createReduceAttributesFromInputs, ReduceAttributes } from './reduce';\nimport { createTransposeProgramInfo } from './transpose';\n\nconst reduceOps: { [key: string]: string } = {\n  max: 'select(bestValue, candidate, candidate > bestValue)',\n  min: 'select(bestValue, candidate, candidate < bestValue)',\n  mean: 'bestValue + candidate',\n  sum: 'bestValue + candidate',\n  prod: 'bestValue * candidate',\n  sumSquare: 'bestValue + candidate * candidate',\n  logSumExp: 'bestValue + exp(candidate)',\n  l1: 'bestValue + abs(candidate)',\n  l2: 'bestValue + candidate * candidate',\n  logSum: 'bestValue + candidate',\n};\n\nconst reduceSharedOps: { [key: string]: string } = {\n  max: 'select(bestValue, candidate, candidate > bestValue)',\n  min: 'select(bestValue, candidate, candidate < bestValue)',\n  mean: 'bestValue + candidate',\n  sum: 'bestValue + candidate',\n  prod: 'bestValue * candidate',\n  sumSquare: 'bestValue + candidate',\n  logSumExp: 'bestValue + candidate',\n  l1: 'bestValue + candidate',\n  l2: 'bestValue + candidate',\n  logSum: 'bestValue + candidate',\n};\n\nconst reduceInitValues: { [key: string]: string } = {\n  max: '_A[offset]',\n  min: '_A[offset]',\n  mean: '0',\n  sum: '0',\n  prod: '1',\n  sumSquare: '0',\n  logSumExp: '0',\n  l1: '0',\n  l2: '0',\n  logSum: '0',\n};\n\nconst reduceOutputValues: { [key: string]: string } = {\n  max: 'bestValue',\n  min: 'bestValue',\n  sum: 'bestValue',\n  prod: 'bestValue',\n  sumSquare: 'bestValue',\n  logSumExp: 'log(bestValue)',\n  l1: 'bestValue',\n  l2: 'sqrt(bestValue)',\n  logSum: 'log(bestValue)',\n};\n\nconst getInnerMostAxes = (numInnerAxes: number, rank: number): number[] => {\n  const res = [];\n  for (let i = rank - numInnerAxes; i < rank; ++i) {\n    res.push(i);\n  }\n  return res;\n};\n\nconst computeOutAndReduceShapes = (shape: readonly number[], axes: readonly number[]): [number[], number[]] => {\n  const outputShape = [];\n  const rank = shape.length;\n  for (let dim = 0; dim < rank; dim++) {\n    if (axes.indexOf(dim) === -1) {\n      outputShape.push(shape[dim]);\n    }\n  }\n  const reduceShape = axes.map((dim) => shape[dim]);\n  return [outputShape, reduceShape];\n};\n\nconst expandShapeToKeepDim = (shape: number[], axes: number[]): number[] => {\n  const rank = shape.length + axes.length;\n  const expandShape = [];\n  let shapeIdx = 0;\n  for (let dim = 0; dim < rank; dim++) {\n    if (axes.indexOf(dim) === -1) {\n      expandShape.push(shape[shapeIdx++]);\n    } else {\n      expandShape.push(1);\n    }\n  }\n  return expandShape;\n};\n\nconst areAxesInnerMostDims = (axes: number[], rank: number): boolean => {\n  for (let i = 0; i < axes.length; ++i) {\n    if (axes[axes.length - i - 1] !== rank - 1 - i) {\n      return false;\n    }\n  }\n  return true;\n};\n\nconst getAxesPermutation = (axes: number[], rank: number): number[] => {\n  const res = [];\n  if (!areAxesInnerMostDims(axes, rank)) {\n    for (let i = 0; i < rank; ++i) {\n      if (axes.indexOf(i) === -1) {\n        res.push(i);\n      }\n    }\n    axes.forEach((axis) => res.push(axis));\n  }\n  return res;\n};\n\nexport const createReduceSharedProgramInfo = (\n  name: string,\n  cacheKey: string,\n  inputs: readonly TensorView[],\n  reduceType: string,\n  outputDataType: DataType,\n  outputShape: number[],\n  reduceShape: number[],\n): ProgramInfo => {\n  const inputShape = inputs[0].dims;\n\n  const outputSize = ShapeUtil.size(outputShape);\n  const reduceSize = ShapeUtil.size(reduceShape);\n\n  const input = inputVariable('_A', inputs[0].dataType, inputShape);\n  const output = outputVariable('output', outputDataType, outputShape);\n\n  let workgroupSize = 64;\n  // If only one workgroup is dispatched, increase workgroupSize to improve parallelism.\n  if (outputSize === 1) {\n    workgroupSize = 256;\n  }\n\n  const sharedMemorySnippet = `\n          var<workgroup> aBestValues : array<f32, ${workgroupSize}>;\n       `;\n\n  const getShaderSource = (shaderHelper: ShaderHelper) => `\n        ${shaderHelper.registerUniform('reduceSize', 'u32').declareVariables(input, output)}\n        ${sharedMemorySnippet}\n        fn DIV_CEIL(a : u32, b : u32) -> u32 {\n          return ((a - 1u) / b + 1u);\n         }\n         ${shaderHelper.mainStart(workgroupSize)}\n\n          let outputIndex = global_idx / ${workgroupSize};\n          let offset = outputIndex * uniforms.reduceSize;\n\n          var bestValue = f32(${reduceInitValues[reduceType]});\n          let Length = uniforms.reduceSize;\n          for (var k = local_idx; k < Length; k = k + ${workgroupSize}) {\n           let candidate = f32(${input.getByOffset('offset + k')});\n           bestValue = ${reduceOps[reduceType]};\n          }\n          aBestValues[local_idx] = bestValue;\n          workgroupBarrier();\n\n         var reduceSize = min(Length, ${workgroupSize}u);\n         for (var currentSize = reduceSize / 2u; reduceSize > 1u;\n             currentSize = reduceSize / 2u) {\n           let interval = DIV_CEIL(reduceSize, 2u);\n           if (local_idx < currentSize) {\n            let candidate = aBestValues[local_idx + interval];\n            bestValue = ${reduceSharedOps[reduceType]};\n            aBestValues[local_idx] = bestValue;\n           }\n           reduceSize = interval;\n           workgroupBarrier();\n         }\n\n         if (local_idx == 0u) {\n          ${output.setByOffset(\n            'outputIndex',\n            `${\n              reduceType === 'mean'\n                ? `${output.type.storage}(bestValue / f32(uniforms.reduceSize))`\n                : `${output.type.storage}(${reduceOutputValues[reduceType]})`\n            }`,\n          )};\n         }\n        }`;\n\n  // One work group is responsible for only one element of output.\n  return {\n    name,\n    // Note that in JSEP, WG size is not included in cache by default, but WebGPU EP it is.\n    shaderCache: { hint: `${cacheKey};${workgroupSize}`, inputDependencies: ['type'] },\n    getShaderSource,\n    getRunData: () => ({\n      outputs: [{ dims: outputShape, dataType: outputDataType }],\n      dispatchGroup: { x: outputSize },\n      programUniforms: [{ type: DataType.uint32, data: reduceSize }],\n    }),\n  };\n};\n\nconst reduceCommon = (\n  context: ComputeContext,\n  name: string,\n  attributes: ReduceAttributes,\n  reduceType: 'sum' | 'sumSquare' | 'prod' | 'min' | 'max' | 'mean' | 'logSumExp' | 'l1' | 'l2' | 'logSum',\n): void => {\n  const updatedAttributes: ReduceAttributes =\n    context.inputs.length === 1 ? attributes : createReduceAttributesFromInputs(context.inputs, attributes);\n\n  let updatedAxes = updatedAttributes.axes;\n  if (updatedAxes.length === 0 && !updatedAttributes.noopWithEmptyAxes) {\n    updatedAxes = context.inputs[0].dims.map((_dim, i) => i);\n  }\n  const normalizeAxes = ShapeUtil.normalizeAxes(updatedAxes, context.inputs[0].dims.length);\n\n  let axes = normalizeAxes;\n  let input = context.inputs[0];\n  const permutedAxes = getAxesPermutation(axes, context.inputs[0].dims.length);\n  if (permutedAxes.length > 0) {\n    input = context.compute(createTransposeProgramInfo(context.inputs[0], permutedAxes), {\n      inputs: [0],\n      outputs: [-1],\n    })[0];\n    axes = getInnerMostAxes(axes.length, input.dims.length);\n  }\n\n  const [outputShape, reduceShape] = computeOutAndReduceShapes(input.dims, axes);\n  let finalOutputShape = outputShape;\n  if (updatedAttributes.keepDims) {\n    finalOutputShape = expandShapeToKeepDim(outputShape, normalizeAxes);\n  }\n\n  context.compute(\n    createReduceSharedProgramInfo(\n      name,\n      updatedAttributes.cacheKey,\n      [input],\n      reduceType,\n      context.inputs[0].dataType,\n      finalOutputShape,\n      reduceShape,\n    ),\n    { inputs: [input] },\n  );\n};\n\nexport const reduceMeanShared = (context: ComputeContext, attributes: ReduceAttributes): void => {\n  reduceCommon(context, 'ReduceMeanShared', attributes, 'mean');\n};\n\nexport const reduceL1Shared = (context: ComputeContext, attributes: ReduceAttributes): void => {\n  reduceCommon(context, 'ReduceL1Shared', attributes, 'l1');\n};\n\nexport const reduceL2Shared = (context: ComputeContext, attributes: ReduceAttributes): void => {\n  reduceCommon(context, 'ReduceL2Shared', attributes, 'l2');\n};\n\nexport const reduceLogSumExpShared = (context: ComputeContext, attributes: ReduceAttributes): void => {\n  reduceCommon(context, 'ReduceLogSumExpShared', attributes, 'logSumExp');\n};\n\nexport const reduceMaxShared = (context: ComputeContext, attributes: ReduceAttributes): void => {\n  reduceCommon(context, 'ReduceMaxShared', attributes, 'max');\n};\n\nexport const reduceMinShared = (context: ComputeContext, attributes: ReduceAttributes): void => {\n  reduceCommon(context, 'ReduceMinShared', attributes, 'min');\n};\n\nexport const reduceProdShared = (context: ComputeContext, attributes: ReduceAttributes): void => {\n  reduceCommon(context, 'ReduceProdShared', attributes, 'prod');\n};\n\nexport const reduceSumShared = (context: ComputeContext, attributes: ReduceAttributes): void => {\n  reduceCommon(context, 'ReduceSumShared', attributes, 'sum');\n};\n\nexport const reduceSumSquareShared = (context: ComputeContext, attributes: ReduceAttributes): void => {\n  reduceCommon(context, 'ReduceSumSquareShared', attributes, 'sumSquare');\n};\n\nexport const reduceLogSumShared = (context: ComputeContext, attributes: ReduceAttributes): void => {\n  reduceCommon(context, 'ReduceLogSumShared', attributes, 'logSum');\n};\n","// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport { DataType } from '../../../wasm-common';\nimport { TensorView } from '../../tensor-view';\nimport { ShapeUtil } from '../../util';\nimport { AttributeWithCacheKey, createAttributeWithCacheKey } from '../attribute-with-cache-key';\nimport { ComputeContext, ProgramInfo, ProgramShaderCacheInfo } from '../types';\n\nimport { createTensorShapeVariables, IndicesHelper, inputVariable, outputVariable, ShaderHelper } from './common';\nimport {\n  reduceL1Shared,\n  reduceL2Shared,\n  reduceLogSumExpShared,\n  reduceLogSumShared,\n  reduceMaxShared,\n  reduceMeanShared,\n  reduceMinShared,\n  reduceProdShared,\n  reduceSumShared,\n  reduceSumSquareShared,\n} from './reduce-shared';\n\nconst validateInputs = (inputs: readonly TensorView[]): void => {\n  if (!inputs || inputs.length === 0 || inputs.length > 2) {\n    throw new Error('Reduce op requires 1 or 2 inputs.');\n  }\n\n  if (inputs.length === 2 && inputs[1].dims.length !== 1) {\n    throw new Error('Invalid axes input dims.');\n  }\n};\n\nexport interface ReduceAttributes extends AttributeWithCacheKey {\n  keepDims: boolean;\n  noopWithEmptyAxes: boolean;\n  axes: number[];\n}\n\nexport type ReduceOp = (\n  input: IndicesHelper,\n  output: IndicesHelper,\n  axes: readonly number[],\n) => [string, string, string, string, ...string[]];\n\nconst noOp: ReduceOp = (input) => ['', '', `var value = ${input.getByIndices('input_indices')};`, ''];\nexport const createReduceProgramInfo = (\n  name: string,\n  shaderCache: ProgramShaderCacheInfo,\n  inputs: readonly TensorView[],\n  reduceOp: ReduceOp,\n  axesInput: number[],\n  outputDataType: DataType,\n  keepDims = false,\n  noopWithEmptyAxes = false,\n): ProgramInfo => {\n  const outputShape: number[] = [];\n  const inputShape = inputs[0].dims;\n  const inputRank = inputShape.length;\n  const axes = ShapeUtil.normalizeAxes(axesInput, inputRank);\n  const reduceOnAllAxes = !noopWithEmptyAxes && axes.length === 0;\n  inputShape.forEach((d, i) => {\n    if (reduceOnAllAxes || axes.indexOf(i) >= 0) {\n      if (keepDims) {\n        outputShape.push(1);\n      } // else { // skip this axis}\n    } else {\n      outputShape.push(d);\n    }\n  });\n  const outputRank = outputShape.length;\n  const outputSize = ShapeUtil.size(outputShape);\n  const getShaderSource = (shaderHelper: ShaderHelper) => {\n    const idxCopy: string[] = []; // copy output indexes to input indexes\n\n    const input = inputVariable('_A', inputs[0].dataType, inputRank);\n    const output = outputVariable('output', outputDataType, outputRank);\n    const ops = reduceOp(input, output, axes);\n    let reduceOps = ops[2];\n\n    for (let k = 0, l = 0; k < inputRank; k++) {\n      // if this axis is reduced\n      if (reduceOnAllAxes || axes.indexOf(k) >= 0) {\n        if (keepDims) {\n          l++;\n        }\n        // loop over the d-th axis\n        reduceOps = `for(var j${k}: u32 = 0; j${k} < ${inputShape[k]}; j${k}++) {\n                  ${ops[2].includes('last_index') ? `let last_index = j${k};` : ''}\n                  ${input.indicesSet('input_indices', k, `j${k}`)}\n                  ${reduceOps}\n                }`;\n      } else {\n        idxCopy.push(`${input.indicesSet('input_indices', k, output.indicesGet('output_indices', l))};`);\n        l++;\n      }\n    }\n    return `\n\n        ${shaderHelper.registerUniform('output_size', 'u32').declareVariables(input, output)}\n\n        ${shaderHelper.mainStart()}\n          ${shaderHelper.guardAgainstOutOfBoundsWorkgroupSizes('uniforms.output_size')}\n          var input_indices: ${input.type.indices};\n          let output_indices = ${output.offsetToIndices('global_idx')};\n\n          ${idxCopy.join('\\n')}\n          ${ops[0]}       // init ops for reduce max/min\n          ${ops[1]}\n          ${reduceOps}\n          ${ops[3]}\n          ${ops.length === 4 ? output.setByOffset('global_idx', 'value') : ops.slice(4).join('\\n')}\n        }`;\n  };\n\n  return {\n    name,\n    shaderCache,\n    getShaderSource,\n    getRunData: () => ({\n      outputs: [{ dims: outputShape, dataType: outputDataType }],\n      dispatchGroup: { x: Math.ceil(outputSize / 64 /* workgroup size */) },\n      programUniforms: [\n        { type: DataType.uint32, data: outputSize },\n        ...createTensorShapeVariables(inputShape, outputShape),\n      ],\n    }),\n  };\n};\n\nexport const createReduceAttributesFromInputs = (\n  inputs: readonly TensorView[],\n  attributes: ReduceAttributes,\n): ReduceAttributes => {\n  const axes: number[] = [];\n  if (inputs[1].dims[0] > 0) {\n    inputs[1].getBigInt64Array().forEach((v) => axes.push(Number(v)));\n  }\n  return createAttributeWithCacheKey({\n    axes,\n    keepDims: attributes.keepDims,\n    noopWithEmptyAxes: attributes.noopWithEmptyAxes,\n  });\n};\n\nconst runReduceProgram = (\n  context: ComputeContext,\n  name: string,\n  attributes: ReduceAttributes,\n  reduceOp: ReduceOp,\n): void => {\n  const inputs = context.inputs;\n  const updatedAttributes: ReduceAttributes =\n    inputs.length === 1 ? attributes : createReduceAttributesFromInputs(inputs, attributes);\n\n  context.compute(\n    createReduceProgramInfo(\n      name,\n      { hint: updatedAttributes.cacheKey, inputDependencies: ['rank'] },\n      [inputs[0]],\n      updatedAttributes.noopWithEmptyAxes && updatedAttributes.axes.length === 0 ? noOp : reduceOp,\n      updatedAttributes.axes,\n      inputs[0].dataType,\n      updatedAttributes.keepDims,\n      updatedAttributes.noopWithEmptyAxes,\n    ),\n    { inputs: [0] },\n  );\n};\n\nconst reduceLogSumNaive = (context: ComputeContext, attributes: ReduceAttributes): void => {\n  validateInputs(context.inputs);\n  const reduceOp: ReduceOp = (input, output) => [\n    `var value = ${output.type.storage}(0);`,\n    '',\n    `value += ${input.getByIndices('input_indices')};`,\n    'value = log(value);',\n  ];\n  runReduceProgram(context, 'ReduceLogSum', attributes, reduceOp);\n};\n\nconst reduceL1Naive = (context: ComputeContext, attributes: ReduceAttributes): void => {\n  validateInputs(context.inputs);\n  const reduceOp: ReduceOp = (input, output) => [\n    `var value = ${output.type.storage}(0);`,\n    '',\n    `value += abs(${input.getByIndices('input_indices')});`,\n    '',\n  ];\n  runReduceProgram(context, 'ReduceL1', attributes, reduceOp);\n};\n\nconst reduceL2Naive = (context: ComputeContext, attributes: ReduceAttributes): void => {\n  validateInputs(context.inputs);\n  const reduceOp: ReduceOp = (input, output) => [\n    `var t = ${output.type.value}(0); var value = ${output.type.value}(0);`,\n    '',\n    `t = ${input.getByIndices('input_indices')}; value += (t * t);`,\n    'value = sqrt(value);',\n  ];\n  runReduceProgram(context, 'ReduceL2', attributes, reduceOp);\n};\n\nconst reduceLogSumExpNaive = (context: ComputeContext, attributes: ReduceAttributes): void => {\n  validateInputs(context.inputs);\n  const reduceOp: ReduceOp = (input, output) => [\n    `var value = ${output.type.storage}(0);`,\n    '',\n    `value += exp(${input.getByIndices('input_indices')});`,\n    'value = log(value);',\n  ];\n  runReduceProgram(context, 'ReduceLogSumExp', attributes, reduceOp);\n};\n\nconst reduceMaxNaive = (context: ComputeContext, attributes: ReduceAttributes): void => {\n  validateInputs(context.inputs);\n  const reduceOp: ReduceOp = (input, _output, axes) => {\n    const idxZero = [];\n    for (let k = 0; k < input.rank; k++) {\n      if (axes.indexOf(k) >= 0 || axes.length === 0) {\n        idxZero.push(input.indicesSet('input_indices', k, 0));\n      }\n    }\n\n    return [\n      `${idxZero.join('\\n')}`,\n      `var value = ${input.getByIndices('input_indices')};`,\n      `value = max(value, ${input.getByIndices('input_indices')});`,\n      '',\n    ];\n  };\n  runReduceProgram(context, 'ReduceMax', attributes, reduceOp);\n};\n\nconst reduceMeanNaive = (context: ComputeContext, attributes: ReduceAttributes): void => {\n  validateInputs(context.inputs);\n  const reduceOp: ReduceOp = (input, output, axes) => {\n    let size = 1.0;\n    for (let k = 0; k < input.rank; k++) {\n      if (axes.indexOf(k) >= 0 || axes.length === 0) {\n        // TODO: this depends on the input dims. If we want to use uniform, this need to be updated.\n        size *= context.inputs[0].dims[k];\n      }\n    }\n\n    return [\n      'var sum = f32(0);',\n      '',\n      `sum += f32(${input.getByIndices('input_indices')});`,\n      `let value = ${output.type.value}(sum / ${size});`,\n    ];\n  };\n  runReduceProgram(context, 'ReduceMean', attributes, reduceOp);\n};\n\nconst reduceMinNaive = (context: ComputeContext, attributes: ReduceAttributes): void => {\n  validateInputs(context.inputs);\n  const reduceOp: ReduceOp = (input, _output, axes) => {\n    const idxZero = [];\n    for (let k = 0; k < input.rank; k++) {\n      if (axes.indexOf(k) >= 0 || axes.length === 0) {\n        idxZero.push(`input_indices[${k}] = 0;`); // first element\n      }\n    }\n\n    return [\n      `${idxZero.join('\\n')}`,\n      `var value = ${input.getByIndices('input_indices')};`,\n      `value = min(value, ${input.getByIndices('input_indices')});`,\n      '',\n    ];\n  };\n  runReduceProgram(context, 'ReduceMin', attributes, reduceOp);\n};\n\nconst reduceProdNaive = (context: ComputeContext, attributes: ReduceAttributes): void => {\n  validateInputs(context.inputs);\n  const reduceOp: ReduceOp = (input, output) => [\n    `var value = ${output.type.storage}(1);`,\n    '',\n    `value *= ${input.getByIndices('input_indices')};`,\n    '',\n  ];\n  runReduceProgram(context, 'ReduceProd', attributes, reduceOp);\n};\n\nconst reduceSumNaive = (context: ComputeContext, attributes: ReduceAttributes): void => {\n  validateInputs(context.inputs);\n  const reduceOp: ReduceOp = (input, output) => [\n    `var value = ${output.type.storage}(0);`,\n    '',\n    `value += ${input.getByIndices('input_indices')};`,\n    '',\n  ];\n  runReduceProgram(context, 'ReduceSum', attributes, reduceOp);\n};\n\nconst reduceSumSquareNaive = (context: ComputeContext, attributes: ReduceAttributes): void => {\n  validateInputs(context.inputs);\n  const reduceOp: ReduceOp = (input, output) => [\n    `var t = ${output.type.value}(0); var value = ${output.type.value}(0);`,\n    '',\n    `t = ${input.getByIndices('input_indices')}; value += t * t;`,\n    '',\n  ];\n  runReduceProgram(context, 'ReduceSumSquare', attributes, reduceOp);\n};\n\nconst useNaiveReduceMethod = (\n  shape: readonly number[],\n  axes: readonly number[],\n  noopWithEmptyAxes: boolean,\n): boolean => {\n  if (axes.length === 0) {\n    return noopWithEmptyAxes;\n  }\n\n  let outputSize = 1;\n  let reduceSize = 1;\n  for (let dim = 0; dim < axes.length; dim++) {\n    if (axes.indexOf(dim) === -1) {\n      outputSize *= shape[dim];\n    } else {\n      reduceSize *= shape[dim];\n    }\n  }\n\n  // The condition data is very rough, although considering the count of Execution Unit (EU), the potential\n  // work groups in a EU and the counts of loops in the naive and shared methods, also doing experiments\n  // on some machines.\n  return reduceSize < 32 && outputSize > 1024;\n};\n\nexport const reduceMean = (context: ComputeContext, attributes: ReduceAttributes): void => {\n  if (useNaiveReduceMethod(context.inputs[0].dims, attributes.axes, attributes.noopWithEmptyAxes)) {\n    reduceMeanNaive(context, attributes);\n  } else {\n    reduceMeanShared(context, attributes);\n  }\n};\n\nexport const reduceL1 = (context: ComputeContext, attributes: ReduceAttributes): void => {\n  if (useNaiveReduceMethod(context.inputs[0].dims, attributes.axes, attributes.noopWithEmptyAxes)) {\n    reduceL1Naive(context, attributes);\n  } else {\n    reduceL1Shared(context, attributes);\n  }\n};\n\nexport const reduceL2 = (context: ComputeContext, attributes: ReduceAttributes): void => {\n  if (useNaiveReduceMethod(context.inputs[0].dims, attributes.axes, attributes.noopWithEmptyAxes)) {\n    reduceL2Naive(context, attributes);\n  } else {\n    reduceL2Shared(context, attributes);\n  }\n};\n\nexport const reduceLogSumExp = (context: ComputeContext, attributes: ReduceAttributes): void => {\n  if (useNaiveReduceMethod(context.inputs[0].dims, attributes.axes, attributes.noopWithEmptyAxes)) {\n    reduceLogSumExpNaive(context, attributes);\n  } else {\n    reduceLogSumExpShared(context, attributes);\n  }\n};\n\nexport const reduceMax = (context: ComputeContext, attributes: ReduceAttributes): void => {\n  if (useNaiveReduceMethod(context.inputs[0].dims, attributes.axes, attributes.noopWithEmptyAxes)) {\n    reduceMaxNaive(context, attributes);\n  } else {\n    reduceMaxShared(context, attributes);\n  }\n};\n\nexport const reduceMin = (context: ComputeContext, attributes: ReduceAttributes): void => {\n  if (useNaiveReduceMethod(context.inputs[0].dims, attributes.axes, attributes.noopWithEmptyAxes)) {\n    reduceMinNaive(context, attributes);\n  } else {\n    reduceMinShared(context, attributes);\n  }\n};\n\nexport const reduceProd = (context: ComputeContext, attributes: ReduceAttributes): void => {\n  if (useNaiveReduceMethod(context.inputs[0].dims, attributes.axes, attributes.noopWithEmptyAxes)) {\n    reduceProdNaive(context, attributes);\n  } else {\n    reduceProdShared(context, attributes);\n  }\n};\n\nexport const reduceSum = (context: ComputeContext, attributes: ReduceAttributes): void => {\n  if (useNaiveReduceMethod(context.inputs[0].dims, attributes.axes, attributes.noopWithEmptyAxes)) {\n    reduceSumNaive(context, attributes);\n  } else {\n    reduceSumShared(context, attributes);\n  }\n};\n\nexport const reduceSumSquare = (context: ComputeContext, attributes: ReduceAttributes): void => {\n  if (useNaiveReduceMethod(context.inputs[0].dims, attributes.axes, attributes.noopWithEmptyAxes)) {\n    reduceSumSquareNaive(context, attributes);\n  } else {\n    reduceSumSquareShared(context, attributes);\n  }\n};\n\nexport const reduceLogSum = (context: ComputeContext, attributes: ReduceAttributes): void => {\n  if (useNaiveReduceMethod(context.inputs[0].dims, attributes.axes, attributes.noopWithEmptyAxes)) {\n    reduceLogSumNaive(context, attributes);\n  } else {\n    reduceLogSumShared(context, attributes);\n  }\n};\n","// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\n// TODO: this is the same naive implementation we use for reduce that has\n// performance limitations when the reduced axis is long. Need to add\n// a optimized codepath for this.\n\nimport { DataType } from '../../../wasm-common';\nimport { TensorView } from '../../tensor-view';\nimport { AttributeWithCacheKey, createAttributeWithCacheKey } from '../attribute-with-cache-key';\nimport { ComputeContext } from '../types';\n\nimport { createReduceProgramInfo, ReduceOp } from './reduce';\n\nconst validateInputs = (inputs: readonly TensorView[]): void => {\n  if (!inputs || inputs.length === 0 || inputs.length > 2) {\n    throw new Error('ArgMinMaxOp op requires 1 or 2 inputs.');\n  }\n  if (inputs[0].dataType !== DataType.float) {\n    throw new Error('Invalid input type.');\n  }\n};\n\nexport interface ArgMinMaxAttributes extends AttributeWithCacheKey {\n  keepDims: boolean;\n  axis: number;\n  selectLastIndex: number;\n}\n\nexport const argMin = (context: ComputeContext, attributes: ArgMinMaxAttributes): void => {\n  validateInputs(context.inputs);\n  const argMinMaxOp: ReduceOp = (input, output, axes) => {\n    const idxZero = [];\n    for (let k = 0; k < input.rank; k++) {\n      if (axes.indexOf(k) >= 0 || axes.length === 0) {\n        idxZero.push(`input_indices[${k}] = 0;`); // first element\n      }\n    }\n    return [\n      `${idxZero.join('\\n')}`,\n      `var value = ${input.getByIndices('input_indices')};\\nvar best_index : i32 = 0;`,\n      `if (${input.getByIndices('input_indices')} ${attributes.selectLastIndex > 0 ? '<=' : '<'} value) {\n         value = ${input.getByIndices('input_indices')};\n         best_index = i32(last_index);\n       }`,\n      '',\n      output.setByOffset('global_idx', 'best_index'),\n    ];\n  };\n\n  context.compute(\n    createReduceProgramInfo(\n      'ArgMin',\n      { hint: attributes.cacheKey, inputDependencies: ['rank'] },\n      [context.inputs[0]],\n      argMinMaxOp,\n      [attributes.axis],\n      DataType.int64,\n      attributes.keepDims,\n    ),\n    { inputs: [0] },\n  );\n};\n\nexport const argMax = (context: ComputeContext, attributes: ArgMinMaxAttributes): void => {\n  validateInputs(context.inputs);\n  const argMinMaxOp: ReduceOp = (input, output, axes) => {\n    const idxZero = [];\n    for (let k = 0; k < input.rank; k++) {\n      if (axes.indexOf(k) >= 0 || axes.length === 0) {\n        idxZero.push(`input_indices[${k}] = 0;`); // first element\n      }\n    }\n    return [\n      `${idxZero.join('\\n')}`,\n      `var value = ${input.getByIndices('input_indices')};\\nvar best_index : i32 = 0;`,\n      `if (${input.getByIndices('input_indices')} ${attributes.selectLastIndex > 0 ? '>=' : '>'} value) {\n         value = ${input.getByIndices('input_indices')};\n         best_index = i32(last_index);\n       }`,\n      '',\n      output.setByOffset('global_idx', 'best_index'),\n    ];\n  };\n\n  context.compute(\n    createReduceProgramInfo(\n      'argMax',\n      { hint: attributes.cacheKey, inputDependencies: ['rank'] },\n      [context.inputs[0]],\n      argMinMaxOp,\n      [attributes.axis],\n      DataType.int64,\n      attributes.keepDims,\n    ),\n    { inputs: [0] },\n  );\n};\n\nexport const parseArgMinMaxAttributes = (attributes: Record<string, unknown>): ArgMinMaxAttributes =>\n  createAttributeWithCacheKey(attributes as Omit<ArgMinMaxAttributes, keyof AttributeWithCacheKey>);\n","// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport { DataType } from '../../../wasm-common';\nimport { TensorView } from '../../tensor-view';\nimport { ShapeUtil } from '../../util';\nimport { ComputeContext, GpuDataType, ProgramInputTensorInfoDependency, ProgramUniform } from '../types';\n\nimport {\n  getMaxComponents,\n  IndicesHelper,\n  inputVariable,\n  outputVariable,\n  ShaderHelper,\n  tensorTypeToWsglStorageType,\n  tensorTypeToWsglValueType,\n  UniformDataElementType,\n  UniformsArrayType,\n} from './common';\n\nexport const enum AttentionQkvFormat {\n  unknown, // enum value not set, or depends on qkv projection implementation details\n  qkvBNSH, // for non-packed qkv, permuted\n  qkvBSNH, // for non-packed qkv, not permuted, used by memory efficient attention or MultiHeadAttention\n  qkvBSN3H, // for TRT fused attention, qkv are packed\n  qkvBNSHqkvBS3NH, // for TRT fused causal attention, data has two formats (qkv is 3BNSH, gemm_buffer is BS3NH)\n  qKvBSNHxBSN2H, // for TRT fused cross attention, kv are packed\n  qkvTNH, // for memory efficient attention, qkv are not packed, and paddings are removed.\n  qkvTN3H, // for TRT fused attention, qkv are packed and paddings are removed\n}\n\nexport const enum AttentionMaskType {\n  none, // No mask\n  mask1dKeySeqLen, // [batch_size], key sequence length\n  mask1dEndStart, // [2 * batch_size] with end positions and start positions\n  mask1DKeySeqLenStart, // [3 * batch_size + 2] with [key_len[0], ..., key_len[batch_size - 1], query_start[0],\n  // ..., query_start[batch_size - 1], query_end[batch_size - 1], key_start[0], ...,\n  // key_start[batch_size - 1], key_end[batch_size - 1]]\n  mask2dDummy, // dummy mask with shape [1, 1] or [batch_size, 1]. It has same effect as no mask.\n  mask2dKeyPadding, // [batch_size, total_sequence_length]\n  mask3dAttention, // [batch_size, sequence_length, total_sequence_length]\n  mask4dMegatron, // Megatron causal mask with shape [batch_size, 1, max_sequence_length, max_sequence_length]\n  maskUnknown,\n}\n\nexport interface AttentionParameters {\n  batchSize: number;\n  sequenceLength: number;\n  pastSequenceLength: number;\n  kvSequenceLength: number;\n  totalSequenceLength: number;\n  maxSequenceLength: number;\n  inputHiddenSize: number;\n  hiddenSize: number;\n  vHiddenSize: number;\n  headSize: number;\n  vHeadSize: number;\n  numHeads: number;\n  kvNumHeads?: number;\n  nReps?: number;\n  isUnidirectional?: boolean;\n  pastPresentShareBuffer: boolean;\n  maskFilterValue?: number;\n  maskType: AttentionMaskType;\n  scale: number;\n  broadcastResPosBias: boolean;\n  passPastInKv: boolean;\n  qkvFormat: AttentionQkvFormat;\n  softcap?: number;\n  doRotary?: number;\n  rotaryInterLeaved?: number;\n  sommoothSoftmax?: number;\n  localWindowsSize?: number;\n}\n\nexport interface AttentionAttrs {\n  numHeads: number;\n  isUnidirectional: number;\n  maskFilterValue: number;\n  scale: number;\n  doRotary: number;\n  qkvHiddenSizes: number[];\n  pastPresentShareBuffer: boolean;\n}\n\nconst validateAttentionInputs = (inputs: readonly TensorView[], attributes: AttentionAttrs): AttentionParameters => {\n  // Abbreviation and Meanings:\n  //   B:    batch_size\n  //   S:    sequence_length (input sequence length of query)\n  //   P:    past_sequence_length (past sequence length of key or value)\n  //   L:    kv_sequence_length (input sequence length of key or value)\n  //   M:    max_sequence_length\n  //   T:    total_sequence_length = past_sequence_length + kv_sequence_length\n  //   N:    num_heads\n  //   H:    head size for Q and K, aka q_head_size or k_head_size or qk_head_size\n  //   H_v:  v_head_size\n  //   D_i:  input hidden size\n  //   D:    hidden size for Q and K (D = N * H), aka q_hidden_size or k_hidden_size or qk_hidden_size\n  //   D_v:  v_hidden_size = num_heads * v_head_size\n\n  // When past state is used, Q, K and V should have same hidden size (unless we split it into past_key and past_value).\n\n  // Input shapes:\n  //   input        (Q/K/V)    : (B, S, D_i)\n  //   weights      (Q/K/V)    : (D_i, D + D + D_v)\n  //   bias         (Q/K/V)    : (D + D + D_v)\n  //   mask_index              : see below\n  //   past         (K/V)      : (2, B, N, P, H) or NULL\n  //   attention_bias          : (B, N, S, T) or NULL\n\n  // For mask_index, the following shapes are supported:\n  //     NULL, (B, 1), (1, 1)\n  //     (B), (2 * B), (3 * B + 2)\n  //     (B, T)\n  //     (B, S, T)\n  //     (B, 1, M, M)\n  //\n  // When a model is pruned (like some attention heads are removed in Q/K/V), input_hidden_size could be larger\n  // than hidden dimension of Q, K and V.\n\n  const input = inputs[0];\n  const weights = inputs[1];\n  const bias = inputs[2];\n  const maskIndex = inputs[3];\n  const past = inputs[4];\n  const attentionBias = inputs[5];\n\n  if (past && attentionBias) {\n    throw new Error('Attention cannot have both past and attention_bias');\n  }\n\n  if (input.dims.length !== 3) {\n    throw new Error('Input \"input\" must have 3 dimensions');\n  }\n\n  const batchSize = input.dims[0];\n  const sequenceLength = input.dims[1];\n  const inputHiddenSize = input.dims[2];\n\n  if (bias.dims.length !== 1) {\n    throw new Error('Input \"bias\" is expected to have 1 dimensions');\n  }\n\n  if (weights.dims.length !== 2) {\n    throw new Error('Input \"weights\" is expected to have 2 dimensions');\n  }\n\n  if (weights.dims[0] !== inputHiddenSize) {\n    throw new Error('Input 1 dimension 0 should have same length as dimension 2 of input 0');\n  }\n\n  if (bias.dims[0] !== weights.dims[1]) {\n    throw new Error('Input \"bias\" dimension 0 should have same length as dimension 1 of input \"weights\"');\n  }\n\n  let qHiddenSize = bias.dims[0] / 3;\n  let kHiddenSize = qHiddenSize;\n  let vHiddenSize = kHiddenSize;\n  if (attributes.qkvHiddenSizes.length > 0) {\n    if (attributes.qkvHiddenSizes.length !== 3) {\n      throw new Error('qkv_hidden_sizes attribute should have 3 elements');\n    }\n    for (const sz of attributes.qkvHiddenSizes) {\n      if (sz % attributes.numHeads !== 0) {\n        throw new Error('qkv_hidden_sizes should be divisible by num_heads');\n      }\n    }\n\n    qHiddenSize = attributes.qkvHiddenSizes[0];\n    kHiddenSize = attributes.qkvHiddenSizes[1];\n    vHiddenSize = attributes.qkvHiddenSizes[2];\n  }\n\n  const kvSequenceLength = sequenceLength;\n\n  if (qHiddenSize !== kHiddenSize) {\n    throw new Error('qkv_hidden_sizes first element should be same as the second');\n  }\n\n  if (bias.dims[0] !== qHiddenSize + kHiddenSize + vHiddenSize) {\n    throw new Error('Input \"bias\" dimension 0 should have same length as sum of Q/K/V hidden sizes');\n  }\n\n  let pastSequenceLength = 0;\n  if (past) {\n    if (kHiddenSize !== vHiddenSize) {\n      throw new Error('Input \"past\" expect k_hidden_size == v_hidden_size');\n    }\n    if (past.dims.length !== 5) {\n      throw new Error('Input \"past\" must have 5 dimensions');\n    }\n    if (past.dims[0] !== 2) {\n      throw new Error('Input \"past\" first dimension must be 2');\n    }\n    if (past.dims[1] !== batchSize) {\n      throw new Error('Input \"past\" second dimension must be batch_size');\n    }\n    if (past.dims[2] !== attributes.numHeads) {\n      throw new Error('Input \"past\" third dimension must be num_heads');\n    }\n    if (past.dims[4] !== kHiddenSize / attributes.numHeads) {\n      throw new Error('Input \"past\" fifth dimension must be k_hidden_size / num_heads');\n    }\n\n    if (!attributes.pastPresentShareBuffer) {\n      pastSequenceLength = past.dims[3];\n    }\n    // TODO: handle past_seq_len\n  }\n\n  const totalSequenceLength = kvSequenceLength + pastSequenceLength;\n  const maxSequenceLength = -1;\n\n  const maskType = AttentionMaskType.none;\n  if (maskIndex) {\n    // maskType = AttentionMaskType.MASK_UNKNOWN;\n    // TODO: handle mask\n    throw new Error('Mask not supported');\n  }\n\n  if (past) {\n    throw new Error('past is not supported');\n  }\n\n  if (attentionBias) {\n    if (attentionBias.dims.length !== 4) {\n      throw new Error('Input \"attention_bias\" must have 4 dimensions');\n    }\n\n    // TODO: support broadcasting the first and second dimensions of attention_bias\n    if (\n      attentionBias.dims[0] !== batchSize ||\n      attentionBias.dims[1] !== attributes.numHeads ||\n      attentionBias.dims[2] !== sequenceLength ||\n      attentionBias.dims[3] !== totalSequenceLength\n    ) {\n      throw new Error('Expect \"attention_bias\" shape (batch_size, num_heads, sequence_length, total_sequence_length)');\n    }\n  }\n\n  return {\n    batchSize,\n    sequenceLength,\n    pastSequenceLength,\n    kvSequenceLength,\n    totalSequenceLength,\n    maxSequenceLength,\n    inputHiddenSize,\n    hiddenSize: qHiddenSize,\n    vHiddenSize,\n    headSize: Math.floor(qHiddenSize / attributes.numHeads),\n    vHeadSize: Math.floor(vHiddenSize / attributes.numHeads),\n    numHeads: attributes.numHeads,\n    isUnidirectional: false,\n    pastPresentShareBuffer: false,\n    maskFilterValue: attributes.maskFilterValue,\n    maskType,\n    scale: attributes.scale,\n    broadcastResPosBias: false,\n    passPastInKv: false,\n    qkvFormat: AttentionQkvFormat.qkvBNSH,\n  };\n};\n\nconst initVarStub = (\n  seqLensInput: IndicesHelper | undefined,\n  totalSequenceLengthInput: IndicesHelper | undefined,\n  initPastSequenceLength: boolean,\n) => {\n  // In the case of GQA, redefine total_sequence_length, present_sequence_length and past_sequence_length based on seqlen_k input\n  if (totalSequenceLengthInput && seqLensInput) {\n    return `\n      let total_sequence_length_input = u32(${totalSequenceLengthInput.getByOffset('0')});\n      let present_sequence_length = max(total_sequence_length_input, uniforms.past_sequence_length);\n      let is_subsequent_prompt: bool = sequence_length > 1 && sequence_length != total_sequence_length_input;\n      let is_first_prompt: bool = is_subsequent_prompt == false && sequence_length == total_sequence_length_input;\n      total_sequence_length = u32(${seqLensInput?.getByOffset('batchIdx')}) + 1;\n      var past_sequence_length: u32 = 0;\n      if (is_first_prompt == false) {\n        past_sequence_length = total_sequence_length - sequence_length;\n      }\n       `;\n  } else {\n    return `\n    ${initPastSequenceLength ? 'let past_sequence_length = uniforms.past_sequence_length' : ''};\n    let present_sequence_length = total_sequence_length;\n    `;\n  }\n};\n\nconst createInPlaceSoftmaxProgramInfo = (\n  input: TensorView,\n  batchSize: number,\n  numHeads: number,\n  pastSequenceLength: number,\n  sequenceLength: number,\n  totalSequenceLength: number,\n  seqLens: TensorView | undefined,\n  totalSequenceLengthInput: TensorView | undefined,\n) => {\n  // Set components to 1 if seqLens is specified, i.e. GroupQueryAttention.\n  const components = getMaxComponents(seqLens ? 1 : totalSequenceLength);\n  let WG = 64;\n  const totalSequenceLengthComp = totalSequenceLength / components;\n  if (totalSequenceLengthComp < WG) {\n    WG = 32;\n  }\n  const elementsPerThread = Math.ceil(totalSequenceLength / components / WG);\n  const programUniforms: ProgramUniform[] = [\n    { type: DataType.uint32, data: batchSize },\n    { type: DataType.uint32, data: numHeads },\n    { type: DataType.uint32, data: pastSequenceLength },\n    { type: DataType.uint32, data: sequenceLength },\n    { type: DataType.uint32, data: totalSequenceLengthComp },\n    { type: DataType.uint32, data: elementsPerThread },\n  ];\n  const dataType = tensorTypeToWsglStorageType(input.dataType, components);\n  const f32Type = tensorTypeToWsglValueType(DataType.float, components);\n  const inputDependencies: ProgramInputTensorInfoDependency[] = ['type'];\n  if (seqLens) {\n    inputDependencies.push('type');\n  }\n  if (totalSequenceLengthInput) {\n    inputDependencies.push('type');\n  }\n  const getShaderSource = (shaderHelper: ShaderHelper) => {\n    const inputHelper = outputVariable('x', input.dataType, input.dims, components);\n    const inputHelpers = [inputHelper];\n    const seqLensInputHelper = seqLens ? inputVariable('seq_lens', seqLens.dataType, seqLens.dims) : undefined;\n    if (seqLensInputHelper) {\n      inputHelpers.push(seqLensInputHelper);\n    }\n\n    const totalSequenceLengthInputHelper = totalSequenceLengthInput\n      ? inputVariable('total_sequence_length_input', totalSequenceLengthInput.dataType, totalSequenceLengthInput.dims)\n      : undefined;\n    if (totalSequenceLengthInputHelper) {\n      inputHelpers.push(totalSequenceLengthInputHelper);\n    }\n    const elemValueType = tensorTypeToWsglValueType(input.dataType);\n    const uniforms: UniformsArrayType = [\n      { name: 'batch_size', type: 'u32' },\n      { name: 'num_heads', type: 'u32' },\n      { name: 'past_sequence_length', type: 'u32' },\n      { name: 'sequence_length', type: 'u32' },\n      { name: 'total_sequence_length', type: 'u32' },\n      { name: 'elements_per_thread', type: 'u32' },\n    ];\n\n    return `\n  var<workgroup> thread_max: array<f32, ${WG}>;\n  var<workgroup> thread_sum: array<f32, ${WG}>;\n  ${shaderHelper.registerUniforms(uniforms).declareVariables(...inputHelpers)}\n  ${shaderHelper.mainStart([WG, 1, 1])}\n    let batchIdx = workgroup_id.z / uniforms.num_heads;\n    let headIdx = workgroup_id.z % uniforms.num_heads;\n    let sequence_length = uniforms.sequence_length;\n    var total_sequence_length = uniforms.total_sequence_length;\n    ${initVarStub(seqLensInputHelper, totalSequenceLengthInputHelper, false)}\n    let local_offset = local_idx * uniforms.elements_per_thread;\n    let offset = (global_idx / ${WG}) * uniforms.total_sequence_length + local_offset;\n    let seq_causal_length = ${seqLens ? 'u32(past_sequence_length + workgroup_id.y + 1)' : 'total_sequence_length'};\n    var thread_max_vector = ${f32Type}(-3.402823e+38f);\n    for (var i: u32 = 0; i < uniforms.elements_per_thread && i + local_offset < seq_causal_length; i++) {\n      thread_max_vector = max(${f32Type}(x[offset + i]), thread_max_vector);\n    }\n    thread_max[local_idx] = ${(() => {\n      switch (components) {\n        case 1:\n          return 'thread_max_vector';\n        case 2:\n          return 'max(thread_max_vector.x, thread_max_vector.y)';\n        case 4:\n          return 'max(max(thread_max_vector.x, thread_max_vector.y), max(thread_max_vector.z, thread_max_vector.w))';\n        default:\n          throw new Error(`Unsupported components: ${components}`);\n      }\n    })()};\n    workgroupBarrier();\n\n    var max_value =  f32(-3.402823e+38f);\n    for (var i = 0u; i < ${WG}; i++) {\n      max_value = max(thread_max[i], max_value);\n    }\n\n    var sum_vector = ${f32Type}(0);\n    for (var i: u32 = 0; i < uniforms.elements_per_thread && i + local_offset < seq_causal_length; i++) {\n      sum_vector += exp(${f32Type}(x[offset + i]) - max_value);\n    }\n    thread_sum[local_idx] = ${(() => {\n      switch (components) {\n        case 1:\n          return 'sum_vector';\n        case 2:\n          return 'sum_vector.x + sum_vector.y';\n        case 4:\n          return 'sum_vector.x + sum_vector.y + sum_vector.z + sum_vector.w';\n        default:\n          throw new Error(`Unsupported components: ${components}`);\n      }\n    })()};\n    workgroupBarrier();\n\n    var sum: f32 = 0;\n    for (var i = 0u; i < ${WG}; i++) {\n      sum += thread_sum[i];\n    }\n\n    if (sum == 0) {\n      for (var i: u32 = 0; i < uniforms.elements_per_thread && i + local_offset < seq_causal_length; i++) {\n        x[offset + i] = ${inputHelper.type.value}(${elemValueType}(1.0) / ${elemValueType}(seq_causal_length));\n      }\n    } else {\n      for (var i: u32 = 0; i < uniforms.elements_per_thread && i + local_offset < seq_causal_length; i++) {\n        var f32input = ${f32Type}(x[offset + i]);\n        x[offset + i] = ${inputHelper.type.value}(exp(f32input - max_value) / sum);\n      }\n    }\n      ${\n        seqLens\n          ? `\n        for (var total_seq_id: u32 = seq_causal_length; total_seq_id + local_offset < uniforms.total_sequence_length; total_seq_id++) {\n          x[offset + total_seq_id] = ${inputHelper.type.value}(${elemValueType}(0));\n        }`\n          : ''\n      };\n  }`;\n  };\n\n  return {\n    name: 'AttentionProbsSoftmax',\n    shaderCache: { hint: `${WG};${dataType};${components}`, inputDependencies },\n    getShaderSource,\n    getRunData: () => ({\n      outputs: [],\n      dispatchGroup: { x: 1, y: sequenceLength, z: batchSize * numHeads },\n      programUniforms,\n    }),\n  };\n};\n\nconst createAttentionProbsProgramInfo = (\n  outputCount: number,\n  q: TensorView,\n  key: TensorView,\n  pastKey: TensorView | undefined,\n  attentionBias: TensorView | undefined,\n  parameters: AttentionParameters,\n  pastSequenceLength: number,\n  seqLens: TensorView | undefined,\n  totalSequenceLengthInput: TensorView | undefined,\n) => {\n  const totalSequenceLength = pastSequenceLength + parameters.kvSequenceLength;\n  const probsShape = [parameters.batchSize, parameters.numHeads, parameters.sequenceLength, totalSequenceLength];\n  const presentKey = outputCount > 1 && pastKey;\n  const kvNumHeads = parameters.kvNumHeads ? parameters.kvNumHeads : parameters.numHeads;\n  const presentKeyShape = presentKey\n    ? [parameters.batchSize, kvNumHeads, totalSequenceLength, parameters.headSize]\n    : undefined;\n  const nReps = parameters.nReps ? parameters.nReps : 1;\n  // TODO: handle mask\n\n  const alpha = parameters.scale === 0 ? 1.0 / Math.sqrt(parameters.headSize) : parameters.scale;\n  const components = getMaxComponents(parameters.headSize);\n  const vectorizedHeadSize = parameters.headSize / components;\n  const TILE_SIZE = 12;\n  const dispatch = {\n    x: Math.ceil(totalSequenceLength / TILE_SIZE),\n    y: Math.ceil(parameters.sequenceLength / TILE_SIZE),\n    z: parameters.batchSize * parameters.numHeads,\n  };\n  const programUniforms: ProgramUniform[] = [\n    { type: DataType.uint32, data: parameters.sequenceLength },\n    { type: DataType.uint32, data: vectorizedHeadSize },\n    { type: DataType.uint32, data: totalSequenceLength },\n    { type: DataType.uint32, data: parameters.numHeads },\n    { type: DataType.uint32, data: parameters.headSize },\n    { type: DataType.float, data: alpha },\n    { type: DataType.uint32, data: pastSequenceLength },\n    { type: DataType.uint32, data: parameters.kvSequenceLength },\n    { type: DataType.uint32, data: nReps },\n  ];\n  // Feed pastKey to the shader-code only if it is non-zero and presentKey is being produced\n  const feedPastKey = presentKey && pastKey && ShapeUtil.size(pastKey.dims) > 0;\n  const inputDependencies: ProgramInputTensorInfoDependency[] = ['type', 'type'];\n  if (feedPastKey) {\n    inputDependencies.push('type');\n  }\n  if (attentionBias) {\n    inputDependencies.push('type');\n  }\n  if (seqLens) {\n    inputDependencies.push('type');\n  }\n  if (totalSequenceLengthInput) {\n    inputDependencies.push('type');\n  }\n  const outputs = [{ dims: probsShape, dataType: q.dataType, gpuDataType: GpuDataType.default }];\n  if (presentKey) {\n    outputs.push({ dims: presentKeyShape!, dataType: q.dataType, gpuDataType: GpuDataType.default });\n  }\n  const getShaderSource = (shaderHelper: ShaderHelper) => {\n    const qInput = inputVariable('q', q.dataType, q.dims, components);\n    const kInput = inputVariable('key', key.dataType, key.dims, components);\n    const inputVars = [qInput, kInput];\n    if (feedPastKey) {\n      const pastKeyInput = inputVariable('past_key', pastKey.dataType, pastKey.dims, components);\n      inputVars.push(pastKeyInput);\n    }\n    if (attentionBias) {\n      inputVars.push(inputVariable('attention_bias', attentionBias.dataType, attentionBias.dims));\n    }\n    const seqLensInputVariable = seqLens ? inputVariable('seq_lens', seqLens.dataType, seqLens.dims) : undefined;\n    if (seqLensInputVariable) {\n      inputVars.push(seqLensInputVariable);\n    }\n    const totalSequenceLengthInputVariable = totalSequenceLengthInput\n      ? inputVariable('total_sequence_length_input', totalSequenceLengthInput.dataType, totalSequenceLengthInput.dims)\n      : undefined;\n    if (totalSequenceLengthInputVariable) {\n      inputVars.push(totalSequenceLengthInputVariable);\n    }\n    const output = outputVariable('output', q.dataType, probsShape);\n    const outputVars = [output];\n    if (presentKey) {\n      outputVars.push(outputVariable('present_key', q.dataType, presentKeyShape!, components));\n    }\n    const f32Type = tensorTypeToWsglValueType(DataType.float, components);\n\n    const uniforms: UniformsArrayType = [\n      { name: 'M', type: 'u32' },\n      { name: 'K', type: 'u32' },\n      { name: 'N', type: 'u32' },\n      { name: 'num_heads', type: 'u32' },\n      { name: 'head_size', type: 'u32' },\n      { name: 'alpha', type: 'f32' as UniformDataElementType },\n      { name: 'past_sequence_length', type: 'u32' },\n      { name: 'kv_sequence_length', type: 'u32' },\n      { name: 'n_reps', type: 'u32' },\n    ];\n    return `\n  const TILE_SIZE = ${TILE_SIZE}u;\n\n  var<workgroup> tileQ: array<${qInput.type.storage}, ${TILE_SIZE * TILE_SIZE}>;\n  var<workgroup> tileK: array<${qInput.type.storage}, ${TILE_SIZE * TILE_SIZE}>;\n  ${shaderHelper.registerUniforms(uniforms).declareVariables(...inputVars, ...outputVars)}\n  ${shaderHelper.mainStart([TILE_SIZE, TILE_SIZE, 1])}\n    // x holds the N and y holds the M\n    let headIdx = workgroup_id.z % uniforms.num_heads;\n    let kvHeadIdx = ${nReps === 1 ? 'headIdx' : 'headIdx / uniforms.n_reps'};\n    let kv_num_heads = ${nReps === 1 ? 'uniforms.num_heads' : 'uniforms.num_heads / uniforms.n_reps'};\n    let batchIdx = workgroup_id.z / uniforms.num_heads;\n    let m = workgroup_id.y * TILE_SIZE;\n    let n = workgroup_id.x * TILE_SIZE;\n    let sequence_length = uniforms.M;\n    var total_sequence_length = uniforms.N;\n    ${initVarStub(seqLensInputVariable, totalSequenceLengthInputVariable, true)}\n    let absKvHeadIdx = batchIdx * kv_num_heads + kvHeadIdx;\n    let qOffset = workgroup_id.z * uniforms.M * uniforms.K + m * uniforms.K;\n    ${feedPastKey && presentKey ? 'let pastKeyOffset = absKvHeadIdx * uniforms.past_sequence_length * uniforms.K;' : ''};\n    let kOffset = absKvHeadIdx * uniforms.kv_sequence_length * uniforms.K;\n    ${presentKey ? 'let presentKeyOffset = absKvHeadIdx * uniforms.N * uniforms.K;' : ''}\n    var value = ${f32Type}(0);\n    for (var w: u32 = 0u; w < uniforms.K; w += TILE_SIZE) {\n      if (global_id.y < uniforms.M && w + local_id.x < uniforms.K) {\n        tileQ[TILE_SIZE * local_id.y + local_id.x] = q[qOffset + local_id.y * uniforms.K + w + local_id.x];\n      }\n      if (n + local_id.y < uniforms.N && w + local_id.x < uniforms.K) {\n        var idx = TILE_SIZE * local_id.y + local_id.x;\n      ${(() => {\n        if (feedPastKey && presentKey) {\n          return `\n              if (n + local_id.y < past_sequence_length) {\n                tileK[idx] = past_key[pastKeyOffset + (n + local_id.y) * uniforms.K + w + local_id.x];\n              } else if (n + local_id.y - past_sequence_length < uniforms.kv_sequence_length) {\n                tileK[idx] = key[kOffset + (n + local_id.y - past_sequence_length) * uniforms.K + w + local_id.x];\n              }`;\n        } else {\n          return `\n          if (n + local_id.y < uniforms.kv_sequence_length) {\n            tileK[idx] = key[kOffset + (n + local_id.y) * uniforms.K + w + local_id.x];\n          }`;\n        }\n      })()}\n      ${\n        presentKey\n          ? `if (n + local_id.y < present_sequence_length) {\n        present_key[presentKeyOffset + (n + local_id.y) * uniforms.K + w + local_id.x] = tileK[idx];\n      }`\n          : ''\n      }\n      }\n      workgroupBarrier();\n\n      for (var k: u32 = 0u; k < TILE_SIZE && w+k < uniforms.K; k++) {\n          value += ${f32Type}(tileQ[TILE_SIZE * local_id.y + k] * tileK[TILE_SIZE * local_id.x + k]);\n      }\n\n      workgroupBarrier();\n    }\n\n    if (global_id.y < uniforms.M && global_id.x < total_sequence_length) {\n      let headOffset = workgroup_id.z * uniforms.M * uniforms.N;\n      let outputIdx = headOffset + global_id.y * uniforms.N + global_id.x;\n      var sum: f32 = ${(() => {\n        switch (components) {\n          case 1:\n            return 'value';\n          case 2:\n            return 'value.x + value.y';\n          case 4:\n            return 'value.x + value.y + value.z + value.w';\n          default:\n            throw new Error(`Unsupported components: ${components}`);\n        }\n      })()};\n        output[outputIdx] = ${output.type.value} (sum * uniforms.alpha) + ${\n          attentionBias ? 'attention_bias[outputIdx]' : '0.0'\n        };\n    }\n  }`;\n  };\n  return {\n    name: 'AttentionProbs',\n    shaderCache: {\n      hint: `${components};${attentionBias !== undefined};${pastKey !== undefined};${outputCount}`,\n      inputDependencies,\n    },\n    getRunData: () => ({ outputs, dispatchGroup: dispatch, programUniforms }),\n    getShaderSource,\n  };\n};\n\nconst createVxAttentionScoreProgramInfo = (\n  outputCount: number,\n  probs: TensorView,\n  v: TensorView,\n  pastValue: TensorView | undefined,\n  params: AttentionParameters,\n  pastSequenceLength: number,\n  seqLens: TensorView | undefined = undefined,\n  totalSequenceLengthInput: TensorView | undefined = undefined,\n) => {\n  const totalSequenceLength = pastSequenceLength + params.kvSequenceLength;\n  const nReps = params.nReps ? params.nReps : 1;\n  const repeatedVHiddenSize = params.vHiddenSize * nReps;\n  const presentValue = outputCount > 1 && pastValue;\n  const kvNumHeads = params.kvNumHeads ? params.kvNumHeads : params.numHeads;\n  const presentValueShape = presentValue\n    ? [params.batchSize, kvNumHeads, totalSequenceLength, params.headSize]\n    : undefined;\n  const outputShape = [params.batchSize, params.sequenceLength, repeatedVHiddenSize];\n  const TILE_SIZE = 12;\n  const dispatch = {\n    x: Math.ceil(params.vHeadSize / TILE_SIZE),\n    y: Math.ceil(params.sequenceLength / TILE_SIZE),\n    z: params.batchSize * params.numHeads,\n  };\n\n  const programUniforms: ProgramUniform[] = [\n    { type: DataType.uint32, data: params.sequenceLength },\n    { type: DataType.uint32, data: totalSequenceLength },\n    { type: DataType.uint32, data: params.vHeadSize },\n    { type: DataType.uint32, data: params.numHeads },\n    { type: DataType.uint32, data: params.headSize },\n    { type: DataType.uint32, data: repeatedVHiddenSize },\n    { type: DataType.uint32, data: pastSequenceLength },\n    { type: DataType.uint32, data: params.kvSequenceLength },\n    { type: DataType.uint32, data: nReps },\n  ];\n  // Feed pastValue to the shader-code only if it is non-empty and presentValue is being produced\n  const feedPastValue = presentValue && pastValue && ShapeUtil.size(pastValue.dims) > 0;\n  const inputDependencies: ProgramInputTensorInfoDependency[] = ['type', 'type'];\n  if (feedPastValue) {\n    inputDependencies.push('type');\n  }\n  if (seqLens) {\n    inputDependencies.push('type');\n  }\n  if (totalSequenceLengthInput) {\n    inputDependencies.push('type');\n  }\n  const outputs = [{ dims: outputShape, dataType: probs.dataType, gpuDataType: GpuDataType.default }];\n  if (presentValue) {\n    outputs.push({ dims: presentValueShape!, dataType: probs.dataType, gpuDataType: GpuDataType.default });\n  }\n  const getShaderSource = (shaderHelper: ShaderHelper) => {\n    const probsHelper = inputVariable('probs', probs.dataType, probs.dims);\n    const vHelper = inputVariable('v', v.dataType, v.dims);\n    const inputVars = [probsHelper, vHelper];\n    if (feedPastValue) {\n      inputVars.push(inputVariable('past_value', pastValue.dataType, pastValue.dims));\n    }\n    const seqLensInputVariable = seqLens ? inputVariable('seq_lens', seqLens.dataType, seqLens.dims) : undefined;\n    if (seqLens) {\n      inputVars.push(seqLensInputVariable!);\n    }\n    const totalSequenceLengthInputVariable = totalSequenceLengthInput\n      ? inputVariable('total_sequence_length_input', totalSequenceLengthInput.dataType, totalSequenceLengthInput.dims)\n      : undefined;\n    if (totalSequenceLengthInput) {\n      inputVars.push(totalSequenceLengthInputVariable!);\n    }\n    const output = outputVariable('output', probs.dataType, outputShape);\n    const outputVars = [output];\n    if (presentValue) {\n      outputVars.push(outputVariable('present_value', probs.dataType, presentValueShape!));\n    }\n    const uniforms: UniformsArrayType = [\n      { name: 'M', type: 'u32' },\n      { name: 'K', type: 'u32' },\n      { name: 'N', type: 'u32' },\n      { name: 'num_heads', type: 'u32' },\n      { name: 'head_size', type: 'u32' },\n      { name: 'v_hidden_size', type: 'u32' },\n      { name: 'past_sequence_length', type: 'u32' },\n      { name: 'kv_sequence_length', type: 'u32' },\n      { name: 'n_reps', type: 'u32' },\n    ];\n    return `\n  const TILE_SIZE = ${TILE_SIZE}u;\n  var<workgroup> tileQ: array<${probsHelper.type.value}, ${TILE_SIZE * TILE_SIZE}>;\n  var<workgroup> tileV: array<${probsHelper.type.value}, ${TILE_SIZE * TILE_SIZE}>;\n  ${shaderHelper.registerUniforms(uniforms).declareVariables(...inputVars, ...outputVars)}\n  ${shaderHelper.mainStart([TILE_SIZE, TILE_SIZE, 1])}\n   let headIdx = workgroup_id.z % uniforms.num_heads;\n   let batchIdx = workgroup_id.z / uniforms.num_heads;\n   let kvHeadIdx = ${nReps === 1 ? 'headIdx' : 'headIdx / uniforms.n_reps'};\n   let kv_num_heads = ${nReps === 1 ? 'uniforms.num_heads' : 'uniforms.num_heads / uniforms.n_reps'};\n   let m = global_id.y;\n   let n = global_id.x;\n   let sequence_length = uniforms.M;\n   var total_sequence_length = uniforms.K;\n   ${initVarStub(seqLensInputVariable, totalSequenceLengthInputVariable, true)}\n   let offsetA = workgroup_id.z * uniforms.M * uniforms.K + m * uniforms.K;\n   let absKvHeadIdx = batchIdx * kv_num_heads + kvHeadIdx; // kvHeadIdx is relative to the batch\n   ${feedPastValue && presentValue ? 'let pastValueOffset = absKvHeadIdx * uniforms.N * uniforms.past_sequence_length + n;' : ''};\n   let vOffset = absKvHeadIdx * uniforms.N * uniforms.kv_sequence_length + n;\n   ${presentValue ? 'let presentValueOffset = absKvHeadIdx * uniforms.N * uniforms.K + n;' : ''}\n   var value = ${probsHelper.type.storage}(0);\n   for (var w: u32 = 0u; w < uniforms.K; w += TILE_SIZE) {\n      if (m < uniforms.M && w + local_id.x < uniforms.K) {\n        tileQ[TILE_SIZE * local_id.y + local_id.x] = probs[offsetA + w + local_id.x];\n      }\n      if (n < uniforms.N && w + local_id.y < uniforms.K) {\n        var idx = TILE_SIZE * local_id.y + local_id.x;\n        ${(() => {\n          if (feedPastValue && presentValue) {\n            return `\n        if (w + local_id.y < past_sequence_length) {\n          tileV[idx] = past_value[pastValueOffset + (w + local_id.y) * uniforms.N];\n        } else if (w + local_id.y - past_sequence_length < uniforms.kv_sequence_length) {\n          tileV[idx] = v[vOffset + (w + local_id.y - past_sequence_length) * uniforms.N];\n        }\n      `;\n          } else {\n            return `\n            if (w + local_id.y < uniforms.kv_sequence_length) {\n              tileV[idx] = v[vOffset + (w + local_id.y) * uniforms.N];\n            }`;\n          }\n        })()}\n        ${\n          presentValue\n            ? `\n            if (w + local_id.y < present_sequence_length) {\n          present_value[presentValueOffset + (w + local_id.y) * uniforms.N] = tileV[idx];\n        }`\n            : ''\n        }\n      }\n     workgroupBarrier();\n     for (var k: u32 = 0u; k < TILE_SIZE && w+k < total_sequence_length; k++) {\n       value += tileQ[TILE_SIZE * local_id.y + k] * tileV[TILE_SIZE * k + local_id.x];\n     }\n     workgroupBarrier();\n   }\n\n   // we need to transpose output from BNSH_v to BSND_v\n   if (m < uniforms.M && n < uniforms.N) {\n     let outputIdx = batchIdx * uniforms.M * uniforms.v_hidden_size + m * uniforms.v_hidden_size\n       + headIdx * uniforms.N + n;\n     output[outputIdx] = value;\n   }\n  }`;\n  };\n\n  return {\n    name: 'AttentionScore',\n    shaderCache: { hint: `${pastValue !== undefined};${outputCount}`, inputDependencies },\n    getRunData: () => ({ outputs, dispatchGroup: dispatch, programUniforms }),\n    getShaderSource,\n  };\n};\n\nexport const applyAttention = (\n  context: ComputeContext,\n  q: TensorView,\n  k: TensorView,\n  v: TensorView,\n  _maskIndex: TensorView | undefined,\n  _past: TensorView | undefined,\n  pastKey: TensorView | undefined,\n  pastValue: TensorView | undefined,\n  attentionBiasInput: TensorView | undefined,\n  parameters: AttentionParameters,\n  seqLens: TensorView | undefined = undefined,\n  totalSequenceLengthInput: TensorView | undefined = undefined,\n) => {\n  // Assumption is that presentKey/presentValue exists only if pastKey/pastValue exists.\n  const outputCount = Math.min(context.outputCount, 1 + (pastKey ? 1 : 0) + (pastValue ? 1 : 0));\n  const pastSequenceLength = outputCount > 1 ? parameters.pastSequenceLength : 0;\n  const totalSequenceLength = pastSequenceLength + parameters.kvSequenceLength;\n  const attentionBias =\n    attentionBiasInput && ShapeUtil.size(attentionBiasInput.dims) > 0 ? attentionBiasInput : undefined;\n\n  const inputsK = [q, k];\n  if (outputCount > 1 && pastKey && ShapeUtil.size(pastKey.dims) > 0) {\n    inputsK.push(pastKey);\n  }\n  if (attentionBias) {\n    inputsK.push(attentionBias);\n  }\n  if (seqLens) {\n    inputsK.push(seqLens);\n  }\n  if (totalSequenceLengthInput) {\n    inputsK.push(totalSequenceLengthInput);\n  }\n  // Run AttentionProbs\n  const probs = context.compute(\n    createAttentionProbsProgramInfo(\n      outputCount,\n      q,\n      k,\n      pastKey,\n      attentionBias,\n      parameters,\n      pastSequenceLength,\n      seqLens,\n      totalSequenceLengthInput,\n    ),\n    { inputs: inputsK, outputs: outputCount > 1 ? [-1, 1] : [-1] },\n  )[0];\n\n  // Run Softmax\n  context.compute(\n    createInPlaceSoftmaxProgramInfo(\n      probs,\n      parameters.batchSize,\n      parameters.numHeads,\n      pastSequenceLength,\n      parameters.sequenceLength,\n      totalSequenceLength,\n      seqLens,\n      totalSequenceLengthInput,\n    ),\n    { inputs: seqLens && totalSequenceLengthInput ? [probs, seqLens, totalSequenceLengthInput] : [probs], outputs: [] },\n  );\n\n  // Run AttentionScore\n  const inputsV = [probs, v];\n  if (outputCount > 1 && pastValue && ShapeUtil.size(pastValue.dims) > 0) {\n    inputsV.push(pastValue);\n  }\n  if (seqLens) {\n    inputsV.push(seqLens);\n  }\n  if (totalSequenceLengthInput) {\n    inputsV.push(totalSequenceLengthInput);\n  }\n  context.compute(\n    createVxAttentionScoreProgramInfo(\n      outputCount,\n      probs,\n      v,\n      pastValue,\n      parameters,\n      pastSequenceLength,\n      seqLens,\n      totalSequenceLengthInput,\n    ),\n    {\n      inputs: inputsV,\n      outputs: outputCount > 1 ? [0, 2] : [0],\n    },\n  );\n};\n\nconst prepare = (context: ComputeContext, parameters: AttentionParameters) => {\n  const outputShape = [parameters.batchSize, parameters.numHeads, parameters.sequenceLength, parameters.headSize];\n  const M = parameters.sequenceLength;\n  const K = parameters.inputHiddenSize;\n  const N = parameters.headSize;\n  const TILE_SIZE = 12;\n  const dispatch = {\n    x: Math.ceil(parameters.headSize / TILE_SIZE),\n    y: Math.ceil(parameters.sequenceLength / TILE_SIZE),\n    z: parameters.batchSize * parameters.numHeads,\n  };\n  const inputs = [context.inputs[0], context.inputs[1], context.inputs[2]];\n  const programUniforms: ProgramUniform[] = [\n    { type: DataType.uint32, data: M },\n    { type: DataType.uint32, data: K },\n    { type: DataType.uint32, data: N },\n    { type: DataType.uint32, data: parameters.numHeads },\n    { type: DataType.uint32, data: parameters.headSize },\n    { type: DataType.uint32, data: parameters.hiddenSize },\n    { type: DataType.uint32, data: parameters.hiddenSize + parameters.hiddenSize + parameters.vHiddenSize },\n  ];\n\n  const getShaderSource = (shaderHelper: ShaderHelper) => {\n    const outputQ = outputVariable('output_q', inputs[0].dataType, outputShape);\n    const outputK = outputVariable('output_k', inputs[0].dataType, outputShape);\n    const outputV = outputVariable('output_v', inputs[0].dataType, outputShape);\n    const input = inputVariable('input', inputs[0].dataType, inputs[0].dims);\n    const weight = inputVariable('weight', inputs[1].dataType, inputs[1].dims);\n    const bias = inputVariable('bias', inputs[2].dataType, inputs[2].dims);\n    const dataType = input.type.storage;\n\n    const uniforms: UniformsArrayType = [\n      { name: 'M', type: 'u32' },\n      { name: 'K', type: 'u32' },\n      { name: 'N', type: 'u32' },\n      { name: 'num_heads', type: 'u32' },\n      { name: 'head_size', type: 'u32' },\n      { name: 'hidden_size', type: 'u32' },\n      { name: 'ldb', type: 'u32' },\n    ];\n    return `\n  const TILE_SIZE = ${TILE_SIZE}u;\n  var<workgroup> tileInput: array<${dataType}, ${TILE_SIZE * TILE_SIZE}>;\n  var<workgroup> tileWeightQ: array<${dataType}, ${TILE_SIZE * TILE_SIZE}>;\n  var<workgroup> tileWeightK: array<${dataType}, ${TILE_SIZE * TILE_SIZE}>;\n  var<workgroup> tileWeightV: array<${dataType}, ${TILE_SIZE * TILE_SIZE}>;\n  ${shaderHelper.registerUniforms(uniforms).declareVariables(input, weight, bias, outputQ, outputK, outputV)}\n  ${shaderHelper.mainStart([TILE_SIZE, TILE_SIZE, 1])}\n    let batchIndex = workgroup_id.z / uniforms.num_heads;\n    let headNumber = workgroup_id.z % uniforms.num_heads;\n    let m = global_id.y;\n    let n = global_id.x;\n\n    let inputOffset = batchIndex * (uniforms.M * uniforms.K) + m * uniforms.K;\n    let biasOffsetQ = headNumber * uniforms.head_size;\n    let biasOffsetK = uniforms.hidden_size + biasOffsetQ;\n    let biasOffsetV = uniforms.hidden_size + biasOffsetK;\n\n    var valueQ = ${dataType}(0);\n    var valueK = ${dataType}(0);\n    var valueV = ${dataType}(0);\n    for (var w: u32 = 0u; w < uniforms.K; w += TILE_SIZE) {\n      if (m < uniforms.M && w + local_id.x < uniforms.K) {\n        tileInput[TILE_SIZE * local_id.y + local_id.x] = input[inputOffset + w + local_id.x];\n      }\n      if (n < uniforms.N && w + local_id.y < uniforms.K) {\n        let offset = n + (w + local_id.y) * uniforms.ldb;\n        tileWeightQ[TILE_SIZE * local_id.y + local_id.x] = weight[biasOffsetQ + offset];\n        tileWeightK[TILE_SIZE * local_id.y + local_id.x] = weight[biasOffsetK + offset];\n        tileWeightV[TILE_SIZE * local_id.y + local_id.x] = weight[biasOffsetV + offset];\n      }\n      workgroupBarrier();\n      for (var k: u32 = 0u; k<TILE_SIZE && w+k < uniforms.K; k++) {\n        let inputTileOffset = TILE_SIZE * local_id.y + k;\n        let weightTileOffset = TILE_SIZE * k + local_id.x;\n        valueQ += tileInput[inputTileOffset] * tileWeightQ[weightTileOffset];\n        valueK += tileInput[inputTileOffset] * tileWeightK[weightTileOffset];\n        valueV += tileInput[inputTileOffset] * tileWeightV[weightTileOffset];\n      }\n\n      workgroupBarrier();\n    }\n\n    let headOffset = (m * uniforms.N + n) % uniforms.head_size;\n    valueQ += bias[headOffset + biasOffsetQ];\n    valueK += bias[headOffset + biasOffsetK];\n    valueV += bias[headOffset + biasOffsetV];\n\n    let offset = workgroup_id.z * uniforms.M * uniforms.N;\n    if (m < uniforms.M && n < uniforms.N) {\n      let outputIdx = offset + m * uniforms.N + n;\n      output_q[outputIdx] = valueQ;\n      output_k[outputIdx] = valueK;\n      output_v[outputIdx] = valueV;\n    }\n  }`;\n  };\n\n  return context.compute(\n    {\n      name: 'AttentionPrepare',\n      shaderCache: { inputDependencies: ['type', 'type', 'type'] },\n      getRunData: () => ({\n        outputs: [\n          { dims: outputShape, dataType: context.inputs[0].dataType, gpuDataType: GpuDataType.default },\n          { dims: outputShape, dataType: context.inputs[0].dataType, gpuDataType: GpuDataType.default },\n          { dims: outputShape, dataType: context.inputs[0].dataType, gpuDataType: GpuDataType.default },\n        ],\n        dispatchGroup: dispatch,\n        programUniforms,\n      }),\n      getShaderSource,\n    },\n    { inputs, outputs: [-1, -1, -1] },\n  );\n};\n\nexport const attention = (context: ComputeContext, attributes: AttentionAttrs): void => {\n  const params = validateAttentionInputs(context.inputs, attributes);\n\n  const [q, k, v] = prepare(context, params);\n\n  return applyAttention(\n    context,\n    q,\n    k,\n    v,\n    context.inputs[4],\n    undefined,\n    undefined,\n    undefined,\n    context.inputs[5],\n    params,\n  );\n};\n","// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport { env } from 'onnxruntime-common';\n\nimport { DataType } from '../../../wasm-common';\nimport { TensorView } from '../../tensor-view';\nimport { ShapeUtil } from '../../util';\nimport { AttributeWithCacheKey, createAttributeWithCacheKey } from '../attribute-with-cache-key';\nimport { ComputeContext, ProgramInfo } from '../types';\n\nimport { createTensorShapeVariables, getMaxComponents, inputVariable, outputVariable, ShaderHelper } from './common';\n\nexport interface BatchNormAttributes extends AttributeWithCacheKey {\n  readonly epsilon: number;\n  readonly momentum: number;\n  readonly spatial: boolean;\n  readonly trainingMode: boolean;\n  readonly format: 'NHWC' | 'NCHW';\n  readonly outputCount: number;\n}\n\nconst validateInputs = (inputs: readonly TensorView[], attributes: BatchNormAttributes): void => {\n  if (!inputs || inputs.length !== 5) {\n    throw new Error('BatchNormalization requires 5 inputs');\n  }\n\n  const checkShapeEqual = (actual: readonly number[], expected: readonly number[], message: string) => {\n    const r = expected.length;\n    if (r !== actual.length) {\n      throw new Error(`${message}: num dimensions != ${r}`);\n    }\n    expected.forEach((v, i) => {\n      if (v !== actual[i]) {\n        throw new Error(`${message}: dim[${i}] do not match`);\n      }\n    });\n  };\n\n  if (inputs[0].dims.length > 1) {\n    const shape =\n      attributes.format === 'NHWC'\n        ? attributes.spatial\n          ? inputs[0].dims.slice(-1)\n          : inputs[0].dims.slice(-1).concat(inputs[0].dims.slice(1, inputs[0].dims.length - 1))\n        : inputs[0].dims.slice(1, attributes.spatial ? 2 : undefined);\n    checkShapeEqual(inputs[1].dims, shape, 'Invalid input scale');\n    checkShapeEqual(inputs[2].dims, shape, 'Invalid input B');\n    checkShapeEqual(inputs[3].dims, shape, 'Invalid input mean');\n    checkShapeEqual(inputs[4].dims, shape, 'Invalid input var');\n  } else {\n    checkShapeEqual(inputs[1].dims, [1], 'Invalid input scale');\n    checkShapeEqual(inputs[2].dims, [1], 'Invalid input B');\n    checkShapeEqual(inputs[3].dims, [1], 'Invalid input mean');\n    checkShapeEqual(inputs[4].dims, [1], 'Invalid input var');\n  }\n};\n\nconst createBatchNormInferenceProgramInfo = (\n  inputs: readonly TensorView[],\n  attributes: BatchNormAttributes,\n): ProgramInfo => {\n  const { epsilon, spatial, format } = attributes;\n  const yShape = inputs[0].dims;\n  const components = spatial ? getMaxComponents(yShape[yShape.length - 1]) : 1;\n  const cComponents = format === 'NHWC' && yShape.length > 1 ? components : 1;\n  const outputSize = ShapeUtil.size(yShape) / components;\n  // Only support uniforms for opset version >= 9 (spatial = true).\n  const useShapesUniforms = spatial;\n  const shapeOrRank = useShapesUniforms ? yShape.length : yShape;\n  const x = inputVariable('x', inputs[0].dataType, inputs[0].dims, components);\n  const scale = inputVariable('scale', inputs[1].dataType, inputs[1].dims, cComponents);\n  const bias = inputVariable('bias', inputs[2].dataType, inputs[2].dims, cComponents);\n  const inputMean = inputVariable('inputMean', inputs[3].dataType, inputs[3].dims, cComponents);\n  const inputVar = inputVariable('inputVar', inputs[4].dataType, inputs[4].dims, cComponents);\n  const y = outputVariable('y', inputs[0].dataType, shapeOrRank, components);\n  // TODO: support inputs with different data type. Current we need to make sure all inputs have the same data type.\n  // Otherwise, the shader compilation will fail.\n  const calcCOffset = (): string => {\n    let cOffset = '';\n    if (spatial) {\n      cOffset = `let cOffset = ${\n        yShape.length === 1\n          ? '0u'\n          : format === 'NHWC'\n            ? `outputIndices[${yShape.length - 1}] / ${components}`\n            : 'outputIndices[1]'\n      };`;\n    } else {\n      if (format === 'NCHW') {\n        cOffset = `\n            ${y.indicesSet('outputIndices', '0', '0')}\n            let cOffset = ${y.indicesToOffset('outputIndices')};`;\n      } else {\n        // update C channel.\n        cOffset = `var cIndices = ${scale.type.indices}(0);\n                       cIndices[0] = outputIndices[${yShape.length - 1}];`;\n        // update D1 x ... x Dn channels.\n        for (let i = 1; i < scale.rank; i++) {\n          cOffset += `cIndices[${i}] = outputIndices[${i}];`;\n        }\n        cOffset += `let cOffset = ${scale.indicesToOffset('cIndices')};`;\n      }\n    }\n    return cOffset;\n  };\n  const getInferenceModeShaderSource = (helper: ShaderHelper) => `\n  const epsilon = ${epsilon};\n  ${helper.registerUniform('outputSize', 'u32').declareVariables(x, scale, bias, inputMean, inputVar, y)}\n  ${helper.mainStart()}\n  ${helper.guardAgainstOutOfBoundsWorkgroupSizes('uniforms.outputSize')}\n    var outputIndices = ${y.offsetToIndices(`global_idx * ${components}`)};\n    ${calcCOffset()}\n    let scale = ${scale.getByOffset('cOffset')};\n    let bias = ${bias.getByOffset('cOffset')};\n    let inputMean = ${inputMean.getByOffset('cOffset')};\n    let inputVar = ${inputVar.getByOffset('cOffset')};\n    let x = ${x.getByOffset('global_idx')};\n    let value = (x - inputMean) * inverseSqrt(inputVar + epsilon) * scale + bias;\n    ${y.setByOffset('global_idx', 'value')}\n  }`;\n  return {\n    name: 'BatchNormalization',\n    shaderCache: {\n      hint: `${attributes.epsilon}_${attributes.format}_${spatial}_${components}`,\n      inputDependencies: useShapesUniforms ? ['rank', 'type', 'type', 'type', 'type'] : undefined,\n    },\n    getShaderSource: getInferenceModeShaderSource,\n    getRunData: () => ({\n      outputs: [{ dims: inputs[0].dims, dataType: inputs[0].dataType }],\n      dispatchGroup: { x: Math.ceil(outputSize / 64 /* workgroup size */) },\n      programUniforms: useShapesUniforms\n        ? [{ type: DataType.uint32, data: outputSize }, ...createTensorShapeVariables(yShape)]\n        : [{ type: DataType.uint32, data: outputSize }],\n    }),\n  };\n};\n\nexport const parseBatchNormAttributes = (attributes: Record<string, unknown>): BatchNormAttributes =>\n  createAttributeWithCacheKey(attributes as Omit<BatchNormAttributes, keyof AttributeWithCacheKey>);\n\nexport const batchNorm = (context: ComputeContext, attributes: Record<string, unknown>): void => {\n  const { inputs, outputCount } = context;\n  const updatedAttributes = parseBatchNormAttributes({ ...attributes, outputCount });\n  if (env.webgpu.validateInputContent) {\n    validateInputs(inputs, updatedAttributes);\n  }\n  if (attributes.trainingMode) {\n    throw new Error('BatchNormalization trainingMode is not supported yet.');\n  } else {\n    context.compute(createBatchNormInferenceProgramInfo(inputs, updatedAttributes));\n  }\n};\n","// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport { TensorView } from '../../tensor-view';\nimport { ShapeUtil } from '../../util';\nimport { ComputeContext, ProgramInfo } from '../types';\n\nimport { inputVariable, outputVariable, ShaderHelper } from './common';\n\nconst validateInputs = (inputs: readonly TensorView[]): void => {\n  if (inputs[0].dims.length !== 3) {\n    throw new Error('input should have 3 dimensions');\n  }\n\n  if (![320, 640, 1280].includes(inputs[0].dims[2])) {\n    throw new Error('number of channels should be 320, 640 or 1280');\n  }\n\n  if (inputs[1].dims.length !== 1) {\n    throw new Error('bias is expected to have 1 dimensions');\n  }\n\n  if (inputs[0].dims[2] !== inputs[1].dims[0]) {\n    throw new Error('last dimension of input and bias are not the same');\n  }\n};\n\nconst createBiasAddProgramInfo = (inputs: readonly TensorView[]): ProgramInfo => {\n  const outputShape = inputs[0].dims;\n\n  const channels = inputs[0].dims[2];\n  // since channel number can be only 320/640/1280, it's always divisable by 4\n  const outputSize = ShapeUtil.size(outputShape) / 4;\n\n  const dataType = inputs[0].dataType;\n  const input = inputVariable('input', dataType, outputShape, 4);\n  const bias = inputVariable('bias', dataType, [channels], 4);\n  const residual = inputVariable('residual', dataType, outputShape, 4);\n  const output = outputVariable('output', dataType, outputShape, 4);\n\n  const getShaderSource = (shaderHelper: ShaderHelper) => `\n  const channels = ${channels}u / 4;\n  ${shaderHelper.declareVariables(input, bias, residual, output)}\n\n  ${shaderHelper.mainStart()}\n    ${shaderHelper.guardAgainstOutOfBoundsWorkgroupSizes(outputSize)}\n    let value = ${input.getByOffset('global_idx')}\n      + ${bias.getByOffset('global_idx % channels')} + ${residual.getByOffset('global_idx')};\n    ${output.setByOffset('global_idx', 'value')}\n  }`;\n\n  return {\n    name: 'BiasAdd',\n    getRunData: () => ({\n      outputs: [{ dims: outputShape, dataType: inputs[0].dataType }],\n      dispatchGroup: { x: Math.ceil(outputSize / 64 /* workgroup size */) },\n    }),\n    getShaderSource,\n  };\n};\n\nexport const biasAdd = (context: ComputeContext): void => {\n  validateInputs(context.inputs);\n  context.compute(createBiasAddProgramInfo(context.inputs));\n};\n","// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport { DataType } from '../../../wasm-common';\nimport { TensorView } from '../../tensor-view';\nimport { ShapeUtil } from '../../util';\nimport { AttributeWithCacheKey, createAttributeWithCacheKey } from '../attribute-with-cache-key';\nimport { ComputeContext, ProgramInfo, ProgramUniform } from '../types';\n\nimport {\n  inputVariable,\n  outputVariable,\n  ShaderHelper,\n  tensorTypeToWsglValueType,\n  UniformDataElementType,\n  UniformsArrayType,\n} from './common';\n\ntype BuiltinFunctionName = string;\ntype ElementwiseCustomExpression = (expression: string) => string;\ntype ElementwiseFunctionCall = BuiltinFunctionName | ElementwiseCustomExpression;\n\nconst createElementwiseProgramShader = (\n  shaderHelper: ShaderHelper,\n  datasize: number,\n  inputDataType: number,\n  outputDataType: number,\n  funcCall: ElementwiseFunctionCall,\n  additionalImplementation?: string,\n  additionalUniformsType?: UniformsArrayType,\n): string => {\n  const vecSize = Math.ceil(datasize / 4);\n\n  let expression = '';\n  if (typeof funcCall === 'string') {\n    expression = `${funcCall}(a)`;\n  } else {\n    expression = funcCall('a');\n  }\n\n  const input = inputVariable('inputData', inputDataType, [vecSize], 4);\n  const output = outputVariable('outputData', outputDataType, [vecSize], 4);\n  const uniforms: UniformsArrayType = [{ name: 'vec_size', type: 'u32' }];\n  if (additionalUniformsType) {\n    uniforms.push(...additionalUniformsType);\n  }\n\n  return `\n      ${shaderHelper.registerUniforms(uniforms).declareVariables(input, output)}\n\n  ${additionalImplementation ?? ''}\n\n  ${shaderHelper.mainStart()}\n    ${shaderHelper.guardAgainstOutOfBoundsWorkgroupSizes('uniforms.vec_size')}\n\n    let a = ${input.getByOffset('global_idx')};\n    ${output.setByOffset('global_idx', expression)}\n  }`;\n};\n\nconst createElementwiseProgramInfo = (\n  input: TensorView,\n  name: string,\n  funcCall: ElementwiseFunctionCall,\n  additionalImplementation?: string,\n  cacheKey?: string,\n  outputDataType: number = input.dataType,\n  additionalUniforms?: ProgramUniform[],\n  additionalUniformsType?: UniformsArrayType,\n): ProgramInfo => {\n  const programUniforms: ProgramUniform[] = [\n    { type: DataType.uint32, data: Math.ceil(ShapeUtil.size(input.dims) / 4) },\n  ];\n  if (additionalUniforms) {\n    programUniforms.push(...additionalUniforms);\n  }\n\n  return {\n    name,\n    shaderCache: { hint: cacheKey, inputDependencies: ['type'] },\n    getShaderSource: (shaderHelper) =>\n      createElementwiseProgramShader(\n        shaderHelper,\n        ShapeUtil.size(input.dims),\n        input.dataType,\n        outputDataType,\n        funcCall,\n        additionalImplementation,\n        additionalUniformsType,\n      ),\n    getRunData: (inputTensors) => ({\n      outputs: [{ dims: input.dims, dataType: outputDataType }],\n      dispatchGroup: {\n        x: Math.ceil(ShapeUtil.size(inputTensors[0].dims) / 64 /* workgroup size */ / 4 /* vec size */),\n      },\n      programUniforms,\n    }),\n  };\n};\n\nexport const abs = (context: ComputeContext): void => {\n  context.compute(createElementwiseProgramInfo(context.inputs[0], 'Abs', 'abs'));\n};\n\nexport const acos = (context: ComputeContext): void => {\n  context.compute(createElementwiseProgramInfo(context.inputs[0], 'Acos', 'acos'));\n};\n\nexport const acosh = (context: ComputeContext): void => {\n  context.compute(createElementwiseProgramInfo(context.inputs[0], 'Acosh', 'acosh'));\n};\n\nexport const asin = (context: ComputeContext): void => {\n  context.compute(createElementwiseProgramInfo(context.inputs[0], 'Asin', 'asin'));\n};\n\nexport const asinh = (context: ComputeContext): void => {\n  context.compute(createElementwiseProgramInfo(context.inputs[0], 'Asinh', 'asinh'));\n};\n\nexport const atan = (context: ComputeContext): void => {\n  context.compute(createElementwiseProgramInfo(context.inputs[0], 'Atan', 'atan'));\n};\nexport const atanh = (context: ComputeContext): void => {\n  context.compute(createElementwiseProgramInfo(context.inputs[0], 'Atanh', 'atanh'));\n};\n\nexport interface CastAttributes extends AttributeWithCacheKey {\n  readonly to: number;\n  readonly saturate?: boolean;\n}\n\nexport const parseCastAttributes = (attributes: Record<string, unknown>): CastAttributes =>\n  createAttributeWithCacheKey(attributes as { to: number });\n\nexport const cast = (context: ComputeContext, attributes: CastAttributes): void => {\n  let func: ElementwiseFunctionCall;\n  switch (attributes.to) {\n    case DataType.float16:\n      func = 'vec4<f16>';\n      break;\n    case DataType.float:\n      func = 'vec4<f32>';\n      break;\n    case DataType.uint32:\n      func = 'vec4<u32>';\n      break;\n    case DataType.int32:\n      func = 'vec4<i32>';\n      break;\n    case DataType.bool:\n      func = 'vec4<bool>';\n      break;\n    default:\n      throw new RangeError(`not supported type (specified in attribute 'to' from 'Cast' operator): ${attributes.to}`);\n  }\n  context.compute(\n    createElementwiseProgramInfo(context.inputs[0], 'Cast', func, undefined, attributes.cacheKey, attributes.to),\n  );\n};\n\nexport interface ClipAttributes extends AttributeWithCacheKey {\n  readonly min: number;\n  readonly max: number;\n}\n\nconst generateClipAttributesFromInputs = (inputs: readonly TensorView[]): ClipAttributes => {\n  let min: number;\n  let max: number;\n  const hasMin = inputs.length >= 2 && inputs[1].data !== 0;\n  const hasMax = inputs.length >= 3 && inputs[2].data !== 0;\n\n  switch (inputs[0].dataType) {\n    case DataType.float:\n      min = hasMin ? inputs[1].getFloat32Array()[0] : -3.4028234663852886e38;\n      max = hasMax ? inputs[2].getFloat32Array()[0] : 3.4028234663852886e38;\n      break;\n    case DataType.float16:\n      min = hasMin ? inputs[1].getUint16Array()[0] : 64511; // uint16(64511) <-> float16(-65504.0)\n      max = hasMax ? inputs[2].getUint16Array()[0] : 31743; // uint16(31743) <-> float16(65504.0)\n      break;\n    default:\n      throw new Error('Unsupport data type');\n  }\n\n  return createAttributeWithCacheKey({ min, max });\n};\n\nexport const clip = (context: ComputeContext, clipAttributes: ClipAttributes): void => {\n  const attributes = clipAttributes ? clipAttributes : generateClipAttributesFromInputs(context.inputs);\n  const dataType = tensorTypeToWsglValueType(context.inputs[0].dataType);\n  context.compute(\n    createElementwiseProgramInfo(\n      context.inputs[0],\n      'Clip',\n      (a) => `clamp(${a}, vec4<${dataType}>(uniforms.min), vec4<${dataType}>(uniforms.max))`,\n      undefined,\n      attributes.cacheKey,\n      undefined,\n      [\n        { type: context.inputs[0].dataType, data: attributes.min },\n        { type: context.inputs[0].dataType, data: attributes.max },\n      ],\n      [\n        { name: 'min', type: dataType as UniformDataElementType },\n        { name: 'max', type: dataType as UniformDataElementType },\n      ],\n    ),\n    { inputs: [0] },\n  );\n};\n\nexport const ceil = (context: ComputeContext): void => {\n  context.compute(createElementwiseProgramInfo(context.inputs[0], 'Ceil', 'ceil'));\n};\n\nexport const cos = (context: ComputeContext): void => {\n  context.compute(createElementwiseProgramInfo(context.inputs[0], 'Cos', 'cos'));\n};\n\nexport const cosh = (context: ComputeContext): void => {\n  context.compute(createElementwiseProgramInfo(context.inputs[0], 'Cosh', 'cosh'));\n};\n\nexport interface AlphaAttributes extends AttributeWithCacheKey {\n  readonly alpha: number;\n}\n\nexport const parseAlphaAttributes = (attributes: Record<string, unknown>): AlphaAttributes =>\n  createAttributeWithCacheKey(attributes as { alpha: number });\n\nexport const elu = (context: ComputeContext, attributes: AlphaAttributes): void => {\n  const dataType = tensorTypeToWsglValueType(context.inputs[0].dataType);\n  context.compute(\n    createElementwiseProgramInfo(\n      context.inputs[0],\n      'Elu',\n      (a) => `elu_vf32(${a})`,\n      `\n  const elu_alpha_ = ${dataType}(${attributes.alpha});\n\n  fn elu_f32(a: ${dataType}) -> ${dataType} {\n  return select((exp(a) - 1.0) * elu_alpha_, a, a >= 0.0);\n  }\n\n  fn elu_vf32(v: vec4<${dataType}>) -> vec4<${dataType}> {\n  return vec4(elu_f32(v.x), elu_f32(v.y), elu_f32(v.z), elu_f32(v.w));\n  }`,\n      attributes.cacheKey,\n    ),\n  );\n};\n\nexport const erfImpl = (varType = 'f32') => `\nconst r0: ${varType} = 0.3275911;\nconst r1: ${varType} = 0.254829592;\nconst r2: ${varType} = -0.284496736;\nconst r3: ${varType} = 1.421413741;\nconst r4: ${varType} = -1.453152027;\nconst r5: ${varType} = 1.061405429;\n\nfn erf_vf32(v: vec4<${varType}>) -> vec4<${varType}> {\n  let absv = abs(v);\n  let x = 1.0 / (1.0 + r0 * absv);\n  return sign(v) * (1.0 - ((((r5 * x + r4) * x + r3) * x + r2) * x + r1) * x * exp(-absv * absv));\n}`;\n\nexport const erf = (context: ComputeContext): void => {\n  const dataType = tensorTypeToWsglValueType(context.inputs[0].dataType);\n  context.compute(createElementwiseProgramInfo(context.inputs[0], 'Erf', (a) => `erf_vf32(${a})`, erfImpl(dataType)));\n};\n\nexport const exp = (context: ComputeContext): void => {\n  context.compute(createElementwiseProgramInfo(context.inputs[0], 'Exp', 'exp'));\n};\n\nexport const floor = (context: ComputeContext): void => {\n  context.compute(createElementwiseProgramInfo(context.inputs[0], 'Floor', 'floor'));\n};\n\nexport const gelu = (context: ComputeContext): void => {\n  const dataType = tensorTypeToWsglValueType(context.inputs[0].dataType);\n  context.compute(\n    createElementwiseProgramInfo(\n      context.inputs[0],\n      'Gelu',\n      (a) => `0.5 * ${a} * (1.0 + erf_vf32(${a} * 0.7071067811865475))`,\n      erfImpl(dataType),\n    ),\n  );\n};\n\nexport const leakyRelu = (context: ComputeContext, attributes: AlphaAttributes): void => {\n  const dataType = tensorTypeToWsglValueType(context.inputs[0].dataType);\n  context.compute(\n    createElementwiseProgramInfo(\n      context.inputs[0],\n      'LeakyRelu',\n      (a) => `select(leaky_relu_alpha_ * ${a}, ${a}, ${a} >= vec4<${dataType}>(0.0))`,\n      `const leaky_relu_alpha_ = ${dataType}(${attributes.alpha});`,\n      attributes.cacheKey,\n    ),\n  );\n};\n\nexport const not = (context: ComputeContext): void => {\n  context.compute(createElementwiseProgramInfo(context.inputs[0], 'Not', (a) => `!${a}`));\n};\n\nexport const neg = (context: ComputeContext): void => {\n  context.compute(createElementwiseProgramInfo(context.inputs[0], 'Neg', (a) => `-${a}`));\n};\n\nexport const reciprocal = (context: ComputeContext): void => {\n  context.compute(createElementwiseProgramInfo(context.inputs[0], 'Reciprocal', (a) => `1.0/${a}`));\n};\n\nexport const relu = (context: ComputeContext): void => {\n  const dataType = tensorTypeToWsglValueType(context.inputs[0].dataType);\n  context.compute(\n    createElementwiseProgramInfo(\n      context.inputs[0],\n      'Relu',\n      (a) => `select(vec4<${dataType}>(0.0), ${a}, ${a} > vec4<${dataType}>(0.0))`,\n    ),\n  );\n};\n\nexport const sigmoid = (context: ComputeContext): void => {\n  context.compute(createElementwiseProgramInfo(context.inputs[0], 'Sigmoid', (a) => `(1.0 / (1.0 + exp(-${a})))`));\n};\n\nexport interface HardSigmoidAttributes extends AttributeWithCacheKey {\n  readonly alpha: number;\n  readonly beta: number;\n}\n\nexport const parseHardSigmoidAttributes = (attributes: Record<string, unknown>): HardSigmoidAttributes =>\n  createAttributeWithCacheKey(\n    attributes as {\n      alpha: number;\n      beta: number;\n    },\n  );\n\nexport const hardSigmoid = (context: ComputeContext, attributes: HardSigmoidAttributes): void => {\n  const dataType = tensorTypeToWsglValueType(context.inputs[0].dataType);\n  context.compute(\n    createElementwiseProgramInfo(\n      context.inputs[0],\n      'HardSigmoid',\n      (a) =>\n        `max(vec4<${dataType}>(0.0), min(vec4<${dataType}>(1.0), ${attributes.alpha} * ${a} + vec4<${dataType}>(${attributes.beta})))`,\n      undefined,\n      attributes.cacheKey,\n    ),\n  );\n};\n\nexport const sin = (context: ComputeContext): void => {\n  context.compute(createElementwiseProgramInfo(context.inputs[0], 'Sin', 'sin'));\n};\n\nexport const sinh = (context: ComputeContext): void => {\n  context.compute(createElementwiseProgramInfo(context.inputs[0], 'Sinh', 'sinh'));\n};\n\nexport const sqrt = (context: ComputeContext): void => {\n  context.compute(createElementwiseProgramInfo(context.inputs[0], 'Sqrt', 'sqrt'));\n};\n\nexport const tan = (context: ComputeContext): void => {\n  context.compute(createElementwiseProgramInfo(context.inputs[0], 'Tan', 'tan'));\n};\n\nexport const tanhExpression = (a: string) => `sign(${a}) * (1 - exp(-2 * abs(${a}))) / (1 + exp(-2 * abs(${a})))`;\n\nexport const tanh = (context: ComputeContext): void => {\n  // TODO: revisit after https://github.com/gpuweb/gpuweb/issues/4458 is resolved\n  context.compute(createElementwiseProgramInfo(context.inputs[0], 'Tanh', tanhExpression));\n};\n\nexport const fastGeluImpl = (varType = 'f32') => `\nconst fast_gelu_a: ${varType} = 0.5;\nconst fast_gelu_b: ${varType} = 0.7978845608028654;\nconst fast_gelu_c: ${varType} = 0.035677408136300125;\n\nfn tanh_v(v: vec4<${varType}>) -> vec4<${varType}> {\n  return ${tanhExpression('v')};\n}\n`;\n\nexport const fastGeluExpression = (x: string) =>\n  `(fast_gelu_a + fast_gelu_a * tanh_v(${x} * (fast_gelu_c * ${x} * ${x} + fast_gelu_b))) * ${x}`;\n\nexport const fastGelu = (context: ComputeContext): void => {\n  const dataType = tensorTypeToWsglValueType(context.inputs[0].dataType);\n  context.compute(\n    createElementwiseProgramInfo(\n      context.inputs[0],\n      'FastGelu',\n      fastGeluExpression,\n      fastGeluImpl(dataType),\n      undefined,\n      context.inputs[0].dataType,\n    ),\n  );\n};\n\nexport const thresholdedRelu = (context: ComputeContext, attributes: AlphaAttributes): number => {\n  const dataType = tensorTypeToWsglValueType(context.inputs[0].dataType);\n  context.compute(\n    createElementwiseProgramInfo(\n      context.inputs[0],\n      'ThresholdedRelu',\n      (a) => `select(vec4<${dataType}>(0.0), ${a}, ${a} > thresholded_relu_alpha_)`,\n      `const thresholded_relu_alpha_ = vec4<${dataType}>(${attributes.alpha});`,\n      attributes.cacheKey,\n    ),\n  );\n  return 0;\n};\n\nexport const log = (context: ComputeContext): void => {\n  context.compute(createElementwiseProgramInfo(context.inputs[0], 'Log', 'log'));\n};\n\nexport const quickGeluImpl = (varType: string, alpha: number) => `\nconst alpha = vec4<${varType}>(${alpha});\nconst one = ${varType}(1.0);\nconst zero = ${varType}(0.0);\n\nfn quick_gelu_impl(x: vec4<${varType}>) -> vec4<${varType}> {\n  let v = x *alpha;\n  var x1 : vec4<${varType}>;\n  for (var i = 0; i < 4; i = i + 1) {\n    if (v[i] >= zero) {\n      x1[i] = one / (one + exp(-v[i]));\n    } else {\n      x1[i] = one - one / (one + exp(v[i]));\n    }\n  }\n  return x * x1;\n}\n`;\n\nexport const quickGeluExpression = (x: string) => `quick_gelu_impl(${x})`;\n\nexport const quickgelu = (context: ComputeContext, attributes: AlphaAttributes): void => {\n  const dType = tensorTypeToWsglValueType(context.inputs[0].dataType);\n  context.compute(\n    createElementwiseProgramInfo(\n      context.inputs[0],\n      'QuickGelu',\n      quickGeluExpression,\n      quickGeluImpl(dType, attributes.alpha),\n      attributes.cacheKey,\n      context.inputs[0].dataType,\n    ),\n  );\n};\n","// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport { TensorView } from '../../tensor-view';\nimport { ShapeUtil } from '../../util';\nimport { ComputeContext, ProgramInfo } from '../types';\n\nimport { inputVariable, outputVariable, ShaderHelper, tensorTypeToWsglStorageType } from './common';\nimport { erfImpl } from './unary-op';\n\nconst validateInputs = (inputs: readonly TensorView[]): void => {\n  if (inputs[0].dims.length !== 3) {\n    throw new Error('input should have 3 dimensions');\n  }\n\n  if (![2560, 5120, 10240].includes(inputs[0].dims[2])) {\n    throw new Error('hidden state should be 2560, 5120 or 10240');\n  }\n\n  if (inputs[1].dims.length !== 1) {\n    throw new Error('bias is expected to have 1 dimensions');\n  }\n\n  if (inputs[0].dims[2] !== inputs[1].dims[0]) {\n    throw new Error('last dimension of input and bias are not the same');\n  }\n};\n\nconst createBiasSplitGeluProgramInfo = (inputs: readonly TensorView[]): ProgramInfo => {\n  const outputShape = inputs[0].dims.slice();\n  outputShape[2] = outputShape[2] / 2;\n\n  const input = inputVariable('input', inputs[0].dataType, inputs[0].dims, 4);\n  const bias = inputVariable('bias', inputs[0].dataType, [inputs[0].dims[2]], 4);\n  const output = outputVariable('output', inputs[0].dataType, outputShape, 4);\n\n  const outputSize = ShapeUtil.size(outputShape) / 4;\n  const dataType = tensorTypeToWsglStorageType(inputs[0].dataType);\n\n  const getShaderSource = (shaderHelper: ShaderHelper) => `\n  const M_SQRT2 = sqrt(2.0);\n  const halfChannels = ${inputs[0].dims[2] / 4 / 2}u;\n\n  ${shaderHelper.declareVariables(input, bias, output)}\n\n  ${erfImpl(dataType)}\n\n  ${shaderHelper.mainStart()}\n    ${shaderHelper.guardAgainstOutOfBoundsWorkgroupSizes(outputSize)}\n    let biasIdx = global_idx % halfChannels;\n    let batchIndex = global_idx / halfChannels;\n    let inputOffset = biasIdx + batchIndex * halfChannels * 2;\n    let valueLeft = input[inputOffset] + bias[biasIdx];\n    let valueRight = input[inputOffset + halfChannels] + bias[biasIdx + halfChannels];\n    let geluRight = valueRight * 0.5 * (erf_vf32(valueRight / M_SQRT2) + 1);\n\n    ${output.setByOffset('global_idx', 'valueLeft * geluRight')}\n  }`;\n\n  return {\n    name: 'BiasSplitGelu',\n    getRunData: () => ({\n      outputs: [{ dims: outputShape, dataType: inputs[0].dataType }],\n      dispatchGroup: { x: Math.ceil(outputSize / 64 /* workgroup size */) },\n    }),\n    getShaderSource,\n  };\n};\n\nexport const biasSplitGelu = (context: ComputeContext): void => {\n  validateInputs(context.inputs);\n  context.compute(createBiasSplitGeluProgramInfo(context.inputs));\n};\n","// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport { DataType } from '../../../wasm-common';\nimport { TensorView } from '../../tensor-view';\nimport { BroadcastUtil, ShapeUtil } from '../../util';\nimport { ComputeContext, ProgramInfo } from '../types';\n\nimport { createTensorShapeVariables, inputVariable, outputVariable, ShaderHelper } from './common';\n\ntype BuiltinFunctionName = string;\ntype BinaryCustomExpression = (expressionA: string, expressionB: string) => string;\ntype BinaryFunctionCall =\n  | BuiltinFunctionName\n  | BinaryCustomExpression\n  | {\n      scalar: BinaryCustomExpression;\n      vector: BinaryCustomExpression;\n    };\n\nconst createBinaryOpProgramShader = (\n  shaderHelper: ShaderHelper,\n  dimsA: readonly number[],\n  dimsB: readonly number[],\n  dimsOutput: readonly number[],\n  vectorize: boolean,\n  doBroadcast: boolean,\n  sharedDimensionDivisibleBy4: boolean,\n  funcCall: BinaryFunctionCall,\n  typeA: number,\n  typeB: number,\n  typeOutput: number,\n  additionalImplementation?: string,\n) => {\n  let expressionScalar: BinaryCustomExpression;\n  let expressionVector: BinaryCustomExpression;\n  if (typeof funcCall === 'string') {\n    expressionScalar = expressionVector = (a, b) => `${funcCall}((${a}),(${b}))`;\n  } else if (typeof funcCall === 'function') {\n    expressionScalar = expressionVector = funcCall;\n  } else {\n    expressionScalar = funcCall.scalar;\n    expressionVector = funcCall.vector;\n  }\n\n  const output = outputVariable('outputData', typeOutput, dimsOutput.length, 4);\n  const a = inputVariable('aData', typeA, dimsA.length, 4);\n  const b = inputVariable('bData', typeB, dimsB.length, 4);\n\n  let assignment: string;\n  if (vectorize) {\n    if (doBroadcast) {\n      const isAOneElement = ShapeUtil.size(dimsA) === 1;\n      const isBOneElement = ShapeUtil.size(dimsB) === 1;\n      const aLastDimDivisibleBy4 = dimsA.length > 0 && dimsA[dimsA.length - 1] % 4 === 0;\n      const bLastDimDivisibleBy4 = dimsB.length > 0 && dimsB[dimsB.length - 1] % 4 === 0;\n      if (isAOneElement || isBOneElement) {\n        assignment = output.setByOffset(\n          'global_idx',\n          expressionVector(\n            isAOneElement ? `${a.type.value}(${a.getByOffset('0')}.x)` : a.getByOffset('global_idx'),\n            isBOneElement ? `${b.type.value}(${b.getByOffset('0')}.x)` : b.getByOffset('global_idx'),\n          ),\n        );\n      } else {\n        assignment = `\n            let outputIndices = ${output.offsetToIndices('global_idx * 4u')};\n            let offsetA = ${a.broadcastedIndicesToOffset('outputIndices', output)};\n            let offsetB = ${b.broadcastedIndicesToOffset('outputIndices', output)};\n            ${output.setByOffset(\n              'global_idx',\n              expressionVector(\n                sharedDimensionDivisibleBy4 || aLastDimDivisibleBy4\n                  ? a.getByOffset('offsetA / 4u')\n                  : `${a.type.value}(${a.getByOffset('offsetA / 4u')}[offsetA % 4u])`,\n                sharedDimensionDivisibleBy4 || bLastDimDivisibleBy4\n                  ? b.getByOffset('offsetB / 4u')\n                  : `${b.type.value}(${b.getByOffset('offsetB / 4u')}[offsetB % 4u])`,\n              ),\n            )}\n          `;\n      }\n    } else {\n      assignment = output.setByOffset(\n        'global_idx',\n        expressionVector(a.getByOffset('global_idx'), b.getByOffset('global_idx')),\n      );\n    }\n  } else {\n    if (!doBroadcast) {\n      throw new Error('no necessary to use scalar implementation for element-wise binary op implementation.');\n    }\n\n    const singleAssignment = (resStr: string, x: number, typeCast = '') => {\n      const expressionA = `aData[indexA${x}][componentA${x}]`;\n      const expressionB = `bData[indexB${x}][componentB${x}]`;\n      return `\n            let outputIndices${x} = ${output.offsetToIndices(`global_idx * 4u + ${x}u`)};\n            let offsetA${x} = ${a.broadcastedIndicesToOffset(`outputIndices${x}`, output)};\n            let offsetB${x} = ${b.broadcastedIndicesToOffset(`outputIndices${x}`, output)};\n            let indexA${x} = offsetA${x} / 4u;\n            let indexB${x} = offsetB${x} / 4u;\n            let componentA${x} = offsetA${x} % 4u;\n            let componentB${x} = offsetB${x} % 4u;\n            ${resStr}[${x}] = ${typeCast}(${expressionScalar(expressionA, expressionB)});\n          `;\n    };\n    if (typeOutput === DataType.bool) {\n      assignment = `\n            var data = vec4<u32>(0);\n            ${singleAssignment('data', 0, 'u32')}\n            ${singleAssignment('data', 1, 'u32')}\n            ${singleAssignment('data', 2, 'u32')}\n            ${singleAssignment('data', 3, 'u32')}\n            outputData[global_idx] = dot(vec4<u32>(0x1, 0x100, 0x10000, 0x1000000), vec4<u32>(data));`;\n    } else {\n      assignment = `\n            ${singleAssignment('outputData[global_idx]', 0)}\n            ${singleAssignment('outputData[global_idx]', 1)}\n            ${singleAssignment('outputData[global_idx]', 2)}\n            ${singleAssignment('outputData[global_idx]', 3)}\n          `;\n    }\n  }\n\n  return `\n        ${shaderHelper.registerUniform('vec_size', 'u32').declareVariables(a, b, output)}\n\n        ${additionalImplementation ?? ''}\n\n        ${shaderHelper.mainStart()}\n        ${shaderHelper.guardAgainstOutOfBoundsWorkgroupSizes('uniforms.vec_size')}\n        ${assignment}\n      }`;\n};\n\nconst createBinaryOpProgramInfo = (\n  name: string,\n  cacheKey: string,\n  a: TensorView,\n  b: TensorView,\n  funcCall: BinaryFunctionCall,\n  additionalImplementation?: string,\n  outputDataType: number = a.dataType,\n): ProgramInfo => {\n  const aDims = a.dims.map((x) => Number(x) ?? 1);\n  const bDims = b.dims.map((x) => Number(x) ?? 1);\n  const isBroadcast = !ShapeUtil.areEqual(aDims, bDims);\n  let outputShape = aDims;\n  let outputSize = ShapeUtil.size(aDims);\n\n  let vectorize = false;\n  let sharedDimensionDivisibleBy4 = false;\n\n  // TODO: deal with zero-sized tensors (eg. dims=[1,0])\n  const cacheKeyAux = [isBroadcast];\n  if (isBroadcast) {\n    const calculatedShape = BroadcastUtil.calcShape(aDims, bDims, false);\n    if (!calculatedShape) {\n      throw new Error(\"Can't perform binary op on the given tensors\");\n    }\n    outputShape = calculatedShape.slice();\n    outputSize = ShapeUtil.size(outputShape);\n    const isAOneElement = ShapeUtil.size(aDims) === 1;\n    const isBOneElement = ShapeUtil.size(bDims) === 1;\n    const aLastDimDivisibleBy4 = aDims.length > 0 && aDims[aDims.length - 1] % 4 === 0;\n    const bLastDimDivisibleBy4 = bDims.length > 0 && bDims[bDims.length - 1] % 4 === 0;\n    cacheKeyAux.push(isAOneElement);\n    cacheKeyAux.push(isBOneElement);\n    cacheKeyAux.push(aLastDimDivisibleBy4);\n    cacheKeyAux.push(bLastDimDivisibleBy4);\n    // check whether vectorize can be enabled\n    let sharedDimension = 1;\n    for (let i = 1; i < outputShape.length; i++) {\n      const dimA = aDims[aDims.length - i];\n      const dimB = bDims[bDims.length - i];\n      if (dimA === dimB) {\n        sharedDimension *= dimA;\n      } else {\n        break;\n      }\n    }\n    if (sharedDimension % 4 === 0) {\n      sharedDimensionDivisibleBy4 = true;\n      vectorize = true;\n    } else if (isAOneElement || isBOneElement || aLastDimDivisibleBy4 || bLastDimDivisibleBy4) {\n      vectorize = true;\n    }\n  } else {\n    // element-wise\n    vectorize = true;\n  }\n  cacheKeyAux.push(vectorize);\n\n  return {\n    name,\n    shaderCache: {\n      hint: cacheKey + cacheKeyAux.map((x) => x.toString()).join('_'),\n      inputDependencies: ['rank', 'rank'],\n    },\n    getShaderSource: (shaderHelper) =>\n      createBinaryOpProgramShader(\n        shaderHelper,\n        aDims,\n        bDims,\n        outputShape,\n        vectorize,\n        isBroadcast,\n        sharedDimensionDivisibleBy4,\n        funcCall,\n        a.dataType,\n        b.dataType,\n        outputDataType,\n        additionalImplementation,\n      ),\n    getRunData: () => ({\n      outputs: [{ dims: outputShape, dataType: outputDataType }],\n      dispatchGroup: { x: Math.ceil(outputSize / 64 /* workgroup size */ / 4 /* component size */) },\n      programUniforms: [\n        { type: DataType.uint32, data: Math.ceil(ShapeUtil.size(outputShape) / 4) },\n        ...createTensorShapeVariables(aDims, bDims, outputShape),\n      ],\n    }),\n  };\n};\n\nconst runBinaryOp = (\n  context: ComputeContext,\n  name: string,\n  funcCall: BinaryFunctionCall,\n  additionalImplementation?: string,\n  cacheKey?: string,\n  outputDataType?: number,\n): void => {\n  context.compute(\n    createBinaryOpProgramInfo(\n      name,\n      cacheKey ?? '',\n      context.inputs[0],\n      context.inputs[1],\n      funcCall,\n      additionalImplementation,\n      outputDataType,\n    ),\n  );\n};\n\nexport const add = (context: ComputeContext): void => {\n  runBinaryOp(context, 'Add', (a, b) => `${a}+${b}`);\n};\n\nexport const div = (context: ComputeContext): void => {\n  runBinaryOp(context, 'Div', (a, b) => `${a}/${b}`);\n};\n\nexport const equal = (context: ComputeContext): void => {\n  runBinaryOp(\n    context,\n    'Equal',\n    { scalar: (a, b) => `u32(${a}==${b})`, vector: (a, b) => `vec4<u32>(${a}==${b})` },\n    undefined,\n    undefined,\n    DataType.bool,\n  );\n};\n\nexport const mul = (context: ComputeContext): void => {\n  runBinaryOp(context, 'Mul', (a, b) => `${a}*${b}`);\n};\n\nexport const pow = (context: ComputeContext): void => {\n  const type = inputVariable('input', context.inputs[0].dataType, context.inputs[0].dims).type.value;\n  const roundStr = type === 'i32' ? 'round' : '';\n  runBinaryOp(\n    context,\n    'Pow',\n    { scalar: (a, b) => `pow_custom(${a},${b})`, vector: (a, b) => `pow_vector_custom(${a},${b})` },\n    `\n    fn pow_custom(a : ${type}, b : ${type}) -> ${type} {\n      if (b == ${type}(0.0)) {\n        return ${type}(1.0);\n      } else if (a < ${type}(0.0) && f32(b) != floor(f32(b))) {\n        return ${type}(pow(f32(a), f32(b))); // NaN\n      }\n      return select(sign(a), ${type}(1.0), round(f32(abs(b) % ${type}(2.0))) != 1.0) * ${type}(${roundStr}(pow(f32(abs(a)), f32(b))));\n    }\n    fn pow_vector_custom(a : vec4<${type}>, b : vec4<${type}>) -> vec4<${type}> {\n      // TODO: implement vectorized pow\n      return vec4<${type}>(pow_custom(a.x, b.x), pow_custom(a.y, b.y), pow_custom(a.z, b.z), pow_custom(a.w, b.w));\n    }\n      `,\n  );\n};\n\nexport const sub = (context: ComputeContext): void => {\n  runBinaryOp(context, 'Sub', (a, b) => `${a}-${b}`);\n};\n\nexport const greater = (context: ComputeContext): void => {\n  runBinaryOp(\n    context,\n    'Greater',\n    { scalar: (a, b) => `u32(${a}>${b})`, vector: (a, b) => `vec4<u32>(${a}>${b})` },\n    undefined,\n    undefined,\n    DataType.bool,\n  );\n};\n\nexport const less = (context: ComputeContext): void => {\n  runBinaryOp(\n    context,\n    'Less',\n    { scalar: (a, b) => `u32(${a}<${b})`, vector: (a, b) => `vec4<u32>(${a}<${b})` },\n    undefined,\n    undefined,\n    DataType.bool,\n  );\n};\n\nexport const greaterOrEqual = (context: ComputeContext): void => {\n  runBinaryOp(\n    context,\n    'GreaterOrEqual',\n    { scalar: (a, b) => `u32(${a}>=${b})`, vector: (a, b) => `vec4<u32>(${a}>=${b})` },\n    undefined,\n    undefined,\n    DataType.bool,\n  );\n};\n\nexport const lessOrEqual = (context: ComputeContext): void => {\n  runBinaryOp(\n    context,\n    'LessOrEqual',\n    { scalar: (a, b) => `u32(${a}<=${b})`, vector: (a, b) => `vec4<u32>(${a}<=${b})` },\n    undefined,\n    undefined,\n    DataType.bool,\n  );\n};\n","// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport { DataType } from '../../../wasm-common';\nimport { TensorView } from '../../tensor-view';\nimport { ShapeUtil } from '../../util';\nimport { AttributeWithCacheKey, createAttributeWithCacheKey } from '../attribute-with-cache-key';\nimport { ComputeContext, ProgramInfo, ProgramInputTensorInfoDependency, ProgramUniform } from '../types';\n\nimport { createTensorShapeVariables, IndicesHelper, inputVariable, outputVariable, ShaderHelper } from './common';\n\nexport interface ConcatAttributes extends AttributeWithCacheKey {\n  readonly axis: number;\n}\n\nconst validateInputs = (inputs: readonly TensorView[], axis: number): void => {\n  if (!inputs || inputs.length < 1) {\n    throw new Error('too few inputs');\n  }\n  const referenceIndex = 0;\n  const referenceInput = inputs[referenceIndex];\n  const inputType = referenceInput.dataType;\n  const inputRank = referenceInput.dims.length;\n  inputs.forEach((input, i) => {\n    if (i === referenceIndex) {\n      return;\n    }\n    // make sure types of all inputs match\n    if (input.dataType !== inputType) {\n      throw new Error('input tensors should be one type');\n    }\n    // make sure the dimensionality of all inputs are the same\n    if (input.dims.length !== inputRank) {\n      throw new Error('input tensors should have the same shape');\n    }\n    input.dims.forEach((dim, i) => {\n      if (i !== axis && dim !== referenceInput.dims[i]) {\n        throw new Error('non concat dimensions must match');\n      }\n    });\n  });\n};\n\nconst calculateInputIndexImpl = (numberOfTensors: number, sizeInConcatAxisStr: string): string => `\n  fn calculateInputIndex(index: u32) -> u32 {\n    let sizeInConcatAxis = array<u32, ${numberOfTensors}u>(${sizeInConcatAxisStr});\n    for (var i: u32 = 0u; i < ${numberOfTensors}; i += 1u ) {\n      if (index < sizeInConcatAxis[i]) {\n        return i;\n      }\n    }\n    return ${numberOfTensors}u;\n  }`;\n\nconst assignOutputData = (inputs: readonly IndicesHelper[], output: IndicesHelper) => {\n  const numberOfTensors = inputs.length;\n\n  const codeLines: string[] = [];\n  for (let i = 0; i < numberOfTensors; ++i) {\n    const returnSnippet = output.setByOffset('global_idx', inputs[i].getByIndices('indices'));\n    if (numberOfTensors === 1) {\n      codeLines.push(returnSnippet);\n    } else if (i === 0) {\n      codeLines.push(`if (inputIndex == ${i}u) { ${returnSnippet} }`);\n    } else if (i === numberOfTensors - 1) {\n      codeLines.push(`else { ${returnSnippet} }`);\n    } else {\n      codeLines.push(`else if (inputIndex == ${i}) { ${returnSnippet} }`);\n    }\n  }\n  return codeLines.join('\\n');\n};\n\nconst createConcatProgramInfo = (\n  inputs: readonly TensorView[],\n  adjustedAxis: number,\n  outputShape: number[],\n  dataType: DataType,\n): ProgramInfo => {\n  const outputSize = ShapeUtil.size(outputShape);\n\n  const sizeInConcatAxis = new Array<number>(inputs.length);\n  const inputVars = new Array<IndicesHelper>(inputs.length);\n\n  let previousSum = 0;\n  const inputDependencies: ProgramInputTensorInfoDependency[] = [];\n  const inputRanks = [];\n  const programUniforms: ProgramUniform[] = [{ type: DataType.uint32, data: outputSize }];\n  for (let i = 0; i < inputs.length; ++i) {\n    previousSum += inputs[i].dims[adjustedAxis];\n    sizeInConcatAxis[i] = previousSum;\n    inputRanks.push(inputs[i].dims.length);\n    inputVars[i] = inputVariable(`input${i}`, dataType, inputRanks[i]);\n    inputDependencies.push('rank');\n    programUniforms.push({ type: DataType.uint32, data: sizeInConcatAxis[i] });\n  }\n  for (let i = 0; i < inputs.length; ++i) {\n    programUniforms.push(...createTensorShapeVariables(inputs[i].dims));\n  }\n  programUniforms.push(...createTensorShapeVariables(outputShape));\n\n  const output = outputVariable('output', dataType, outputShape.length);\n  const indicesAxis = output.indicesGet('indices', adjustedAxis);\n  const sizeInConcatAxisStr = Array.from(Array(sizeInConcatAxis.length).keys())\n    .map((i) => `uniforms.sizeInConcatAxis${i}`)\n    .join(',');\n  const getShaderSource = (shaderHelper: ShaderHelper) => `\n\n  ${(() => {\n    shaderHelper.registerUniform('outputSize', 'u32');\n    for (let i = 0; i < inputs.length; i++) {\n      shaderHelper.registerUniform(`sizeInConcatAxis${i}`, 'u32');\n    }\n    return shaderHelper.declareVariables(...inputVars, output);\n  })()}\n\n  ${calculateInputIndexImpl(sizeInConcatAxis.length, sizeInConcatAxisStr)}\n\n  ${shaderHelper.mainStart()}\n    ${shaderHelper.guardAgainstOutOfBoundsWorkgroupSizes('uniforms.outputSize')}\n\n    var indices = ${output.offsetToIndices('global_idx')};\n\n    let inputIndex = calculateInputIndex(${indicesAxis});\n    if (inputIndex != 0u) {\n      let sizeInConcatAxis = array<u32, ${sizeInConcatAxis.length}u>(${sizeInConcatAxisStr});\n      ${indicesAxis} -= sizeInConcatAxis[inputIndex - 1u];\n    }\n\n    ${assignOutputData(inputVars, output)}\n  }`;\n\n  return {\n    name: 'Concat',\n    shaderCache: { hint: `${adjustedAxis}`, inputDependencies },\n    getRunData: () => ({\n      outputs: [{ dims: outputShape, dataType }],\n      dispatchGroup: { x: Math.ceil(outputSize / 64 /* workgroup size */) },\n      programUniforms,\n    }),\n    getShaderSource,\n  };\n};\n\nexport const concat = (context: ComputeContext, attributes: ConcatAttributes): void => {\n  const inputs = context.inputs;\n  const inputShape = inputs[0].dims;\n  const adjustedAxis = ShapeUtil.normalizeAxis(attributes.axis, inputShape.length);\n  validateInputs(inputs, adjustedAxis);\n  const outputShape = inputShape.slice();\n  outputShape[adjustedAxis] = inputs.reduce(\n    (sum, input) => sum + (input.dims.length > adjustedAxis ? input.dims[adjustedAxis] : 0),\n    0,\n  );\n  // 0 length tensors are valid for concat, remove them\n  const nonEmptyInputs = inputs.filter((input) => ShapeUtil.size(input.dims) > 0);\n  context.compute(createConcatProgramInfo(nonEmptyInputs, adjustedAxis, outputShape, inputs[0].dataType), {\n    inputs: nonEmptyInputs,\n  });\n};\n\nexport const parseConcatAttributes = (attributes: Record<string, unknown>): ConcatAttributes =>\n  createAttributeWithCacheKey({ axis: attributes.axis as number });\n","// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport { DataType } from '../../../wasm-common';\nimport { MAX_CLIP, MIN_CLIP } from '../../util';\nimport { ProgramUniform } from '../types';\n\nimport { UniformsArrayType } from './common';\n\nexport interface InternalActivationAttributes {\n  readonly activation: string;\n  readonly clipMin?: number;\n  readonly clipMax?: number;\n  readonly alpha?: number;\n  readonly beta?: number;\n}\n\nexport const getActivationSnippet = (\n  attributes: InternalActivationAttributes,\n  valueType: string,\n  baseType = 'f32',\n): string => {\n  switch (attributes.activation) {\n    case 'Relu':\n      return `value = max(value, ${valueType}(0.0));`;\n    case 'Sigmoid':\n      return `value = (${valueType}(1.0) / (${valueType}(1.0) + exp(-value)));`;\n    case 'Clip':\n      return `value = clamp(value, ${valueType}(${baseType}(uniforms.clip_min)), ${valueType}(${\n        baseType\n      }(uniforms.clip_max)));`;\n    case 'HardSigmoid':\n      return `value = max(${valueType}(0.0), min(${valueType}(1.0), ${baseType}(uniforms.alpha) * value + ${\n        baseType\n      }(uniforms.beta)));`;\n    case 'LeakyRelu':\n      return `value = select(${baseType}(uniforms.alpha) * value, value, value >= ${valueType}(0.0));`;\n    case 'Tanh':\n      return `let e2x = exp(-2.0 * abs(value));\n              value = sign(value) * (1.0 - e2x) / (1.0 + e2x);\n        `;\n    case '':\n      return '';\n    // TODO: adding other activations that can be fused.\n    default:\n      throw new Error(`Unsupported activation ${attributes.activation}`);\n  }\n};\n\nexport const appendActivationUniformsData = (\n  attributes: InternalActivationAttributes,\n  programUniform: ProgramUniform[],\n) => {\n  if (attributes.activation === 'Clip') {\n    programUniform.push(\n      { type: DataType.float, data: attributes.clipMax! },\n      { type: DataType.float, data: attributes.clipMin! },\n    );\n  } else if (attributes.activation === 'HardSigmoid') {\n    programUniform.push(\n      { type: DataType.float, data: attributes.alpha! },\n      { type: DataType.float, data: attributes.beta! },\n    );\n  } else if (attributes.activation === 'LeakyRelu') {\n    programUniform.push({ type: DataType.float, data: attributes.alpha! });\n  }\n};\n\nexport const appendActivationUniforms = (attributes: InternalActivationAttributes, uniforms: UniformsArrayType) => {\n  if (attributes.activation === 'Clip') {\n    uniforms.push({ name: 'clip_max', type: 'f32' }, { name: 'clip_min', type: 'f32' });\n  } else if (attributes.activation === 'HardSigmoid') {\n    uniforms.push({ name: 'alpha', type: 'f32' }, { name: 'beta', type: 'f32' });\n  } else if (attributes.activation === 'LeakyRelu') {\n    uniforms.push({ name: 'alpha', type: 'f32' });\n  }\n};\n\nexport const parseInternalActivationAttributes = (\n  attributes: Record<string, unknown> | undefined,\n): InternalActivationAttributes => {\n  const activation = (attributes?.activation as string) || '';\n  if (activation === 'HardSigmoid') {\n    const [alpha, beta] = (attributes?.activation_params as [number, number]) || [0.2, 0.5];\n    return { activation, alpha, beta };\n  } else if (activation === 'Clip') {\n    const [clipMin, clipMax] = (attributes?.activation_params as [number, number]) || [MIN_CLIP, MAX_CLIP];\n    return { activation, clipMax, clipMin };\n  } else if (activation === 'LeakyRelu') {\n    const [alpha] = (attributes?.activation_params as [number]) || [0.01];\n    return { activation, alpha };\n  }\n  return { activation };\n};\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\n// sampled from [@tensorflow/tfjs] tfjs-backend-webgpu/src/activation_util.ts\n//\n// modified to fit the needs of the project\n\nexport const typeSnippet = (component: number, dataType: string) => {\n  switch (component) {\n    case 1:\n      return dataType;\n    case 2:\n      return `vec2<${dataType}>`;\n    case 3:\n      return `vec3<${dataType}>`;\n    case 4:\n      return `vec4<${dataType}>`;\n    default:\n      throw new Error(`${component}-component is not supported.`);\n  }\n};\n\nexport const biasSnippet = (hasBias: boolean): string => `\n      ${hasBias ? 'value = value + getBiasByOutputCoords(coords);' : ''}\n      `;\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\n// sampled from [@tensorflow/tfjs] tfjs-core/src/ops/conv_util.ts\n//\n// modified to fit the needs of the project\n\nexport const utilFunctions = (strideStr: string) => `\nfn getIndexFromCoords4D(coords : vec4<i32>, shape : vec4<i32>) -> i32 {\n  return dot(coords, vec4<i32>(\n      shape.y * shape.z * shape.w, shape.z * shape.w, shape.w, 1));\n}\nfn getOutputIndexFromCoords(coords : vec4<i32>) -> i32 {\n  return dot(coords, vec4<i32>(\n    i32(${strideStr}.x), i32(${strideStr}.y), i32(${strideStr}.z), 1));\n}\n`;\n","// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport { DataType } from '../../../wasm-common';\nimport { TensorView } from '../../tensor-view';\nimport { ShapeUtil } from '../../util';\nimport { ProgramInfo, ProgramUniform } from '../types';\n\nimport {\n  createTensorShapeVariables,\n  getElementAt,\n  getMaxComponents,\n  IndicesHelper,\n  inputVariable,\n  internalVariable,\n  outputVariable,\n  ShaderHelper,\n  tensorTypeToWsglStorageType,\n  UniformsArrayType,\n} from './common';\nimport {\n  appendActivationUniforms,\n  appendActivationUniformsData,\n  getActivationSnippet,\n  InternalActivationAttributes,\n} from './fuse-utils';\n\n// Helper that convert output batch indices to input batch indices using only the rank and\n// the shape information in uniform\nexport const convertOutputBatchIndicesToInputBatchIndices = (\n  targetIndicesName: string,\n  inputVariable: IndicesHelper,\n  inputBatchRank: number,\n  outputBatchRank: number,\n  batchIndicesName: string,\n) => {\n  // Assume outputBatchRank >= inputBatchRank, the first outputBatchRank - inputBatchRank of\n  // outputBatchRank should be ignored.\n  const extendingInputRank = outputBatchRank - inputBatchRank;\n  return `\n      ${Array.from({ length: inputBatchRank })\n        .map(\n          (_, i) => `\n      if (${getElementAt(inputVariable.shape, i, inputVariable.rank)} != 1) {\n        ${inputVariable.indicesSet(targetIndicesName, i, getElementAt(batchIndicesName, i + extendingInputRank, outputBatchRank))}\n      } else {\n        ${inputVariable.indicesSet(targetIndicesName, i, 0)}\n      }`,\n        )\n        .join('')}\n`;\n};\n\nexport const createNaiveMatmulProgramInfo = (\n  inputs: readonly TensorView[],\n  activationAttributes: InternalActivationAttributes,\n  outputShape: readonly number[],\n  reshapedOutputShape?: readonly number[],\n  isChannelsLast = false /* only used for conv2dByMatMul*/,\n  squeezeOutputShapeFunction?: (shape: readonly number[]) => number[],\n): ProgramInfo => {\n  const aShape = inputs[0].dims;\n  const bShape = inputs[1].dims;\n\n  const M = aShape[aShape.length - 2];\n  const N = bShape[bShape.length - 1];\n  const K = aShape[aShape.length - 1];\n  const components = getMaxComponents(N);\n  const aComponents = getMaxComponents(K);\n  const outputNumber = getMaxComponents(M);\n  const outputSize = ShapeUtil.size(outputShape) / components / outputNumber;\n  const hasBias = inputs.length > 2;\n  const outerDims = reshapedOutputShape ? reshapedOutputShape.slice(0, -2) : outputShape.slice(0, -2);\n  const batchSize = ShapeUtil.size(outerDims);\n  const outputShapeInShader = [batchSize, M, N];\n\n  const programUniforms: ProgramUniform[] = [\n    { type: DataType.uint32, data: outputSize },\n    { type: DataType.uint32, data: M },\n    { type: DataType.uint32, data: N },\n    { type: DataType.uint32, data: K },\n  ];\n  appendActivationUniformsData(activationAttributes, programUniforms);\n  programUniforms.push(...createTensorShapeVariables(outerDims, aShape, bShape));\n  if (hasBias) {\n    programUniforms.push(...createTensorShapeVariables(inputs[2].dims));\n  }\n  programUniforms.push(...createTensorShapeVariables(outputShapeInShader));\n\n  const getShaderSource = (shaderHelper: ShaderHelper) => {\n    const batchDims = internalVariable('batch_dims', inputs[0].dataType, outerDims.length);\n    const a = inputVariable('a', inputs[0].dataType, aShape.length, aComponents);\n    const b = inputVariable('b', inputs[1].dataType, bShape.length, components);\n    const output = outputVariable('output', inputs[0].dataType, outputShapeInShader.length, components);\n    const baseType = tensorTypeToWsglStorageType(output.type.tensor);\n    const applyActivation = getActivationSnippet(activationAttributes, output.type.value, baseType);\n    const inputVariables = [a, b];\n    let processBias = '';\n    if (hasBias) {\n      const biasComponents = isChannelsLast ? components : 1;\n      inputVariables.push(inputVariable('bias', inputs[2].dataType, inputs[2].dims.length, biasComponents));\n      processBias = `${\n        isChannelsLast ? `value += bias[col / ${biasComponents}];` : `value += ${output.type.value}(bias[row + i]);`\n      }`;\n    }\n\n    const uniforms: UniformsArrayType = [\n      { name: 'output_size', type: 'u32' },\n      { name: 'M', type: 'u32' },\n      { name: 'N', type: 'u32' },\n      { name: 'K', type: 'u32' },\n    ];\n    appendActivationUniforms(activationAttributes, uniforms);\n\n    const calcResult = (): string => {\n      let calcStr = `var a_data: ${a.type.value};`;\n      for (let i = 0; i < aComponents; i++) {\n        calcStr += `\n              let b_data${i} = b[(b_offset + (k + ${i}) * uniforms.N + col) / ${components}];`;\n      }\n      for (let i = 0; i < outputNumber; i++) {\n        calcStr += `a_data = a[(a_offset + (row + ${i}) * uniforms.K + k) / ${aComponents}];`;\n\n        for (let j = 0; j < aComponents; j++) {\n          calcStr += `\n            values[${i}] = fma(${b.type.value}(a_data${aComponents === 1 ? '' : `[${j}]`}), b_data${j}, values[${i}]);\\n`;\n        }\n      }\n      return calcStr;\n    };\n\n    return `\n  ${shaderHelper\n    .registerUniforms(uniforms)\n    .registerInternalVariables(batchDims)\n    .declareVariables(...inputVariables, output)}\n  ${shaderHelper.mainStart()}\n    ${shaderHelper.guardAgainstOutOfBoundsWorkgroupSizes('uniforms.output_size')}\n    let col = (global_idx % (uniforms.N / ${components})) * ${components};\n    var index1 = global_idx / (uniforms.N / ${components});\n    let stride1 = uniforms.M / ${outputNumber};\n    let row = (index1 % stride1) * ${outputNumber};\n    let batch = index1 / stride1;\n\n    ${outputShape.length === 2 ? '' : `let batch_indices = ${batchDims.offsetToIndices('batch')};`}\n\n    var a_indices: ${a.type.indices};\n    ${convertOutputBatchIndicesToInputBatchIndices('a_indices', a, a.rank - 2, batchDims.rank, 'batch_indices')}\n    ${a.indicesSet('a_indices', a.rank - 2, 0)}\n    ${a.indicesSet('a_indices', a.rank - 1, 0)}\n    let a_offset = ${a.indicesToOffset('a_indices')};\n\n    var b_indices: ${b.type.indices};\n    ${convertOutputBatchIndicesToInputBatchIndices('b_indices', b, b.rank - 2, batchDims.rank, 'batch_indices')}\n    ${b.indicesSet('b_indices', b.rank - 2, 0)}\n    ${b.indicesSet('b_indices', b.rank - 1, 0)}\n    let b_offset = ${b.indicesToOffset('b_indices')};\n    var values: array<${output.type.value}, ${outputNumber}>;\n    for (var k: u32 = 0u; k < uniforms.K; k = k + ${aComponents}) {\n      ${calcResult()}\n    }\n    for (var i = 0u; i < ${outputNumber}u; i++) {\n      var value = values[i];\n      ${processBias}\n      ${applyActivation}\n      let cur_indices = ${output.type.indices}(batch, row + i, col);\n      let offset = ${output.indicesToOffset('cur_indices')};\n      ${output.setByOffset(`offset / ${components}`, 'value')};\n    }\n  }\n  `;\n  };\n  return {\n    name: 'MatMulNaive',\n    shaderCache: {\n      hint: `${activationAttributes.activation};${components};${aComponents};${outputNumber};${isChannelsLast}`,\n      inputDependencies: hasBias ? ['rank', 'rank', 'rank'] : ['rank', 'rank'],\n    },\n    getRunData: () => ({\n      outputs: [\n        {\n          dims: squeezeOutputShapeFunction ? squeezeOutputShapeFunction(outputShape) : outputShape,\n          dataType: inputs[0].dataType,\n        },\n      ],\n      dispatchGroup: { x: Math.ceil(outputSize / 64 /* workgroup size */) },\n      programUniforms,\n    }),\n    getShaderSource,\n  };\n};\n","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\n// sampled from [@tensorflow/tfjs] tfjs-backend-webgpu/src/matmul_packed_webgpu.ts\n//\n// modified to fit the needs of the project\n\nimport { DataType } from '../../../../wasm-common';\nimport { TensorView } from '../../../tensor-view';\nimport { ShapeUtil } from '../../../util';\nimport { ProgramInfo, ProgramInputTensorInfoDependency, ProgramUniform } from '../../types';\nimport {\n  createTensorShapeVariables,\n  IndicesHelper,\n  inputVariable,\n  internalVariable,\n  outputVariable,\n  ShaderHelper,\n  tensorTypeToWsglStorageType,\n  UniformsArrayType,\n} from '../common';\nimport {\n  appendActivationUniforms,\n  appendActivationUniformsData,\n  getActivationSnippet,\n  InternalActivationAttributes,\n} from '../fuse-utils';\nimport { convertOutputBatchIndicesToInputBatchIndices } from '../matmul-shaders';\n\nimport { typeSnippet } from './activation_util';\n\nconst writeDataToSubAVec4Snippet = (transpose: boolean, batchDims?: IndicesHelper) => {\n  if (transpose) {\n    return `\n        mm_Asub[inputRow][inputCol] = mm_readA(batch,\n          kStart + inputRow,\n          globalRowStart / innerElementSize + inputCol${batchDims ? ', batchIndices' : ''});\n        `;\n  } else {\n    return `\n        mm_Asub[inputRow][inputCol] = mm_readA(batch,\n          globalRow + innerRow,\n          kStart / innerElementSize + inputCol${batchDims ? ', batchIndices' : ''});\n        `;\n  }\n};\n\nconst calculateResultSnippet = (transposeA: boolean, innerElementSize: number) => {\n  if (transposeA) {\n    return `\n        let ACached0 = mm_Asub[k * innerElementSize][localRow];\n        let ACached1 = mm_Asub[k * innerElementSize + 1][localRow];\n        let ACached2 = mm_Asub[k * innerElementSize + 2][localRow];\n        ${innerElementSize === 3 ? '' : 'let ACached3 = mm_Asub[k * innerElementSize + 3][localRow];'}\n        for (var i = 0; i < rowPerThread; i = i + 1) {\n          acc[i] = BCached0 * ACached0[i] + acc[i];\n          acc[i] = BCached1 * ACached1[i] + acc[i];\n          acc[i] = BCached2 * ACached2[i] + acc[i];\n          ${innerElementSize === 3 ? '' : 'acc[i] = BCached3 * ACached3[i] + acc[i];'}\n        }`;\n  } else {\n    return `\n        for (var i = 0; i < rowPerThread; i = i + 1) {\n          let ACached = mm_Asub[tileRow + i][k];\n          acc[i] = BCached0 * ACached.x + acc[i];\n          acc[i] = BCached1 * ACached.y + acc[i];\n          acc[i] = BCached2 * ACached.z + acc[i];\n          ${innerElementSize === 3 ? '' : 'acc[i] = BCached3 * ACached.w + acc[i];'}\n        }`;\n  }\n};\n\nexport const makeMatMulPackedVec4Source = (\n  workPerThread: number[],\n  workgroupSize: [number, number, number],\n  type = 'f32',\n  batchDims?: IndicesHelper,\n  transposeA = false,\n  tileInner = 32,\n  splitK = false,\n  splitedDimInner = 32,\n): string => {\n  const tileAOuter = workgroupSize[1] * workPerThread[1];\n  const tileBOuter = workgroupSize[0] * workPerThread[0];\n  const tileAWidth = transposeA ? tileAOuter : tileInner;\n  const tileAHight = transposeA ? tileInner : tileAOuter;\n  const innerElementSize = tileAWidth / workgroupSize[0];\n  const rowPerThreadB = tileInner / workgroupSize[1];\n\n  if (\n    !(\n      ((transposeA && innerElementSize === 4 && workPerThread[1] === 4) ||\n        (!transposeA && (innerElementSize === 3 || innerElementSize === 4))) &&\n      tileAWidth % workgroupSize[0] === 0 &&\n      tileInner % workgroupSize[1] === 0 &&\n      workPerThread[0] === 4\n    )\n  ) {\n    throw new Error(`If transposeA ${transposeA} is true, innerElementSize ${innerElementSize} and workPerThread[1] ${workPerThread[1]} must be 4.\n      Otherwise, innerElementSize ${innerElementSize} must be 3 or 4.\n  tileAWidth ${tileAWidth} must be divisible by workgroupSize[0]${workgroupSize[0]}. tileInner ${tileInner} must be divisible by workgroupSize[1] ${workgroupSize[1]}. colPerThread ${workPerThread[0]} must be 4.`);\n  }\n  return `\nvar<workgroup> mm_Asub: array<array<vec${innerElementSize}<${type}>, ${tileAWidth / innerElementSize}>, ${tileAHight}>;\nvar<workgroup> mm_Bsub: array<array<vec4<${type}>, ${tileBOuter / workPerThread[0]}>, ${tileInner}>;\n\nconst rowPerThread = ${workPerThread[1]};\nconst colPerThread = ${workPerThread[0]};\nconst innerElementSize = ${innerElementSize};\nconst tileInner = ${tileInner};\n\n@compute @workgroup_size(${workgroupSize[0]}, ${workgroupSize[1]}, ${workgroupSize[2]})\nfn main(@builtin(local_invocation_id) localId : vec3<u32>,\n        @builtin(global_invocation_id) globalId : vec3<u32>,\n        @builtin(workgroup_id) workgroupId : vec3<u32>) {\n  let localRow = i32(localId.y);\n  let tileRow = localRow * rowPerThread;\n  let tileCol = i32(localId.x);\n\n  let globalRow =i32(globalId.y) * rowPerThread;\n  let globalCol = i32(globalId.x);\n  let batch = ${splitK ? '0' : 'i32(globalId.z)'};\n  ${batchDims ? `let batchIndices = ${batchDims.offsetToIndices('u32(batch)')};` : ''}\n  let globalRowStart = i32(workgroupId.y) * ${tileAOuter};\n\n  let num_tiles = ${splitK ? `${Math.ceil(splitedDimInner / tileInner)}` : '(uniforms.dim_inner - 1) / tileInner + 1'};\n  var kStart = ${splitK ? `i32(globalId.z) * ${splitedDimInner}` : '0'};\n\n  var acc: array<vec4<${type}>, rowPerThread>;\n\n  // Loop over shared dimension.\n  let tileRowB = localRow * ${rowPerThreadB};\n  for (var t = 0; t < num_tiles; t = t + 1) {\n      // Load one tile of A into local memory.\n      for (var innerRow = 0; innerRow < rowPerThread; innerRow = innerRow + 1) {\n          let inputRow = tileRow + innerRow;\n          let inputCol = tileCol;\n          ${writeDataToSubAVec4Snippet(transposeA, batchDims)}\n      }\n\n      // Load one tile of B into local memory.\n      for (var innerRow = 0; innerRow < ${rowPerThreadB}; innerRow = innerRow + 1) {\n          let inputRow = tileRowB + innerRow;\n          let inputCol = tileCol;\n          mm_Bsub[inputRow][inputCol] = mm_readB(batch, kStart + inputRow, globalCol${\n            batchDims ? ', batchIndices' : ''\n          });\n      }\n      kStart = kStart + tileInner;\n      workgroupBarrier();\n\n      // Compute acc values for a single thread.\n      for (var k = 0; k < tileInner / innerElementSize; k = k + 1) {\n          let BCached0 = mm_Bsub[k * innerElementSize][tileCol];\n          let BCached1 = mm_Bsub[k * innerElementSize + 1][tileCol];\n          let BCached2 = mm_Bsub[k * innerElementSize + 2][tileCol];\n          ${innerElementSize === 3 ? '' : 'let BCached3 = mm_Bsub[k * innerElementSize + 3][tileCol];'}\n\n          ${calculateResultSnippet(transposeA, innerElementSize)}\n      }\n\n      workgroupBarrier();\n  }\n\n  for (var innerRow = 0; innerRow < rowPerThread; innerRow = innerRow + 1) {\n      mm_write(batch, globalRow + innerRow, globalCol, acc[innerRow]);\n  }\n}`;\n};\n\nconst writeDataToSubASnippet = (transpose: boolean, batchDims?: IndicesHelper) => {\n  if (transpose) {\n    return `\n            mm_Asub[inputRow][inputCol] = mm_readA(batch,\n              kStart + inputRow,\n              globalRowStart + inputCol${batchDims ? ', batchIndices' : ''});\n            `;\n  } else {\n    return `\n            mm_Asub[inputRow][inputCol] = mm_readA(batch,\n              globalRowStart + inputRow,\n              kStart + inputCol${batchDims ? ', batchIndices' : ''});\n            `;\n  }\n};\n\nconst readDataFromSubASnippet = (transposeA: boolean) =>\n  transposeA ? 'let ACached = mm_Asub[k][tileRow + innerRow];' : 'let ACached = mm_Asub[tileRow + innerRow][k];';\n\n// sequentialAccessByThreads means sequential data in memory is accessed by\n// threads, instead of a single thread (default behavior).\nexport const makeMatMulPackedSource = (\n  workPerThread: number[],\n  workgroupSize: [number, number, number],\n  type = 'f32',\n  batchDims?: IndicesHelper,\n  transposeA = false,\n  tileInner = 32,\n  splitK = false,\n  splitedDimInner = 32,\n  sequentialAccessByThreads = false,\n): string => {\n  const tileAOuter = workPerThread[1] * workgroupSize[1];\n  const tileBOuter = workPerThread[0] * workgroupSize[0];\n  const tileAWidth = transposeA ? tileAOuter : tileInner;\n  const tileAHight = transposeA ? tileInner : tileAOuter;\n\n  if (\n    !(tileAHight % workgroupSize[1] === 0 && tileAWidth % workgroupSize[0] === 0 && tileInner % workgroupSize[1] === 0)\n  ) {\n    throw new Error(\n      `tileAHight ${tileAHight} must be divisible by workgroupSize[1]${workgroupSize[1]}, tileAWidth ${tileAWidth} must be divisible by workgroupSize[0]${workgroupSize[0]}, tileInner ${tileInner} must be divisible by workgroupSize[1]${workgroupSize[1]}`,\n    );\n  }\n  const rowPerThreadA = tileAHight / workgroupSize[1];\n  const colPerThreadA = tileAWidth / workgroupSize[0];\n  const rowPerThreadB = tileInner / workgroupSize[1];\n  const matmulSnippet = sequentialAccessByThreads\n    ? `\n    let localRow = i32(localId.y);\n    let localCol = i32(localId.x);\n    let globalRowStart = i32(workgroupId.y) * ${tileAOuter};\n    let globalColStart = i32(workgroupId.x) * ${tileBOuter};\n\n    // Loop over shared dimension.\n    for (var t = 0; t < num_tiles; t = t + 1) {\n      // Load one tile of A into local memory.\n      for (var inputRow = localRow; inputRow < ${tileAHight}; inputRow = inputRow + ${workgroupSize[1]}) {\n        for (var inputCol = localCol; inputCol < ${tileAWidth}; inputCol = inputCol + ${workgroupSize[0]}) {\n          ${writeDataToSubASnippet(transposeA, batchDims)}\n        }\n      }\n      // Load one tile of B into local memory.\n      for (var inputRow = localRow; inputRow < ${tileInner}; inputRow = inputRow + ${workgroupSize[1]}) {\n            for (var inputCol = localCol; inputCol < ${tileBOuter}; inputCol = inputCol + ${workgroupSize[0]}) {\n          mm_Bsub[inputRow][inputCol] = mm_readB(batch,\n            kStart + inputRow,\n            globalColStart + inputCol${batchDims ? ', batchIndices' : ''});\n        }\n      }\n      kStart = kStart + tileInner;\n      workgroupBarrier();\n\n      // Compute acc values for a single thread.\n      var BCached : array<${type}, colPerThread>;\n      for (var k = 0; k < tileInner; k = k + 1) {\n        for (var inner = 0; inner < colPerThread; inner = inner + 1) {\n          BCached[inner] = mm_Bsub[k][localCol + inner * ${workgroupSize[0]}];\n        }\n        for (var innerRow = 0; innerRow < rowPerThread; innerRow = innerRow + 1) {\n          let ACached = ${\n            transposeA\n              ? `mm_Asub[k][localRow + innerRow * ${workgroupSize[1]}];`\n              : `mm_Asub[localRow + innerRow * ${workgroupSize[1]}][k];`\n          }\n          for (var innerCol = 0; innerCol < colPerThread; innerCol = innerCol + 1) {\n            acc[innerRow][innerCol] = acc[innerRow][innerCol] +\n                ACached * BCached[innerCol];\n          }\n        }\n      }\n      workgroupBarrier();\n    }\n    for (var innerRow = 0; innerRow < rowPerThread; innerRow = innerRow + 1) {\n      let gRow = globalRowStart + localRow + innerRow * ${workgroupSize[1]};\n      for (var innerCol = 0; innerCol < colPerThread; innerCol = innerCol + 1) {\n        let gCol = globalColStart + localCol + innerCol * ${workgroupSize[0]};\n        mm_write(batch, gRow, gCol, acc[innerRow][innerCol]);\n      }\n    }\n    `\n    : `\nlet tileRow = i32(localId.y) * rowPerThread;\nlet tileCol = i32(localId.x) * colPerThread;\n\nlet globalRow = i32(globalId.y) * rowPerThread;\nlet globalCol = i32(globalId.x) * colPerThread;\nlet globalRowStart = i32(workgroupId.y) * ${tileAOuter};\n\nlet tileRowA = i32(localId.y) * ${rowPerThreadA};\nlet tileColA = i32(localId.x) * ${colPerThreadA};\nlet tileRowB = i32(localId.y) * ${rowPerThreadB};\n// Loop over shared dimension.\nfor (var t = 0; t < num_tiles; t = t + 1) {\n  // Load one tile of A into local memory.\n  for (var innerRow = 0; innerRow < ${rowPerThreadA}; innerRow = innerRow + 1) {\n    for (var innerCol = 0; innerCol < ${colPerThreadA}; innerCol = innerCol + 1) {\n      let inputRow = tileRowA + innerRow;\n      let inputCol = tileColA + innerCol;\n      ${writeDataToSubASnippet(transposeA, batchDims)}\n    }\n  }\n\n  // Load one tile of B into local memory.\n  for (var innerRow = 0; innerRow < ${rowPerThreadB}; innerRow = innerRow + 1) {\n    for (var innerCol = 0; innerCol < colPerThread; innerCol = innerCol + 1) {\n      let inputRow = tileRowB + innerRow;\n      let inputCol = tileCol + innerCol;\n      mm_Bsub[inputRow][inputCol] = mm_readB(batch,\n        kStart + inputRow,\n        globalCol + innerCol${batchDims ? ', batchIndices' : ''});\n    }\n  }\n  kStart = kStart + tileInner;\n  workgroupBarrier();\n\n  // Compute acc values for a single thread.\n  var BCached : array<${type}, colPerThread>;\n  for (var k = 0; k < tileInner; k = k + 1) {\n    for (var inner = 0; inner < colPerThread; inner = inner + 1) {\n      BCached[inner] = mm_Bsub[k][tileCol + inner];\n    }\n\n    for (var innerRow = 0; innerRow < rowPerThread; innerRow = innerRow + 1) {\n      ${readDataFromSubASnippet(transposeA)}\n      for (var innerCol = 0; innerCol < colPerThread; innerCol = innerCol + 1) {\n        acc[innerRow][innerCol] = acc[innerRow][innerCol] + ACached * BCached[innerCol];\n      }\n    }\n  }\n\n  workgroupBarrier();\n}\n\nfor (var innerRow = 0; innerRow < rowPerThread; innerRow = innerRow + 1) {\n  for (var innerCol = 0; innerCol < colPerThread; innerCol = innerCol + 1) {\n    mm_write(batch, globalRow + innerRow, globalCol + innerCol,\n        acc[innerRow][innerCol]);\n  }\n}\n`;\n\n  return `\n  var<workgroup> mm_Asub : array<array<${type}, ${tileAWidth}>, ${tileAHight}>;\n  var<workgroup> mm_Bsub : array<array<${type}, ${tileBOuter}>, ${tileInner}>;\n  const rowPerThread = ${workPerThread[1]};\n  const colPerThread = ${workPerThread[0]};\n  const tileInner = ${tileInner};\n\n@compute @workgroup_size(${workgroupSize[0]}, ${workgroupSize[1]}, ${workgroupSize[2]})\nfn main(@builtin(local_invocation_id) localId : vec3<u32>,\n        @builtin(global_invocation_id) globalId : vec3<u32>,\n        @builtin(workgroup_id) workgroupId : vec3<u32>) {\n    let batch = ${splitK ? '0' : 'i32(globalId.z)'};\n    ${batchDims ? `let batchIndices = ${batchDims.offsetToIndices('u32(batch)')};` : ''}\n    let num_tiles = ${\n      splitK ? `${Math.ceil(splitedDimInner / tileInner)}` : '(uniforms.dim_inner - 1) / tileInner + 1'\n    };\n    var kStart = ${splitK ? `i32(globalId.z) * ${splitedDimInner}` : '0'};\n\n    var acc : array<array<${type}, colPerThread>, rowPerThread>;\n    ${matmulSnippet}\n  }\n`;\n};\n\nconst matMulReadWriteFnSource = (\n  component: number,\n  hasBias: boolean,\n  applyActivation: string,\n  variables: IndicesHelper[],\n  isChannelsLast = false,\n): string => {\n  const [batchVariable, aVariable, bVariable, outputVariable] = variables;\n  const dataType = tensorTypeToWsglStorageType(variables[0].type.tensor);\n\n  const source = `\n    fn mm_readA(batch: i32, row: i32, colIn: i32, batchIndices: ${batchVariable.type.indices}) -> ${typeSnippet(\n      component,\n      dataType,\n    )} {\n      var value = ${typeSnippet(component, dataType)}(0.0);\n      let col = colIn * ${component};\n      if(row < uniforms.dim_a_outer && col < uniforms.dim_inner)\n      {\n        var aIndices: ${aVariable.type.indices};\n        ${convertOutputBatchIndicesToInputBatchIndices(\n          'aIndices',\n          aVariable,\n          aVariable.rank - 2,\n          batchVariable.rank,\n          'batchIndices',\n        )}\n        ${aVariable.indicesSet('aIndices', aVariable.rank - 2, 'u32(row)')}\n        ${aVariable.indicesSet('aIndices', aVariable.rank - 1, 'u32(colIn)')}\n        value = ${aVariable.getByIndices('aIndices')};\n      }\n      return value;\n    }\n\n    fn mm_readB(batch: i32, row: i32, colIn: i32, batchIndices: ${batchVariable.type.indices}) -> ${typeSnippet(\n      component,\n      dataType,\n    )} {\n      var value = ${typeSnippet(component, dataType)}(0.0);\n      let col = colIn * ${component};\n      if(row < uniforms.dim_inner && col < uniforms.dim_b_outer)\n      {\n        var bIndices: ${bVariable.type.indices};\n        ${convertOutputBatchIndicesToInputBatchIndices(\n          'bIndices',\n          bVariable,\n          bVariable.rank - 2,\n          batchVariable.rank,\n          'batchIndices',\n        )}\n        ${bVariable.indicesSet('bIndices', bVariable.rank - 2, 'u32(row)')}\n        ${bVariable.indicesSet('bIndices', bVariable.rank - 1, 'u32(colIn)')}\n        value = ${bVariable.getByIndices('bIndices')};\n      }\n      return value;\n    }\n\n    fn mm_write(batch: i32, row: i32, colIn: i32, valueIn: ${typeSnippet(component, dataType)}) {\n      let col = colIn * ${component};\n      if (row < uniforms.dim_a_outer && col < uniforms.dim_b_outer) {\n        var value = valueIn;\n        let coords = vec3<i32>(batch, row, colIn);\n        ${\n          hasBias\n            ? `value = value + ${isChannelsLast ? 'bias[colIn]' : `${typeSnippet(component, dataType)}(bias[row])`};`\n            : ''\n        }\n        ${applyActivation}\n        ${outputVariable.setByIndices('vec3<u32>(coords)', 'value')}\n      }\n    }\n    `;\n  return source;\n};\n\nexport const createMatmulProgramInfo = (\n  inputs: readonly TensorView[],\n  activationAttributes: InternalActivationAttributes,\n  outputShape: readonly number[],\n  reshapedOutputShape?: readonly number[],\n  isChannelsLast = false /* only used for conv2dByMatMul*/,\n  squeezeOutputShapeFunction?: (shape: readonly number[]) => number[],\n): ProgramInfo => {\n  const aShape = inputs[0].dims;\n  const bShape = inputs[1].dims;\n  const outerDimsA = aShape.slice(0, -2);\n  const outerDimsB = bShape.slice(0, -2);\n  const outerDims = reshapedOutputShape ? reshapedOutputShape.slice(0, -2) : outputShape.slice(0, -2);\n  const batchSize = ShapeUtil.size(outerDims);\n  const dimAOuter = aShape[aShape.length - 2];\n  const dimInner = aShape[aShape.length - 1];\n  const dimBOuter = bShape[bShape.length - 1];\n  const isVec4 = dimInner % 4 === 0 && dimBOuter % 4 === 0;\n\n  // TODO: fine tune size\n  const elementsPerThread = dimAOuter <= 8 ? [4, 1, 1] : [4, 4, 1];\n  const workgroupSize: [number, number, number] = [8, 8, 1];\n  const dispatch = [\n    Math.ceil(dimBOuter / workgroupSize[0] / elementsPerThread[0]),\n    Math.ceil(dimAOuter / workgroupSize[1] / elementsPerThread[1]),\n    Math.ceil(batchSize / workgroupSize[2] / elementsPerThread[2]),\n  ];\n\n  const components = isVec4 ? 4 : 1;\n  const aShapeTemp = [...outerDimsA, dimAOuter, dimInner / components];\n  const aRank = aShapeTemp.length;\n  const bShapeTemp = [...outerDimsB, dimInner, dimBOuter / components];\n  const bRank = bShapeTemp.length;\n  const outputShapeTemp = [batchSize, dimAOuter, dimBOuter / components];\n  const programUniforms: ProgramUniform[] = [\n    { type: DataType.int32, data: dimAOuter },\n    { type: DataType.int32, data: dimBOuter },\n    { type: DataType.int32, data: dimInner },\n  ];\n  appendActivationUniformsData(activationAttributes, programUniforms);\n  programUniforms.push(...createTensorShapeVariables(outerDims, aShapeTemp, bShapeTemp));\n  const inputDependencies: ProgramInputTensorInfoDependency[] = ['rank', 'rank'];\n\n  const hasBias = inputs.length > 2;\n  if (hasBias) {\n    programUniforms.push(...createTensorShapeVariables(inputs[2].dims));\n    inputDependencies.push('rank');\n  }\n  programUniforms.push(...createTensorShapeVariables(outputShapeTemp));\n\n  const getShaderSource = (shaderHelper: ShaderHelper) => {\n    const batchRank = outerDims.length;\n    const batchDims = internalVariable('batchDims', inputs[0].dataType, batchRank, 1);\n    const dataType = tensorTypeToWsglStorageType(inputs[0].dataType);\n\n    const A = inputVariable('a', inputs[0].dataType, aRank, components);\n    const B = inputVariable('b', inputs[1].dataType, bRank, components);\n    const output = outputVariable('result', inputs[0].dataType, outputShapeTemp.length, components);\n    const inputVariables = [A, B];\n    if (hasBias) {\n      const biasComponents = isChannelsLast ? components : 1;\n      inputVariables.push(inputVariable('bias', inputs[2].dataType, inputs[2].dims.length, biasComponents));\n    }\n    const uniforms: UniformsArrayType = [\n      { name: 'dim_a_outer', type: 'i32' },\n      { name: 'dim_b_outer', type: 'i32' },\n      { name: 'dim_inner', type: 'i32' },\n    ];\n    appendActivationUniforms(activationAttributes, uniforms);\n    const baseType = tensorTypeToWsglStorageType(output.type.tensor);\n    const applyActivation = getActivationSnippet(activationAttributes, output.type.value, baseType);\n    const declareFunctions = matMulReadWriteFnSource(\n      components,\n      hasBias,\n      applyActivation,\n      [batchDims, A, B, output],\n      isChannelsLast,\n    );\n    return `\n  ${shaderHelper\n    .registerUniforms(uniforms)\n    .registerInternalVariables(batchDims)\n    .declareVariables(...inputVariables, output)}\n  ${declareFunctions}\n  ${\n    isVec4\n      ? makeMatMulPackedVec4Source(elementsPerThread, workgroupSize, dataType, batchDims)\n      : makeMatMulPackedSource(elementsPerThread, workgroupSize, dataType, batchDims)\n  }\n                   `;\n  };\n  return {\n    name: 'MatMul',\n    shaderCache: {\n      hint: `${elementsPerThread};${activationAttributes.activation};${isVec4};${isChannelsLast}`,\n      inputDependencies,\n    },\n    getRunData: () => ({\n      outputs: [\n        {\n          dims: squeezeOutputShapeFunction ? squeezeOutputShapeFunction(outputShape) : outputShape,\n          dataType: inputs[0].dataType,\n        },\n      ],\n      dispatchGroup: { x: dispatch[0], y: dispatch[1], z: dispatch[2] },\n      programUniforms,\n    }),\n    getShaderSource,\n  };\n};\n","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\n// sampled from [@tensorflow/tfjs] tfjs-backend-webgpu/src/conv2d_mm_webgpu.ts\n//\n// modified to fit the needs of the project\n\nimport { DataType } from '../../../../wasm-common';\nimport { LOG_DEBUG } from '../../../log';\nimport { TensorView } from '../../../tensor-view';\nimport { ProgramInfo, ProgramInputTensorInfoDependency, ProgramUniform } from '../../types';\nimport {\n  createTensorShapeVariables,\n  inputVariable,\n  outputVariable,\n  ShaderHelper,\n  tensorTypeToWsglStorageType,\n  UniformsArrayType,\n} from '../common';\nimport { ConvAttributes } from '../conv';\nimport { appendActivationUniforms, appendActivationUniformsData, getActivationSnippet } from '../fuse-utils';\n\nimport { biasSnippet, typeSnippet } from './activation_util';\nimport { utilFunctions } from './conv_util';\nimport { makeMatMulPackedSource, makeMatMulPackedVec4Source } from './matmul_packed_webgpu';\n\nconst conv2dCommonSnippet = (\n  isChannelsLast: boolean,\n  fitAOuter: boolean,\n  fitBOuter: boolean,\n  fitInner: boolean,\n  addBias = false,\n  attributes: ConvAttributes,\n  innerElementSizeX = 4,\n  innerElementSizeW = 4,\n  innerElementSize = 4,\n  dataType = 'f32',\n): string => {\n  const getXSnippet = (innerElementSize: number) => {\n    switch (innerElementSize) {\n      case 1:\n        return 'resData = x[xIndex];';\n      case 3:\n        return `resData = vec3<${dataType}>(x[xIndex], x[xIndex + 1], x[xIndex + 2]);`;\n      case 4:\n        return 'resData = x[xIndex / 4];';\n      default:\n        throw new Error(`innerElementSize ${innerElementSize} is not supported.`);\n    }\n  };\n  const getWSnippet = (innerElementSize: number) => {\n    switch (innerElementSize) {\n      case 1:\n        return 'return w[row * i32(uniforms.w_shape[3]) + colIn];';\n      case 4:\n        return 'return w[row * i32(uniforms.w_shape[3]) / 4 + colIn];';\n      default:\n        throw new Error(`innerElementSize ${innerElementSize} is not supported.`);\n    }\n  };\n  const coordASnippet = isChannelsLast\n    ? `\n    let coord = vec4<i32>(batch, xRow, xCol, xCh);\n    `\n    : `\n    let coord = vec4<i32>(batch, xCh, xRow, xCol);\n    `;\n\n  const coordResSnippet = isChannelsLast\n    ? `\n    let coords = vec4<i32>(\n      batch,\n      row / outWidth,\n      row % outWidth,\n      col);\n    `\n    : `\n    let coords = vec4<i32>(\n      batch,\n      row,\n      col / outWidth,\n      col % outWidth);\n    `;\n\n  const xHeight = isChannelsLast ? 'i32(uniforms.x_shape[1])' : 'i32(uniforms.x_shape[2])';\n  const xWidth = isChannelsLast ? 'i32(uniforms.x_shape[2])' : 'i32(uniforms.x_shape[3])';\n  const row = isChannelsLast ? 'row' : 'col';\n  const col = isChannelsLast ? 'col' : 'row';\n  const readXSnippet = `\n    let inChannels = i32(uniforms.w_shape[2]);\n    let outWidth = ${isChannelsLast ? 'i32(uniforms.result_shape[2])' : 'i32(uniforms.result_shape[3])'};\n    let outRow = ${row} / outWidth;\n    let outCol = ${row} % outWidth;\n\n    let WRow = ${col} / (i32(uniforms.w_shape[1]) * inChannels);\n    let WCol = ${col} / inChannels % i32(uniforms.w_shape[1]);\n    let xRow = outRow * uniforms.stride[0] + uniforms.dilation[0] * WRow - uniforms.pad[0];\n    let xCol = outCol * uniforms.stride[1] + uniforms.dilation[1] * WCol - uniforms.pad[1];\n    let xCh = ${col} % inChannels;\n    var resData = ${typeSnippet(innerElementSizeX, dataType)}(0.0);\n    // The bounds checking is always needed since we use it to pad zero for\n    // the 'same' padding type.\n    if (xRow >= 0 && xRow < ${xHeight} && xCol >= 0 && xCol < ${xWidth}) {\n      ${coordASnippet}\n      let xIndex = getIndexFromCoords4D(coord, vec4<i32>(uniforms.x_shape));\n      ${getXSnippet(innerElementSizeX)}\n    }\n    return resData;`;\n\n  const sampleX = isChannelsLast\n    ? fitAOuter && fitInner\n      ? `\n    let col = colIn * ${innerElementSizeX};\n    ${readXSnippet}`\n      : `\n    let col = colIn * ${innerElementSizeX};\n    if (row < uniforms.dim_a_outer && col < uniforms.dim_inner) {\n      ${readXSnippet}\n    }\n    return ${typeSnippet(innerElementSizeX, dataType)}(0.0);`\n    : fitInner && fitBOuter\n      ? `\n    let col = colIn * ${innerElementSizeX};\n    ${readXSnippet}`\n      : `\n    let col = colIn * ${innerElementSizeX};\n    if (row < uniforms.dim_inner && col < uniforms.dim_b_outer) {\n      ${readXSnippet}\n    }\n    return ${typeSnippet(innerElementSizeX, dataType)}(0.0);`;\n\n  const sampleW = isChannelsLast\n    ? fitInner && fitBOuter\n      ? getWSnippet(innerElementSizeW)\n      : `\n    let col = colIn * ${innerElementSizeW};\n    if (row < uniforms.dim_inner && col < uniforms.dim_b_outer) {\n      ${getWSnippet(innerElementSizeW)}\n    }\n    return ${typeSnippet(innerElementSizeW, dataType)}(0.0);`\n    : `\n    let col = colIn * ${innerElementSizeW};\n    if (row < uniforms.dim_inner && col < uniforms.dim_a_outer) {\n      ${getWSnippet(innerElementSizeW)}\n    }\n    return ${typeSnippet(innerElementSizeW, dataType)}(0.0);`;\n\n  const resType = typeSnippet(innerElementSize, dataType);\n  const aType = isChannelsLast ? typeSnippet(innerElementSizeX, dataType) : typeSnippet(innerElementSizeW, dataType);\n  const bType = isChannelsLast ? typeSnippet(innerElementSizeW, dataType) : typeSnippet(innerElementSizeX, dataType);\n  const applyActivation = getActivationSnippet(attributes, resType, dataType);\n  const userCode = `\n    fn mm_readA(batch: i32, row : i32, colIn : i32) -> ${aType} {\n      ${isChannelsLast ? sampleX : sampleW}\n    }\n\n    fn mm_readB(batch: i32, row : i32, colIn : i32) -> ${bType} {\n      ${isChannelsLast ? sampleW : sampleX}\n    }\n\n    fn mm_write(batch: i32, row : i32, colIn : i32, valueIn : ${resType}) {\n      let col = colIn * ${innerElementSize};\n      if (row < uniforms.dim_a_outer && col < uniforms.dim_b_outer)\n      {\n      var value = valueIn;\n      let outWidth = ${isChannelsLast ? 'i32(uniforms.result_shape[2])' : 'i32(uniforms.result_shape[3])'};\n      ${coordResSnippet}\n      ${biasSnippet(addBias)}\n      ${applyActivation}\n      setOutputAtCoords(coords[0], coords[1], coords[2], coords[3], value);\n      }\n    }`;\n  return userCode;\n};\n\nexport const createConv2DMatMulProgramInfo = (\n  inputs: readonly TensorView[],\n  attributes: ConvAttributes,\n  outputShape: readonly number[],\n  dimAOuter: number,\n  dimBOuter: number,\n  dimInner: number,\n  hasBias: boolean,\n  sequentialAccessByThreads: boolean,\n  squeezeOutputShapeFunction?: (shape: readonly number[]) => number[],\n): ProgramInfo => {\n  const isChannelsLast = attributes.format === 'NHWC';\n  const inChannels = isChannelsLast ? inputs[0].dims[3] : inputs[0].dims[1];\n  const batchSize = outputShape[0];\n  const outWidth = isChannelsLast ? outputShape[2] : outputShape[3];\n  const outHeight = isChannelsLast ? outputShape[1] : outputShape[2];\n  const outChannels = isChannelsLast ? outputShape[3] : outputShape[1];\n  // TODO: enable vec4 for NCHW\n  const isVec4 = isChannelsLast && (inChannels % 4 === 0 || inChannels % 3 === 0) && outChannels % 4 === 0;\n\n  // TODO: fine tune size\n  const dispatchX = isChannelsLast ? outChannels : outWidth * outHeight;\n  const dispatchY = isChannelsLast ? outWidth * outHeight : outChannels;\n  const workGroupSize: [number, number, number] = [8, 8, 1];\n  const elementsPerThread = dimAOuter <= 8 ? [4, 1, 1] : [4, 4, 1];\n  const dispatch = [\n    Math.ceil(dispatchX / workGroupSize[0] / elementsPerThread[0]),\n    Math.ceil(dispatchY / workGroupSize[1] / elementsPerThread[1]),\n    Math.ceil(batchSize / workGroupSize[2] / elementsPerThread[2]),\n  ];\n\n  LOG_DEBUG('verbose', () => `[conv2d_mm_webgpu] dispatch = ${dispatch}`);\n\n  const innerElementSize = isVec4 ? (isChannelsLast && inChannels % 4 !== 0 ? 3 : 4) : 1;\n  const tileAOuter = workGroupSize[1] * elementsPerThread[1];\n  const tileBOuter = workGroupSize[0] * elementsPerThread[0];\n  const tileInner = Math.max(workGroupSize[0] * innerElementSize, workGroupSize[1]);\n  const fitAOuter = dimAOuter % tileAOuter === 0;\n  const fitBOuter = dimBOuter % tileBOuter === 0;\n  const fitInner = dimInner % tileInner === 0;\n  const elementsSize = isVec4 ? [innerElementSize, 4, 4] : [1, 1, 1];\n\n  const programUniforms: ProgramUniform[] = [\n    { type: DataType.int32, data: dimAOuter },\n    { type: DataType.int32, data: dimBOuter },\n    { type: DataType.int32, data: dimInner },\n    { type: DataType.int32, data: [attributes.pads[0], attributes.pads[1]] },\n    { type: DataType.int32, data: attributes.strides },\n    { type: DataType.int32, data: attributes.dilations },\n  ];\n  appendActivationUniformsData(attributes, programUniforms);\n  programUniforms.push(...createTensorShapeVariables(inputs[0].dims, inputs[1].dims));\n  const inputDependencies: ProgramInputTensorInfoDependency[] = ['rank', 'rank'];\n  if (hasBias) {\n    programUniforms.push(...createTensorShapeVariables(inputs[2].dims));\n    inputDependencies.push('rank');\n  }\n  programUniforms.push(...createTensorShapeVariables(outputShape));\n\n  const getShaderSource = (shaderHelper: ShaderHelper) => {\n    const uniforms: UniformsArrayType = [\n      { name: 'dim_a_outer', type: 'i32' },\n      { name: 'dim_b_outer', type: 'i32' },\n      { name: 'dim_inner', type: 'i32' },\n      { name: 'pad', type: 'i32', length: 2 },\n      { name: 'stride', type: 'i32', length: 2 },\n      { name: 'dilation', type: 'i32', length: 2 },\n    ];\n    appendActivationUniforms(attributes, uniforms);\n\n    // TODO: support component 2, 3.\n    const components = isVec4 ? 4 : 1;\n    const t = tensorTypeToWsglStorageType(inputs[0].dataType);\n    let declareFunctions = `\n      fn setOutputAtIndex(flatIndex : i32, value : ${isVec4 ? `vec4<${t}>` : t}) {\n        result[flatIndex] = ${isVec4 ? `vec4<${t}>` : t}(value);\n      }\n      fn setOutputAtCoords(d0 : i32, d1 : i32, d2 : i32, d3 : i32, value : ${isVec4 ? `vec4<${t}>` : t}) {\n        let flatIndex = getOutputIndexFromCoords(vec4<i32>(d0, d1, d2, d3));\n        setOutputAtIndex(flatIndex ${isVec4 ? '/ 4' : ''}, value);\n      }`;\n    const x = inputVariable(\n      'x',\n      inputs[0].dataType,\n      inputs[0].dims.length,\n      innerElementSize === 3 ? 1 : innerElementSize,\n    );\n    const w = inputVariable('w', inputs[1].dataType, inputs[1].dims.length, components);\n    const inputVariables = [x, w];\n    const output = outputVariable('result', inputs[0].dataType, outputShape.length, components);\n    if (hasBias) {\n      const bias = inputVariable('bias', inputs[2].dataType, inputs[2].dims.length, components);\n      inputVariables.push(bias);\n      declareFunctions += `\n        fn getBiasByOutputCoords(coords : vec4<i32>) -> ${isVec4 ? `vec4<${t}>` : t} {\n          return bias[coords.${isChannelsLast ? 'w' : 'y'}${isVec4 ? '/ 4' : ''}];\n        }`;\n    }\n\n    return `\n        ${utilFunctions('uniforms.result_strides')}\n        //struct Uniforms { xShape : vec4<i32>, wShape : vec4<i32>, outShape : vec4<i32>,\n        //  outShapeStrides: vec3<i32>, filterDims : vec2<i32>, pad : vec2<i32>, stride : vec2<i32>,\n        //  dilation : vec2<i32>, dimAOuter : i32, dimBOuter : i32, dimInner : i32 };\n        ${shaderHelper.registerUniforms(uniforms).declareVariables(...inputVariables, output)}\n        ${declareFunctions}\n        ${conv2dCommonSnippet(\n          isChannelsLast,\n          fitAOuter,\n          fitBOuter,\n          fitInner,\n          hasBias,\n          attributes,\n          elementsSize[0],\n          elementsSize[1],\n          elementsSize[2],\n          t,\n        )}\n        ${\n          isVec4\n            ? makeMatMulPackedVec4Source(elementsPerThread, workGroupSize, t, undefined, !isChannelsLast, tileInner)\n            : makeMatMulPackedSource(\n                elementsPerThread,\n                workGroupSize,\n                t,\n                undefined,\n                !isChannelsLast,\n                tileInner,\n                false,\n                undefined,\n                sequentialAccessByThreads,\n              )\n        }`;\n  };\n  return {\n    name: 'Conv2DMatMul',\n    shaderCache: {\n      hint: `${attributes.cacheKey};${innerElementSize};${isVec4};${fitAOuter};${fitBOuter};${fitInner};${tileAOuter};${tileBOuter};${tileInner}`,\n      inputDependencies,\n    },\n    getRunData: () => ({\n      outputs: [\n        {\n          dims: squeezeOutputShapeFunction ? squeezeOutputShapeFunction(outputShape) : outputShape,\n          dataType: inputs[0].dataType,\n        },\n      ],\n      dispatchGroup: { x: dispatch[0], y: dispatch[1], z: dispatch[2] },\n      programUniforms,\n    }),\n    getShaderSource,\n  };\n};\n","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\n// sampled from [@tensorflow/tfjs] tfjs-backend-webgpu/src/conv3d_naive_webgpu.ts\n//\n// modified to fit the needs of the project\n\nimport { DataType } from '../../../../wasm-common';\nimport { LOG_DEBUG } from '../../../log';\nimport { TensorView } from '../../../tensor-view';\nimport { ShapeUtil } from '../../../util';\nimport { ProgramInfo, ProgramInputTensorInfoDependency, ProgramUniform } from '../../types';\nimport {\n  createTensorShapeVariables,\n  getElementAt,\n  inputVariable,\n  outputVariable,\n  ShaderHelper,\n  tensorTypeToWsglStorageType,\n  UniformsArrayType,\n} from '../common';\nimport { ConvAttributes } from '../conv';\nimport { appendActivationUniforms, appendActivationUniformsData, getActivationSnippet } from '../fuse-utils';\n\nimport { typeSnippet } from './activation_util';\n\nconst arrayProduct = (arr: number[]) => {\n  let product = 1;\n  for (let i = 0; i < arr.length; i++) {\n    product *= arr[i];\n  }\n  return product;\n};\n\nconst parse3TupleParam = (param: number | [number, number, number]): [number, number, number] =>\n  typeof param === 'number' ? [param, param, param] : param;\n\nconst getEffectiveFilterSize = (filterSize: number, dilation: number): number => {\n  if (dilation <= 1) {\n    return filterSize;\n  }\n\n  return filterSize + (filterSize - 1) * (dilation - 1);\n};\n\nconst computeDefaultPad = (\n  inputShape: [number, number] | [number, number, number, number],\n  fieldSize: number,\n  stride: number,\n  dilation = 1,\n): number => {\n  const effectiveFieldSize = getEffectiveFilterSize(fieldSize, dilation);\n  return Math.floor((inputShape[0] * (stride - 1) - stride + effectiveFieldSize) / 2);\n};\n\nconst computeOutputShape4D = (\n  inShape: [number, number, number, number],\n  filterShape: [number, number, number],\n  outChannels: number,\n  strides: [number, number, number],\n  zeroPad?: number,\n): [number, number, number, number] => {\n  if (zeroPad == null) {\n    // eslint-disable-next-line no-param-reassign\n    zeroPad = computeDefaultPad(inShape, filterShape[0], strides[0]);\n  }\n  const outShape: [number, number, number, number] = [0, 0, 0, outChannels];\n  for (let index = 0; index < 3; index++) {\n    if (inShape[index] + 2 * zeroPad >= filterShape[index]) {\n      outShape[index] = Math.trunc((inShape[index] - filterShape[index] + 2 * zeroPad) / strides[index] + 1);\n    }\n  }\n  return outShape;\n};\n\nconst get3DPadAndOutInfo = (\n  pad: number | string | number[],\n  inDepth: number,\n  inHeight: number,\n  inWidth: number,\n  strideDepth: number,\n  strideHeight: number,\n  strideWidth: number,\n  filterDepth: number,\n  filterHeight: number,\n  filterWidth: number,\n): { padInfo: PadInfo3D; outDepth: number; outHeight: number; outWidth: number } => {\n  let padInfo: PadInfo3D;\n  let outDepth: number;\n  let outHeight: number;\n  let outWidth: number;\n\n  if (pad === 'VALID') {\n    // eslint-disable-next-line no-param-reassign\n    pad = 0;\n  }\n\n  if (typeof pad === 'number') {\n    padInfo = { top: pad, bottom: pad, left: pad, right: pad, front: pad, back: pad };\n    const outShape = computeOutputShape4D(\n      [inDepth, inHeight, inWidth, 1],\n      [filterDepth, filterHeight, filterWidth],\n      1,\n      [strideDepth, strideHeight, strideWidth],\n      pad,\n    );\n    outDepth = outShape[0];\n    outHeight = outShape[1];\n    outWidth = outShape[2];\n  } else if (Array.isArray(pad)) {\n    if (!pad.every((val, _, arr) => val === arr[0])) {\n      throw Error(`Unsupported padding parameter: ${pad}`);\n    }\n    padInfo = { top: pad[0], bottom: pad[1], left: pad[2], right: pad[3], front: pad[4], back: pad[5] };\n    const outShape = computeOutputShape4D(\n      [inDepth, inHeight, inWidth, 1],\n      [filterDepth, filterHeight, filterWidth],\n      1,\n      [strideDepth, strideHeight, strideWidth],\n      pad[0],\n    );\n    outDepth = outShape[0];\n    outHeight = outShape[1];\n    outWidth = outShape[2];\n  } else if (pad === 'SAME_UPPER') {\n    // TODO: support 'SAME_LOWER'.\n    outDepth = Math.ceil(inDepth / strideDepth);\n    outHeight = Math.ceil(inHeight / strideHeight);\n    outWidth = Math.ceil(inWidth / strideWidth);\n    const padAlongDepth = (outDepth - 1) * strideDepth + filterDepth - inDepth;\n    const padAlongHeight = (outHeight - 1) * strideHeight + filterHeight - inHeight;\n    const padAlongWidth = (outWidth - 1) * strideWidth + filterWidth - inWidth;\n    const front = Math.floor(padAlongDepth / 2);\n    const back = padAlongDepth - front;\n    const top = Math.floor(padAlongHeight / 2);\n    const bottom = padAlongHeight - top;\n    const left = Math.floor(padAlongWidth / 2);\n    const right = padAlongWidth - left;\n\n    padInfo = { top, bottom, left, right, front, back };\n  } else {\n    throw Error(`Unknown padding parameter: ${pad}`);\n  }\n  return { padInfo, outDepth, outHeight, outWidth };\n};\n\ntype PadInfo3D = {\n  top: number;\n  left: number;\n  right: number;\n  bottom: number;\n  front: number;\n  back: number;\n};\n\nexport type Conv3DInfo = {\n  batchSize: number;\n  inDepth: number;\n  inHeight: number;\n  inWidth: number;\n  inChannels: number;\n  outDepth: number;\n  outHeight: number;\n  outWidth: number;\n  outChannels: number;\n  dataFormat: 'channelsFirst' | 'channelsLast';\n  strideDepth: number;\n  strideHeight: number;\n  strideWidth: number;\n  dilationDepth: number;\n  dilationHeight: number;\n  dilationWidth: number;\n  filterDepth: number;\n  filterHeight: number;\n  filterWidth: number;\n  effectiveFilterDepth: number;\n  effectiveFilterHeight: number;\n  effectiveFilterWidth: number;\n  padInfo: PadInfo3D;\n  inShape: [number, number, number, number, number];\n  outShape: [number, number, number, number, number];\n  filterShape: [number, number, number, number, number];\n};\n\nexport const computeConv3DInfo = (\n  inShape: [number, number, number, number, number],\n  filterShape: [number, number, number, number, number],\n  strides: number | [number, number, number],\n  dilations: number | [number, number, number],\n  pad: number | string | number[],\n  depthwise = false,\n  dataFormat: 'channelsFirst' | 'channelsLast' = 'channelsLast',\n): Conv3DInfo => {\n  let batchSize, inDepth, inHeight, inWidth, inChannels;\n  if (dataFormat === 'channelsLast') {\n    [batchSize, inDepth, inHeight, inWidth, inChannels] = inShape;\n  } else if (dataFormat === 'channelsFirst') {\n    [batchSize, inChannels, inDepth, inHeight, inWidth] = inShape;\n  } else {\n    throw new Error(`Unknown dataFormat ${dataFormat}`);\n  }\n  const [filterChannels, , filterDepth, filterHeight, filterWidth] = filterShape;\n\n  const [strideDepth, strideHeight, strideWidth] = parse3TupleParam(strides);\n  const [dilationDepth, dilationHeight, dilationWidth] = parse3TupleParam(dilations);\n\n  const effectiveFilterDepth = getEffectiveFilterSize(filterDepth, dilationDepth);\n  const effectiveFilterHeight = getEffectiveFilterSize(filterHeight, dilationHeight);\n  const effectiveFilterWidth = getEffectiveFilterSize(filterWidth, dilationWidth);\n  const { padInfo, outDepth, outHeight, outWidth } = get3DPadAndOutInfo(\n    pad,\n    inDepth,\n    inHeight,\n    inWidth,\n    strideDepth,\n    strideHeight,\n    strideWidth,\n    effectiveFilterDepth,\n    effectiveFilterHeight,\n    effectiveFilterWidth,\n  );\n\n  const outChannels = depthwise ? filterChannels * inChannels : filterChannels;\n\n  let outShape: [number, number, number, number, number] = [0, 0, 0, 0, 0];\n  if (dataFormat === 'channelsFirst') {\n    outShape = [batchSize, outChannels, outDepth, outHeight, outWidth];\n  } else if (dataFormat === 'channelsLast') {\n    outShape = [batchSize, outDepth, outHeight, outWidth, outChannels];\n  }\n\n  return {\n    batchSize,\n    dataFormat,\n    inDepth,\n    inHeight,\n    inWidth,\n    inChannels,\n    outDepth,\n    outHeight,\n    outWidth,\n    outChannels,\n    padInfo,\n    strideDepth,\n    strideHeight,\n    strideWidth,\n    filterDepth,\n    filterHeight,\n    filterWidth,\n    effectiveFilterDepth,\n    effectiveFilterHeight,\n    effectiveFilterWidth,\n    dilationDepth,\n    dilationHeight,\n    dilationWidth,\n    inShape,\n    outShape,\n    filterShape,\n  };\n};\n\nexport const createConv3DNaiveProgramInfo = (\n  inputs: readonly TensorView[],\n  attributes: ConvAttributes,\n  outputShape: readonly number[],\n  filterDims: readonly number[],\n  pads: readonly number[],\n  dataFormat: string,\n): ProgramInfo => {\n  const isChannelLast = dataFormat === 'channelsLast';\n  const inChannels = isChannelLast ? inputs[0].dims[3] : inputs[0].dims[1];\n  // TODO: enable vec4.\n  const isVec4 = false;\n  const workGroupSize: [number, number, number] = [64, 1, 1];\n  const dispatchLayout = { x: outputShape.map((_, i) => i) };\n  const dispatch = [Math.ceil(arrayProduct(dispatchLayout.x.map((d) => outputShape[d])) / workGroupSize[0]), 1, 1];\n\n  LOG_DEBUG('verbose', () => `[conv3d_naive_webgpu] dispatch = ${dispatch}`);\n\n  const innerElementSize = isVec4 ? (isChannelLast && inChannels % 4 !== 0 ? 3 : 4) : 1;\n  const outputSize = ShapeUtil.size(outputShape);\n  const programUniforms: ProgramUniform[] = [\n    { type: DataType.uint32, data: outputSize },\n    { type: DataType.uint32, data: filterDims },\n    { type: DataType.uint32, data: pads },\n    { type: DataType.uint32, data: attributes.strides },\n    { type: DataType.uint32, data: attributes.dilations },\n  ];\n  appendActivationUniformsData(attributes, programUniforms);\n  programUniforms.push(...createTensorShapeVariables(inputs[0].dims, inputs[1].dims));\n  const inputDependencies: ProgramInputTensorInfoDependency[] = ['rank', 'rank'];\n  const hasBias = inputs.length === 3;\n  if (hasBias) {\n    programUniforms.push(...createTensorShapeVariables(inputs[2].dims));\n    inputDependencies.push('rank');\n  }\n  programUniforms.push(...createTensorShapeVariables(outputShape));\n\n  const getShaderSource = (shaderHelper: ShaderHelper) => {\n    const uniforms: UniformsArrayType = [\n      { name: 'output_size', type: 'u32' },\n      { name: 'filter_dims', type: 'u32', length: filterDims.length },\n      { name: 'pads', type: 'u32', length: pads.length },\n      { name: 'strides', type: 'u32', length: attributes.strides.length },\n      { name: 'dilations', type: 'u32', length: attributes.dilations.length },\n    ];\n    appendActivationUniforms(attributes, uniforms);\n    // TODO: support component 2, 3.\n    const components = isVec4 ? 4 : 1;\n    const t = tensorTypeToWsglStorageType(inputs[0].dataType);\n\n    const x = inputVariable(\n      'x',\n      inputs[0].dataType,\n      inputs[0].dims.length,\n      innerElementSize === 3 ? 1 : innerElementSize,\n    );\n    const w = inputVariable('W', inputs[1].dataType, inputs[1].dims.length, components);\n    const inputVariables = [x, w];\n    const output = outputVariable('result', inputs[0].dataType, outputShape.length, components);\n    let declareFunctions = '';\n    if (hasBias) {\n      const bias = inputVariable('bias', inputs[2].dataType, inputs[2].dims.length, components);\n      inputVariables.push(bias);\n      declareFunctions += `\n        fn getBiasByOutputCoords(coords : array<u32, 5>) -> ${isVec4 ? `vec4<${t}>` : t} {\n          return bias[${isChannelLast ? getElementAt('coords', 4, 5) : getElementAt('coords', 1, 5)}${\n            isVec4 ? '/ 4' : ''\n          }];\n        }`;\n    }\n    const resType = typeSnippet(innerElementSize, t);\n    const applyActivation = getActivationSnippet(attributes, resType, t);\n\n    return `\n            ${declareFunctions}\n            fn getX(d0 : u32, d1 : u32, d2 : u32, d3 : u32, d4 : u32) -> f32 {\n              let aIndices = array<u32, 5>(d0, d1, d2, d3, d4);\n              return ${x.getByIndices('aIndices')};\n            }\n            fn getW(d0 : u32, d1 : u32, d2 : u32, d3 : u32, d4 : u32) -> f32 {\n              let aIndices = array<u32, 5>(d0, d1, d2, d3, d4);\n              return ${w.getByIndices('aIndices')};\n            }\n          ${shaderHelper.registerUniforms(uniforms).declareVariables(...inputVariables, output)}\n          ${shaderHelper.mainStart()}\n          ${shaderHelper.guardAgainstOutOfBoundsWorkgroupSizes('uniforms.output_size')}\n              let coords = ${output.offsetToIndices('global_idx')};\n              let batch = ${getElementAt('coords', 0, x.rank)};\n              let d2 = ${\n                isChannelLast ? getElementAt('coords', x.rank - 1, x.rank) : getElementAt('coords', 1, x.rank)\n              };\n              let xFRCCorner = vec3<u32>(${\n                isChannelLast ? getElementAt('coords', 1, x.rank) : getElementAt('coords', 2, x.rank)\n              },\n              ${isChannelLast ? getElementAt('coords', 2, x.rank) : getElementAt('coords', 3, x.rank)},\n              ${\n                isChannelLast ? getElementAt('coords', 3, x.rank) : getElementAt('coords', 4, x.rank)\n              }) * uniforms.strides - uniforms.pads;\n              let xFCorner = xFRCCorner.x;\n              let xRCorner = xFRCCorner.y;\n              let xCCorner = xFRCCorner.z;\n              let xShapeY = ${\n                isChannelLast\n                  ? getElementAt('uniforms.x_shape', 1, x.rank)\n                  : getElementAt('uniforms.x_shape', 2, x.rank)\n              };\n              let xShapeZ = ${\n                isChannelLast\n                  ? getElementAt('uniforms.x_shape', 2, x.rank)\n                  : getElementAt('uniforms.x_shape', 3, x.rank)\n              };\n              let xShapeW = ${\n                isChannelLast\n                  ? getElementAt('uniforms.x_shape', 3, x.rank)\n                  : getElementAt('uniforms.x_shape', 4, x.rank)\n              };\n              let xShapeU = ${\n                isChannelLast\n                  ? getElementAt('uniforms.x_shape', 4, x.rank)\n                  : getElementAt('uniforms.x_shape', 1, x.rank)\n              };\n              let inputDepthNearestVec4 = (xShapeU / 4) * 4;\n              let inputDepthVec4Remainder = xShapeU % 4;\n\n              var value = 0.0;\n              for (var wF = 0u; wF < uniforms.filter_dims[0]; wF++) {\n                let xF = xFCorner + wF * uniforms.dilations[0];\n                if (xF < 0 || xF >= xShapeY) {\n                  continue;\n                }\n\n                for (var wR = 0u; wR < uniforms.filter_dims[1]; wR++) {\n                  let xR = xRCorner + wR * uniforms.dilations[1];\n                  if (xR < 0 || xR >= xShapeZ) {\n                    continue;\n                  }\n\n                  for (var wC = 0u; wC < uniforms.filter_dims[2]; wC++) {\n                    let xC = xCCorner + wC * uniforms.dilations[2];\n                    if (xC < 0 || xC >= xShapeW) {\n                      continue;\n                    }\n\n                    for (var d1 = 0u; d1 < inputDepthNearestVec4; d1 += 4) {\n                      ${\n                        isChannelLast\n                          ? `let xValues = vec4<f32>(\n                               getX(batch, xF, xR, xC, d1),\n                               getX(batch, xF, xR, xC, d1 + 1),\n                               getX(batch, xF, xR, xC, d1 + 2),\n                               getX(batch, xF, xR, xC, d1 + 3));\n                            `\n                          : `let xValues = vec4<f32>(\n                               getX(batch, d1, xF, xR, xC),\n                               getX(batch, d1 + 1, xF, xR, xC),\n                               getX(batch, d1 + 2, xF, xR, xC),\n                               getX(batch, d1 + 3, xF, xR, xC));\n                            `\n                      }\n                            let wValues = vec4<f32>(\n                              getW(d2, d1, wF, wR, wC),\n                              getW(d2, d1 + 1, wF, wR, wC),\n                              getW(d2, d1 + 2, wF, wR, wC),\n                              getW(d2, d1 + 3, wF, wR, wC));\n                      value += dot(xValues, wValues);\n                    }\n                    if (inputDepthVec4Remainder == 1) {\n                        ${\n                          isChannelLast\n                            ? `value += getX(batch, xF, xR, xC, inputDepthNearestVec4)\n                          * getW(d2, inputDepthNearestVec4, wF, wR, wC);`\n                            : `value += getX(batch, inputDepthNearestVec4, xF, xR, xC)\n                          * getW(d2, inputDepthNearestVec4, wF, wR, wC);`\n                        }\n                    } else if (inputDepthVec4Remainder == 2) {\n                      ${\n                        isChannelLast\n                          ? `let xValues = vec2<f32>(\n                        getX(batch, xF, xR, xC, inputDepthNearestVec4),\n                        getX(batch, xF, xR, xC, inputDepthNearestVec4 + 1));\n                      `\n                          : `let xValues = vec2<f32>(\n                        getX(batch, inputDepthNearestVec4, xF, xR, xC),\n                        getX(batch, inputDepthNearestVec4 + 1, xF, xR, xC));\n                    `\n                      }\n                    let wValues = vec2<f32>(\n                      getW(d2, inputDepthNearestVec4, wF, wR, wC),\n                      getW(d2, inputDepthNearestVec4 + 1, wF, wR, wC));\n                      value += dot(xValues, wValues);\n                    } else if (inputDepthVec4Remainder == 3) {\n                      ${\n                        isChannelLast\n                          ? `let xValues = vec3<f32>(\n                        getX(batch, xF, xR, xC, inputDepthNearestVec4),\n                        getX(batch, xF, xR, xC, inputDepthNearestVec4 + 1),\n                        getX(batch, xF, xR, xC, inputDepthNearestVec4 + 2));\n                      `\n                          : `let xValues = vec3<f32>(\n                        getX(batch, inputDepthNearestVec4, xF, xR, xC),\n                        getX(batch, inputDepthNearestVec4 + 1, xF, xR, xC),\n                        getX(batch, inputDepthNearestVec4 + 2, xF, xR, xC));\n                    `\n                      }\n                    let wValues = vec3<f32>(\n                      getW(d2, inputDepthNearestVec4, wF, wR, wC),\n                      getW(d2, inputDepthNearestVec4 + 1, wF, wR, wC),\n                      getW(d2, inputDepthNearestVec4 + 2, wF, wR, wC));\n                      value += dot(xValues, wValues);\n                    }\n                  }\n                }\n              }\n              ${hasBias ? 'value = value + getBiasByOutputCoords(coords)' : ''};\n              ${applyActivation}\n              result[global_idx] = f32(value);\n          }`;\n  };\n  return {\n    name: 'Conv3DNaive',\n    shaderCache: { hint: `${attributes.cacheKey};${isChannelLast};${innerElementSize};${hasBias}`, inputDependencies },\n    getRunData: () => ({\n      outputs: [{ dims: outputShape, dataType: inputs[0].dataType }],\n      dispatchGroup: { x: dispatch[0], y: dispatch[1], z: dispatch[2] },\n      programUniforms,\n    }),\n    getShaderSource,\n  };\n};\n","// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport { DataType } from '../../../wasm-common';\nimport { TensorView } from '../../tensor-view';\nimport { ShapeUtil } from '../../util';\nimport { ProgramInfo, ProgramInputTensorInfoDependency, ProgramUniform } from '../types';\n\nimport {\n  createTensorShapeVariables,\n  getMaxComponents,\n  inputVariable,\n  outputVariable,\n  ShaderHelper,\n  tensorTypeToWsglStorageType,\n  UniformsArrayType,\n} from './common';\nimport { ConvAttributes } from './conv';\nimport { appendActivationUniforms, appendActivationUniformsData, getActivationSnippet } from './fuse-utils';\n\n/**\n * naive grouped conv implementation, supports 1d/2d conv\n * @param squeezeOutputShapeFunction - an optional function to squeeze the output shape, only used in conv1d\n */\nexport const createGroupedConvProgramInfo = (\n  inputs: readonly TensorView[],\n  attributes: ConvAttributes,\n  outputShape: readonly number[],\n  squeezeOutputShapeFunction?: (shape: readonly number[]) => number[],\n): ProgramInfo => {\n  const hasBias = inputs.length > 2;\n  const processBias = hasBias ? 'value += b[output_channel];' : '';\n  const xShape = inputs[0].dims;\n  const wShape = inputs[1].dims;\n\n  const isChannelLast = attributes.format === 'NHWC';\n  const outputChannels = isChannelLast ? outputShape[3] : outputShape[1];\n  const outputChannelsPerGroup = outputChannels / attributes.group;\n  const components = isChannelLast && outputChannelsPerGroup >= 4 ? getMaxComponents(outputChannels) : 1;\n  const outputSize = ShapeUtil.size(outputShape) / components;\n\n  const programUniforms: ProgramUniform[] = [\n    { type: DataType.uint32, data: outputSize },\n    { type: DataType.uint32, data: attributes.dilations },\n    { type: DataType.uint32, data: [attributes.strides[0], attributes.strides[1]] },\n    { type: DataType.uint32, data: [attributes.pads[0], attributes.pads[1]] },\n    { type: DataType.uint32, data: outputChannelsPerGroup },\n  ];\n  appendActivationUniformsData(attributes, programUniforms);\n  programUniforms.push(\n    ...createTensorShapeVariables(xShape, [wShape[0], wShape[1], wShape[2], wShape[3] / components]),\n  );\n  const inputDependencies: ProgramInputTensorInfoDependency[] = hasBias ? ['rank', 'rank', 'rank'] : ['rank', 'rank'];\n  programUniforms.push(\n    ...createTensorShapeVariables([outputShape[0], outputShape[1], outputShape[2], outputShape[3] / components]),\n  );\n\n  const getShaderSource = (shaderHelper: ShaderHelper) => {\n    const output = outputVariable('output', inputs[0].dataType, outputShape.length, components);\n    const baseType = tensorTypeToWsglStorageType(output.type.tensor);\n    const applyActivation = getActivationSnippet(attributes, output.type.value, baseType);\n    const x = inputVariable('x', inputs[0].dataType, xShape.length);\n    const w = inputVariable('w', inputs[1].dataType, wShape.length, components);\n    const inputVars = [x, w];\n    if (hasBias) {\n      inputVars.push(inputVariable('b', inputs[2].dataType, inputs[2].dims, components));\n    }\n\n    const uniforms: UniformsArrayType = [\n      { name: 'output_size', type: 'u32' },\n      { name: 'dilations', type: 'u32', length: attributes.dilations.length },\n      { name: 'strides', type: 'u32', length: 2 },\n      { name: 'pads', type: 'u32', length: 2 },\n      { name: 'output_channels_per_group', type: 'u32' },\n    ];\n    appendActivationUniforms(attributes, uniforms);\n\n    const calculateResult = isChannelLast\n      ? `\n      for (var wHeight: u32 = 0u; wHeight < uniforms.w_shape[0]; wHeight++) {\n        let xHeight = xRCCorner.x + wHeight * uniforms.dilations[0];\n\n        if (xHeight < 0u || xHeight >= uniforms.x_shape[1]) {\n          continue;\n        }\n\n        for (var wWidth: u32 = 0u; wWidth < uniforms.w_shape[1]; wWidth++) {\n          let xWidth = xRCCorner.y + wWidth * uniforms.dilations[1];\n          if (xWidth < 0u || xWidth >= uniforms.x_shape[2]) {\n            continue;\n          }\n\n          for (var wInChannel: u32 = 0u; wInChannel < uniforms.w_shape[2]; wInChannel++) {\n            let input_channel = in_channel_offset + wInChannel;\n            let xVal = ${x.get('batch', 'xHeight', 'xWidth', 'input_channel')};\n            let wVal = ${w.get('wHeight', 'wWidth', 'wInChannel', 'output_channel')};\n            value += xVal * wVal;\n          }\n        }\n      }\n      `\n      : `\n      for (var wInChannel: u32 = 0u; wInChannel < uniforms.w_shape[1]; wInChannel++) {\n        let input_channel = in_channel_offset + wInChannel;\n        for (var wHeight: u32 = 0u; wHeight < uniforms.w_shape[2]; wHeight++) {\n          let xHeight = xRCCorner.x + wHeight * uniforms.dilations[0];\n\n          if (xHeight < 0u || xHeight >= uniforms.x_shape[2]) {\n            continue;\n          }\n\n          for (var wWidth: u32 = 0u; wWidth < uniforms.w_shape[3]; wWidth++) {\n            let xWidth = xRCCorner.y + wWidth * uniforms.dilations[1];\n            if (xWidth < 0u || xWidth >= uniforms.x_shape[3]) {\n              continue;\n            }\n\n            let xVal = ${x.get('batch', 'input_channel', 'xHeight', 'xWidth')};\n            let wVal = ${w.get('output_channel', 'wInChannel', 'wHeight', 'wWidth')};\n            value += xVal * wVal;\n          }\n        }\n      }\n      `;\n    return `\n  ${shaderHelper.registerUniforms(uniforms).declareVariables(...inputVars, output)}\n\n  ${shaderHelper.mainStart()}\n    ${shaderHelper.guardAgainstOutOfBoundsWorkgroupSizes('uniforms.output_size')}\n\n    let outputIndices = ${output.offsetToIndices('global_idx')};\n    let batch: u32 = outputIndices[0];\n    let output_channel: u32 = outputIndices[${isChannelLast ? 3 : 1}];\n    let xRCCorner: vec2<u32> = vec2<u32>(outputIndices[${isChannelLast ? 1 : 2}], outputIndices[${\n      isChannelLast ? 2 : 3\n    }]) * uniforms.strides - uniforms.pads;\n    let group_id: u32 = output_channel * ${components} / uniforms.output_channels_per_group;\n    var in_channel_offset = group_id * uniforms.w_shape[${isChannelLast ? 2 : 1}];\n\n    var value: ${output.type.value} = ${output.type.value}(0);\n    ${calculateResult}\n    ${processBias}\n    ${applyActivation}\n    ${output.setByOffset('global_idx', 'value')}\n  }`;\n  };\n  return {\n    name: 'GroupedConv',\n    shaderCache: { hint: `${attributes.cacheKey}_${components}`, inputDependencies },\n    getRunData: () => ({\n      outputs: [\n        {\n          dims: squeezeOutputShapeFunction ? squeezeOutputShapeFunction(outputShape) : outputShape,\n          dataType: inputs[0].dataType,\n        },\n      ],\n      dispatchGroup: { x: Math.ceil(outputSize / 64 /* workgroup size */) },\n      programUniforms,\n    }),\n    getShaderSource,\n  };\n};\n\nexport const createGroupedConvVectorizeProgramInfo = (\n  inputs: readonly TensorView[],\n  attributes: ConvAttributes,\n  outputShape: readonly number[],\n  squeezeOutputShapeFunction?: (shape: readonly number[]) => number[],\n): ProgramInfo => {\n  const hasBias = inputs.length > 2;\n  const components = getMaxComponents(outputShape[3]);\n  const outputNumber = getMaxComponents(outputShape[2]);\n  const outputSize = ShapeUtil.size(outputShape) / components / outputNumber;\n  const xShape = [inputs[0].dims[0], inputs[0].dims[1], inputs[0].dims[2], inputs[0].dims[3] / components];\n  const wShape = [inputs[1].dims[0], inputs[1].dims[1], inputs[1].dims[2], inputs[1].dims[3] / components];\n  const outputShapeInShader = [outputShape[0], outputShape[1], outputShape[2], outputShape[3] / components];\n\n  const programUniforms: ProgramUniform[] = [\n    { type: DataType.uint32, data: outputSize },\n    { type: DataType.int32, data: [attributes.strides[0], attributes.strides[1]] },\n    { type: DataType.int32, data: [attributes.pads[0], attributes.pads[1]] },\n  ];\n  appendActivationUniformsData(attributes, programUniforms);\n  programUniforms.push(...createTensorShapeVariables(xShape, wShape, outputShapeInShader));\n  const xNumber = (outputNumber - 1) * attributes.strides[1] + wShape[1];\n  const getShaderSource = (shaderHelper: ShaderHelper) => {\n    const output = outputVariable('output', inputs[0].dataType, outputShapeInShader.length, components);\n    const baseType = tensorTypeToWsglStorageType(output.type.tensor);\n    const applyActivation = getActivationSnippet(attributes, output.type.value, baseType);\n    const x = inputVariable('x', inputs[0].dataType, xShape.length, components);\n    const w = inputVariable('w', inputs[1].dataType, wShape.length, components);\n    const inputVars = [x, w];\n    if (hasBias) {\n      inputVars.push(inputVariable('b', inputs[2].dataType, inputs[2].dims, components));\n    }\n    const processBias = hasBias ? 'value += b[output_channel];' : '';\n    const uniforms: UniformsArrayType = [\n      { name: 'output_size', type: 'u32' },\n      { name: 'strides', type: 'i32', length: 2 },\n      { name: 'pads', type: 'i32', length: 2 },\n    ];\n    appendActivationUniforms(attributes, uniforms);\n    return `\n  ${shaderHelper.registerUniforms(uniforms).declareVariables(...inputVars, output)}\n  ${shaderHelper.mainStart()}\n    ${shaderHelper.guardAgainstOutOfBoundsWorkgroupSizes('uniforms.output_size')}\n    let width0 = uniforms.output_shape[3];\n    let output_channel = global_idx % width0;\n    var index1 = global_idx / width0;\n    let width1 = uniforms.output_shape[2] / ${outputNumber}u;\n    let col = (index1 % width1) * ${outputNumber}u;\n    index1 = index1 / width1;\n    let row = index1 % uniforms.output_shape[1];\n    let batch = index1 / uniforms.output_shape[1];\n\n    let x_corner = vec2<i32>(i32(row), i32(col)) * uniforms.strides - uniforms.pads;\n\n    var x_vals: array<${x.type.value}, ${xNumber}>;\n    var values: array<${output.type.value}, ${outputNumber}>;\n    let input_channel = output_channel;\n    // Use constant instead of uniform can give better performance for w's height/width.\n    for (var w_height: u32 = 0u; w_height < ${wShape[0]}; w_height++) {\n      let x_height = x_corner.x + i32(w_height);\n      if (x_height >= 0 && u32(x_height) < uniforms.x_shape[1]) {\n        for (var i = 0; i < ${xNumber}; i++) {\n          let x_width = x_corner.y + i;\n          if (x_width >= 0 && u32(x_width) < uniforms.x_shape[2]) {\n            x_vals[i] = ${x.get('batch', 'u32(x_height)', 'u32(x_width)', 'input_channel')};\n          } else {\n            x_vals[i] = ${x.type.value}(0);\n          }\n        }\n        for (var w_width: u32 = 0u; w_width < ${wShape[1]}; w_width++) {\n          let w_val = ${w.get('w_height', 'w_width', '0', 'output_channel')};\n          for (var i = 0u; i < ${outputNumber}u; i++) {\n            values[i] = fma(x_vals[i * u32(uniforms.strides[1]) + w_width], w_val, values[i]);\n          }\n        }\n      }\n    }\n\n    for (var i = 0u; i < ${outputNumber}u; i++) {\n      var value = values[i];\n      ${processBias}\n      ${applyActivation}\n      ${output.set('batch', 'row', 'col + i', 'output_channel', 'value')};\n    }\n  }`;\n  };\n\n  return {\n    name: 'GroupedConv-Vectorize',\n    shaderCache: {\n      hint: `${attributes.cacheKey};${components};${outputNumber};${xNumber};${wShape[0]};${wShape[1]}`,\n      inputDependencies: hasBias ? ['rank', 'rank', 'type'] : ['rank', 'rank'],\n    },\n    getRunData: () => ({\n      outputs: [\n        {\n          dims: squeezeOutputShapeFunction ? squeezeOutputShapeFunction(outputShape) : outputShape,\n          dataType: inputs[0].dataType,\n        },\n      ],\n      dispatchGroup: { x: Math.ceil(outputSize / 64 /* workgroup size */) },\n      programUniforms,\n    }),\n    getShaderSource,\n  };\n};\n","// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport { TensorView } from '../../tensor-view';\nimport { PoolConvUtil } from '../../util';\nimport { AttributeWithCacheKey } from '../attribute-with-cache-key';\nimport { ComputeContext } from '../types';\n\nimport { createConv2DMatMulProgramInfo } from './3rd-party/conv2d_mm_webgpu';\nimport { computeConv3DInfo, createConv3DNaiveProgramInfo } from './3rd-party/conv3d_naive_webgpu';\nimport { createMatmulProgramInfo } from './3rd-party/matmul_packed_webgpu';\nimport { createGroupedConvProgramInfo, createGroupedConvVectorizeProgramInfo } from './conv-grouped';\nimport { InternalActivationAttributes, parseInternalActivationAttributes } from './fuse-utils';\nimport { createNaiveMatmulProgramInfo } from './matmul-shaders';\nimport { createTransposeProgramInfo } from './transpose';\n\nexport const calculateOutputShape = (\n  inputShape: readonly number[],\n  kernelShape: readonly number[],\n  dilations: readonly number[],\n  adjustPads: readonly number[],\n  strides: readonly number[],\n  isChannelLast: boolean,\n): number[] => {\n  const batchSize = inputShape[0];\n  const inputSpatialShape = inputShape.slice(isChannelLast ? 1 : 2, isChannelLast ? 3 : 4);\n  const spatialRank = inputSpatialShape.length;\n  const outChannels = kernelShape[0];\n  const kernelSpatialShape = kernelShape.slice(2);\n  const dilatedKernelShape = kernelSpatialShape.map((v, i) => v + (v - 1) * (dilations[i] - 1));\n  const inputSpatialShapeWithPad = inputSpatialShape.map((v, i) => v + adjustPads[i] + adjustPads[i + spatialRank]);\n  const outputShape = inputSpatialShapeWithPad.map((v, i) =>\n    Math.floor((v - dilatedKernelShape[i] + strides[i]) / strides[i]),\n  );\n  outputShape.splice(0, 0, batchSize);\n  outputShape.splice(isChannelLast ? 3 : 1, 0, outChannels);\n  return outputShape;\n};\n\nexport interface ConvAttributes extends InternalActivationAttributes, AttributeWithCacheKey {\n  readonly autoPad: string;\n  readonly dilations: readonly number[];\n  readonly format: 'NHWC' | 'NCHW';\n  readonly group: number;\n  readonly kernelShape: readonly number[];\n  readonly pads: readonly number[];\n  readonly strides: readonly number[];\n  readonly wIsConst: boolean;\n}\n\n// for transposing weight tensor from [M, C/group, KH, KW] to [KH, KW, C/group, M]\nconst weightTransposeAttribute = [2, 3, 1, 0];\n\nconst validateInputs = (inputs: readonly TensorView[], attributes: ConvAttributes): void => {\n  // Refer to the below link for all input checks\n  // https://github.com/onnx/onnx/blob/master/docs/Operators.md#Conv\n  if (!inputs || (inputs.length !== 2 && inputs.length !== 3)) {\n    throw new Error('Conv requires 2 or 3 inputs');\n  }\n\n  if (inputs[0].dims.length > 5) {\n    throw new Error('greater than 5D is not supported');\n  }\n\n  if (inputs[0].dims.length !== inputs[1].dims.length) {\n    throw new Error('filter does not have same dimension as input');\n  }\n\n  // FILTER_IN_CHANNEL should be equal to DATA_CHANNEL\n  const dataChannel = inputs[0].dims[attributes.format === 'NHWC' ? inputs[0].dims.length - 1 : 1];\n  const filterInChannel = inputs[1].dims[1] * attributes.group;\n  if (dataChannel !== filterInChannel) {\n    throw new Error('FILTER_IN_CHANNEL should be equal to DATA_CHANNEL');\n  }\n\n  // if bias is provided it should be 1D and the number of elements should be equal to the number of feature maps\n  if (inputs.length === 3 && (inputs[2].dims.length !== 1 || inputs[1].dims[0] !== inputs[2].dims[0])) {\n    throw new Error('invalid bias');\n  }\n\n  const spatialRank = inputs[0].dims.length - 2;\n  // wrong dilations dimension\n  if (attributes.dilations.length !== spatialRank) {\n    throw new Error(`dilations should be ${spatialRank}D`);\n  }\n\n  // Wrong strides dimension\n  if (attributes.strides.length !== spatialRank) {\n    throw new Error(`strides should be ${spatialRank}D`);\n  }\n\n  // Wrong pads dimension\n  if (attributes.pads.length !== spatialRank * 2) {\n    throw new Error(`pads should be ${spatialRank * 2}D`);\n  }\n\n  // if kernelShape is specified, it's data length must be 2 less than dims length of the weights tensor\n  // (the first 2 dims are batch_size and channels)\n  if (attributes.kernelShape.length !== 0 && attributes.kernelShape.length !== inputs[1].dims.length - 2) {\n    throw new Error('invalid kernel shape');\n  }\n};\n\nconst getAdjustedConvAttributes = <T extends ConvAttributes>(attributes: T, inputs: readonly TensorView[]): T => {\n  const kernelShape = attributes.kernelShape.slice();\n  // if kernelShape is not well specified in the attributes, infer it from the weight tensor dims\n  if (kernelShape.length < inputs[1].dims.length - 2) {\n    kernelShape.push(...Array(inputs[1].dims.length - 2 - kernelShape.length).fill(0));\n  }\n  for (let i = 2; i < inputs[1].dims.length; ++i) {\n    if (kernelShape[i - 2] === 0) {\n      kernelShape[i - 2] = inputs[1].dims[i];\n    }\n  }\n  const pads = attributes.pads.slice();\n  PoolConvUtil.adjustPadsBasedOnAutoPad(\n    inputs[0].dims,\n    attributes.strides,\n    attributes.dilations,\n    kernelShape,\n    pads,\n    attributes.format === 'NHWC',\n    attributes.autoPad,\n  );\n\n  // always return a new object so does not modify the original attributes\n  const newAttributes: T = Object.assign({}, attributes);\n  Object.assign(newAttributes, { kernelShape, pads });\n  return newAttributes;\n};\n\nexport const parseConvAttributes = (attributes: Record<string, unknown>): ConvAttributes => {\n  const activationAttributes = parseInternalActivationAttributes(attributes);\n  // TODO : Make this generic enough to compute default attributes for multi-dimensional conv\n  const format = attributes.format as 'NHWC' | 'NCHW';\n  const autoPad = ['NOTSET', 'VALID', 'SAME_UPPER', 'SAME_LOWER'][attributes.auto_pad as number];\n  const dilations = attributes.dilations as number[];\n  const group = attributes.group as number;\n  const kernelShape = attributes.kernel_shape as number[];\n  const pads = attributes.pads as number[];\n  const strides = attributes.strides as number[];\n  const wIsConst = (attributes.w_is_const as () => boolean)();\n\n  return {\n    autoPad,\n    format,\n    dilations,\n    group,\n    kernelShape,\n    pads,\n    strides,\n    wIsConst,\n    ...activationAttributes,\n    cacheKey: `${attributes.format};${activationAttributes.activation};`,\n  };\n};\n\nconst conv2d = (\n  context: ComputeContext,\n  inputs: readonly TensorView[],\n  attributes: ConvAttributes,\n  squeezeOutputShapeFunction?: (shape: readonly number[]) => number[],\n): void => {\n  // check attributes\n\n  // const hasPreluActivationWeights = false; /* TODO: add support for prelu activation weights */\n  const isChannelsLast = attributes.format === 'NHWC';\n  const outputShape = calculateOutputShape(\n    inputs[0].dims,\n    inputs[1].dims,\n    attributes.dilations,\n    attributes.pads,\n    attributes.strides,\n    isChannelsLast,\n  );\n  if (attributes.group !== 1) {\n    const convInputs = [inputs[0]];\n    if (isChannelsLast) {\n      const transposedWeight =\n        (context.kernelCustomData.wT as TensorView | undefined) ??\n        context.compute(createTransposeProgramInfo(inputs[1], weightTransposeAttribute), {\n          inputs: [1],\n          outputs: [attributes.wIsConst ? -2 : -1],\n        })[0];\n      if (attributes.wIsConst && !context.kernelCustomData.wT) {\n        context.kernelCustomData.wT = transposedWeight;\n      }\n      convInputs.push(transposedWeight);\n    } else {\n      convInputs.push(inputs[1]);\n    }\n    if (inputs.length === 3) {\n      convInputs.push(inputs[2]);\n    }\n    // NVIDIA GPU with ampere architecture fails with below 2 cases, but we couldn't repro them with any other\n    // GPUs. So just disable vectorize on NVIDIA ampere to ensure always correct outputs.\n    // [webgpu]Conv - conv - vectorize group - B\n    // [webgpu]Conv - conv - vectorize group - D\n    const enableGroupedConvVectorize = !context.adapterInfo.isArchitecture('ampere');\n    if (\n      enableGroupedConvVectorize &&\n      isChannelsLast &&\n      inputs[1].dims[0] === attributes.group &&\n      inputs[1].dims[1] === 1 &&\n      attributes.dilations[0] === 1 &&\n      attributes.dilations[1] === 1\n    ) {\n      context.compute(\n        createGroupedConvVectorizeProgramInfo(convInputs, attributes, outputShape, squeezeOutputShapeFunction),\n        { inputs: convInputs },\n      );\n    } else {\n      context.compute(createGroupedConvProgramInfo(convInputs, attributes, outputShape, squeezeOutputShapeFunction), {\n        inputs: convInputs,\n      });\n    }\n    return;\n  }\n\n  const hasBias = inputs.length === 3;\n  const inputHeight = inputs[0].dims[isChannelsLast ? 1 : 2];\n  const inputWidth = inputs[0].dims[isChannelsLast ? 2 : 3];\n  const inputChannels = inputs[0].dims[isChannelsLast ? 3 : 1];\n  const weightHeight = inputs[1].dims[2];\n  const weightWidth = inputs[1].dims[3];\n\n  const outHeight = outputShape[isChannelsLast ? 1 : 2];\n  const outWidth = outputShape[isChannelsLast ? 2 : 3];\n  const outChannels = outputShape[isChannelsLast ? 3 : 1];\n\n  const sameSize =\n    isChannelsLast &&\n    weightHeight === inputHeight &&\n    weightWidth === inputWidth &&\n    attributes.pads[0] === 0 &&\n    attributes.pads[1] === 0;\n  if (\n    sameSize ||\n    (weightHeight === 1 &&\n      weightWidth === 1 &&\n      attributes.dilations[0] === 1 &&\n      attributes.dilations[1] === 1 &&\n      attributes.strides[0] === 1 &&\n      attributes.strides[1] === 1 &&\n      attributes.pads[0] === 0 &&\n      attributes.pads[1] === 0)\n  ) {\n    // conv2dByMatMul\n    const batch = outputShape[0];\n    let xReshaped, wReshaped, matmulOutputShape;\n    const matmulInputs = [];\n    if (isChannelsLast) {\n      const transposedWeight =\n        (context.kernelCustomData.wT as TensorView | undefined) ??\n        context.compute(createTransposeProgramInfo(inputs[1], weightTransposeAttribute), {\n          inputs: [1],\n          outputs: [attributes.wIsConst ? -2 : -1],\n        })[0];\n      if (attributes.wIsConst && !context.kernelCustomData.wT) {\n        context.kernelCustomData.wT = transposedWeight;\n      }\n      if (sameSize) {\n        const sharedDim = inputHeight * inputWidth * inputChannels;\n        xReshaped = inputs[0].reshape([1, batch, sharedDim]);\n        wReshaped = transposedWeight.reshape([1, sharedDim, outChannels]);\n        matmulOutputShape = [1, batch, outChannels];\n      } else {\n        xReshaped = inputs[0].reshape([batch, inputHeight * inputWidth, inputChannels]);\n        wReshaped = transposedWeight.reshape([1, inputChannels, outChannels]);\n        matmulOutputShape = [batch, outHeight * outWidth, outChannels];\n      }\n      matmulInputs.push(xReshaped);\n      matmulInputs.push(wReshaped);\n    } else {\n      xReshaped = inputs[0].reshape([batch, inputChannels, inputHeight * inputWidth]);\n      wReshaped = inputs[1].reshape([1, outChannels, inputChannels]);\n      matmulOutputShape = [batch, outChannels, outHeight * outWidth];\n      matmulInputs.push(wReshaped);\n      matmulInputs.push(xReshaped);\n    }\n    if (hasBias) {\n      matmulInputs.push(inputs[2]);\n    }\n    const N = matmulOutputShape[2];\n    const K = matmulInputs[0].dims[matmulInputs[0].dims.length - 1];\n    // Tune the threshold.\n    if (N < 8 && K < 8) {\n      context.compute(\n        createNaiveMatmulProgramInfo(\n          matmulInputs,\n          attributes,\n          outputShape,\n          matmulOutputShape,\n          isChannelsLast,\n          squeezeOutputShapeFunction,\n        ),\n        { inputs: matmulInputs },\n      );\n    } else {\n      context.compute(\n        createMatmulProgramInfo(\n          matmulInputs,\n          attributes,\n          outputShape,\n          matmulOutputShape,\n          isChannelsLast,\n          squeezeOutputShapeFunction,\n        ),\n        { inputs: matmulInputs },\n      );\n    }\n    return;\n  }\n\n  // TODO: implement conv2dWithIm2Col()\n\n  const sequentialAccessByThreads = /* backend.adapterInfo.isIntel() */ true;\n\n  // STEP.1: transpose weight\n  const transposedWeight =\n    (context.kernelCustomData.wT as TensorView | undefined) ??\n    context.compute(createTransposeProgramInfo(inputs[1], weightTransposeAttribute), {\n      inputs: [1],\n      outputs: [attributes.wIsConst ? -2 : -1],\n    })[0];\n  if (attributes.wIsConst && !context.kernelCustomData.wT) {\n    context.kernelCustomData.wT = transposedWeight;\n  }\n\n  // STEP.2: prepare reshaped inputs\n  const convInputs = [inputs[0], transposedWeight];\n  if (hasBias) {\n    convInputs.push(inputs[2]);\n  }\n\n  // STEP.3: compute matmul\n  const dimAOuter = isChannelsLast ? outHeight * outWidth : outChannels;\n  const dimBOuter = isChannelsLast ? outChannels : outHeight * outWidth;\n  const dimInner = weightHeight * weightWidth * inputChannels;\n  context.compute(\n    createConv2DMatMulProgramInfo(\n      convInputs,\n      attributes,\n      outputShape,\n      dimAOuter,\n      dimBOuter,\n      dimInner,\n      hasBias,\n      sequentialAccessByThreads,\n      squeezeOutputShapeFunction,\n    ),\n    { inputs: convInputs },\n  );\n};\n\nconst conv1d = (context: ComputeContext, attributes: ConvAttributes): void => {\n  // extend the input to 2D by adding H dimension\n  const isChannelLast = attributes.format === 'NHWC';\n  const inputs = [\n    context.inputs[0].reshape(\n      isChannelLast\n        ? // [N, W, C] -> [N, H=1, W, C]\n          [context.inputs[0].dims[0], 1, context.inputs[0].dims[1], context.inputs[0].dims[2]]\n        : // [N, C, W] -> [N, C, H=1, W]\n          [context.inputs[0].dims[0], context.inputs[0].dims[1], 1, context.inputs[0].dims[2]],\n    ),\n    //[FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, kW] -> [FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, kH=1, kW]\n    context.inputs[1].reshape([context.inputs[1].dims[0], context.inputs[1].dims[1], 1, context.inputs[1].dims[2]]),\n  ];\n  if (context.inputs.length === 3) {\n    inputs.push(context.inputs[2]);\n  }\n  const pads = [0, attributes.pads[0], 0, attributes.pads[1]];\n  const strides = [1].concat(attributes.strides);\n  const dilations = [1].concat(attributes.dilations);\n  const kernelShape = [1].concat(attributes.kernelShape);\n  const adjustedAttributes = getAdjustedConvAttributes(\n    { ...attributes, pads, strides, dilations, kernelShape },\n    inputs,\n  );\n  conv2d(context, inputs, adjustedAttributes, (outputShape) =>\n    isChannelLast ? [outputShape[0], outputShape[2], outputShape[3]] : [outputShape[0], outputShape[1], outputShape[3]],\n  );\n};\n\nconst conv3d = (context: ComputeContext, inputs: readonly TensorView[], attributes: ConvAttributes): void => {\n  const format = attributes.format === 'NHWC' ? 'channelsLast' : 'channelsFirst';\n  const adjustedAttributes = getAdjustedConvAttributes(attributes, inputs);\n  const pads = attributes.autoPad === 'NOTSET' ? attributes.pads : attributes.autoPad;\n  const convInfo = computeConv3DInfo(\n    inputs[0].dims as [number, number, number, number, number],\n    inputs[1].dims as [number, number, number, number, number],\n    attributes.strides as number | [number, number, number],\n    attributes.dilations as number | [number, number, number],\n    pads as string | number[],\n    false,\n    format,\n  );\n  context.compute(\n    createConv3DNaiveProgramInfo(\n      inputs,\n      adjustedAttributes,\n      convInfo.outShape,\n      [convInfo.filterDepth, convInfo.filterHeight, convInfo.filterWidth],\n      [convInfo.padInfo.front, convInfo.padInfo.top, convInfo.padInfo.left],\n      format,\n    ),\n  );\n};\n\nexport const conv = (context: ComputeContext, attributes: ConvAttributes): void => {\n  validateInputs(context.inputs, attributes);\n  if (context.inputs[0].dims.length === 3) {\n    conv1d(context, attributes);\n  } else if (context.inputs[0].dims.length === 5) {\n    conv3d(context, context.inputs, attributes);\n  } else {\n    const adjustedAttributes = getAdjustedConvAttributes(attributes, context.inputs);\n    conv2d(context, context.inputs, adjustedAttributes);\n  }\n};\n","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\n// sampled from [@tensorflow/tfjs] tfjs-backend-webgpu/src/conv_backprop_webgpu.ts\n\nimport { DataType } from '../../../../wasm-common';\nimport { LOG_DEBUG } from '../../../log';\nimport { TensorView } from '../../../tensor-view';\nimport { ShapeUtil } from '../../../util';\nimport { ProgramInfo, ProgramInputTensorInfoDependency, ProgramUniform } from '../../types';\nimport {\n  createTensorShapeVariables,\n  inputVariable,\n  outputVariable,\n  ShaderHelper,\n  tensorTypeToWsglStorageType,\n  UniformsArrayType,\n  getMaxComponents,\n} from '../common';\nimport { ConvTransposeAttributes } from '../conv-transpose';\n\nexport const createConvTranspose2DProgramInfo = (\n  inputs: readonly TensorView[],\n  attributes: ConvTransposeAttributes,\n  squeezeOutputShapeFunction?: (shape: readonly number[]) => number[],\n): ProgramInfo => {\n  const hasBias = inputs.length > 2;\n  const outputShape = attributes.outputShape;\n  const isChannelsLast = attributes.format === 'NHWC';\n  const group = attributes.group;\n  const wShape = inputs[1].dims;\n  const inputChannelsPerGroup = wShape[2] / group;\n  const outputChannelsPerGroup = wShape[3];\n  const aComponents = isChannelsLast ? getMaxComponents(inputChannelsPerGroup) : 1;\n  const packInputAs4 = isChannelsLast && outputChannelsPerGroup === 1 && inputChannelsPerGroup >= 4;\n  const inputChannelsPerGroupInt = packInputAs4\n    ? Math.floor(inputChannelsPerGroup / 4) * 4\n    : Math.floor(inputChannelsPerGroup / aComponents) * aComponents;\n  const inputChannelsRemainder = inputChannelsPerGroup - inputChannelsPerGroupInt;\n  const components = isChannelsLast ? getMaxComponents(outputChannelsPerGroup) : 1;\n  const bComponents = isChannelsLast ? (outputChannelsPerGroup === 1 ? aComponents : components) : 1;\n  const outputSize = ShapeUtil.size(outputShape) / components;\n  const dispatch = [Math.ceil(outputSize / 64), 1, 1];\n  LOG_DEBUG('verbose', () => `[conv2d_backprop_webgpu] dispatch = ${dispatch}`);\n\n  const inputDependencies: ProgramInputTensorInfoDependency[] = ['rank', 'rank'];\n  const strides = [attributes.strides[0], attributes.strides[1]];\n  const filterDims = [attributes.kernelShape[isChannelsLast ? 1 : 2], attributes.kernelShape[isChannelsLast ? 2 : 3]];\n  const dilations = [attributes.dilations[0], attributes.dilations[1]];\n  const effectiveFilterDims = [\n    filterDims[0] +\n      (attributes.dilations[0] <= 1\n        ? 0\n        : (attributes.kernelShape[isChannelsLast ? 1 : 2] - 1) * (attributes.dilations[0] - 1)),\n    filterDims[1] +\n      (attributes.dilations[1] <= 1\n        ? 0\n        : (attributes.kernelShape[isChannelsLast ? 2 : 3] - 1) * (attributes.dilations[1] - 1)),\n  ];\n  const pads = [\n    effectiveFilterDims[0] - 1 - Math.floor((attributes.pads[0] + attributes.pads[2]) / 2),\n    effectiveFilterDims[1] - 1 - Math.floor((attributes.pads[1] + attributes.pads[3]) / 2),\n  ];\n\n  const programUniforms: ProgramUniform[] = [\n    { type: DataType.uint32, data: outputSize },\n    { type: DataType.uint32, data: strides },\n    { type: DataType.uint32, data: filterDims },\n    { type: DataType.uint32, data: dilations },\n    { type: DataType.uint32, data: effectiveFilterDims },\n    { type: DataType.int32, data: pads },\n    { type: DataType.uint32, data: inputChannelsPerGroupInt },\n    { type: DataType.uint32, data: inputChannelsPerGroup },\n    { type: DataType.uint32, data: outputChannelsPerGroup },\n    ...createTensorShapeVariables(inputs[0].dims, inputs[1].dims),\n  ];\n  if (hasBias) {\n    programUniforms.push(...createTensorShapeVariables(inputs[2].dims));\n    inputDependencies.push('rank');\n  }\n  programUniforms.push(...createTensorShapeVariables(outputShape));\n\n  const getShaderSource = (shaderHelper: ShaderHelper) => {\n    const uniforms: UniformsArrayType = [\n      { name: 'output_size', type: 'u32' },\n      { name: 'strides', type: 'u32', length: strides.length },\n      { name: 'filter_dims', type: 'u32', length: filterDims.length },\n      { name: 'dilations', type: 'u32', length: filterDims.length },\n      { name: 'effective_filter_dims', type: 'u32', length: effectiveFilterDims.length },\n      { name: 'pads', type: 'i32', length: pads.length },\n      { name: 'input_channels_per_group_int', type: 'u32' },\n      { name: 'input_channels_per_group', type: 'u32' },\n      { name: 'output_channels_per_group', type: 'u32' },\n    ];\n    const dataType = tensorTypeToWsglStorageType(inputs[0].dataType);\n    const rowDim = isChannelsLast ? 1 : 2;\n    const colDim = isChannelsLast ? 2 : 3;\n    const channelDim = isChannelsLast ? 3 : 1;\n\n    const w = inputVariable('W', inputs[1].dataType, inputs[1].dims.length, bComponents);\n    const dy = inputVariable('Dy', inputs[0].dataType, inputs[0].dims.length, aComponents);\n    const inputVariables = [dy, w];\n    if (hasBias) {\n      inputVariables.push(inputVariable('bias', inputs[2].dataType, [outputShape[channelDim]].length, components));\n    }\n    const output = outputVariable('result', inputs[0].dataType, outputShape.length, components);\n\n    const calculateResult = (): string => {\n      let calcStr = '';\n      if (packInputAs4) {\n        if (aComponents === 4) {\n          calcStr += `\n        let xValue = ${dy.getByOffset('x_offset')};\n        let wValue = ${w.getByOffset('w_offset')};\n        dotProd = dotProd + dot(xValue, wValue);\n        x_offset += 1u;\n        w_offset += 1u;`;\n        } else if (aComponents === 2) {\n          calcStr += `\n          dotProd = dotProd + dot(vec4<${dataType}>(${dy.getByOffset('x_offset')}, ${dy.getByOffset('x_offset + 1u')}), vec4<${dataType}>(${w.getByOffset('w_offset')}, ${w.getByOffset('w_offset + 1u')}));\n          x_offset += 2u;\n          w_offset += 2u;`;\n        } else if (aComponents === 1) {\n          calcStr += `\n          dotProd = dotProd + dot(vec4<${dataType}>(${dy.getByOffset('x_offset')}, ${dy.getByOffset('x_offset + 1u')}, ${dy.getByOffset('x_offset + 2u')}, ${dy.getByOffset('x_offset + 3u')}), vec4<${dataType}>(${w.getByOffset('w_offset')}, ${w.getByOffset('w_offset + 1u')}, ${w.getByOffset('w_offset + 2u')}, ${w.getByOffset('w_offset + 3u')}));\n          x_offset += 4u;\n          w_offset += 4u;`;\n        }\n      } else {\n        calcStr += `\n                  let xValue = ${\n                    isChannelsLast\n                      ? dy.getByOffset(\n                          `${dy.indicesToOffset(`${dy.type.indices}(batch, idyR, idyC, inputChannel)`)} / ${aComponents}`,\n                        )\n                      : dy.get('batch', 'inputChannel', 'idyR', 'idyC')\n                  };\n        `;\n        if (aComponents === 1) {\n          calcStr += `\n          let w_offset = ${w.indicesToOffset(`${w.type.indices}(u32(wRPerm), u32(wCPerm), inputChannel, wOutChannel)`)};\n          let wValue = ${w.getByOffset(`w_offset / ${bComponents}`)};\n          dotProd = dotProd + xValue * wValue;`;\n        } else {\n          for (let c = 0; c < aComponents; c++) {\n            calcStr += `\n            let wValue${c} = ${w.getByOffset(`${w.indicesToOffset(`${w.type.indices}(u32(wRPerm), u32(wCPerm), inputChannel + ${c}, wOutChannel)`)} / ${bComponents}`)};\n            dotProd = dotProd + xValue[${c}] * wValue${c};`;\n          }\n        }\n      }\n      return calcStr;\n    };\n    const calculateRemainder = (): string => {\n      if (inputChannelsRemainder === 0) {\n        return '';\n      }\n      if (!packInputAs4) {\n        throw new Error(`packInputAs4 ${packInputAs4} is not true.`);\n      }\n      let calcStr = '';\n      if (aComponents === 1) {\n        calcStr += 'dotProd = dotProd';\n        for (let i = 0; i < inputChannelsRemainder; i++) {\n          calcStr += `\n            + ${dy.getByOffset(`x_offset + ${i}`)} * ${w.getByOffset(`w_offset + ${i}`)}`;\n        }\n        calcStr += ';';\n      } else if (aComponents === 2) {\n        if (inputChannelsRemainder !== 2) {\n          throw new Error(`Invalid inputChannelsRemainder ${inputChannelsRemainder}.`);\n        }\n        calcStr += `\n          let xValue = ${dy.getByOffset('x_offset')};\n          let wValue = ${w.getByOffset('w_offset')};\n          dotProd = dotProd + dot(xValue, wValue);`;\n      }\n      return calcStr;\n    };\n    const codeSnippet = `\n            let outputIndices = ${output.offsetToIndices(`global_idx * ${components}`)};\n            let batch = ${output.indicesGet('outputIndices', 0)};\n            let d1 = ${output.indicesGet('outputIndices', channelDim)};\n            let r = ${output.indicesGet('outputIndices', rowDim)};\n            let c = ${output.indicesGet('outputIndices', colDim)};\n            let dyCorner = vec2<i32>(i32(r), i32(c)) - uniforms.pads;\n            let dyRCorner = dyCorner.x;\n            let dyCCorner = dyCorner.y;\n            let groupId = d1 / uniforms.output_channels_per_group;\n            let wOutChannel = d1 - groupId * uniforms.output_channels_per_group;\n            // Convolve dy(?, ?, d2) with w(:, :, d1, d2) to compute dx(xR, xC, d1).\n            // ? = to be determined. : = across all values in that axis.\n            var dotProd = ${output.type.value}(0.0);\n            var wR: u32 = 0;\n            if (uniforms.dilations.x == 1) {\n              // Minimum wR >= 0 that satisfies (dyRCorner + wR) % (uniforms.strides.x) == 0\n              wR = u32(((dyRCorner + i32(uniforms.strides.x) - 1) / i32(uniforms.strides.x)) * i32(uniforms.strides.x) - dyRCorner);\n            }\n            for (; wR < uniforms.effective_filter_dims.x; wR = wR + 1) {\n              if (wR % uniforms.dilations.x != 0) {\n                continue;\n              }\n              let dyR = (${dataType}(dyRCorner) + ${dataType}(wR)) / ${dataType}(uniforms.strides[0]);\n              let wRPerm = uniforms.filter_dims.x - 1 - wR / uniforms.dilations.x;\n              if (dyR < 0.0 || dyR >= ${dataType}(uniforms.Dy_shape[${rowDim}]) || fract(dyR) > 0.0 ||\n                  wRPerm < 0) {\n                continue;\n              }\n              let idyR: u32 = u32(dyR);\n              var wC: u32 = 0;\n              if (uniforms.dilations.y == 1) {\n                // Minimum wC >= 0 that satisfies (dyCCorner + wC) % (uniforms.strides.y) == 0\n                wC = u32(((dyCCorner + i32(uniforms.strides.y) - 1) / i32(uniforms.strides.y)) * i32(uniforms.strides.y) - dyCCorner);\n              }\n              for (; wC < uniforms.effective_filter_dims.y; wC = wC + 1) {\n                if (wC % uniforms.dilations.y != 0) {\n                  continue;\n                }\n                let dyC = (${dataType}(dyCCorner) + ${dataType}(wC)) / ${dataType}(uniforms.strides.y);\n                let wCPerm = uniforms.filter_dims.y - 1 - wC / uniforms.dilations.y;\n                if (dyC < 0.0 || dyC >= ${dataType}(uniforms.Dy_shape[${colDim}]) ||\n                    fract(dyC) > 0.0 || wCPerm < 0) {\n                  continue;\n                }\n                let idyC: u32 = u32(dyC);\n                var inputChannel = groupId * uniforms.input_channels_per_group;\n                ${\n                  packInputAs4\n                    ? `\n                var x_offset = ${dy.indicesToOffset(`${dy.type.indices}(batch, idyR, idyC, inputChannel)`)} / ${aComponents};\n                var w_offset = ${w.indicesToOffset(`${w.type.indices}(wRPerm, wCPerm, inputChannel, wOutChannel)`)} / ${bComponents};\n                  `\n                    : ''\n                }\n                for (var d2: u32 = 0; d2 < uniforms.input_channels_per_group_int; d2 = d2 + ${packInputAs4 ? 4 : aComponents}) {\n                  ${calculateResult()}\n                  inputChannel = inputChannel + ${packInputAs4 ? 4 : aComponents};\n                }\n                ${calculateRemainder()}\n                wC = wC + uniforms.strides.y - 1;\n              }\n              wR = wR + uniforms.strides[0] - 1;\n            }\n            let value = dotProd${hasBias ? ` + bias[d1 / ${components}]` : ''};\n            ${output.setByOffset('global_idx', 'value')};\n          `;\n\n    return `\n    ${shaderHelper.registerUniforms(uniforms).declareVariables(...inputVariables, output)}\n      ${shaderHelper.mainStart()}\n      ${shaderHelper.guardAgainstOutOfBoundsWorkgroupSizes('uniforms.output_size')};\n    ${codeSnippet}}`;\n  };\n\n  return {\n    name: 'ConvTranspose2D',\n    shaderCache: {\n      hint: `${attributes.cacheKey};${aComponents}${bComponents}${components}${packInputAs4}${inputChannelsRemainder}`,\n      inputDependencies,\n    },\n    getRunData: () => ({\n      dispatchGroup: { x: dispatch[0], y: dispatch[1], z: dispatch[2] },\n      outputs: [\n        {\n          dims: squeezeOutputShapeFunction ? squeezeOutputShapeFunction(outputShape) : outputShape,\n          dataType: inputs[0].dataType,\n        },\n      ],\n      programUniforms,\n    }),\n    getShaderSource,\n  };\n};\n","// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport { TensorView } from '../../tensor-view';\nimport { ComputeContext } from '../types';\n\nimport { createConvTranspose2DProgramInfo } from './3rd-party/conv_backprop_webgpu';\nimport { ConvAttributes } from './conv';\nimport { parseInternalActivationAttributes } from './fuse-utils';\nimport { createTransposeProgramInfo } from './transpose';\n\nconst computeTotalPad = (\n  inDim: number,\n  stride: number,\n  adj: number,\n  kernel: number,\n  dilation: number,\n  outSize: number,\n) => (inDim - 1) * stride + adj + (kernel - 1) * dilation + 1 - outSize;\n\nconst distributePadding = (totalPad: number, autoPad: string, pads: number[], head: number, tail: number) => {\n  const smallPad = Math.floor(totalPad / 2);\n  if (autoPad === 'SAME_UPPER') {\n    pads[head] = smallPad;\n    pads[tail] = totalPad - smallPad;\n  } else if (autoPad === 'SAME_LOWER') {\n    pads[head] = totalPad - smallPad;\n    pads[tail] = smallPad;\n  }\n};\n\nconst calculateOutputShapeAndPads = (\n  inputShape: readonly number[],\n  kernelShape: readonly number[],\n  dilations: readonly number[],\n  autoPad: string,\n  group: number,\n  pads: number[],\n  strides: readonly number[],\n  isChannelLast: boolean,\n  outputPadding: number[],\n  outputShape: number[],\n) => {\n  const spatialRank = inputShape.length - 2;\n  const updateOutputShape = outputShape.length === 0;\n  if (outputPadding.length < spatialRank) {\n    outputPadding.push(...Array(spatialRank - outputPadding.length).fill(0));\n  }\n  const batchSize = inputShape[0];\n  const outChannels = kernelShape[isChannelLast ? 3 : 1] * group;\n  for (let i = 0, j = inputShape.length - spatialRank - (isChannelLast ? 1 : 0); i < spatialRank; ++i, ++j) {\n    const inSize = inputShape[j];\n    const outSize = updateOutputShape ? inSize * strides[i] : outputShape[i];\n    const totalPad = computeTotalPad(inSize, strides[i], pads[i], kernelShape[j], dilations[i], outSize);\n    distributePadding(totalPad, autoPad, pads, i, i + spatialRank);\n    if (updateOutputShape) {\n      outputShape.push(\n        strides[i] * (inSize - 1) +\n          outputPadding[i] +\n          (kernelShape[j] - 1) * dilations[i] +\n          1 -\n          pads[i] -\n          pads[i + spatialRank],\n      );\n    }\n  }\n  outputShape.splice(0, 0, batchSize);\n  outputShape.splice(isChannelLast ? 3 : 1, 0, outChannels);\n};\n\nexport interface ConvTransposeAttributes extends ConvAttributes {\n  readonly outputPadding: readonly number[];\n  readonly outputShape: readonly number[];\n}\n\nconst getAdjustedConvTransposeAttributes = <T extends ConvTransposeAttributes>(\n  attributes: T,\n  inputs: readonly TensorView[],\n): T => {\n  const kernelShape = attributes.kernelShape.slice();\n  // if kernelShape is not specified in the attributes of this op, infer it from the weight tensor dims\n  if (attributes.kernelShape.length === 0 || attributes.kernelShape.reduce((a, b) => a * b, 1) === 0) {\n    kernelShape.length = 0;\n    for (let i = 2; i < inputs[1].dims.length; ++i) {\n      kernelShape.push(inputs[1].dims[i]);\n    }\n  }\n  const isChannelsLast = attributes.format === 'NHWC';\n  kernelShape.splice(0, 0, inputs[1].dims[0]);\n  kernelShape.splice(isChannelsLast ? 3 : 1, 0, inputs[1].dims[1]);\n\n  const pads = attributes.pads.slice();\n  const outputShape = attributes.outputShape.slice();\n  const outputPadding = attributes.outputPadding.slice();\n  const inputShape = inputs[0].dims;\n  let dilations = attributes.dilations.slice();\n  if (dilations.reduce((a, b) => a + b, 0) === 0) {\n    const spatialRank = inputs[0].dims.length - 2;\n    dilations = new Array(spatialRank).fill(1);\n  }\n  let strides = attributes.strides.slice();\n  if (strides.reduce((a, b) => a + b, 0) === 0) {\n    const spatialRank = inputs[0].dims.length - 2;\n    strides = new Array(spatialRank).fill(1);\n  }\n  // If outputShape is not specified in the attributes of this op, infer it from the parameters\n  // Similarly, automatically infer pads if not specified\n  calculateOutputShapeAndPads(\n    inputShape,\n    kernelShape,\n    dilations,\n    attributes.autoPad,\n    attributes.group,\n    pads,\n    strides,\n    isChannelsLast,\n    outputPadding,\n    outputShape,\n  );\n\n  // always return a new object so does not modify the original attributes\n  const newAttributes: T = Object.assign({}, attributes);\n  Object.assign(newAttributes, { kernelShape, pads, outputPadding, outputShape, dilations, strides });\n  return newAttributes;\n};\n\nexport const parseConvTransposeAttributes = (attributes: Record<string, unknown>): ConvTransposeAttributes => {\n  const activationAttributes = parseInternalActivationAttributes(attributes);\n  // TODO : Make this generic enough to compute default attributes for multi-dimensional conv\n  const format = attributes.format as 'NHWC' | 'NCHW';\n  const autoPad = ['NOTSET', 'VALID', 'SAME_UPPER', 'SAME_LOWER'][\n    typeof attributes.autoPad == 'undefined' ? 0 : (attributes.autoPad as number)\n  ];\n  const dilations = attributes.dilations as [number, number];\n  const group = attributes.group as number;\n  const kernelShape = attributes.kernelShape as [number, number];\n  const pads = attributes.pads as [number, number, number, number];\n  const strides = attributes.strides as [number, number];\n  const wIsConst = (attributes.wIsConst as () => boolean)();\n  const outputPadding = attributes.outputPadding as [number, number, number, number];\n  const outputShape = attributes.outputShape as [number, number];\n  return {\n    autoPad,\n    format,\n    dilations,\n    group,\n    kernelShape,\n    outputPadding,\n    outputShape,\n    pads,\n    strides,\n    wIsConst,\n    ...activationAttributes,\n    cacheKey: `${attributes.format};${activationAttributes.activation};`,\n  };\n};\n\nconst validateInputs = (inputs: readonly TensorView[], attributes: ConvTransposeAttributes): void => {\n  // Refer to the below link for all input checks\n  // https://github.com/onnx/onnx/blob/main/docs/Operators.md#ConvTranspose\n  if (!inputs || (inputs.length !== 2 && inputs.length !== 3)) {\n    throw new Error('Conv requires 2 or 3 inputs');\n  }\n\n  // TODO : Need to add support for multi-dimensional conv\n  if (inputs[0].dims.length !== 4 && inputs[0].dims.length !== 3) {\n    throw new Error('currently only support 2-dimensional conv');\n  }\n\n  if (inputs[0].dims.length !== inputs[1].dims.length) {\n    throw new Error('filter does not have same dimension as input');\n  }\n\n  // FILTER_IN_CHANNEL should be equal to DATA_CHANNEL\n  const dataChannel = inputs[0].dims[attributes.format === 'NHWC' ? inputs[0].dims.length - 1 : 1];\n  const filterInChannel = inputs[1].dims[0];\n  if (dataChannel !== filterInChannel) {\n    throw new Error('FILTER_IN_CHANNEL should be equal to DATA_CHANNEL');\n  }\n\n  const featureMaps = inputs[1].dims[1] * attributes.group;\n\n  // if bias is provided it should be 1D and the number of elements should be equal to the number of feature maps\n  if (inputs.length === 3 && (inputs[2].dims.length !== 1 || inputs[2].dims[0] !== featureMaps)) {\n    throw new Error('invalid bias');\n  }\n\n  const spatialRank = inputs[0].dims.length - 2;\n  const dilationsSet = attributes.dilations.reduce((a, b) => a + b, 0) > 0;\n  // wrong dilations dimension\n  if (dilationsSet && attributes.dilations.length !== spatialRank) {\n    throw new Error(`dilations should be ${spatialRank}D`);\n  }\n\n  const stridesSet = attributes.strides.reduce((a, b) => a + b, 0) > 0;\n  // Wrong strides dimension\n  if (stridesSet && attributes.strides.length !== spatialRank) {\n    throw new Error(`strides should be ${spatialRank}D`);\n  }\n\n  // Wrong pads dimension\n  const padsSet = attributes.pads.reduce((a, b) => a + b, 0) > 0;\n  if (padsSet && attributes.pads.length !== spatialRank * 2) {\n    throw new Error(`pads should be ${spatialRank * 2}D`);\n  }\n\n  // Wrong output padding dimension\n  if (attributes.outputPadding.length !== spatialRank && attributes.outputPadding.length !== 0) {\n    throw new Error(`output_padding should be ${spatialRank}D`);\n  }\n\n  // if kernelShape is specified, it's data length must be 2 less than dims length of the weights tensor\n  // (the first 2 dims are batch_size and channels)\n  const kernelShapeSet = attributes.kernelShape.reduce((a, b) => a + b, 0) > 0;\n  if (\n    kernelShapeSet &&\n    attributes.kernelShape.length !== 0 &&\n    attributes.kernelShape.length !== inputs[1].dims.length - 2\n  ) {\n    throw new Error('invalid kernel shape');\n  }\n\n  // as with kernelShape, must have same number of spatial dims as input\n  if (attributes.outputShape.length !== 0 && attributes.outputShape.length !== inputs[0].dims.length - 2) {\n    throw new Error('invalid output shape');\n  }\n};\n\nconst convTranspose2d = (\n  context: ComputeContext,\n  inputs: readonly TensorView[],\n  attributes: ConvTransposeAttributes,\n  squeezeOutputShapeFunction?: (shape: readonly number[]) => number[],\n): void => {\n  // STEP.1: transpose weight\n  const transposedWeight =\n    (context.kernelCustomData.wT as TensorView | undefined) ??\n    context.compute(createTransposeProgramInfo(inputs[1], [2, 3, 0, 1]), {\n      inputs: [1],\n      outputs: [attributes.wIsConst ? -2 : -1],\n    })[0];\n  if (attributes.wIsConst && !context.kernelCustomData.wT) {\n    context.kernelCustomData.wT = transposedWeight;\n  }\n\n  // STEP.2: prepare reshaped inputs\n  const convTransposeInputs = [inputs[0], transposedWeight];\n  if (inputs.length === 3) {\n    convTransposeInputs.push(inputs[2]);\n  }\n  context.compute(createConvTranspose2DProgramInfo(convTransposeInputs, attributes, squeezeOutputShapeFunction), {\n    inputs: convTransposeInputs,\n  });\n};\n\nconst convTranspose1d = (context: ComputeContext, attributes: ConvTransposeAttributes): void => {\n  // extend the input to 2D by adding H dimension\n  const isChannelLast = attributes.format === 'NHWC';\n\n  const inputs = [\n    context.inputs[0].reshape(\n      isChannelLast\n        ? // [N, W, C] -> [N, H=1, W, C]\n          [context.inputs[0].dims[0], 1, context.inputs[0].dims[1], context.inputs[0].dims[2]]\n        : // [N, C, W] -> [N, C, H=1, W]\n          [context.inputs[0].dims[0], context.inputs[0].dims[1], 1, context.inputs[0].dims[2]],\n    ),\n    //[FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, kW] -> [FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, kH=1, kW]\n    context.inputs[1].reshape([context.inputs[1].dims[0], context.inputs[1].dims[1], 1, context.inputs[1].dims[2]]),\n  ];\n  if (context.inputs.length === 3) {\n    inputs.push(context.inputs[2]);\n  }\n  let kernelShape = attributes.kernelShape;\n  if (kernelShape.length === 0 || kernelShape[0] === 0) {\n    kernelShape = [context.inputs[1].dims[2]];\n  }\n  let dilations = attributes.dilations;\n  if (dilations.length === 0 || dilations[0] === 0) {\n    dilations = [1];\n  }\n  let strides = attributes.strides;\n  if (strides.length === 0 || strides[0] === 0) {\n    strides = [1];\n  }\n  let pads = attributes.pads;\n  if (pads.length === 0) {\n    pads = [0, 0];\n  }\n  pads = [0, pads[0], 0, pads[1]];\n  strides = [1].concat(strides);\n  dilations = [1].concat(dilations);\n  kernelShape = [1].concat(kernelShape);\n  let outputPadding = attributes.outputPadding;\n  outputPadding = [0].concat(outputPadding);\n  const adjustedAttributes = getAdjustedConvTransposeAttributes(\n    { ...attributes, pads, strides, dilations, kernelShape, outputPadding },\n    inputs,\n  );\n\n  convTranspose2d(context, inputs, adjustedAttributes, (outputShape) =>\n    isChannelLast ? [outputShape[0], outputShape[2], outputShape[3]] : [outputShape[0], outputShape[1], outputShape[3]],\n  );\n};\n\nexport const convTranspose = (context: ComputeContext, attributes: ConvTransposeAttributes): void => {\n  validateInputs(context.inputs, attributes);\n  if (context.inputs[0].dims.length === 3) {\n    convTranspose1d(context, attributes);\n  } else {\n    const adjustedAttributes = getAdjustedConvTransposeAttributes(attributes, context.inputs);\n    convTranspose2d(context, context.inputs, adjustedAttributes);\n  }\n};\n","// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport { DataType } from '../../../wasm-common';\nimport { TensorView } from '../../tensor-view';\nimport { ShapeUtil } from '../../util';\nimport { AttributeWithCacheKey, createAttributeWithCacheKey } from '../attribute-with-cache-key';\nimport { ComputeContext, ProgramInfo } from '../types';\n\nimport { createTensorShapeVariables, getElementAt, inputVariable, outputVariable, ShaderHelper } from './common';\n\nexport interface CumSumAttributes extends AttributeWithCacheKey {\n  readonly exclusive: boolean;\n  readonly reverse: boolean;\n}\nconst createCumsumProgramInfo = (\n  inputType: number,\n  inputShape: readonly number[],\n  axisInput: TensorView,\n  attributes: CumSumAttributes,\n): ProgramInfo => {\n  const outputSize = ShapeUtil.size(inputShape); // outputShape is same as inputShape.\n  const rank = inputShape.length; // input/output rank\n  const input = inputVariable('input', inputType, rank);\n  const output = outputVariable('output', inputType, rank);\n  const axisValue =\n    axisInput.dataType === DataType.int32 ? axisInput.getInt32Array()[0] : Number(axisInput.getBigInt64Array()[0]);\n  const axis = ShapeUtil.normalizeAxis(axisValue, rank);\n  const getShaderSource = (shaderHelper: ShaderHelper) => {\n    const index = ` i32(${input.indicesGet('inputIndices', 'uniforms.axis')}) `;\n    const max = getElementAt('uniforms.input_shape', 'uniforms.axis', rank);\n    const lowerLimit = attributes.reverse ? index + (attributes.exclusive ? ' + 1' : '') : '0';\n    const upperLimit = attributes.reverse ? max : index + (attributes.exclusive ? '' : ' + 1');\n    return `\n                ${shaderHelper\n                  .registerUniform('outputSize', 'u32')\n                  .registerUniform('axis', 'u32')\n                  .declareVariables(input, output)}\n                ${shaderHelper.mainStart()}\n                  ${shaderHelper.guardAgainstOutOfBoundsWorkgroupSizes('uniforms.outputSize')}\n                  var inputIndices = ${output.offsetToIndices('global_idx')};\n                  var sum = ${output.type.value}(0);\n                  let first : i32 = ${lowerLimit};\n                  let last : i32 = ${upperLimit};\n                  for (var i : i32 = first; i < last; i++) {\n                    ${input.indicesSet('inputIndices', 'uniforms.axis', 'u32(i)')};\n                    sum = sum + ${input.getByIndices('inputIndices')};\n                  }\n                  ${output.setByOffset('global_idx', 'sum')};\n                }`;\n  };\n  return {\n    name: 'CumSum',\n    shaderCache: { hint: attributes.cacheKey, inputDependencies: ['rank'] },\n    getRunData: () => ({\n      outputs: [{ dims: inputShape, dataType: inputType }],\n      dispatchGroup: { x: Math.ceil(outputSize / 64 /* workgroup size */) },\n      programUniforms: [\n        { type: DataType.uint32, data: outputSize },\n        { type: DataType.uint32, data: axis },\n        ...createTensorShapeVariables(inputShape, inputShape),\n      ],\n    }),\n    getShaderSource,\n  };\n};\n\nexport const cumsum = (context: ComputeContext, attributes: CumSumAttributes): void => {\n  const inputShape = context.inputs[0].dims;\n  const inputType = context.inputs[0].dataType;\n  const axis = context.inputs[1];\n  context.compute(createCumsumProgramInfo(inputType, inputShape, axis, attributes), { inputs: [0] });\n};\n\nexport const parseCumSumAttributes = (attributes: Record<string, unknown>): CumSumAttributes => {\n  const exclusive = (attributes.exclusive as number) === 1;\n  const reverse = (attributes.reverse as number) === 1;\n  return createAttributeWithCacheKey({ exclusive, reverse });\n};\n","// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport { DataType } from '../../../wasm-common';\nimport { TensorView } from '../../tensor-view';\nimport { ShapeUtil } from '../../util';\nimport { AttributeWithCacheKey, createAttributeWithCacheKey } from '../attribute-with-cache-key';\nimport { ComputeContext, ProgramInfo } from '../types';\n\nimport { createTensorShapeVariables, IndicesHelper, inputVariable, outputVariable, ShaderHelper } from './common';\n\nexport interface FormatAttributes {\n  readonly format: 'NHWC' | 'NCHW';\n}\n\nexport interface DepthToSpaceAttributes extends FormatAttributes, AttributeWithCacheKey {\n  readonly blocksize: number;\n  readonly mode: string;\n}\n\nconst validateInputs = (inputs: readonly TensorView[]): void => {\n  if (!inputs || inputs.length !== 1) {\n    throw new Error('DepthToSpace requires 1 input.');\n  }\n  if (inputs[0].dims.length !== 4) {\n    throw new Error('DepthToSpace requires 4D input.');\n  }\n};\n\nconst permFunctionBody = (perm: number[], rank: number, input: IndicesHelper, output: IndicesHelper): string => {\n  const reverseFunc = [];\n  reverseFunc.push(`fn perm(i: ${output.type.indices}) -> ${input.type.indices} {\n    var a: ${input.type.indices};`);\n  for (let i = 0; i < rank; ++i) {\n    reverseFunc.push(input.indicesSet('a', perm[i], `i[${i}]`));\n  }\n  reverseFunc.push('return a;}');\n  return reverseFunc.join('\\n');\n};\n\nconst createDepthToSpaceProgramInfo = (inputTensor: TensorView, attributes: DepthToSpaceAttributes): ProgramInfo => {\n  let n: number, h: number, w: number, c: number;\n  let shape: number[];\n  let perm: number[];\n  const isChannelLast = attributes.format === 'NHWC';\n  const blocksize = attributes.blocksize;\n  const isDCRmode = attributes.mode === 'DCR';\n  if (isChannelLast) {\n    [n, h, w, c] = inputTensor.dims;\n    shape = isDCRmode\n      ? [n, h, w, blocksize, blocksize, c / blocksize ** 2]\n      : [n, h, w, c / blocksize ** 2, blocksize, blocksize];\n    perm = isDCRmode ? [0, 1, 3, 2, 4, 5] : [0, 1, 4, 2, 5, 3];\n  } else {\n    [n, h, w, c] = [inputTensor.dims[0], inputTensor.dims[2], inputTensor.dims[3], inputTensor.dims[1]];\n    shape = isDCRmode\n      ? [n, blocksize, blocksize, c / blocksize ** 2, h, w]\n      : [n, c / blocksize ** 2, blocksize, blocksize, h, w];\n    perm = isDCRmode ? [0, 3, 4, 1, 5, 2] : [0, 1, 4, 2, 5, 3];\n  }\n  const reshapedInputTensor = inputTensor.reshape(shape);\n  const reshapedInputRank = reshapedInputTensor.dims.length;\n  const inputDataType = inputTensor.dataType;\n\n  const reshapedInput = inputVariable('a', inputDataType, reshapedInputRank);\n  const permedOutput = outputVariable('output', inputDataType, reshapedInputRank);\n\n  const getShaderSource = (shaderHelper: ShaderHelper) => `\n  ${shaderHelper.registerUniform('output_size', 'u32').declareVariables(reshapedInput, permedOutput)}\n\n  ${permFunctionBody(perm, reshapedInputRank, reshapedInput, permedOutput)}\n\n  ${shaderHelper.mainStart()}\n    ${shaderHelper.guardAgainstOutOfBoundsWorkgroupSizes('uniforms.output_size')}\n\n    let indices = ${permedOutput.offsetToIndices('global_idx')};\n    let aIndices = perm(indices);\n\n    ${permedOutput.setByOffset('global_idx', reshapedInput.getByIndices('aIndices'))}\n  }`;\n\n  return {\n    name: 'DepthToSpace',\n    shaderCache: {\n      hint: `${inputTensor.dims};${attributes.blocksize};${attributes.mode}`,\n      inputDependencies: ['rank'],\n    },\n    getRunData: (inputs) => {\n      const outputShape = isChannelLast\n        ? [n, h * blocksize, w * blocksize, c / blocksize ** 2]\n        : [n, c / blocksize ** 2, h * blocksize, w * blocksize];\n      const outputSize = ShapeUtil.size(outputShape);\n      const shapeBeforePerm = reshapedInputTensor.dims;\n      const shapeAfterPerm = ShapeUtil.sortBasedOnPerm(shapeBeforePerm, perm);\n      return {\n        outputs: [{ dims: outputShape, dataType: inputs[0].dataType }],\n        dispatchGroup: { x: Math.ceil(outputSize / 64 /* workgroup size */) },\n        programUniforms: [\n          { type: DataType.uint32, data: outputSize },\n          ...createTensorShapeVariables(shapeBeforePerm, shapeAfterPerm),\n        ],\n      };\n    },\n    getShaderSource,\n  };\n};\n\nexport const depthToSpace = (context: ComputeContext, attributes: DepthToSpaceAttributes): void => {\n  validateInputs(context.inputs);\n  context.compute(createDepthToSpaceProgramInfo(context.inputs[0], attributes));\n};\n\nexport const parseDepthToSpaceAttributes = (attributes: Record<string, unknown>): DepthToSpaceAttributes =>\n  createAttributeWithCacheKey({\n    blocksize: attributes.blocksize as number,\n    mode: attributes.mode as string,\n    format: attributes.format as 'NHWC' | 'NCHW',\n  });\n","// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport { DataType } from '../../../wasm-common';\nimport { TensorView } from '../../tensor-view';\nimport { ShapeUtil } from '../../util';\nimport { AttributeWithCacheKey, createAttributeWithCacheKey } from '../attribute-with-cache-key';\nimport { ComputeContext, ProgramInfo, ProgramUniform } from '../types';\n\nimport { createTensorShapeVariables, inputVariable, outputVariable, ShaderHelper } from './common';\n\nexport interface EinsumAttributes extends AttributeWithCacheKey {\n  readonly equation: string;\n}\n// The equation attribute value is a string which consists of left hand side (LHS) and optionally right hand side (RHS)\n// separated by '->'. Ex. \"ij,jk -> ik\" expresses matrix multiplication\n//     \"ij->ji\" expresses matrix transpose\n//      \"ii->i\" diagonal elements of a square matrix\n// LHS consists of a sequence of terms separated by commas. Each term corresponds to an input variable.\n// Each symbol corresponds to a dimension in the input variable. The symbol can be either a letter, 'a' to 'z' or 'A' to\n// 'Z' or '...' to represent arbitrary dimensions.\n\nconst symbolPattern = '[a-zA-Z]|\\\\.\\\\.\\\\.'; // The pattern each symbol in each term in the symbolic equation should match\nconst termPattern = '(' + symbolPattern + ')+'; // The pattern each term in the symbolic equation should match\nconst termPatternOnly = '^' + termPattern + '$'; // The patterns only matchs a term begin to end.\nconst lhsPattern = '(' + termPattern + ',)*' + termPattern; // The pattern the LHS should match\nconst lhsPatternOnly = '^' + lhsPattern + '$'; // The patterns only matchs a LHS begin to end.\n\ninterface SymbolInfo {\n  count: number; // Symbol corresponding to a dimmension of an input\n  inputIndices: number[]; // Number of input variables the symbol corresponds to\n  dimValue: number; // Number of dimensions the symbol corresponds to\n}\n\nclass EinsumTerm {\n  constructor(inputIndex = -1) {\n    this.symbolToIndices = new Map<string, number[]>();\n    this.inputIndex = inputIndex;\n  }\n\n  // Add a symbol to the term\n  addSymbol(symbol: string, index: number) {\n    let value = this.symbolToIndices.get(symbol);\n    if (value === undefined) {\n      value = [index];\n    } else {\n      value.push(index);\n    }\n    this.symbolToIndices.set(symbol, value);\n  }\n\n  symbolToIndices: Map<string, number[]>; // Map from symbol to dimensions of the input corresponding to the term\n  inputIndex: number; // -1 for output and 0, 1, 2, ... for inputs\n}\n\nclass EinsumEquation {\n  constructor(\n    inputs: readonly TensorView[],\n    public readonly equation: string,\n  ) {\n    this.hasEllipsis = false;\n    this.symbolToInfo = new Map<string, SymbolInfo>();\n    this.lhs = new Array<EinsumTerm>();\n    this.outputDims = [];\n    // As rhs needs to be updated allow using let instead of const for both lhs and rhs.\n    // eslint-disable-next-line prefer-const\n    let [lhs, rhs] = equation.includes('->') ? equation.split('->', 2) : [equation, ''];\n    if (!lhs.match(RegExp(lhsPatternOnly))) {\n      throw new Error('Invalid LHS term');\n    }\n    const inputTerms = lhs.split(',');\n    inputTerms.forEach((inputTerm, index) => {\n      const dims = inputs[index].dims.slice();\n      if (!inputTerm.match(RegExp(termPatternOnly))) {\n        throw new Error('Invalid LHS term');\n      }\n      const einsumTerm = this.processTerm(inputTerm, true, dims, index);\n      this.lhs.push(einsumTerm);\n    });\n\n    // Initialize the RHS if not specified\n    if (rhs === '') {\n      // Construct RHS from LHS terms/symbols\n      rhs += [...this.symbolToInfo.entries()]\n        .filter(([sym, info]) => info.count === 1 || sym === '...')\n        .map(([sym]) => sym)\n        .join('');\n    } else {\n      if (!rhs.match(RegExp(termPattern))) {\n        throw new Error('Invalid RHS');\n      }\n    }\n\n    // Compute output dims\n    const rhsSymbols = rhs.match(RegExp(symbolPattern, 'g'));\n    rhsSymbols?.forEach((symbol) => {\n      if (symbol === '...') {\n        this.outputDims = this.outputDims.concat(this.ellipsisDims);\n      } else {\n        const info = this.symbolToInfo.get(symbol);\n        if (info === undefined) {\n          throw new Error('Invalid RHS symbol');\n        }\n        this.outputDims.push(info.dimValue);\n      }\n    });\n    this.rhs = this.processTerm(rhs, false, this.outputDims);\n  } // End of EinsumEqation constructor\n\n  // Add a symbol to the equation\n  addSymbol(symbol: string, dimValue: number, inputIndex: number) {\n    let info = this.symbolToInfo.get(symbol);\n    if (info !== undefined) {\n      if (info.dimValue !== dimValue && info.count !== 1) {\n        throw new Error('Dimension mismatch');\n      } else {\n        info.count++;\n        info.inputIndices.push(inputIndex);\n      }\n    } else {\n      info = { count: 1, dimValue, inputIndices: [inputIndex] };\n    }\n    this.symbolToInfo.set(symbol, info);\n  }\n\n  // Process one input/output term\n  processTerm(term: string, isInput: boolean, dims: readonly number[], index = -1): EinsumTerm {\n    const rank = dims.length;\n    let ellipsis = false;\n    let ellipsisDims = [];\n    let nextDim = 0;\n    // For output empty string is allowed because the output may be reduced to a scalar value\n    if (!term.match(RegExp(termPatternOnly)) && !isInput && term !== '') {\n      throw new Error('Invalid LHS term');\n    }\n    const indexSymbols = term.match(RegExp(symbolPattern, 'g'));\n    const einsumTerm = new EinsumTerm(index);\n    // symbol can be either a lettre, 'a' to 'z' or 'A' to 'Z', or '...'\n    indexSymbols?.forEach((symbol: string, i: number) => {\n      if (symbol === '...') {\n        if (ellipsis) {\n          throw new Error('Only one ellipsis is allowed per input term');\n        }\n        ellipsis = true;\n        const ellipsisDimLength = rank - indexSymbols.length + 1;\n        if (ellipsisDimLength < 0) {\n          throw new Error('Ellipsis out of bounds');\n        }\n        ellipsisDims = dims.slice(nextDim, nextDim + ellipsisDimLength);\n        if (this.hasEllipsis) {\n          if (\n            this.ellipsisDims.length !== ellipsisDims.length ||\n            this.ellipsisDims.toString() !== ellipsisDims.toString()\n          ) {\n            throw new Error('Ellipsis dimensions mismatch');\n          }\n        } else if (isInput) {\n          this.hasEllipsis = true;\n          this.ellipsisDims = ellipsisDims;\n        } else {\n          throw new Error('Ellipsis must be specified in the LHS');\n        }\n        // Add '0', '1', '2', '3', '4', etc to represent ellipsis dimensions to avoid special handling\n        for (let j = 0; j < ellipsisDims.length; j++) {\n          const symbol = String.fromCharCode('0'.charCodeAt(0) + j);\n          einsumTerm.addSymbol(symbol, i + j);\n          this.addSymbol(symbol, dims[nextDim++], index);\n        }\n      } else {\n        einsumTerm.addSymbol(symbol, i + (this.hasEllipsis ? this.ellipsisDims.length - 1 : 0));\n        this.addSymbol(symbol, dims[nextDim++], index);\n      }\n    });\n    return einsumTerm;\n  }\n\n  symbolToInfo: Map<string, SymbolInfo>; // All symbols in the equation\n  hasEllipsis: boolean; // The equation has ellipsis or not\n  ellipsisDims: number[]; // The dimensions of the equation ellipsis corresponds to.\n  lhs: EinsumTerm[]; // Terms on the left-hand side of the equation\n  rhs: EinsumTerm; // Term on the right-hand side of the equation\n  outputDims: number[]; // Output dimensions of the equation\n} // End of class EinsumEquation\n\nconst appendMax = (name: string): string => name + '_max';\n\nconst createEinsumProgramInfo = (\n  inputShapes: Array<readonly number[]>,\n  dataType: number,\n  einsumEquation: EinsumEquation,\n  outputShape: readonly number[],\n): ProgramInfo => {\n  const ranks = inputShapes.map((dims) => dims.length);\n  const inputVars = ranks.map((rank, index) => inputVariable(`input${index}`, dataType, rank));\n  const outputSize = ShapeUtil.size(outputShape);\n  const output = outputVariable('output', dataType, outputShape.length);\n  const uniformsSymbols = [...einsumEquation.symbolToInfo.keys()].filter(\n    (symbol) => !einsumEquation.rhs.symbolToIndices.has(symbol),\n  );\n  const getShaderSource = (shaderHelper: ShaderHelper) => {\n    const idxCopy: string[] = [];\n    const initProd = 'var prod = 1.0;';\n    const initSum = 'var sum = 0.0;';\n    const updateSum = 'sum += prod;';\n    const reduceOpsSetIndices: string[] = [];\n    const reduceOpsLoopHeaders: string[] = [];\n    const reduceOpsLoopFooters: string[] = [];\n    const reduceOpCompute: string[] = [];\n    const isReduceOpsWithoutLoop = einsumEquation.symbolToInfo.size === einsumEquation.rhs.symbolToIndices.size;\n    einsumEquation.symbolToInfo.forEach((info, symbol) => {\n      if (einsumEquation.rhs.symbolToIndices.has(symbol)) {\n        const outputIndex = einsumEquation.rhs.symbolToIndices.get(symbol)?.[0];\n        if (outputIndex !== undefined) {\n          einsumEquation.lhs.forEach((term, i) => {\n            if (info.inputIndices.includes(i)) {\n              const indices = term.symbolToIndices.get(symbol);\n              if (indices === undefined) {\n                throw new Error('Invalid symbol error');\n              }\n              indices.forEach((index) => {\n                idxCopy.push(\n                  `${inputVars[i].indicesSet(\n                    `input${i}Indices`,\n                    index,\n                    output.indicesGet('outputIndices', outputIndex),\n                  )}`,\n                );\n              });\n            }\n          });\n        }\n      } else {\n        einsumEquation.lhs.forEach((term, i) => {\n          if (info.inputIndices.includes(i)) {\n            const indices = term.symbolToIndices.get(symbol);\n            if (indices === undefined) {\n              throw new Error('Invalid symbol error');\n            }\n            indices.forEach((index) => {\n              reduceOpsSetIndices.push(`${inputVars[i].indicesSet(`input${i}Indices`, index, `${symbol}`)}`);\n            });\n            reduceOpCompute.push(`prod *= ${inputVars[i].getByIndices(`input${i}Indices`)};`);\n          }\n        });\n        reduceOpsLoopHeaders.push(\n          `for(var ${symbol}: u32 = 0; ${symbol} < uniforms.${appendMax(symbol)}; ${symbol}++) {`,\n        );\n        reduceOpsLoopFooters.push('}');\n      }\n    });\n    const reduceOps = isReduceOpsWithoutLoop\n      ? [\n          ...idxCopy,\n          `let sum = ${inputVars.map((inputVar, i) => inputVar.getByIndices(`input${i}Indices`)).join(' * ')};`,\n        ]\n      : [\n          ...idxCopy,\n          initSum,\n          ...reduceOpsLoopHeaders,\n          ...reduceOpsSetIndices,\n          initProd,\n          ...reduceOpCompute,\n          updateSum,\n          ...reduceOpsLoopFooters,\n        ];\n    return `\n            ${shaderHelper\n              .registerUniforms(uniformsSymbols.map((symbol) => ({ name: `${appendMax(symbol)}`, type: 'u32' })))\n              .registerUniform('outputSize', 'u32')\n              .declareVariables(...inputVars, output)}\n\n            ${shaderHelper.mainStart()}\n            ${shaderHelper.guardAgainstOutOfBoundsWorkgroupSizes('uniforms.outputSize')}\n            var outputIndices = ${output.offsetToIndices('global_idx')};\n            ${inputVars.map((_var, i) => `var input${i}Indices: ${inputVars[i].type.indices};`).join('\\n')}\n            ${reduceOps.join('\\n')};\n            ${output.setByOffset('global_idx', 'sum')};\n          }`;\n  };\n  return {\n    name: 'Einsum',\n    shaderCache: { hint: einsumEquation.equation, inputDependencies: inputShapes.map(() => 'rank') },\n    getRunData: () => {\n      // The symbols from uniformSymbols array are guaranteed to exist in einsumEquations.symbolToInfo map. The\n      // filter is added to make sure that dimValue is never 0.\n      const programUniformsInit: ProgramUniform[] = uniformsSymbols\n        .filter((symbol) => einsumEquation.symbolToInfo.has(symbol))\n        .map((symbol) => ({ type: DataType.uint32, data: einsumEquation.symbolToInfo.get(symbol)?.dimValue || 0 }));\n      programUniformsInit.push({ type: DataType.uint32, data: outputSize });\n      const programUniforms: ProgramUniform[] = inputShapes\n        .map((dims, _) => [...createTensorShapeVariables(dims)])\n        .reduce((acc, inputProgramUniforms) => acc.concat(inputProgramUniforms), programUniformsInit);\n      programUniforms.push(...createTensorShapeVariables(outputShape));\n      return {\n        outputs: [{ dims: outputShape, dataType }],\n        dispatchGroup: { x: Math.ceil(outputSize / 64 /* workgroup size */) },\n        programUniforms,\n      };\n    },\n    getShaderSource,\n  };\n};\n\nexport const einsum = (context: ComputeContext, attributes: EinsumAttributes): void => {\n  const einsumEquation = new EinsumEquation(context.inputs, attributes.equation);\n  const outputShape = einsumEquation.outputDims;\n  const inputShapes = context.inputs.map((input, _) => input.dims);\n  context.compute(createEinsumProgramInfo(inputShapes, context.inputs[0].dataType, einsumEquation, outputShape));\n};\n\nexport const parseEinsumAttributes = (attributes: Record<string, unknown>): EinsumAttributes => {\n  const equation = (attributes.equation as string).replace(/\\s+/g, '');\n  return createAttributeWithCacheKey({ equation });\n};\n","// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport { DataType } from '../../../wasm-common';\nimport { TensorView } from '../../tensor-view';\nimport { ShapeUtil } from '../../util';\nimport { ComputeContext, ProgramInfo, ProgramUniform } from '../types';\n\nimport { createTensorShapeVariables, inputVariable, outputVariable, ShaderHelper } from './common';\n\nconst validateInputs = (inputs: readonly TensorView[]): void => {\n  if (!inputs || inputs.length !== 2) {\n    throw new Error('Expand requires 2 input.');\n  }\n  const inputShape = inputs[0].dims;\n  const shape = Array.from(inputs[1].getBigInt64Array(), Number);\n\n  let shapeIndex = shape.length < inputShape.length ? 0 : shape.length - inputShape.length;\n  let inputShapeIndex = inputShape.length < shape.length ? 0 : inputShape.length - shape.length;\n  for (; shapeIndex < shape.length && inputShapeIndex < inputShape.length; ++shapeIndex, ++inputShapeIndex) {\n    if (\n      shape[shapeIndex] !== inputShape[inputShapeIndex] &&\n      shape[shapeIndex] !== 1 &&\n      inputShape[inputShapeIndex] !== 1\n    ) {\n      throw new Error('Expand requires shape to be broadcastable to input');\n    }\n  }\n};\n\nconst getAdjustedShape = (shape1: readonly number[], shape2: readonly number[]): number[] => {\n  const diff = shape1.length - shape2.length;\n  const shape: number[] = [];\n  for (let i = 0; i < diff; ++i) {\n    shape.push(shape1[i]);\n  }\n  for (let i = 0; i < shape2.length; ++i) {\n    shape.push(shape2[i] === 1 ? shape1[i + diff] : shape2[i]);\n  }\n  return shape;\n};\n\nconst calculateOutputShape = (inputShape: readonly number[], shape: readonly number[]): number[] =>\n  inputShape.length > shape.length ? getAdjustedShape(inputShape, shape) : getAdjustedShape(shape, inputShape);\n\nconst createExpandProgramInfo = (inputs: readonly TensorView[]): ProgramInfo => {\n  const inputShape = inputs[0].dims;\n  const shape = Array.from(inputs[1].getBigInt64Array(), Number);\n  const outputShape: number[] = calculateOutputShape(inputShape, shape);\n  const dataType = inputs[0].dataType;\n  const isBoolOrScalar = dataType === DataType.bool || ShapeUtil.size(inputShape) === 1;\n  const iComponents =\n    dataType === DataType.bool ? 4 : inputShape.length > 0 && inputShape[inputShape.length - 1] % 4 === 0 ? 4 : 1;\n  const components = isBoolOrScalar\n    ? 4\n    : outputShape.length > 0 && outputShape[outputShape.length - 1] % 4 === 0\n      ? 4\n      : 1;\n  const outputSize = Math.ceil(ShapeUtil.size(outputShape) / components);\n\n  const getShaderSource = (shaderHelper: ShaderHelper) => {\n    const input = inputVariable('input', dataType, inputShape.length, iComponents);\n    const output = outputVariable('output', dataType, outputShape.length, components);\n    let assignment: string;\n    if (dataType === DataType.bool) {\n      const singleAssignment = (resStr: string, x: number, typeCast = '') => `\n          let outputIndices${x} = ${output.offsetToIndices(`outputOffset + ${x}u`)};\n          let offset${x} = ${input.broadcastedIndicesToOffset(`outputIndices${x}`, output)};\n          let index${x} = offset${x} / 4u;\n          let component${x} = offset${x} % 4u;\n          ${resStr}[${x}] = ${typeCast}(${input.getByOffset(`index${x}`)}[component${x}]);\n        `;\n      assignment = `\n        let outputOffset = global_idx * ${components};\n        var data = vec4<u32>(0);\n        ${singleAssignment('data', 0, 'u32')}\n        ${singleAssignment('data', 1, 'u32')}\n        ${singleAssignment('data', 2, 'u32')}\n        ${singleAssignment('data', 3, 'u32')}\n        ${output.setByOffset('global_idx', 'data')}\n      }`;\n    } else {\n      assignment = `\n        let outputIndices = ${output.offsetToIndices(`global_idx * ${components}`)};\n        let inputOffset = ${input.broadcastedIndicesToOffset('outputIndices', output)};\n        let data = ${output.type.value}(${input.getByOffset(`inputOffset / ${iComponents}`)});\n        ${output.setByOffset('global_idx', 'data')}\n      }`;\n    }\n    return `\n    ${shaderHelper.registerUniform('vec_size', 'u32').declareVariables(input, output)}\n    ${shaderHelper.mainStart()}\n    ${shaderHelper.guardAgainstOutOfBoundsWorkgroupSizes('uniforms.vec_size')}\n    ${assignment}`;\n  };\n\n  const programUniforms: ProgramUniform[] = [\n    { type: DataType.uint32, data: outputSize },\n    ...createTensorShapeVariables(inputShape, outputShape),\n  ];\n  return {\n    name: 'Expand',\n    shaderCache: { hint: `${outputShape.length};${iComponents}${components}`, inputDependencies: ['rank'] },\n    getShaderSource,\n    getRunData: () => ({\n      outputs: [{ dims: outputShape, dataType: inputs[0].dataType }],\n      dispatchGroup: { x: Math.ceil(outputSize / 64 /* workgroup size */) },\n      programUniforms,\n    }),\n  };\n};\n\nexport const expand = (context: ComputeContext): void => {\n  validateInputs(context.inputs);\n  context.compute(createExpandProgramInfo(context.inputs), { inputs: [0] });\n};\n","// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport { DataType } from '../../../wasm-common';\nimport { TensorView } from '../../tensor-view';\nimport { ShapeUtil } from '../../util';\nimport { ComputeContext, ProgramInfo } from '../types';\n\nimport {\n  inputVariable,\n  outputVariable,\n  ShaderHelper,\n  tensorTypeToWsglValueType,\n  UniformsArrayType,\n  WORKGROUP_SIZE,\n} from './common';\nimport * as unary from './unary-op';\n\n// GELU is defined as Y=0.5*X*(1+tanh(0.797885*X+0.035677*X*X*X)), where X may pre-add a bias.\n\nconst createFastGeluProgramInfo = (inputTensors: readonly TensorView[]): ProgramInfo => {\n  const dataType = inputTensors[0].dataType;\n  const outputSize = ShapeUtil.size(inputTensors[0].dims);\n  const biasLength = ShapeUtil.size(inputTensors[1].dims);\n  // can only use vec4 when bias length is multiple of 4\n  const useVec4 = biasLength % 4 === 0;\n  const getShaderSource = (shaderHelper: ShaderHelper): string => {\n    const x = inputVariable('x', dataType, [1], 4);\n    const bias = inputVariable('bias', dataType, [1], 4);\n    const y = outputVariable('y', dataType, [1], 4);\n\n    const uniforms: UniformsArrayType = [\n      { name: 'output_vec_size', type: 'u32' },\n      { name: 'bias_size', type: 'u32' },\n    ];\n\n    const singleElementBias = (i: 0 | 1 | 2 | 3) => `\n      let bias${i}_offset: u32 = (global_idx * 4 + ${i}) % uniforms.bias_size;\n      let bias${i} = ${bias.getByOffset(`bias${i}_offset / 4`)}[bias${i}_offset % 4];`;\n    const biasGetExpression = useVec4\n      ? `\n      let bias = ${bias.getByOffset('global_idx % (uniforms.bias_size / 4)')};`\n      : `${singleElementBias(0)}${singleElementBias(1)}${singleElementBias(2)}${singleElementBias(3)}\n      let bias = ${x.type.value}(bias0, bias1, bias2, bias3);`;\n\n    return `${shaderHelper.registerUniforms(uniforms).declareVariables(x, bias, y)}\n\n    ${unary.fastGeluImpl(tensorTypeToWsglValueType(dataType))}\n\n    ${shaderHelper.mainStart(WORKGROUP_SIZE)}\n      ${shaderHelper.guardAgainstOutOfBoundsWorkgroupSizes('uniforms.output_vec_size')}\n\n      let x = ${x.getByOffset('global_idx')};\n      ${biasGetExpression}\n      let x_in = x + bias;\n      ${y.setByOffset('global_idx', unary.fastGeluExpression('x_in'))}\n    }`;\n  };\n\n  return {\n    name: 'FastGeluWithBias',\n    shaderCache: { hint: `${useVec4}`, inputDependencies: ['type', 'type'] },\n    getShaderSource,\n    getRunData: (inputs) => ({\n      outputs: [{ dims: inputs[0].dims, dataType: inputs[0].dataType }],\n      programUniforms: [\n        { type: DataType.uint32, data: Math.ceil(outputSize / 4) },\n        { type: DataType.uint32, data: biasLength },\n      ],\n      dispatchGroup: { x: Math.ceil(outputSize / WORKGROUP_SIZE / 4) },\n    }),\n  };\n};\n\nexport const fastGelu = (context: ComputeContext): void => {\n  if (context.inputs.length < 2 || ShapeUtil.size(context.inputs[1].dims) === 0) {\n    unary.fastGelu(context);\n  } else {\n    context.compute(createFastGeluProgramInfo(context.inputs));\n  }\n};\n","// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport { DataType } from '../../../wasm-common';\nimport { TensorView } from '../../tensor-view';\nimport { ShapeUtil } from '../../util';\nimport { AttributeWithCacheKey, createAttributeWithCacheKey } from '../attribute-with-cache-key';\nimport { ComputeContext, ProgramInfo, ProgramUniform } from '../types';\n\nimport { createTensorShapeVariables, inputVariable, outputVariable, ShaderHelper } from './common';\n\nexport interface GatherAttributes extends AttributeWithCacheKey {\n  axis: number;\n}\n\nconst validateInputs = (inputs: readonly TensorView[]): void => {\n  if (!inputs || inputs.length !== 2) {\n    throw new Error('Gather requires 2 inputs.');\n  }\n};\n\nconst createGatherProgramInfo = (inputs: readonly TensorView[], attributes: GatherAttributes): ProgramInfo => {\n  const inputShape = inputs[0].dims;\n  const indicesShape = inputs[1].dims;\n\n  const inputRank = inputShape.length;\n  const axis = ShapeUtil.normalizeAxis(attributes.axis, inputRank);\n\n  const outputShape = inputShape.slice(0);\n  outputShape.splice(axis, 1, ...indicesShape);\n\n  const axisDimLimit = inputShape[axis];\n  const components = inputs[0].dataType === DataType.bool ? 4 : 1;\n  const outputSize = Math.ceil(ShapeUtil.size(outputShape) / components);\n\n  const programUniforms: ProgramUniform[] = [\n    { type: DataType.uint32, data: outputSize },\n    { type: DataType.int32, data: axisDimLimit },\n    { type: DataType.uint32, data: axis },\n    ...createTensorShapeVariables(inputs[0].dims, inputs[1].dims, outputShape),\n  ];\n\n  const getShaderSource = (shaderHelper: ShaderHelper) => {\n    const data = inputVariable('data', inputs[0].dataType, inputs[0].dims.length, components);\n    const indices = inputVariable('inputIndices', inputs[1].dataType, inputs[1].dims.length);\n    const output = outputVariable('output', inputs[0].dataType, outputShape.length, components);\n\n    const calcDataIndices = (x: number | string): string => {\n      const indicesRank = indicesShape.length;\n      let calcStr = `var indicesIndices${x}  = ${indices.type.indices}(0);`;\n      for (let i = 0; i < indicesRank; i++) {\n        calcStr += `${indicesRank > 1 ? `indicesIndices${x}[${i}]` : `indicesIndices${x}`} = ${\n          outputShape.length > 1 ? `outputIndices${x}[uniforms.axis + ${i}]` : `outputIndices${x}`\n        };`;\n      }\n      calcStr += `\n          var idx${x} = ${indices.getByIndices(`indicesIndices${x}`)};\n          if (idx${x} < 0) {\n            idx${x} = idx${x} + uniforms.axisDimLimit;\n          }\n          var dataIndices${x} : ${data.type.indices};\n        `;\n      for (let i = 0, j = 0; i < inputRank; i++) {\n        if (i === axis) {\n          calcStr += `${inputRank > 1 ? `dataIndices${x}[${i}]` : `dataIndices${x}`} = u32(idx${x});`;\n          j += indicesRank;\n        } else {\n          calcStr += `${inputRank > 1 ? `dataIndices${x}[${i}]` : `dataIndices${x}`} = ${\n            outputShape.length > 1 ? `outputIndices${x}[${j}]` : `outputIndices${x}`\n          };`;\n          j++;\n        }\n      }\n      return calcStr;\n    };\n    let assignment: string;\n    if (inputs[0].dataType === DataType.bool) {\n      const singleAssignment = (resStr: string, x: number, typeCast = '') => `\n          let outputIndices${x} = ${output.offsetToIndices(`outputOffset + ${x}u`)};\n          ${calcDataIndices(x)};\n          let offset${x} = ${data.indicesToOffset(`dataIndices${x}`)};\n          let index${x} = offset${x} / 4u;\n          let component${x} = offset${x} % 4u;\n          ${resStr}[${x}] = ${typeCast}(${data.getByOffset(`index${x}`)}[component${x}]);\n        `;\n      assignment = `\n        let outputOffset = global_idx * ${components};\n        var value = vec4<u32>(0);\n        ${singleAssignment('value', 0, 'u32')}\n        ${singleAssignment('value', 1, 'u32')}\n        ${singleAssignment('value', 2, 'u32')}\n        ${singleAssignment('value', 3, 'u32')}\n        ${output.setByOffset('global_idx', 'value')}\n      `;\n    } else {\n      assignment = `\n      let outputIndices = ${output.offsetToIndices('global_idx')};\n      ${calcDataIndices('')};\n      let value = ${data.getByIndices('dataIndices')};\n      ${output.setByOffset('global_idx', 'value')};\n      `;\n    }\n    return `\n      ${shaderHelper\n        .registerUniform('outputSize', 'u32')\n        .registerUniform('axisDimLimit', 'i32')\n        .registerUniform('axis', 'u32')\n        .declareVariables(data, indices, output)}\n      ${shaderHelper.mainStart()}\n        ${shaderHelper.guardAgainstOutOfBoundsWorkgroupSizes('uniforms.outputSize')}\n        ${assignment}\n      }`;\n  };\n  return {\n    name: 'Gather',\n    shaderCache: { hint: attributes.cacheKey, inputDependencies: ['rank', 'rank'] },\n    getRunData: () => ({\n      outputs: [{ dims: outputShape, dataType: inputs[0].dataType }],\n      dispatchGroup: { x: Math.ceil(outputSize / 64 /* workgroup size */) },\n      programUniforms,\n    }),\n    getShaderSource,\n  };\n};\n\nexport const parseGatherAttributes = (attributes: Record<string, unknown>): GatherAttributes =>\n  createAttributeWithCacheKey({ axis: attributes.axis as number });\n\nexport const gather = (context: ComputeContext, attributes: GatherAttributes): void => {\n  const inputs = context.inputs;\n  validateInputs(inputs);\n  context.compute(createGatherProgramInfo(context.inputs, attributes));\n};\n","// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport { DataType } from '../../../wasm-common';\nimport { TensorView } from '../../tensor-view';\nimport { ShapeUtil } from '../../util';\nimport { AttributeWithCacheKey } from '../attribute-with-cache-key';\nimport { ComputeContext, ProgramUniform } from '../types';\n\nimport { createTensorShapeVariables, inputVariable, outputVariable, ShaderHelper, UniformsArrayType } from './common';\n\nexport interface GatherNDAttributes extends AttributeWithCacheKey {\n  readonly batchDims: number;\n}\n\nconst computeSliceOffsets = (\n  context: ComputeContext,\n  indicesData: TensorView,\n  sizesFromSliceDimsData: number[],\n  batchDims: number,\n  inputDims: readonly number[],\n  numSlices: number,\n  numSlicesPerBatch: number,\n  inputBatchStride: number,\n  numSliceDims: number,\n) => {\n  const programUniforms: ProgramUniform[] = [\n    { type: DataType.uint32, data: numSlices },\n    { type: DataType.uint32, data: batchDims },\n    { type: DataType.uint32, data: inputDims },\n    { type: DataType.uint32, data: sizesFromSliceDimsData },\n    { type: DataType.uint32, data: numSlicesPerBatch },\n    { type: DataType.uint32, data: inputBatchStride },\n    { type: DataType.uint32, data: numSliceDims },\n  ];\n\n  const outputShape = [numSlices];\n  programUniforms.push(...createTensorShapeVariables(indicesData.dims, outputShape));\n\n  const getShaderSource = (shaderHelper: ShaderHelper) => {\n    const indices = inputVariable('indices_data', indicesData.dataType, indicesData.dims.length);\n    const output = outputVariable('input_slice_offsets_data', DataType.uint32, 1, 1);\n    const variables = [indices, output];\n    const uniforms: UniformsArrayType = [\n      { name: 'output_size', type: 'u32' },\n      { name: 'batch_dims', type: 'u32' },\n      { name: 'input_dims', type: 'u32', length: inputDims.length },\n      { name: 'sizes_from_slice_dims_data', type: 'u32', length: sizesFromSliceDimsData.length },\n      { name: 'num_slices_per_batch', type: 'u32' },\n      { name: 'input_batch_stride', type: 'u32' },\n      { name: 'num_slice_dims', type: 'u32' },\n    ];\n    return `\n  ${shaderHelper.registerUniforms(uniforms).declareVariables(...variables)}\n  ${shaderHelper.mainStart()}\n    ${shaderHelper.guardAgainstOutOfBoundsWorkgroupSizes('uniforms.output_size')}\n    let batch_idx = global_idx / uniforms.num_slices_per_batch;\n    let base_offset = batch_idx * uniforms.input_batch_stride;\n\n    let slice_indices_base_offset = global_idx * uniforms.num_slice_dims;\n    var relative_slice_offset = 0;\n    for (var dim_idx = 0u; dim_idx < uniforms.num_slice_dims; dim_idx ++) {\n      var index = i32(indices_data[dim_idx + slice_indices_base_offset].x);\n      let input_dim_idx = uniforms.batch_dims + dim_idx;\n      if (index < 0) {\n        ${\n          inputDims.length === 1\n            ? 'index += i32(uniforms.input_dims);'\n            : 'index += i32(uniforms.input_dims[input_dim_idx]);'\n        }\n      }\n      ${\n        sizesFromSliceDimsData.length === 1\n          ? 'relative_slice_offset += index * i32(uniforms.sizes_from_slice_dims_data);'\n          : 'relative_slice_offset += index * i32(uniforms.sizes_from_slice_dims_data[dim_idx]);'\n      }\n    }\n\n    input_slice_offsets_data[global_idx] =  base_offset + u32(relative_slice_offset);\n  }`;\n  };\n\n  return context.compute(\n    {\n      name: 'computeSliceOffsets',\n      shaderCache: { hint: `${inputDims.length}_${sizesFromSliceDimsData.length}`, inputDependencies: ['rank'] },\n      getRunData: () => ({\n        outputs: [{ dims: outputShape, dataType: context.inputs[1].dataType }],\n        dispatchGroup: { x: Math.ceil(numSlices / 64) },\n        programUniforms,\n      }),\n      getShaderSource,\n    },\n    { inputs: [indicesData], outputs: [-1] },\n  )[0];\n};\n\nexport const gatherND = (context: ComputeContext, attributes: GatherNDAttributes) => {\n  const inputs = context.inputs;\n  const inputShape = inputs[0].dims;\n  const inputType = inputs[0].dataType;\n  const indicesShape = inputs[1].dims;\n  const numSliceDims = indicesShape[indicesShape.length - 1];\n  const numSlices = ShapeUtil.sizeToDimension(indicesShape, indicesShape.length - 1);\n  const sliceSize = ShapeUtil.sizeFromDimension(inputShape, attributes.batchDims + numSliceDims);\n  const numBatches = ShapeUtil.sizeToDimension(inputShape, attributes.batchDims);\n  const inputBatchStride = ShapeUtil.sizeFromDimension(inputShape, attributes.batchDims);\n  const numSlicesPerBatch = numSlices / numBatches;\n  const sizesFromSliceDims = new Array(numSliceDims);\n  let runningProduct = sliceSize;\n  for (let i = 0; i < numSliceDims; ++i) {\n    sizesFromSliceDims[numSliceDims - 1 - i] = runningProduct;\n    runningProduct *= inputShape[attributes.batchDims + numSliceDims - 1 - i];\n  }\n\n  const inputSliceOffsets = computeSliceOffsets(\n    context,\n    inputs[1],\n    sizesFromSliceDims,\n    attributes.batchDims,\n    inputShape,\n    numSlices,\n    numSlicesPerBatch,\n    inputBatchStride,\n    numSliceDims,\n  );\n\n  const lastIndicesDimension = attributes.batchDims + numSliceDims;\n  if (lastIndicesDimension > inputShape.length) {\n    throw new Error('last dimension of indices must not be larger than rank of input tensor');\n  }\n\n  const outputShape = indicesShape.slice(0, -1).concat(inputShape.slice(lastIndicesDimension));\n  const outputSize = ShapeUtil.size(outputShape);\n\n  const programUniforms: ProgramUniform[] = [\n    { type: DataType.uint32, data: outputSize },\n    { type: DataType.uint32, data: sliceSize },\n    ...createTensorShapeVariables(inputs[0].dims, inputSliceOffsets.dims, outputShape),\n  ];\n\n  const getShaderSource = (shaderHelper: ShaderHelper) => {\n    const input = inputVariable('data', inputs[0].dataType, inputs[0].dims.length);\n    const indices = inputVariable('slice_offsets', DataType.uint32, inputSliceOffsets.dims.length);\n\n    const output = outputVariable('output', inputs[0].dataType, outputShape.length);\n    return `\n          ${shaderHelper\n            .registerUniform('output_size', 'u32')\n            .registerUniform('slice_size', 'u32')\n            .declareVariables(input, indices, output)}\n            ${shaderHelper.mainStart()}\n            ${shaderHelper.guardAgainstOutOfBoundsWorkgroupSizes('uniforms.output_size')}\n          let slice_offset = slice_offsets[global_idx / uniforms.slice_size];\n          output[global_idx] = data[u32(slice_offset) + global_idx % uniforms.slice_size];\n        }`;\n  };\n  context.compute(\n    {\n      name: 'GatherND',\n      shaderCache: { hint: attributes.cacheKey, inputDependencies: ['rank', 'rank'] },\n      getRunData: () => ({\n        outputs: [{ dims: outputShape, dataType: inputType }],\n        dispatchGroup: { x: Math.ceil(outputSize / 64 /* workgroup size */) },\n        programUniforms,\n      }),\n      getShaderSource,\n    },\n    { inputs: [inputs[0], inputSliceOffsets] },\n  );\n};\n\nexport const parseGatherNDAttributes = (attributes: Record<string, unknown>): GatherNDAttributes => {\n  const batchDims = attributes.batch_dims as number;\n  return {\n    batchDims,\n    cacheKey: '',\n  };\n};\n","// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport { DataType } from '../../../wasm-common';\nimport { TensorView } from '../../tensor-view';\nimport { ShapeUtil } from '../../util';\nimport { AttributeWithCacheKey, createAttributeWithCacheKey } from '../attribute-with-cache-key';\nimport { ComputeContext, ProgramInfo, ProgramUniform } from '../types';\n\nimport {\n  createTensorShapeVariables,\n  inputVariable,\n  outputVariable,\n  ShaderHelper,\n  tensorTypeToWsglValueType,\n  UniformsArrayType,\n} from './common';\n\nexport interface GatherBlockQuantizedAttributes extends AttributeWithCacheKey {\n  gatherAxis: number;\n  quantizeAxis: number;\n  blockSize: number;\n}\n\nexport const validateInputs = (inputs: readonly TensorView[], attributes: GatherBlockQuantizedAttributes): void => {\n  if (inputs.length < 3 || inputs.length > 4) {\n    throw new Error('GatherBlockQuantized requires 3 or 4 inputs.');\n  }\n  const quantizeAxis = ShapeUtil.normalizeAxis(attributes.quantizeAxis, inputs[0].dims.length);\n  const blockSize = attributes.blockSize;\n  const data = inputs[0];\n  const scales = inputs[2];\n  const zeroPoint = inputs.length === 4 ? inputs[3] : undefined;\n  if (\n    scales.dims.length !== data.dims.length ||\n    !data.dims\n      .map((d, i) => (i === quantizeAxis ? Math.ceil(d / blockSize) === scales.dims[i] : d === scales.dims[i]))\n      .reduce((a, b) => a && b, true)\n  ) {\n    throw new Error(\n      'Scales must have the same rank as the input tensor and the dims should match except on gatherAxis.',\n    );\n  }\n  // TODO Uncomment the following check once the test case creation code is fixed to create data correctly aligned.\n  // const indices = inputs[1];\n  // const validIndex = (index: number) => index >= 0 && index < data.dims[attributes.gatherAxis];\n  // if (indices.dataType === DataType.int32 && indices.getInt32Array().some((v) => !validIndex(v)) ||\n  //     indices.dataType === DataType.int64 && indices.getBigInt64Array().some((v) => !validIndex(Number(v)))) {\n  //   throw new Error('Indices must be within the bounds of the gatherAxis.');\n  // }\n  if (zeroPoint) {\n    if (zeroPoint.dataType !== data.dataType) {\n      throw new Error('Zero point must have the same data type as the input tensor.');\n    }\n    if (\n      zeroPoint.dims.length !== scales.dims.length ||\n      !zeroPoint.dims.map((d, i) => d === scales.dims[i]).reduce((a, b) => a && b, true)\n    ) {\n      throw new Error(\n        'Zero point must have the same rank as the input tensor and the dims should match except on quantizeAxis.',\n      );\n    }\n  }\n};\n\nconst createGatherBlockQuantizedProgramInfo = (\n  inputs: readonly TensorView[],\n  attributes: GatherBlockQuantizedAttributes,\n): ProgramInfo => {\n  const inputShape = inputs[0].dims;\n  const indicesShape = inputs[1].dims;\n  const inputRank = inputShape.length;\n  const gatherAxis = ShapeUtil.normalizeAxis(attributes.gatherAxis, inputRank);\n  const quantizeAxis = ShapeUtil.normalizeAxis(attributes.quantizeAxis, inputRank);\n  const outputShape = inputShape.slice(0);\n  outputShape.splice(gatherAxis, 1, ...indicesShape);\n  const outputSize = ShapeUtil.size(outputShape);\n  const outputType = inputs[2].dataType;\n  const inputType = inputs[0].dataType;\n  const isSigned = inputType === DataType.int4; // input data type is either int4 or uint4.\n  const programUniforms: ProgramUniform[] = [\n    { type: DataType.uint32, data: outputSize },\n    { type: DataType.uint32, data: quantizeAxis },\n    { type: DataType.uint32, data: gatherAxis },\n    { type: DataType.uint32, data: attributes.blockSize },\n    ...createTensorShapeVariables(...inputs.map((input, _) => input.dims), outputShape),\n  ];\n\n  const getShaderSource = (shaderHelper: ShaderHelper) => {\n    const data = inputVariable('data', inputs[0].dataType, inputs[0].dims.length);\n    const indices = inputVariable('inputIndices', inputs[1].dataType, inputs[1].dims.length);\n    const scales = inputVariable('scales', inputs[2].dataType, inputs[2].dims.length);\n    const zeroPoint =\n      inputs.length > 3 ? inputVariable('zeroPoint', inputs[3].dataType, inputs[3].dims.length) : undefined;\n    const output = outputVariable('output', outputType, outputShape.length);\n    const inputVariables = [data, indices, scales];\n    if (zeroPoint) {\n      inputVariables.push(zeroPoint);\n    }\n    const uniforms: UniformsArrayType = [\n      { name: 'output_size', type: 'u32' },\n      { name: 'quantize_axis', type: 'u32' },\n      { name: 'gather_axis', type: 'u32' },\n      { name: 'block_size', type: 'u32' },\n    ];\n    return `\n        ${shaderHelper.registerUniforms(uniforms).declareVariables(...inputVariables, output)}\n        ${shaderHelper.mainStart()}\n        let output_indices = ${output.offsetToIndices('global_idx')};\n        var indices_indices = ${indices.type.indices}(0);\n        ${(() => {\n          if (indicesShape.length > 1) {\n            return `\n          for (var i: u32 = 0; i < ${indicesShape.length}; i++) {\n            let index = ${output.indicesGet('output_indices', 'uniforms.gather_axis + i')};\n            ${indices.indicesSet('indices_indices', 'i', 'index')};\n          }`;\n          } else {\n            return `indices_indices = ${output.indicesGet('output_indices', 'uniforms.gather_axis')};`;\n          }\n        })()};\n        var data_indices = ${data.type.indices}(0);\n        for (var i: u32 = 0; i < uniforms.gather_axis; i++) {\n          let index = ${output.indicesGet('output_indices', 'i')};\n          ${data.indicesSet('data_indices', 'i', 'index')};\n        }\n        var index_from_indices = ${indices.getByIndices('indices_indices')};\n        if (index_from_indices < 0) {\n          index_from_indices += ${inputShape[gatherAxis]};\n        }\n        ${data.indicesSet('data_indices', 'uniforms.gather_axis', 'u32(index_from_indices)')};\n        for (var i = uniforms.gather_axis + 1; i < ${outputShape.length}; i++) {\n          let index = ${output.indicesGet('output_indices', `i + ${indicesShape.length} - 1`)};\n          ${data.indicesSet('data_indices', 'i', 'index')};\n        }\n        let data_offset = ${data.indicesToOffset('data_indices')};\n        let data_index = data_offset % 8;\n        // Convert 4-bit packed data to 8-bit packed data.\n        let packed_4bit_quantized_data = ${data.getByOffset('data_offset / 8')};\n        let packed_8bit_quantized_data = (packed_4bit_quantized_data >> (4 * (data_index % 2))) & 0x0f0f0f0f;\n        let quantized_data_vec = ${isSigned ? 'unpack4xI8' : 'unpack4xU8'}(u32(packed_8bit_quantized_data));\n        let quantized_data = quantized_data_vec[data_index / 2];\n        var scale_indices = data_indices;\n        let quantize_axis_index = ${scales.indicesGet('data_indices', 'uniforms.quantize_axis')} / uniforms.block_size;\n        ${scales.indicesSet('scale_indices', 'uniforms.quantize_axis', 'quantize_axis_index')};\n        var scale = ${scales.getByIndices('scale_indices')};\n        ${(() => {\n          if (!zeroPoint) {\n            return 'var zero_point = 0';\n          } else {\n            return `\n              let zero_point_indices = scale_indices;\n              let zero_point_offset = ${zeroPoint.indicesToOffset('zero_point_indices')};\n              let zero_point_index = zero_point_offset % 8;\n              let packed_4bit_zero_points = ${zeroPoint.getByOffset('zero_point_offset / 8')};\n              let packed_8bit_zero_points = (packed_4bit_zero_points >> (4 * (zero_point_index % 2))) & 0x0f0f0f0f;\n              let zero_point_vec = ${isSigned ? 'unpack4xI8' : 'unpack4xU8'}(u32(packed_8bit_zero_points));\n              let zero_point = zero_point_vec[zero_point_index / 2];`;\n          }\n        })()};\n        let dequantized_data = ${tensorTypeToWsglValueType(outputType)}(quantized_data - zero_point) * scale;\n        ${output.setByOffset('global_idx', 'dequantized_data')};\n    }`;\n  };\n  return {\n    name: 'GatherBlockQuantized',\n    shaderCache: {\n      hint: `${attributes.cacheKey};${inputs\n        .filter((_, i) => i !== 1)\n        .map((input) => input.dims.join('_'))\n        .join(';')}`,\n      inputDependencies: Array.from({ length: inputs.length }, (_v, _i) => 'rank'),\n    },\n    getRunData: () => ({\n      outputs: [{ dims: outputShape, dataType: outputType }],\n      dispatchGroup: { x: Math.ceil(outputSize / 64 /* workgroup size */) },\n      programUniforms,\n    }),\n    getShaderSource,\n  };\n};\n\nexport const gatherBlockQuantized = (context: ComputeContext, attributes: GatherBlockQuantizedAttributes): void => {\n  const inputs = context.inputs;\n  validateInputs(inputs, attributes);\n  context.compute(createGatherBlockQuantizedProgramInfo(context.inputs, attributes));\n};\n\nexport const parseGatherBlockQuantizedAttributes = (\n  attributes: Record<string, unknown>,\n): GatherBlockQuantizedAttributes =>\n  createAttributeWithCacheKey({\n    blockSize: attributes.blockSize as number,\n    gatherAxis: attributes.gatherAxis as number,\n    quantizeAxis: attributes.quantizeAxis as number,\n  });\n","// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport { DataType } from '../../../wasm-common';\nimport { TensorView } from '../../tensor-view';\nimport { ShapeUtil } from '../../util';\nimport { AttributeWithCacheKey, createAttributeWithCacheKey } from '../attribute-with-cache-key';\nimport { ComputeContext, ProgramInfo, ProgramInputTensorInfoDependency, ProgramUniform } from '../types';\n\nimport { createTensorShapeVariables, inputVariable, outputVariable, ShaderHelper } from './common';\n\nexport interface GatherElementsAttributes extends AttributeWithCacheKey {\n  axis: number;\n}\n\nconst validateInputs = (inputs: readonly TensorView[]): void => {\n  if (!inputs || inputs.length !== 2) {\n    throw new Error('GatherElements requires 2 inputs.');\n  }\n\n  if (inputs[0].dims.length < 1) {\n    throw new Error('GatherElements requires that the data input be rank >= 1.');\n  }\n\n  if (inputs[0].dims.length !== inputs[1].dims.length) {\n    throw new Error(`GatherElements requires that the data input and\n                     indices input tensors be of same rank.`);\n  }\n};\n\nconst createGatherElementsProgramInfo = (\n  inputs: readonly TensorView[],\n  attributes: GatherElementsAttributes,\n): ProgramInfo => {\n  const inputShape = inputs[0].dims;\n  const inputOutputDataType = inputs[0].dataType;\n  const inputRank = inputShape.length;\n\n  const indicesShape = inputs[1].dims;\n  const indicesDataType = inputs[1].dataType;\n  const axis = ShapeUtil.normalizeAxis(attributes.axis, inputRank);\n  const axisDimLimit = inputShape[axis];\n\n  const outputShape = indicesShape.slice(0);\n  const outputSize = ShapeUtil.size(outputShape);\n\n  const input = inputVariable('input', inputOutputDataType, inputRank);\n  const indices = inputVariable('indicesInput', indicesDataType, indicesShape.length);\n  const output = outputVariable('output', inputOutputDataType, outputShape.length);\n\n  const programUniforms: ProgramUniform[] = [\n    { type: DataType.uint32, data: outputSize },\n    { type: DataType.int32, data: axisDimLimit },\n    { type: DataType.uint32, data: axis },\n  ];\n  programUniforms.push(...createTensorShapeVariables(inputShape, indicesShape, outputShape));\n  const inputDependencies: ProgramInputTensorInfoDependency[] = ['rank', 'rank'];\n\n  // int64 indices would be treated as little endian i32 with assumption they fall in i32 limits\n  // That assumption is safe as it's not possible to allocate >2gb buffer for input tensor\n  // Input data will be treated as u32 or two u32 for 8-byte tensors\n  const getShaderSource = (shaderHelper: ShaderHelper) => `\n      ${shaderHelper\n        .registerUniform('outputSize', 'u32')\n        .registerUniform('axisDimLimit', 'i32')\n        .registerUniform('axis', 'u32')\n        .declareVariables(input, indices, output)}\n      ${shaderHelper.mainStart()}\n      ${shaderHelper.guardAgainstOutOfBoundsWorkgroupSizes('uniforms.outputSize')}\n\n      let outputIndices = ${output.offsetToIndices('global_idx')};\n\n      var idx = ${indices.getByOffset('global_idx')};\n      if (idx < 0) {\n        idx = idx + uniforms.axisDimLimit;\n      }\n      var inputIndices = ${input.type.indices}(outputIndices);\n      ${input.indicesSet('inputIndices', 'uniforms.axis', 'u32(idx)')};\n      let value = ${input.getByIndices('inputIndices')};\n\n      ${output.setByOffset('global_idx', 'value')};\n  }`;\n\n  return {\n    name: 'GatherElements',\n    shaderCache: { inputDependencies },\n    getRunData: () => ({\n      outputs: [{ dims: outputShape, dataType: inputs[0].dataType }],\n      dispatchGroup: { x: Math.ceil(outputSize / 64 /* workgroup size */) },\n      programUniforms,\n    }),\n    getShaderSource,\n  };\n};\n\nexport const parseGatherElementsAttributes = (attributes: Record<string, unknown>): GatherElementsAttributes =>\n  createAttributeWithCacheKey({ axis: attributes.axis as number });\n\nexport const gatherElements = (context: ComputeContext, attributes: GatherElementsAttributes): void => {\n  const inputs = context.inputs;\n  validateInputs(inputs);\n  context.compute(createGatherElementsProgramInfo(context.inputs, attributes));\n};\n","// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport { DataType } from '../../../wasm-common';\nimport { TensorView } from '../../tensor-view';\nimport { GemmUtil, ShapeUtil } from '../../util';\nimport { AttributeWithCacheKey } from '../attribute-with-cache-key';\nimport { ComputeContext, ProgramInfo, ProgramInputTensorInfoDependency, ProgramUniform } from '../types';\n\nimport {\n  createTensorShapeVariables,\n  IndicesHelper,\n  inputVariable,\n  outputVariable,\n  ShaderHelper,\n  UniformsArrayType,\n} from './common';\n\nconst validateInputs = (inputs: readonly TensorView[]): void => {\n  if (!inputs) {\n    throw new Error('Input is missing');\n  }\n  if (inputs.length < 2 || inputs.length > 3) {\n    throw new Error('Invaid input number.');\n  }\n\n  // 'C' can be of dimensionality 0, 1 or 2 only\n  if (inputs.length === 3 && inputs[2].dims.length > 2) {\n    throw new Error('Invalid input shape of C');\n  }\n\n  if (inputs[0].dataType !== inputs[1].dataType || (inputs.length === 3 && inputs[0].dataType !== inputs[2].dataType)) {\n    throw new Error('Input types are mismatched');\n  }\n};\n\nexport interface GemmAttributes extends AttributeWithCacheKey {\n  transA: boolean;\n  transB: boolean;\n  alpha: number;\n  beta: number;\n}\n\nconst createGemmProgramInfo = (inputs: readonly TensorView[], attributes: GemmAttributes): ProgramInfo => {\n  const aShape = inputs[0].dims.slice();\n  const bShape = inputs[1].dims.slice();\n  const [M, N, K] = GemmUtil.getShapeOfGemmResult(\n    aShape,\n    attributes.transA,\n    bShape,\n    attributes.transB,\n    inputs.length === 3 ? inputs[2].dims : undefined,\n  );\n  const outputShape = [M, N];\n  if (!outputShape) {\n    throw new Error(\"Can't use gemm on the given tensors\");\n  }\n  const tileSize = 16;\n  const numTileN = Math.ceil(N / tileSize);\n  const numTileM = Math.ceil(M / tileSize);\n  // TODO: Find the condition when to use the naive one.\n  const useShared = true;\n\n  const outputSize = ShapeUtil.size(outputShape);\n  const programUniforms: ProgramUniform[] = [\n    { type: DataType.uint32, data: useShared ? numTileN : outputSize },\n    { type: DataType.uint32, data: M },\n    { type: DataType.uint32, data: N },\n    { type: DataType.uint32, data: K },\n    { type: DataType.float, data: attributes.alpha },\n    { type: DataType.float, data: attributes.beta },\n  ];\n  const inputDependencies: ProgramInputTensorInfoDependency[] = ['type', 'type'];\n  if (inputs.length === 3) {\n    programUniforms.push(...createTensorShapeVariables(inputs[2].dims));\n    inputDependencies.push('rank');\n  }\n  programUniforms.push(...createTensorShapeVariables(outputShape));\n\n  const getShaderSource = (shaderHelper: ShaderHelper) => {\n    let line = '';\n    if (attributes.transA && attributes.transB) {\n      line = 'value += a[k * uniforms.M + m] * b[n * uniforms.K + k];';\n    } else if (attributes.transA && !attributes.transB) {\n      line = 'value += a[k * uniforms.M + m] * b[k * uniforms.N + n];';\n    } else if (!attributes.transA && attributes.transB) {\n      line = 'value += a[m * uniforms.K + k] * b[n * uniforms.K + k];';\n    } else if (!attributes.transA && !attributes.transB) {\n      line = 'value += a[m * uniforms.K + k] * b[k * uniforms.N + n];';\n    }\n\n    const calculateAlpha = attributes.alpha === 1 ? '' : 'value *= uniforms.alpha;';\n    const a = inputVariable('a', inputs[0].dataType, inputs[0].dims);\n    const b = inputVariable('b', inputs[1].dataType, inputs[1].dims);\n    const dataType = a.type.value;\n    let c: IndicesHelper | null = null;\n    const variables = [a, b];\n    if (inputs.length === 3) {\n      c = inputVariable('c', inputs[2].dataType, inputs[2].dims.length);\n      variables.push(c);\n    }\n    const output = outputVariable('output', inputs[0].dataType, outputShape.length);\n    variables.push(output);\n    const uniforms: UniformsArrayType = [\n      { name: 'output_size', type: 'u32' },\n      { name: 'M', type: 'u32' },\n      { name: 'N', type: 'u32' },\n      { name: 'K', type: 'u32' },\n      { name: 'alpha', type: 'f32' },\n      { name: 'beta', type: 'f32' },\n    ];\n    return `\n  ${shaderHelper.registerUniforms(uniforms).declareVariables(...variables)}\n\n  ${shaderHelper.mainStart()}\n    ${shaderHelper.guardAgainstOutOfBoundsWorkgroupSizes('uniforms.output_size')}\n\n    let m = global_idx / uniforms.N;\n    let n = global_idx % uniforms.N;\n\n    var value = ${dataType}(0);\n    for (var k: u32 = 0u; k < uniforms.K; k++) {\n      ${line}\n    }\n\n    ${calculateAlpha}\n    ${(() => {\n      if (c != null) {\n        return `let cOffset = ${c.broadcastedIndicesToOffset('vec2(m, n)', output)}; value += ${\n          dataType\n        }(uniforms.beta) * ${c.getByOffset('cOffset')};`;\n      }\n      return '';\n    })()}\n    output[global_idx] = value;\n  }`;\n  };\n\n  const getShaderSourceShared = (shaderHelper: ShaderHelper) => {\n    const a = inputVariable('a', inputs[0].dataType, inputs[0].dims);\n    const b = inputVariable('b', inputs[1].dataType, inputs[1].dims);\n    let c: IndicesHelper | null = null;\n    const variables = [a, b];\n    if (inputs.length === 3) {\n      c = inputVariable('c', inputs[2].dataType, inputs[2].dims.length);\n      variables.push(c);\n    }\n    const output = outputVariable('output', inputs[0].dataType, outputShape.length);\n    variables.push(output);\n    const uniforms: UniformsArrayType = [\n      { name: 'num_tile_n', type: 'u32' },\n      { name: 'M', type: 'u32' },\n      { name: 'N', type: 'u32' },\n      { name: 'K', type: 'u32' },\n      { name: 'alpha', type: 'f32' },\n      { name: 'beta', type: 'f32' },\n    ];\n\n    let calcResult = '';\n    let fillWorkgroupMemory = '';\n    if (attributes.transA && attributes.transB) {\n      fillWorkgroupMemory = `\n      var col = tile_row_start + local_id.x;\n      var row = k_start + local_id.y;\n      if (col < uniforms.M && row < uniforms.K) {\n        tile_a[local_id.y][local_id.x] = a[row * uniforms.M + col];\n      } else {\n        tile_a[local_id.y][local_id.x] = ${a.type.value}(0);\n      }\n\n      col = k_start + local_id.x;\n      row = tile_col_start + local_id.y;\n      if (col < uniforms.K && row < uniforms.N) {\n        tile_b[local_id.y][local_id.x] = b[row * uniforms.K + col];\n      } else {\n        tile_b[local_id.y][local_id.x] = ${b.type.value}(0);\n      }\n      `;\n      calcResult = `value += tile_a[k][local_id.y] * tile_b[local_id.x][k];`;\n    } else if (attributes.transA && !attributes.transB) {\n      fillWorkgroupMemory = `\n      var col = tile_row_start + local_id.x;\n      var row = k_start + local_id.y;\n      if (col < uniforms.M && row < uniforms.K) {\n        tile_a[local_id.y][local_id.x] = a[row * uniforms.M + col];\n      } else {\n        tile_a[local_id.y][local_id.x] = ${a.type.value}(0);\n      }\n\n      col = tile_col_start + local_id.x;\n      row = k_start + local_id.y;\n      if (col < uniforms.N && row < uniforms.K) {\n        tile_b[local_id.y][local_id.x] = b[row * uniforms.N + col];\n      } else {\n        tile_b[local_id.y][local_id.x] = ${b.type.value}(0);\n      }\n      `;\n      calcResult = `value += tile_a[k][local_id.y] * tile_b[k][local_id.x];`;\n    } else if (!attributes.transA && attributes.transB) {\n      fillWorkgroupMemory = `\n      var col = k_start + local_id.x;\n      var row = tile_row_start + local_id.y;\n      if (col < uniforms.K && row < uniforms.M) {\n        tile_a[local_id.y][local_id.x] = a[row * uniforms.K + col];\n      } else {\n        tile_a[local_id.y][local_id.x] = ${a.type.value}(0);\n      }\n\n      col = k_start + local_id.x;\n      row = tile_col_start + local_id.y;\n      if (col < uniforms.K && row < uniforms.N) {\n        tile_b[local_id.y][local_id.x] = b[row * uniforms.K + col];\n      } else {\n        tile_b[local_id.y][local_id.x] = ${b.type.value}(0);\n      }\n      `;\n      calcResult = `value += tile_a[local_id.y][k] * tile_b[local_id.x][k];`;\n    } else if (!attributes.transA && !attributes.transB) {\n      fillWorkgroupMemory = `\n      var col = k_start + local_id.x;\n      var row = tile_row_start + local_id.y;\n      if (col < uniforms.K && row < uniforms.M) {\n        tile_a[local_id.y][local_id.x] = a[row * uniforms.K + col];\n      } else {\n        tile_a[local_id.y][local_id.x] = ${a.type.value}(0);\n      }\n\n      col = tile_col_start + local_id.x;\n      row = k_start + local_id.y;\n      if (col < uniforms.N && row < uniforms.K) {\n        tile_b[local_id.y][local_id.x] = b[row * uniforms.N + col];\n      } else {\n        tile_b[local_id.y][local_id.x] = ${b.type.value}(0);\n      }\n      `;\n      calcResult = `value += tile_a[local_id.y][k] * tile_b[k][local_id.x];`;\n    }\n\n    const calculateAlpha = attributes.alpha === 1 ? '' : 'value *= uniforms.alpha;';\n\n    return `\n  ${shaderHelper.registerUniforms(uniforms).declareVariables(...variables)}\n  var<workgroup> tile_a: array<array<${a.type.storage}, ${tileSize}>, ${tileSize}>;\n  var<workgroup> tile_b: array<array<${b.type.storage}, ${tileSize}>, ${tileSize}>;\n  ${shaderHelper.mainStart([tileSize, tileSize, 1])}\n    let tile_col_start = (workgroup_index % uniforms.num_tile_n) * ${tileSize};\n    let tile_row_start = (workgroup_index / uniforms.num_tile_n) * ${tileSize};\n    let num_tiles = (uniforms.K - 1) / ${tileSize} + 1;\n    var k_start = 0u;\n    var value = ${output.type.value}(0);\n    for (var t: u32 = 0u; t < num_tiles; t++) {\n      ${fillWorkgroupMemory}\n      k_start = k_start + ${tileSize};\n      workgroupBarrier();\n\n      for (var k: u32 = 0u; k < ${tileSize}; k++) {\n        ${calcResult}\n      }\n      workgroupBarrier();\n    }\n\n    ${calculateAlpha}\n    let m = tile_row_start + local_id.y;\n    let n = tile_col_start + local_id.x;\n    ${(() => {\n      if (c != null) {\n        return `let cOffset = ${c.broadcastedIndicesToOffset('vec2(m, n)', output)}; value += ${\n          output.type.value\n        }(uniforms.beta) * ${c.getByOffset('cOffset')};`;\n      }\n      return '';\n    })()}\n    if (m < uniforms.M && n < uniforms.N) {\n      output[m * uniforms.N + n] = value;\n    }\n  }`;\n  };\n\n  if (useShared) {\n    return {\n      name: 'GemmShared',\n      shaderCache: { hint: `${attributes.cacheKey}`, inputDependencies },\n      getRunData: () => ({\n        outputs: [{ dims: outputShape, dataType: inputs[0].dataType }],\n        dispatchGroup: { x: numTileN * numTileM },\n        programUniforms,\n      }),\n      getShaderSource: getShaderSourceShared,\n    };\n  }\n\n  return {\n    name: 'Gemm',\n    shaderCache: { hint: `${attributes.cacheKey}`, inputDependencies },\n    getRunData: () => ({\n      outputs: [{ dims: outputShape, dataType: inputs[0].dataType }],\n      dispatchGroup: { x: Math.ceil(outputSize / 64 /* workgroup size */) },\n      programUniforms,\n    }),\n    getShaderSource,\n  };\n};\n\nexport const parseGemmAttributes = (attributes: Record<string, unknown>): GemmAttributes => {\n  const transA = attributes.transA as boolean;\n  const transB = attributes.transB as boolean;\n  const alpha = attributes.alpha as number;\n  const beta = attributes.beta as number;\n  return {\n    transA,\n    transB,\n    alpha,\n    beta,\n    cacheKey: `${attributes.transA};${attributes.transB};${attributes.alpha === 1}`,\n  };\n};\n\nexport const gemm = (context: ComputeContext, attributes: GemmAttributes): void => {\n  validateInputs(context.inputs);\n  context.compute(createGemmProgramInfo(context.inputs, attributes));\n};\n","// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport { DataType } from '../../../wasm-common';\nimport { TensorView } from '../../tensor-view';\nimport { ShapeUtil } from '../../util';\nimport { AttributeWithCacheKey, createAttributeWithCacheKey } from '../attribute-with-cache-key';\nimport { ComputeContext, ProgramInfo, ProgramUniform } from '../types';\n\nimport { createTensorShapeVariables, IndicesHelper, inputVariable, outputVariable, ShaderHelper } from './common';\n\nlet [idxN, idxC, idxH, idxW] = [0, 1, 2, 3]; // NCHW\ntype Mode = 'bilinear' | 'nearest' | 'bicubic';\ntype PaddingMode = 'zeros' | 'border' | 'reflection';\ntype Format = 'NHWC' | 'NCHW';\nexport interface GridSampeAttributes extends AttributeWithCacheKey {\n  alignCorners: number;\n  mode: Mode;\n  paddingMode: PaddingMode;\n  format: Format;\n}\n\nconst validateInputs = (inputs: readonly TensorView[]): void => {\n  if (inputs[0].dims.length !== 4) {\n    throw new Error('only 4-D tensor is supported.');\n  }\n  if (inputs[0].dims.length !== inputs[1].dims.length) {\n    throw new Error('input dimensions must be equal to grid dimensions');\n  }\n\n  if (inputs[0].dims.length - 2 !== inputs[1].dims[inputs[1].dims.length - 1]) {\n    throw new Error(`last dimension of grid must be equal to ${inputs[0].dims.length - 2}`);\n  }\n\n  if (inputs[0].dims[0] !== inputs[1].dims[0]) {\n    throw new Error('grid batch size must match input batch size');\n  }\n};\n\nconst gsGetCubicCoeffs = `\n  fn gs_get_cubic_coeffs(x: f32) -> vec4<f32> {\n    let cubic_alpha = -0.75f;\n    let x_abs = abs(x);\n    var coeffs: vec4<f32>;\n    coeffs[0] = (((cubic_alpha * (x_abs + 1) - 5 * cubic_alpha) * (x_abs + 1) + 8 * cubic_alpha) * (x_abs + 1) - 4 * cubic_alpha);\n    coeffs[1] = (((cubic_alpha + 2) * x_abs - (cubic_alpha + 3)) * x_abs * x_abs + 1);\n    coeffs[2] = (((cubic_alpha + 2) * (1 - x_abs) - (cubic_alpha + 3)) * (1 - x_abs) * (1 - x_abs) + 1);\n    coeffs[3] = (((cubic_alpha * (2 - x_abs) - 5 * cubic_alpha) * (2 - x_abs) + 8 * cubic_alpha) * (2 - x_abs) - 4 * cubic_alpha);\n    return coeffs;\n  }\n`;\n\nconst gsBicubicInterpolate = (dataType: string): string => `\n  fn gs_bicubic_interpolate(p: mat4x4<${dataType}>, x: f32, y: f32) -> ${dataType} {\n    var v: vec4<f32>;\n    var coeffs = gs_get_cubic_coeffs(x);\n    for (var i = 0; i < 4; i++) {\n      v[i] = coeffs[0] * p[i][0] + coeffs[1] * p[i][1] + coeffs[2] * p[i][2] + coeffs[3] * p[i][3];\n    }\n    coeffs = gs_get_cubic_coeffs(y);\n    let pixel = ${dataType}(coeffs[0] * v[0] + coeffs[1] * v[1] + coeffs[2] * v[2] + coeffs[3] * v[3]);\n    return pixel;\n  }\n`;\n\nconst gsDenormalize = (attributes: GridSampeAttributes): string => `\n  fn gs_denormalize(n: f32, length: i32) -> f32 {\n    ${\n      attributes.alignCorners === 0\n        ? `\n    // alignCorners: false => [-1, 1] to [-0.5, length - 0.5]\n    return ((n + 1.0) * f32(length) - 1.0) / 2.0;\n    `\n        : `\n    // alignCorners: true => [-1, 1] to [0, length - 1]\n    return (n + 1.0) / 2.0 * (f32(length - 1));\n    `\n    }\n  }\n`;\n\nconst gsReflect = (attributes: GridSampeAttributes): string => `\n  ${\n    attributes.paddingMode === 'reflection'\n      ? `\n      fn gs_reflect(x: i32, x_min: f32, x_max: f32) -> u32 {\n        var dx = 0.0;\n        var fx = f32(x);\n        let range = x_max - x_min;\n        if (fx < x_min) {\n          dx = x_min - fx;\n          let n = u32(dx / range);\n          let r = dx - f32(n) * range;\n          if (n % 2 == 0) {\n            fx = x_min + r;\n          } else {\n            fx = x_max - r;\n          }\n        } else if (fx > x_max) {\n          dx = fx - x_max;\n          let n = u32(dx / range);\n          let r = dx - f32(n) * range;\n          if (n % 2 == 0) {\n            fx = x_max - r;\n          } else {\n            fx = x_min + r;\n          }\n        }\n        return u32(fx);\n      }`\n      : ''\n  }\n`;\n\nconst pixelAtGrid = (input: IndicesHelper, dataType: string, attributes: GridSampeAttributes): string =>\n  `\n  fn pixel_at_grid(r: i32, c: i32, H: i32, W: i32, batch: u32, channel: u32, border: vec4<f32>) -> ${dataType} {\n     var pixel = ${dataType}(0);\n     var indices = vec4<u32>(0);\n     indices[${idxN}] = batch;\n     indices[${idxC}] = channel;` +\n  (() => {\n    switch (attributes.paddingMode) {\n      case 'zeros':\n        return `\n          if (r >= 0 && r < H && c >=0 && c < W) {\n            indices[${idxH}] = u32(r);\n            indices[${idxW}] = u32(c);\n          }\n        `;\n      case 'border':\n        return `\n          indices[${idxH}] = u32(clamp(r, 0, H - 1));\n          indices[${idxW}] = u32(clamp(c, 0, W - 1));\n        `;\n      case 'reflection':\n        return `\n          indices[${idxH}] = gs_reflect(r, border[1], border[3]);\n          indices[${idxW}] = gs_reflect(c, border[0], border[2]);\n        `;\n      default:\n        throw new Error(`padding mode ${attributes.paddingMode} is not supported`);\n    }\n  })() +\n  `\n    return ${input.getByIndices('indices')};\n  }\n`;\n\nconst computePixel = (output: IndicesHelper, dataType: string, attributes: GridSampeAttributes): string =>\n  (() => {\n    switch (attributes.mode) {\n      case 'nearest':\n        return `\n          let result = pixel_at_grid(i32(round(y)), i32(round(x)), H_in, W_in, indices[${idxN}], indices[${idxC}], border);\n        `;\n      case 'bilinear':\n        return `\n          let x1 = i32(floor(x));\n          let y1 = i32(floor(y));\n          let x2 = x1 + 1;\n          let y2 = y1 + 1;\n\n          let p11 = pixel_at_grid(y1, x1, H_in, W_in, indices[${idxN}], indices[${idxC}], border);\n          let p12 = pixel_at_grid(y1, x2, H_in, W_in, indices[${idxN}], indices[${idxC}], border);\n          let p21 = pixel_at_grid(y2, x1, H_in, W_in, indices[${idxN}], indices[${idxC}], border);\n          let p22 = pixel_at_grid(y2, x2, H_in, W_in, indices[${idxN}], indices[${idxC}], border);\n\n          let dx2 = ${dataType}(f32(x2) - x);\n          let dx1 = ${dataType}(x - f32(x1));\n          let dy2 = ${dataType}(f32(y2) - y);\n          let dy1 = ${dataType}(y - f32(y1));\n          let result = dy2 * (dx2 * p11 + dx1 * p12) + dy1 * (dx2 * p21 + dx1 * p22);\n        `;\n      case 'bicubic':\n        return `\n          let x0 = i32(floor(x)) - 1;\n          let y0 = i32(floor(y)) - 1;\n          var p: mat4x4<${dataType}>;\n          for (var h = 0; h < 4; h++) {\n            for (var w = 0; w < 4; w++) {\n              p[h][w] = pixel_at_grid(h + y0, w + x0, H_in, W_in, indices[${idxN}], indices[${idxC}], border);\n            }\n          }\n\n          let dx = x - f32(x0 + 1);\n          let dy = y - f32(y0 + 1);\n          let result = gs_bicubic_interpolate(p, dx, dy);\n        `;\n      default:\n        throw new Error(`mode ${attributes.mode} is not supported`);\n    }\n  })() + `${output.setByOffset('global_idx', 'result')}`;\n\nconst createGridSampleProgramInfo = (inputs: readonly TensorView[], attributes: GridSampeAttributes): ProgramInfo => {\n  const x = inputVariable('x', inputs[0].dataType, inputs[0].dims.length);\n  // discard last dimension for using vec2 to access grid data\n  const gridShape = [inputs[1].dims[0], inputs[1].dims[1], inputs[1].dims[2]];\n  const grid = inputVariable('grid', inputs[1].dataType, gridShape.length, 2);\n  let outputShape = [inputs[0].dims[0], inputs[0].dims[1], inputs[1].dims[1], inputs[1].dims[2]];\n  if (attributes.format === 'NHWC') {\n    outputShape = [inputs[0].dims[0], inputs[1].dims[1], inputs[1].dims[2], inputs[0].dims[3]];\n    [idxN, idxC, idxH, idxW] = [0, 3, 1, 2];\n  }\n  const output = outputVariable('output', inputs[0].dataType, outputShape.length);\n  const dataType = x.type.value;\n  const outputSize = ShapeUtil.size(outputShape);\n\n  const programUniforms: ProgramUniform[] = [\n    { type: DataType.uint32, data: outputSize },\n    ...createTensorShapeVariables(inputs[0].dims, gridShape, outputShape),\n  ];\n\n  const getShaderSource = (shaderHelper: ShaderHelper) => `\n  ${shaderHelper.registerUniform('output_size', 'u32').declareVariables(x, grid, output)}\n  ${gsGetCubicCoeffs}\n  ${gsBicubicInterpolate(dataType)}\n  ${gsDenormalize(attributes)}\n  ${gsReflect(attributes)}\n  ${pixelAtGrid(x, dataType, attributes)}\n\n  ${shaderHelper.mainStart()}\n    ${shaderHelper.guardAgainstOutOfBoundsWorkgroupSizes('uniforms.output_size')}\n      let H_in = i32(uniforms.x_shape[${idxH}]);\n      let W_in = i32(uniforms.x_shape[${idxW}]);\n\n      ${\n        attributes.alignCorners === 0\n          ? `\n      let x_min = -0.5;\n      let x_max = f32(W_in) - 0.5;\n      let y_min = -0.5;\n      let y_max = f32(H_in) - 0.5;\n      `\n          : `\n      let x_min = 0.0;\n      let x_max = f32(W_in) - 1.0;\n      let y_min = 0.0;\n      let y_max = f32(H_in) - 1.0;\n      `\n      };\n      let border = vec4<f32>(x_min, y_min, x_max, y_max);\n\n      let indices = ${output.offsetToIndices('global_idx')};\n      var grid_indices = vec3<u32>(indices[${idxN}], indices[${idxH}], indices[${idxW}]);\n      let nxy = ${grid.getByIndices('grid_indices')};\n      var x = gs_denormalize(f32(nxy[0]), W_in);\n      var y = gs_denormalize(f32(nxy[1]), H_in);\n\n      ${computePixel(output, dataType, attributes)}\n  }`;\n\n  return {\n    name: 'GridSample',\n    shaderCache: { hint: `${attributes.cacheKey}`, inputDependencies: ['type', 'type'] },\n    getRunData: (inputs) => {\n      const outputSize = ShapeUtil.size(outputShape);\n      return {\n        outputs: [{ dims: outputShape, dataType: inputs[0].dataType }],\n        dispatchGroup: { x: Math.ceil(outputSize / 64 /* workgroup size */) },\n        programUniforms,\n      };\n    },\n    getShaderSource,\n  };\n};\n\nexport const gridSample = (context: ComputeContext, attributes: GridSampeAttributes): void => {\n  validateInputs(context.inputs);\n  context.compute(createGridSampleProgramInfo(context.inputs, attributes));\n};\n\nexport const parseGridSampleAttributes = (attributes: Record<string, unknown>): GridSampeAttributes =>\n  createAttributeWithCacheKey({\n    alignCorners: attributes.align_corners as number,\n    mode: attributes.mode as Mode,\n    paddingMode: attributes.padding_mode as PaddingMode,\n    format: attributes.format as Format,\n  });\n","// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport { DataType } from '../../../wasm-common';\nimport { TensorView } from '../../tensor-view';\nimport { ShapeUtil } from '../../util';\nimport { createAttributeWithCacheKey } from '../attribute-with-cache-key';\nimport { ComputeContext, GpuDataType, ProgramUniform } from '../types';\n\nimport {\n  applyAttention,\n  AttentionAttrs,\n  AttentionMaskType,\n  AttentionParameters,\n  AttentionQkvFormat,\n} from './attention';\nimport { inputVariable, outputVariable, ShaderHelper, UniformsArrayType } from './common';\nimport { createTransposeProgramInfo, TransposeAttributes } from './transpose';\n\nconst getInput = (inputs: readonly TensorView[], i: number) =>\n  inputs.length > i && inputs[i].dims.length > 0 ? inputs[i] : undefined;\n\nconst validateInputs = (inputs: readonly TensorView[], attributes: AttentionAttrs): AttentionParameters => {\n  const query = inputs[0];\n  const key = getInput(inputs, 1);\n  const value = getInput(inputs, 2);\n  const bias = getInput(inputs, 3);\n  const keyPaddingMask = getInput(inputs, 4);\n  const attentionBias = getInput(inputs, 5);\n  const pastKey = getInput(inputs, 6);\n  const pastValue = getInput(inputs, 7);\n\n  // ---------------------------------------------------------------\n  // Notations:\n  //    B: batch_size\n  //    N: num_heads\n  //    H: head_size of Q and K\n  //    H_v: head_size of V\n  //    D: hidden_size for Q and K, where D = N * H\n  //    D_v: hidden_size of V, where D_v = N * H_v\n  //    S: q_sequence_length\n  //    P: past_sequence_length of kv cache\n  //    L: kv_sequence_length\n  //    T: total_sequence_length = P + L\n  //    M: max_sequence_length of kv cache when past and present share buffer\n  // ---------------------------------------------------------------\n  // MultiHeadAttention inputs:\n  // ---------------------------------------------------------------\n  //  Q_K_V_BSNH - no packing:\n  //     query            (Q)       : (B, S, D)\n  //     key              (K)       : (B, L, D)\n  //     value            (V)       : (B, L, D_v)\n  //  Q_K_V_BSNH_BNSH_BNSH - cross attention (kv cache is not used, L == T, D == D_v):\n  //     query            (Q)       : (B, S, D)\n  //     key              (K)       : (B, N, L, H)\n  //     value            (V)       : (B, N, L, H_v)\n  //  Q_KV_BSNH_BSN2H - packed kv (kv cache is not used, bias is not allowed for packed kv):\n  //     query            (Q)       : (B, S, D)\n  //     key              (K/V)     : (B, L, N, 2, H)\n  //     value                      : None\n  //  QKV_BSN3H - packed qkv (kv cache is not used, S == L, D == D_v):\n  //     query            (Q/K/V)   : (B, S, N, 3, H)\n  //     key                        : None\n  //     value                      : None\n  //\n  //  Other inputs:\n  //     bias             (Q/K/V)   : None or (D + D + D_v)\n  //     key_padding_mask (K/V)     : (B) or (3 * B + 2) or (B, T) or (B, S, T)\n  //     attention_bias             : None or (B, N, S, T), (1, N, S, T), (B, 1, S, T) or (1, 1, S, T)\n  //     past_key                   : (B, N, P, H) or None. Past state is only allowed for Q_K_V_BSNH.\n  //     past_value                 : (B, N, P, H) or None. Past state is only allowed for Q_K_V_BSNH.\n  //\n  //  Not Supported:\n  //     key_padding_mask, packed kv, packed qkv, and broadcast for attention_bias.\n\n  if (query.dims.length !== 3 && query.dims.length !== 5) {\n    throw new Error('Input query is expected to have 3 or 5 dimensions');\n  }\n\n  const batchSize = query.dims[0];\n  const sequenceLength = query.dims[1];\n  const hiddenSize = query.dims.length === 3 ? query.dims[2] : attributes.numHeads * query.dims[4];\n  let kvSequenceLength = sequenceLength;\n\n  let pastSequenceLength = 0;\n  let maxSequenceLength = 0;\n  const headSize = Math.floor(hiddenSize / attributes.numHeads);\n  if (pastKey && pastValue && ShapeUtil.size(pastKey.dims) && ShapeUtil.size(pastValue.dims)) {\n    if (pastKey.dims.length !== 4) {\n      throw new Error('Input \"past_key\" is expected to have 4 dimensions');\n    }\n    if (pastKey.dims[0] !== batchSize || pastKey.dims[1] !== attributes.numHeads || pastKey.dims[3] !== headSize) {\n      throw new Error('Input \"past_key\" shape (batch_size, num_heads, past_sequence_length, head_size)');\n    }\n    if (\n      pastValue.dims[0] !== batchSize ||\n      pastValue.dims[1] !== attributes.numHeads ||\n      pastValue.dims[3] !== headSize\n    ) {\n      throw new Error('Input \"past_value\" shape (batch_size, num_heads, past_sequence_length, head_size)');\n    }\n    if (pastKey.dims[2] !== pastValue.dims[2]) {\n      throw new Error('Input \"past_key\" and \"past_value\" shall have same dim 2 (past_sequence_length)');\n    }\n    if (pastValue.dims.length !== 4) {\n      throw new Error('Input \"past_value\" is expected to have 4 dimensions');\n    }\n    pastSequenceLength = pastKey.dims[2];\n    maxSequenceLength = pastKey.dims[2];\n  } else if ((pastKey && ShapeUtil.size(pastKey.dims)) || (pastValue && ShapeUtil.size(pastValue.dims))) {\n    throw new Error('Input \"past_key\" and \"past_value\" shall be both present or both absent');\n  }\n\n  let qkvFormat: AttentionQkvFormat;\n  if (key && ShapeUtil.size(key.dims) > 0) {\n    if (query.dims.length !== 3) {\n      throw new Error('Input \"query\" is expected to have 3 dimensions when key is given');\n    }\n    if (key.dims.length < 3 || key.dims.length > 5) {\n      throw new Error('Input \"key\" is expected to have 3, 4, or 5 dimensions');\n    }\n    if (query.dims[0] !== key.dims[0]) {\n      throw new Error('Input \"query\" and \"key\" shall have same dim 0 (batch size)');\n    }\n\n    if (key.dims.length === 3) {\n      if (key.dims[2] !== query.dims[2]) {\n        throw new Error('Input \"query\" and \"key\" shall have same dim 2 (hidden_size)');\n      }\n      qkvFormat = AttentionQkvFormat.qkvBSNH;\n      kvSequenceLength = key.dims[1];\n    } else if (key.dims.length === 5) {\n      if (key.dims[2] !== attributes.numHeads || key.dims[3] !== 2 || key.dims[4] !== headSize) {\n        throw new Error('Expect \"key\" shape (batch_size, kv_sequence_length, num_heads, 2, head_size) for packed kv');\n      }\n      if (value) {\n        throw new Error('Expect \"value\" be none when \"key\" has packed kv format.');\n      }\n      qkvFormat = AttentionQkvFormat.qKvBSNHxBSN2H;\n      kvSequenceLength = key.dims[1];\n    } else {\n      // key_dims.size() == 4 (cross-attention with past_key)\n      if (key.dims[1] !== attributes.numHeads || key.dims[3] !== headSize) {\n        throw new Error('Expect \"key\" shape (batch_size, num_heads, kv_sequence_length, head_size) for past_key');\n      }\n\n      qkvFormat = AttentionQkvFormat.unknown; // Q_K_V_BSNH_BNSH_BNSH\n      kvSequenceLength = key.dims[2];\n    }\n  } else {\n    // packed QKV\n    if (query.dims.length !== 5) {\n      throw new Error('Input \"query\" is expected to have 5 dimensions when key is empty');\n    }\n    if (query.dims[2] !== attributes.numHeads || query.dims[3] !== 3) {\n      throw new Error('Expect \"query\" shape (batch_size, kv_sequence_length, num_heads, 3, head_size) for packed kv');\n    }\n\n    qkvFormat = AttentionQkvFormat.qkvBSN3H;\n  }\n\n  if (bias && ShapeUtil.size(bias.dims) > 0) {\n    if (bias.dims.length !== 1) {\n      throw new Error('Input \"bias\" is expected to have 1 dimension');\n    }\n\n    if (key) {\n      if (key.dims.length === 5 && key.dims[3] === 2) {\n        throw new Error('bias is not allowed for packed kv.');\n      }\n    }\n  }\n\n  const totalSequenceLength = pastSequenceLength + kvSequenceLength;\n\n  let maskType: AttentionMaskType = AttentionMaskType.none;\n  if (keyPaddingMask && ShapeUtil.size(keyPaddingMask.dims) > 0) {\n    maskType = AttentionMaskType.maskUnknown;\n    const maskDims = keyPaddingMask.dims;\n    if (maskDims.length === 1) {\n      if (maskDims[0] === batchSize) {\n        maskType = AttentionMaskType.mask1dKeySeqLen;\n      } else if (maskDims[0] === 3 * batchSize + 2) {\n        maskType = AttentionMaskType.mask1DKeySeqLenStart;\n      }\n    } else if (maskDims.length === 2 && maskDims[0] === batchSize && maskDims[1] === totalSequenceLength) {\n      maskType = AttentionMaskType.mask2dKeyPadding;\n    }\n    if (maskType === AttentionMaskType.maskUnknown) {\n      throw new Error('Input \"key_padding_mask\" shape shall be (batch_size) or (batch_size, total_sequence_length)');\n    }\n    throw new Error('Mask not supported');\n  }\n\n  let passPastInKv = false;\n  let vHiddenSize = hiddenSize;\n  if (value && ShapeUtil.size(value.dims) > 0) {\n    if (value.dims.length !== 3 && value.dims.length !== 4) {\n      throw new Error('Input \"value\" is expected to have 3 or 4 dimensions');\n    }\n\n    if (query.dims[0] !== value.dims[0]) {\n      throw new Error('Input \"query\" and \"value\" shall have same dim 0 (batch_size)');\n    }\n\n    if (value.dims.length === 3) {\n      if (kvSequenceLength !== value.dims[1]) {\n        throw new Error('Input \"key\" and \"value\" shall have the same dim 1 (kv_sequence_length)');\n      }\n      vHiddenSize = value.dims[2];\n    } else {\n      // Q_K_V_BSNH_BNSH_BNSH\n      if (kvSequenceLength !== value.dims[2]) {\n        throw new Error('Input \"key\" and \"value\" shall have the same dim 2 (kv_sequence_length)');\n      }\n      vHiddenSize = value.dims[1] * value.dims[3];\n      passPastInKv = true;\n    }\n  }\n\n  const broadcastResPosBias = false;\n\n  if (keyPaddingMask && ShapeUtil.size(keyPaddingMask.dims) > 0) {\n    throw new Error('Key padding mask is not supported');\n  }\n\n  if (attentionBias && ShapeUtil.size(attentionBias.dims) > 0) {\n    if (attentionBias.dims.length !== 4) {\n      throw new Error('Input \"attention_bias\" is expected to have 4 dimensions');\n    }\n\n    // TODO: support broadcasting the first and second dimensions of attention_bias.\n    if (\n      attentionBias.dims[0] !== batchSize ||\n      attentionBias.dims[1] !== attributes.numHeads ||\n      attentionBias.dims[2] !== sequenceLength ||\n      attentionBias.dims[3] !== totalSequenceLength\n    ) {\n      throw new Error('Expect \"attention_bias\" shape (batch_size, num_heads, sequence_length, total_sequence_length)');\n    }\n  }\n\n  return {\n    batchSize,\n    sequenceLength,\n    pastSequenceLength,\n    kvSequenceLength,\n    totalSequenceLength,\n    maxSequenceLength,\n    inputHiddenSize: 0,\n    hiddenSize,\n    vHiddenSize,\n    headSize,\n    vHeadSize: Math.floor(vHiddenSize / attributes.numHeads),\n    numHeads: attributes.numHeads,\n    isUnidirectional: false,\n    pastPresentShareBuffer: false,\n    maskFilterValue: attributes.maskFilterValue,\n    maskType,\n    scale: attributes.scale,\n    broadcastResPosBias,\n    passPastInKv,\n    qkvFormat,\n  };\n};\n\nexport const parseMultiHeadAttentionAttributes = (attributes: AttentionAttrs): AttentionAttrs =>\n  createAttributeWithCacheKey({ ...attributes });\n\nconst weightTransposeAttribute: TransposeAttributes = createAttributeWithCacheKey({ perm: [0, 2, 1, 3] });\n\nconst addBiasTranspose = (\n  context: ComputeContext,\n  qkv: TensorView,\n  bias: TensorView,\n  batchSize: number,\n  sequenceLength: number,\n  hiddenSize: number,\n  biasOffset: number,\n) => {\n  const outputShape = [batchSize, sequenceLength, hiddenSize];\n  const outputSize = ShapeUtil.size(outputShape);\n  const programUniforms: ProgramUniform[] = [\n    { type: DataType.uint32, data: outputSize },\n    { type: DataType.uint32, data: biasOffset },\n    { type: DataType.uint32, data: hiddenSize },\n  ];\n\n  const getShaderSource = (shaderHelper: ShaderHelper) => {\n    const output = outputVariable('qkv_with_bias', qkv.dataType, outputShape);\n    const qkvInput = inputVariable('qkv', qkv.dataType, outputShape);\n    const biasInput = inputVariable('bias', bias.dataType, outputShape);\n\n    const uniforms: UniformsArrayType = [\n      { name: 'output_size', type: 'u32' },\n      { name: 'bias_offset', type: 'u32' },\n      { name: 'hidden_size', type: 'u32' },\n    ];\n    return `\n  ${shaderHelper.registerUniforms(uniforms).declareVariables(qkvInput, biasInput, output)}\n  ${shaderHelper.mainStart()}\n    ${shaderHelper.guardAgainstOutOfBoundsWorkgroupSizes('uniforms.output_size')}\n    let bias_offset_idx = (global_idx % uniforms.hidden_size) + uniforms.bias_offset;\n\n    qkv_with_bias[global_idx] = qkv[global_idx] + bias[bias_offset_idx];\n  }`;\n  };\n\n  return context.compute(\n    {\n      name: 'MultiHeadAttentionAddBias',\n      shaderCache: { inputDependencies: ['type', 'type'] },\n      getRunData: () => ({\n        outputs: [{ dims: outputShape, dataType: qkv.dataType, gpuDataType: GpuDataType.default }],\n        dispatchGroup: { x: Math.ceil(outputSize / 64 /* workgroup size */) },\n        programUniforms,\n      }),\n      getShaderSource,\n    },\n    { inputs: [qkv, bias], outputs: [-1] },\n  )[0];\n};\n\nexport const maybeTransposeToBNSHAndAddBias = (\n  context: ComputeContext,\n  batchSize: number,\n  numHeads: number,\n  sequenceLength: number,\n  headSize: number,\n  input: TensorView,\n  bias?: TensorView,\n  biasOffset?: number,\n) => {\n  // const newDims = [];\n\n  let reshapedInput = input;\n  if (!(bias && ShapeUtil.size(bias.dims) > 0)) {\n    if (input.dims.length === 3) {\n      reshapedInput = input.reshape([batchSize, sequenceLength, numHeads, headSize]);\n    }\n    if (numHeads === 1 || sequenceLength === 1) {\n      return reshapedInput;\n    }\n    return context.compute(createTransposeProgramInfo(reshapedInput, weightTransposeAttribute.perm), {\n      inputs: [reshapedInput],\n      outputs: [-1],\n    })[0];\n  } else {\n    if (sequenceLength === 1) {\n      throw new Error('AddBiasReshape is not implemented. Please export your model with packed QKV or KV');\n    } else {\n      reshapedInput = addBiasTranspose(\n        context,\n        input,\n        bias,\n        batchSize,\n        sequenceLength,\n        numHeads * headSize,\n        biasOffset!,\n      );\n      reshapedInput = reshapedInput.reshape([batchSize, sequenceLength, numHeads, headSize]);\n      if (numHeads === 1 || sequenceLength === 1) {\n        return reshapedInput;\n      }\n      return context.compute(createTransposeProgramInfo(reshapedInput, weightTransposeAttribute.perm), {\n        inputs: [reshapedInput],\n        outputs: [-1],\n      })[0];\n    }\n  }\n};\n\nexport const multiHeadAttention = (context: ComputeContext, attributes: AttentionAttrs): void => {\n  const params = validateInputs(context.inputs, attributes);\n  const query = context.inputs[0];\n  const key = getInput(context.inputs, 1);\n  const value = getInput(context.inputs, 2);\n  const bias = getInput(context.inputs, 3);\n  const keyPaddingMask = getInput(context.inputs, 4);\n  const attentionBias = getInput(context.inputs, 5);\n  const pastKey = getInput(context.inputs, 6);\n  const pastValue = getInput(context.inputs, 7);\n  if (query.dims.length === 5) {\n    throw new Error('Packed QKV is not implemented');\n  }\n\n  if (key?.dims.length === 5) {\n    throw new Error('Packed KV is not implemented');\n  }\n\n  // applyAttention expects BNSH inputs\n  const kvBNSH = key && value && key.dims.length === 4 && value.dims.length === 4;\n\n  const Q = maybeTransposeToBNSHAndAddBias(\n    context,\n    params.batchSize,\n    params.numHeads,\n    params.sequenceLength,\n    params.headSize,\n    query,\n    bias,\n    0,\n  );\n\n  if (kvBNSH) {\n    return applyAttention(context, Q, key, value, keyPaddingMask, undefined, pastKey, pastValue, attentionBias, params);\n  }\n  if (!key || !value) {\n    throw new Error('key and value must be provided');\n  }\n  const K = maybeTransposeToBNSHAndAddBias(\n    context,\n    params.batchSize,\n    params.numHeads,\n    params.kvSequenceLength,\n    params.headSize,\n    key,\n    bias,\n    params.hiddenSize,\n  );\n\n  const V = maybeTransposeToBNSHAndAddBias(\n    context,\n    params.batchSize,\n    params.numHeads,\n    params.kvSequenceLength,\n    params.vHeadSize,\n    value,\n    bias,\n    2 * params.hiddenSize,\n  );\n\n  applyAttention(context, Q, K, V, keyPaddingMask, undefined, pastKey, pastValue, attentionBias, params);\n};\n","// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport { DataType } from '../../../wasm-common';\nimport { TensorView } from '../../tensor-view';\nimport { ShapeUtil } from '../../util';\nimport { AttributeWithCacheKey, createAttributeWithCacheKey } from '../attribute-with-cache-key';\nimport { ComputeContext, ProgramInfo, ProgramUniform, TensorInfo } from '../types';\n\nimport {\n  createTensorShapeVariables,\n  getElementAt,\n  IndicesHelper,\n  inputVariable,\n  outputVariable,\n  ShaderHelper,\n} from './common';\n\nexport interface SplitAttributes extends AttributeWithCacheKey {\n  readonly axis: number;\n  readonly numOutputs: number;\n  readonly splitSizes: number[];\n}\n\nconst validateInputs = (inputs: readonly TensorView[]): void => {\n  if (!inputs || inputs.length < 1) {\n    throw new Error('too few inputs');\n  }\n};\n\nconst createSplitAttributesFromInputs = (\n  inputs: readonly TensorView[],\n  attributes: SplitAttributes,\n): SplitAttributes => {\n  const splitSizes: number[] = [];\n  let numOutputs: number = attributes.numOutputs;\n  if (inputs[1].dims[0] > 0) {\n    inputs[1].getBigInt64Array().forEach((v) => splitSizes.push(Number(v)));\n    numOutputs = splitSizes.length;\n  }\n  return createAttributeWithCacheKey({ numOutputs, axis: attributes.axis, splitSizes });\n};\n\nconst calculateOutputIndexImpl = (numberOfTensors: number): string => `\nfn calculateOutputIndex(index: u32) -> u32 {\n    for (var i: u32 = 0u; i < ${numberOfTensors}u; i += 1u ) {\n    if (index < ${getElementAt('uniforms.size_in_split_axis', 'i', numberOfTensors)}) {\n        return i;\n    }\n    }\n    return ${numberOfTensors}u;\n}`;\nconst writeBufferDataImpl = (outputs: readonly IndicesHelper[]) => {\n  const numberOfTensors = outputs.length;\n  const codeLines: string[] = [];\n  for (let i = 0; i < numberOfTensors; ++i) {\n    const returnSnippet = outputs[i].setByIndices('indices', 'input[global_idx]');\n    if (numberOfTensors === 1) {\n      codeLines.push(returnSnippet);\n    } else if (i === 0) {\n      codeLines.push(`if (output_number == ${i}u) { ${returnSnippet} }`);\n    } else if (i === numberOfTensors - 1) {\n      codeLines.push(`else { ${returnSnippet} }`);\n    } else {\n      codeLines.push(`else if (output_number == ${i}) { ${returnSnippet} }`);\n    }\n  }\n  return `\n      fn writeBufferData(output_number: u32, indices: ${outputs[0].type.indices}, global_idx: u32) {\n        ${codeLines.join('\\n')}\n      }`;\n};\n\nexport const createSplitProgramInfo = (inputs: readonly TensorView[], attributes: SplitAttributes): ProgramInfo => {\n  const inputShape = inputs[0].dims;\n  const inputSize = ShapeUtil.size(inputShape);\n  const dataType = inputs[0].dataType;\n  const axis = ShapeUtil.normalizeAxis(attributes.axis, inputShape.length);\n  const outputs = new Array<IndicesHelper>(attributes.numOutputs);\n  const input = inputVariable('input', dataType, inputShape.length);\n  const sizeInSplitAxis = new Array<number>(attributes.numOutputs);\n  const outputsTensorInfo: TensorInfo[] = [];\n  const outputShapes: number[][] = [];\n  let previousSum = 0;\n  const programUniforms: ProgramUniform[] = [{ type: DataType.uint32, data: inputSize }];\n  for (let i = 0; i < attributes.numOutputs; i++) {\n    previousSum += attributes.splitSizes[i];\n    sizeInSplitAxis[i] = previousSum;\n    const outputShape = inputShape.slice();\n    outputShape[axis] = attributes.splitSizes[i];\n    outputShapes.push(outputShape);\n    outputs[i] = outputVariable(`output${i}`, dataType, outputShape.length);\n    outputsTensorInfo.push({ dims: outputShapes[i], dataType: inputs[0].dataType });\n  }\n  programUniforms.push(\n    { type: DataType.uint32, data: sizeInSplitAxis },\n    ...createTensorShapeVariables(inputShape, ...outputShapes),\n  );\n  const getShaderSource = (shaderHelper: ShaderHelper) => `\n  ${shaderHelper\n    .registerUniform('input_size', 'u32')\n    .registerUniform('size_in_split_axis', 'u32', sizeInSplitAxis.length)\n    .declareVariables(input, ...outputs)}\n  ${calculateOutputIndexImpl(sizeInSplitAxis.length)}\n  ${writeBufferDataImpl(outputs)}\n\n  ${shaderHelper.mainStart()}\n    ${shaderHelper.guardAgainstOutOfBoundsWorkgroupSizes('uniforms.input_size')}\n\n    var indices = ${input.offsetToIndices('global_idx')};\n    var index = ${input.indicesGet('indices', axis)};\n    let output_number = calculateOutputIndex(index);\n    if (output_number != 0) {\n      index -= ${getElementAt('uniforms.size_in_split_axis', 'output_number - 1u', sizeInSplitAxis.length)};\n      ${input.indicesSet('indices', axis, 'index')};\n    }\n    writeBufferData(output_number, indices, global_idx);\n  }`;\n  return {\n    name: 'Split',\n    shaderCache: { hint: attributes.cacheKey, inputDependencies: ['rank'] },\n    getShaderSource,\n    getRunData: () => ({\n      outputs: outputsTensorInfo,\n      dispatchGroup: { x: Math.ceil(inputSize / 64 /* workgroup size */) },\n      programUniforms,\n    }),\n  };\n};\n\nexport const split = (context: ComputeContext, attributes: SplitAttributes): void => {\n  validateInputs(context.inputs);\n  const updatedAttributes =\n    context.inputs.length === 1 ? attributes : createSplitAttributesFromInputs(context.inputs, attributes);\n  context.compute(createSplitProgramInfo(context.inputs, updatedAttributes), { inputs: [0] });\n};\n\nexport const parseSplitAttributes = (attributes: Record<string, unknown>): SplitAttributes => {\n  const axis = attributes.axis as number;\n  const splitSizes: number[] = attributes.splitSizes as number[];\n  const numOutputs = (attributes.numOutputs as number) < 0 ? splitSizes.length : (attributes.numOutputs as number);\n  if (numOutputs !== splitSizes.length) {\n    throw new Error('numOutputs and splitSizes lengh must be equal');\n  }\n  return createAttributeWithCacheKey({ axis, numOutputs, splitSizes });\n};\n","// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport { TensorView } from '../../tensor-view';\nimport { createAttributeWithCacheKey } from '../attribute-with-cache-key';\nimport { ComputeContext } from '../types';\n\nimport { applyAttention, AttentionMaskType, AttentionParameters, AttentionQkvFormat } from './attention';\nimport { maybeTransposeToBNSHAndAddBias } from './multihead-attention';\nimport { createSplitProgramInfo, SplitAttributes } from './split';\nimport { createTransposeProgramInfo, TransposeAttributes } from './transpose';\nexport interface GroupQueryAttentionAttributes {\n  numHeads: number;\n  kvNumHeads: number;\n  scale: number;\n  softcap: number;\n  doRotary: number;\n  rotaryInterleaved: number;\n  smoothSoftmax: boolean;\n  localWindowSize: number;\n}\n\nexport const validateInputs = (\n  inputs: readonly TensorView[],\n  attributes: GroupQueryAttentionAttributes,\n): AttentionParameters => {\n  if (attributes.doRotary) {\n    throw new Error('GroupQuerryAttention do_rotary attribute is not supported');\n  }\n  if (attributes.doRotary && inputs.length <= 7) {\n    throw new Error('cos_cache and sin_cache inputs are required if do_rotary is specified');\n  }\n  const query = inputs[0];\n  const key = inputs[1];\n  const value = inputs[2];\n  const pastKey = inputs[3];\n  const pastValue = inputs[4];\n  if (attributes.localWindowSize !== -1) {\n    throw new Error('Local attention is not supported');\n  }\n  if (attributes.softcap !== 0) {\n    throw new Error('Softcap is not supported');\n  }\n  if (attributes.rotaryInterleaved !== 0) {\n    throw new Error('Rotary interleaved is not supported');\n  }\n  if (attributes.smoothSoftmax) {\n    throw new Error('Smooth softmax is not supported');\n  }\n  // Abbreviation and Meanings:\n  //   B:    batch_size\n  //   S:    sequence_length (input sequence length of query)\n  //   P:    past_sequence_length (past sequence length of key or value)\n  //   L:    kv_sequence_length (input sequence length of key or value)\n  //   M:    max_sequence_length\n  //   T:    total_sequence_length = past_sequence_length + kv_sequence_length\n  //   N:    num_heads\n  //   H:    head size for Q and K, aka q_head_size or k_head_size or qk_head_size\n  //   H_v:  v_head_size\n  //   D_i:  input hidden size\n  //   D:    hidden size for Q and K (D = N * H), aka q_hidden_size or k_hidden_size or qk_hidden_size\n  //   D_v:  v_hidden_size = num_heads * v_head_size\n\n  //     past_key                   : (B, N, S*, H)\n  //     past_value                 : (B, N, S*, H)\n  // When no packing for q/k/v:\n  //     query            (Q)       : (B, S, D)\n  //     key              (K)       : (B, L, D) or (B, N, S*, H)\n  //     value            (V)       : (B, L, D_v) or (B, N, S*, H)\n  // When packed kv is used:\n  //     query            (Q)       : (B, S, D)\n  //     key              (K)       : (B, L, N, 2, H)\n  //     value            (V)       : None\n  // When packed qkv is used:\n  //     query            (Q)       : (B, L, N, 3, H) or (B, S, 3*D)\n  //     key              (K)       : None\n  //     value            (V)       : None\n\n  if (query.dims.length !== 3 && query.dims.length !== 5) {\n    throw new Error('Input query is expected to have 3 or 5 dimensions');\n  }\n\n  const dmmhaPacking = false;\n  const batchSize = query.dims[0];\n  const sequenceLength = query.dims[1];\n  let hiddenSize =\n    query.dims.length === 3 ? (dmmhaPacking ? query.dims[2] / 3 : query.dims[2]) : attributes.numHeads * query.dims[4];\n  let kvSequenceLength = sequenceLength;\n\n  let pastSequenceLength = 0;\n  const packedQKV = !key || key.dims.length === 0;\n  const headSize = !packedQKV\n    ? Math.floor(hiddenSize / attributes.numHeads)\n    : Math.floor(hiddenSize / (attributes.numHeads + 2 * attributes.kvNumHeads));\n  if (packedQKV) {\n    hiddenSize = headSize * attributes.numHeads;\n  }\n  const hasPastKey = pastKey && pastKey.dims.length !== 0;\n  const hasPastValue = pastValue && pastValue.dims.length !== 0;\n  // Currenly the onnxruntime GQA specification only support key/value BNSH format.\n  const isPastkvBSNH =\n    hasPastKey &&\n    pastKey.dims.length === 4 &&\n    pastKey.dims[0] === batchSize &&\n    pastKey.dims[1] !== attributes.kvNumHeads &&\n    pastKey.dims[2] === attributes.kvNumHeads &&\n    pastKey.dims[3] === headSize;\n\n  if (isPastkvBSNH) {\n    throw new Error('BSNH pastKey/pastValue is not supported');\n  }\n  if (hasPastKey && hasPastValue) {\n    if (pastKey.dims.length !== 4) {\n      throw new Error('Input \"past_key\" is expected to have 4 dimensions');\n    }\n    if (pastValue.dims.length !== 4) {\n      throw new Error('Input \"past_value\" is expected to have 4 dimensions');\n    }\n    pastSequenceLength = pastKey.dims[2];\n  } else if (hasPastKey || hasPastValue) {\n    throw new Error('Input \"past_key\" and \"past_value\" shall be both present or both absent');\n  }\n\n  let qkvFormat: AttentionQkvFormat = AttentionQkvFormat.qkvBNSH;\n  if (key && key.dims.length > 0) {\n    if (query.dims.length !== 3) {\n      throw new Error('Input \"query\" is expected to have 3 dimensions when key is given');\n    }\n    if (key.dims.length < 3 || key.dims.length > 5) {\n      throw new Error('Input \"key\" is expected to have 3, 4, or 5 dimensions');\n    }\n    if (query.dims[0] !== key.dims[0]) {\n      throw new Error('Input \"query\" and \"key\" shall have same dim 0 (batch size)');\n    }\n\n    if (key.dims.length === 3) {\n      if (query.dims[2] % key.dims[2] !== 0) {\n        throw new Error('Dimension 2 of \"query\" should be a multiple of \"key\"');\n      }\n      kvSequenceLength = key.dims[1];\n    } else if (key.dims.length === 5) {\n      if (key.dims[2] !== attributes.numHeads || key.dims[3] !== 2 || key.dims[4] !== headSize) {\n        throw new Error('Expect \"key\" shape (batch_size, kv_sequence_length, num_heads, 2, head_size) for packed kv');\n      }\n      if (value) {\n        throw new Error('Expect \"value\" be none when \"key\" has packed kv format.');\n      }\n      kvSequenceLength = key.dims[1];\n    } else {\n      // key_dims.size() == 4 (cross-attention with past_key)\n      if (key.dims[1] !== attributes.numHeads || key.dims[3] !== headSize) {\n        throw new Error('Expect \"key\" shape (batch_size, num_heads, kv_sequence_length, head_size) for past_key');\n      }\n      kvSequenceLength = key.dims[2];\n    }\n  } else {\n    // packed QKV\n    if (query.dims.length !== 3 && query.dims.length !== 5) {\n      throw new Error('Input \"query\" is expected to have 3 or 5 dimensions when key is empty');\n    }\n    if (query.dims.length === 5 && (query.dims[2] !== attributes.numHeads || query.dims[3] !== 3)) {\n      throw new Error('Expect \"query\" shape (batch_size, kv_sequence_length, num_heads, 3, head_size) for packed kv');\n    }\n\n    qkvFormat = AttentionQkvFormat.qkvBSN3H;\n  }\n\n  const maskType: AttentionMaskType = AttentionMaskType.none;\n  let passPastInKv = false;\n  let vHiddenSize = attributes.kvNumHeads ? headSize * attributes.kvNumHeads : hiddenSize;\n  if (value && value.dims.length > 0) {\n    if (value.dims.length !== 3 && value.dims.length !== 4) {\n      throw new Error('Input \"value\" is expected to have 3 or 4 dimensions');\n    }\n\n    if (query.dims[0] !== value.dims[0]) {\n      throw new Error('Input \"query\" and \"value\" shall have same dim 0 (batch_size)');\n    }\n\n    if (value.dims.length === 3) {\n      if (kvSequenceLength !== value.dims[1]) {\n        throw new Error('Input \"key\" and \"value\" shall have the same dim 1 (kv_sequence_length)');\n      }\n      vHiddenSize = value.dims[2];\n    } else {\n      if (kvSequenceLength !== value.dims[2]) {\n        throw new Error('Input \"past_key\" and \"past_value\" shall have the same dim 2 (kv_sequence_length)');\n      }\n      vHiddenSize = value.dims[1] * value.dims[3];\n      passPastInKv = true;\n    }\n  }\n  const seqlLens = inputs.length > 4 ? inputs[5] : undefined;\n  if (seqlLens && seqlLens.dims.length !== 1 && seqlLens.dims[0] !== batchSize) {\n    throw new Error('Input \"seqlens\" is expected to have 1 dimension and the same dim 0 as batch_size');\n  }\n  const totalSequenceLength = -1;\n  const maxSequenceLength = -1;\n  const broadcastResPosBias = false;\n\n  return {\n    batchSize,\n    sequenceLength,\n    pastSequenceLength,\n    kvSequenceLength,\n    totalSequenceLength,\n    maxSequenceLength,\n    inputHiddenSize: 0,\n    hiddenSize,\n    vHiddenSize,\n    headSize,\n    vHeadSize: Math.floor(vHiddenSize / attributes.kvNumHeads),\n    numHeads: attributes.numHeads,\n    kvNumHeads: attributes.kvNumHeads,\n    nReps: attributes.numHeads / attributes.kvNumHeads,\n    pastPresentShareBuffer: false,\n    maskType,\n    scale: attributes.scale,\n    broadcastResPosBias,\n    passPastInKv,\n    qkvFormat,\n  };\n};\n\nconst weightTransposeAttribute: TransposeAttributes = createAttributeWithCacheKey({ perm: [0, 2, 1, 3] });\n\nconst maybeTransposeToBNSH = (context: ComputeContext, input: TensorView, params: AttentionParameters) => {\n  let reshapedInput = input;\n  const numHeads = params.kvNumHeads!;\n  if (input.dims.length === 3 && params.kvSequenceLength !== 0) {\n    reshapedInput = input.reshape([params.batchSize, params.kvSequenceLength, numHeads, params.headSize]);\n    reshapedInput = context.compute(createTransposeProgramInfo(reshapedInput, weightTransposeAttribute.perm), {\n      inputs: [reshapedInput],\n      outputs: [-1],\n    })[0];\n  }\n\n  return reshapedInput;\n};\n\nexport const groupQueryAttention = (context: ComputeContext, attributes: GroupQueryAttentionAttributes): void => {\n  const params = validateInputs(context.inputs, attributes);\n  if (context.inputs[0].dims.length === 5) {\n    throw new Error('Packed QKV is not implemented');\n  }\n\n  if (context.inputs[1]?.dims.length === 5) {\n    throw new Error('Packed KV is not implemented');\n  }\n\n  const q = context.inputs[0];\n  const k = context.inputs[1] && context.inputs[1].dims.length > 0 ? context.inputs[1] : undefined;\n  const v = context.inputs[2] && context.inputs[2].dims.length > 0 ? context.inputs[2] : undefined;\n  const pastKey = context.inputs[3] && context.inputs[3].dims.length !== 0 ? context.inputs[3] : undefined;\n  const pastValue = context.inputs[4] && context.inputs[4].dims.length !== 0 ? context.inputs[4] : undefined;\n  const seqLens = context.inputs.length > 4 ? context.inputs[5] : undefined;\n  const totalSequenceLengthInput = context.inputs.length > 5 ? context.inputs[6] : undefined;\n  const kvNumHeads = params.kvNumHeads ? params.kvNumHeads : params.numHeads;\n\n  // TODO Remove explicit split operation and use indexing in Attention implementation to avoid overhead.\n\n  const splitAttributes: SplitAttributes = createAttributeWithCacheKey({\n    axis: 2,\n    numOutputs: 3,\n    splitSizes: [params.numHeads * params.headSize, kvNumHeads * params.headSize, kvNumHeads * params.headSize],\n  });\n  const [query, key, value] =\n    !k && !v\n      ? context.compute(createSplitProgramInfo([q], splitAttributes), { inputs: [q], outputs: [-1, -1, -1] })\n      : [q, k!, v!];\n\n  const Q = maybeTransposeToBNSHAndAddBias(\n    context,\n    params.batchSize,\n    params.numHeads,\n    params.sequenceLength,\n    params.headSize,\n    query,\n    undefined,\n    0,\n  );\n  applyAttention(\n    context,\n    Q,\n    maybeTransposeToBNSH(context, key, params),\n    maybeTransposeToBNSH(context, value, params),\n    undefined,\n    undefined,\n    pastKey,\n    pastValue,\n    undefined,\n    params,\n    seqLens,\n    totalSequenceLengthInput,\n  );\n};\n","// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport { DataType } from '../../../wasm-common';\nimport { TensorView } from '../../tensor-view';\nimport { ShapeUtil } from '../../util';\nimport { ComputeContext, ProgramInputTensorInfoDependency, ProgramUniform } from '../types';\nimport { createTransposeProgramInfo } from './transpose';\n\nimport {\n  createTensorShapeVariables,\n  getMaxComponents,\n  inputVariable,\n  outputVariable,\n  ShaderHelper,\n  sumVector,\n  tensorTypeToWsglStorageType,\n} from './common';\n\nexport interface InstanceNormAttributes {\n  epsilon: number;\n  format: 'NHWC' | 'NCHW';\n}\n\nconst computeChannelScaleShift = (\n  context: ComputeContext,\n  input: TensorView,\n  scale: TensorView,\n  bias: TensorView,\n  n: number,\n  h: number,\n  c: number,\n  epsilon: number,\n) => {\n  const components = getMaxComponents(h);\n  const f32Type = components === 1 ? 'f32' : `vec${components}f`;\n  const wgType = components === 1 ? 'vec2f' : `mat2x${components}f`;\n  const unitsOfWork = n * c;\n  let workgroupSize = 64;\n  if (unitsOfWork === 1) {\n    workgroupSize = 256;\n  }\n  const inputShape = [n, c, h / components];\n  const outputShape = [n, c, 2];\n  const inputDependencies: ProgramInputTensorInfoDependency[] = ['rank', 'type', 'type'];\n  const programUniforms: ProgramUniform[] = [];\n  programUniforms.push(...createTensorShapeVariables(inputShape, outputShape));\n\n  const getShaderSource = (shaderHelper: ShaderHelper) => {\n    const x = inputVariable('x', input.dataType, 3, components);\n    const s = inputVariable('scale', scale.dataType, scale.dims);\n    const b = inputVariable('bias', bias.dataType, bias.dims);\n    const output = outputVariable('output', DataType.float, 3, 2);\n    const variables = [x, s, b, output];\n    return `\n  var<workgroup> workgroup_shared : array<${wgType}, ${workgroupSize}>;\n  const workgroup_size = ${workgroupSize}u;\n  ${shaderHelper.declareVariables(...variables)}\n  ${shaderHelper.mainStart(workgroupSize)}\n    let batch = workgroup_index / uniforms.x_shape[1];\n    let channel = workgroup_index % uniforms.x_shape[1];\n    let hight = uniforms.x_shape[2];\n    // initialize workgroup memory\n    var sum = ${f32Type}(0);\n    var squared_sum = ${f32Type}(0);\n    for (var h = local_idx; h < hight; h += workgroup_size) {\n      let value = ${f32Type}(${x.get('batch', 'channel', 'h')});\n      sum += value;\n      squared_sum += value * value;\n    }\n    workgroup_shared[local_idx] = ${wgType}(sum, squared_sum);\n    workgroupBarrier();\n\n    for (var currSize = workgroup_size >> 1;  currSize > 0; currSize = currSize >> 1) {\n      if (local_idx < currSize) {\n        workgroup_shared[local_idx] = workgroup_shared[local_idx] + workgroup_shared[local_idx + currSize];\n      }\n      workgroupBarrier();\n    }\n    if (local_idx == 0) {\n      let sum_final = ${sumVector('workgroup_shared[0][0]', components)} / f32(hight * ${components});\n      let squared_sum_final = ${sumVector('workgroup_shared[0][1]', components)} / f32(hight * ${components});\n\n      let inv_std_dev = inverseSqrt(squared_sum_final - sum_final * sum_final + f32(${epsilon}));\n      let channel_scale = inv_std_dev * f32(scale[channel]);\n      let channel_shift = f32(bias[channel]) - sum_final * channel_scale;\n      output[workgroup_index] = vec2f(channel_scale, channel_shift);\n    }\n  }`;\n  };\n\n  return context.compute(\n    {\n      name: 'InstanceNormComputeChannelScaleShift',\n      // TODO: use epsilon as uniform. Currently epsilon as uniform fails test_instancenorm_epsilon.\n      shaderCache: { hint: `${components};${epsilon};${workgroupSize}`, inputDependencies },\n      getRunData: () => ({\n        outputs: [{ dims: outputShape, dataType: DataType.float }],\n        dispatchGroup: { x: unitsOfWork },\n        programUniforms,\n      }),\n      getShaderSource,\n    },\n    { inputs: [input, scale, bias], outputs: [-1] },\n  )[0];\n};\n\nconst createInstanceNormProgramInfo = (\n  context: ComputeContext,\n  inputs: readonly TensorView[],\n  attributes: InstanceNormAttributes,\n) => {\n  const xShape = inputs[0].dims;\n  const outputShape = xShape;\n  const axis = 2;\n  const N = xShape[0];\n  const C = xShape[1];\n  const H = ShapeUtil.sizeFromDimension(xShape, axis);\n  const components = getMaxComponents(H);\n  const outputSize = ShapeUtil.size(outputShape) / components;\n  // compute channel scale and channel shift.\n  const channelScaleShift = computeChannelScaleShift(\n    context,\n    inputs[0],\n    inputs[1],\n    inputs[2],\n    N,\n    H,\n    C,\n    attributes.epsilon,\n  );\n\n  const inputShape = [N, C, H / components];\n  const scaleShape = [N, C];\n  const inputDependencies: ProgramInputTensorInfoDependency[] = ['type', 'none'];\n\n  const getShaderSource = (shaderHelper: ShaderHelper) => {\n    const x = inputVariable('x', inputs[0].dataType, inputShape.length, components);\n    const scale = inputVariable('scale_shift', DataType.float, scaleShape.length, 2);\n    const output = outputVariable('output', inputs[0].dataType, inputShape.length, components);\n    const variables = [x, scale, output];\n    return `\n  ${shaderHelper.registerUniform('output_size', 'u32').declareVariables(...variables)}\n  ${shaderHelper.mainStart()}\n  ${shaderHelper.guardAgainstOutOfBoundsWorkgroupSizes('uniforms.output_size')}\n      let outputIndices = ${output.offsetToIndices('global_idx')};\n      let batch = outputIndices[0];\n      let channel = outputIndices[1];\n      let scale_shift = ${scale.getByIndices('vec2<u32>(batch, channel)')};\n      let value = ${x.getByOffset('global_idx')} * ${output.type.value}(scale_shift.x) + ${output.type.value}(scale_shift.y);\n      ${output.setByOffset('global_idx', 'value')};\n  }`;\n  };\n\n  context.compute(\n    {\n      name: 'InstanceNormalization',\n      shaderCache: { hint: `${components}`, inputDependencies },\n      getRunData: () => ({\n        outputs: [{ dims: outputShape, dataType: inputs[0].dataType }],\n        dispatchGroup: { x: Math.ceil(outputSize / 64 /* workgroup size */) },\n        programUniforms: [\n          { type: DataType.uint32, data: outputSize },\n          ...createTensorShapeVariables(inputShape, scaleShape, inputShape),\n        ],\n      }),\n      getShaderSource,\n    },\n    { inputs: [inputs[0], channelScaleShift] },\n  );\n};\n\nconst createInstanceNormNHWCProgramInfo = (\n  context: ComputeContext,\n  inputs: readonly TensorView[],\n  attributes: InstanceNormAttributes,\n) => {\n  const xShape = inputs[0].dims;\n  const outputShape = xShape;\n  const N = xShape[0];\n  const C = xShape[xShape.length - 1];\n  const H = ShapeUtil.sizeFromDimension(xShape, 1) / C;\n  const components = getMaxComponents(C);\n  const outputSize = ShapeUtil.size(outputShape) / components;\n  const programUniforms: ProgramUniform[] = [\n    { type: DataType.uint32, data: H },\n    { type: DataType.uint32, data: Math.floor(C / components) },\n  ];\n  const inputDependencies: ProgramInputTensorInfoDependency[] = ['type', 'type'];\n\n  // 1. transpose x from NHWC to NCHW\n  let needTranspose = false;\n  const transposedXPerm = [0, xShape.length - 1];\n  for (let i = 0; i < xShape.length - 2; i++) {\n    needTranspose = needTranspose || xShape[i + 1] !== 1;\n    transposedXPerm.push(i + 1);\n  }\n\n  needTranspose = needTranspose && xShape[xShape.length - 1] !== 1;\n\n  const transposedX = needTranspose\n    ? context.compute(createTransposeProgramInfo(context.inputs[0], transposedXPerm), {\n        inputs: [context.inputs[0]],\n        outputs: [-1],\n      })[0]\n    : context.inputs[0].reshape(Array.from({ length: xShape.length }, (_, i) => xShape[transposedXPerm[i]]));\n  // 2. compute channel scale and channel shift.\n  const channelScaleShift = computeChannelScaleShift(\n    context,\n    transposedX,\n    inputs[1],\n    inputs[2],\n    N,\n    H,\n    C,\n    attributes.epsilon,\n  );\n  const getShaderSource = (shaderHelper: ShaderHelper) => {\n    const dataType = tensorTypeToWsglStorageType(inputs[0].dataType);\n    const scaleType = components === 1 ? 'vec2f' : `mat${components}x2f`;\n    const scaleData = (num: number) => {\n      const index = num === 0 ? 'x' : 'y';\n      const f32Type = components === 1 ? 'f32' : `vec${components}f`;\n      switch (components) {\n        case 1:\n          return `${dataType}(${f32Type}(scale.${index}))`;\n        case 2:\n          return `vec2<${dataType}>(${f32Type}(scale[0].${index}, scale[1].${index}))`;\n        case 4:\n          return `vec4<${dataType}>(${f32Type}(scale[0].${index}, scale[1].${index}, scale[2].${index}, scale[3].${index}))`;\n        default:\n          throw new Error(`Not supported compoents ${components}`);\n      }\n    };\n    const inputHelper = inputVariable('input', inputs[0].dataType, inputs[0].dims, components);\n    const outputHelper = outputVariable('output', inputs[0].dataType, outputShape, components);\n\n    return `\n  @group(0) @binding(0) var<storage, read> input : array<${inputHelper.type.storage}>;\n  @group(0) @binding(1) var<storage, read> scale_input : array<${scaleType}>;\n  @group(0) @binding(2) var<storage, read_write> output : array<${outputHelper.type.storage}>;\n  struct Uniforms {H: u32, C : u32};\n  @group(0) @binding(3) var<uniform> uniforms: Uniforms;\n\n  ${shaderHelper.mainStart()}\n    let current_image_number = global_idx / (uniforms.C * uniforms.H);\n    let current_channel_number = global_idx % uniforms.C;\n\n    let scale_offset = current_image_number * uniforms.C + current_channel_number;\n    let scale = scale_input[scale_offset];\n    output[global_idx] = fma(input[global_idx], ${scaleData(0)}, ${scaleData(1)});\n  }`;\n  };\n  context.compute(\n    {\n      name: 'InstanceNormalizationNHWC',\n      shaderCache: { hint: `${components}`, inputDependencies },\n      getRunData: () => ({\n        outputs: [{ dims: outputShape, dataType: inputs[0].dataType }],\n        dispatchGroup: { x: Math.ceil(outputSize / 64 /* workgroup size */) },\n        programUniforms,\n      }),\n      getShaderSource,\n    },\n    { inputs: [inputs[0], channelScaleShift] },\n  );\n};\n\nexport const instanceNorm = (context: ComputeContext, attributes: InstanceNormAttributes): void => {\n  if (attributes.format === 'NHWC') {\n    createInstanceNormNHWCProgramInfo(context, context.inputs, attributes);\n  } else {\n    createInstanceNormProgramInfo(context, context.inputs, attributes);\n  }\n};\n","// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport { DataType } from '../../../wasm-common';\nimport { TensorView } from '../../tensor-view';\nimport { ShapeUtil } from '../../util';\nimport { ComputeContext, ProgramInfo, ProgramInputTensorInfoDependency, ProgramUniform } from '../types';\n\nimport {\n  castToF32,\n  fillVector,\n  getMaxComponents,\n  inputVariable,\n  outputVariable,\n  ShaderHelper,\n  sumVector,\n  tensorTypeToWsglStorageType,\n  UniformsArrayType,\n} from './common';\n\ninterface LayerNormAttributes {\n  simplified: boolean;\n  axis: number;\n  epsilon: number;\n}\n\nconst validateInputs = (inputs: readonly TensorView[]): void => {\n  if (!inputs || inputs.length < 2) {\n    throw new Error('layerNorm requires at least 2 inputs.');\n  }\n};\n\nconst createLayerNormProgramInfo = (\n  inputs: readonly TensorView[],\n  attributes: LayerNormAttributes,\n  outputCount: number,\n): ProgramInfo => {\n  const simplified = attributes.simplified;\n\n  const xShape = inputs[0].dims;\n  const scale = inputs[1];\n  const bias = !simplified && inputs[2];\n\n  const outputShape = xShape;\n  const axis = ShapeUtil.normalizeAxis(attributes.axis, xShape.length);\n  const normCount = ShapeUtil.sizeToDimension(xShape, axis);\n  const normSize = ShapeUtil.sizeFromDimension(xShape, axis);\n\n  const scaleSize = ShapeUtil.size(scale.dims);\n  const biasSize = bias ? ShapeUtil.size(bias.dims) : 0;\n  if (scaleSize !== normSize || (bias && biasSize !== normSize)) {\n    throw new Error(`Size of X.shape()[axis:] == ${normSize}.\n       Size of scale and bias (if provided) must match this.\n       Got scale size of ${scaleSize} and bias size of ${biasSize}`);\n  }\n\n  const meanInvStdDevDim: number[] = [];\n  for (let i = 0; i < xShape.length; ++i) {\n    if (i < axis) {\n      meanInvStdDevDim.push(xShape[i]);\n    } else {\n      meanInvStdDevDim.push(1);\n    }\n  }\n  const components = getMaxComponents(normSize);\n  const inputDependencies: ProgramInputTensorInfoDependency[] = ['type', 'type'];\n  const programUniforms: ProgramUniform[] = [\n    { type: DataType.uint32, data: normCount },\n    { type: DataType.float, data: normSize },\n    { type: DataType.uint32, data: Math.floor(normSize / components) },\n    { type: DataType.float, data: attributes.epsilon },\n  ];\n  if (bias) {\n    inputDependencies.push('type');\n  }\n  const hasMeanDataOutput = outputCount > 1;\n  const hasInvStdOutput = outputCount > 2;\n\n  const getShaderSource = (shaderHelper: ShaderHelper) => {\n    const dataType = tensorTypeToWsglStorageType(inputs[0].dataType);\n    const variables = [\n      inputVariable('x', inputs[0].dataType, inputs[0].dims, components),\n      inputVariable('scale', scale.dataType, scale.dims, components),\n    ];\n    if (bias) {\n      variables.push(inputVariable('bias', bias.dataType, bias.dims, components));\n    }\n    variables.push(outputVariable('output', inputs[0].dataType, outputShape, components));\n    if (hasMeanDataOutput) {\n      variables.push(outputVariable('mean_data_output', DataType.float, meanInvStdDevDim));\n    }\n    if (hasInvStdOutput) {\n      variables.push(outputVariable('inv_std_output', DataType.float, meanInvStdDevDim));\n    }\n\n    const uniforms: UniformsArrayType = [\n      { name: 'norm_count', type: 'u32' },\n      { name: 'norm_size', type: 'f32' },\n      { name: 'norm_size_vectorized', type: 'u32' },\n      { name: 'epsilon', type: 'f32' },\n    ];\n    return `\n  ${shaderHelper.registerUniforms(uniforms).declareVariables(...variables)}\n  ${shaderHelper.mainStart()}\n    ${shaderHelper.guardAgainstOutOfBoundsWorkgroupSizes('uniforms.norm_count')}\n    let offset = global_idx * uniforms.norm_size_vectorized;\n    var mean_vector = ${fillVector('f32', components)};\n    var mean_square_vector = ${fillVector('f32', components)};\n\n    for (var h: u32 = 0u; h < uniforms.norm_size_vectorized; h++) {\n      let value = ${castToF32(dataType, components, 'x[h + offset]')};\n      mean_vector += value;\n      mean_square_vector += value * value;\n    }\n    let mean = ${sumVector('mean_vector', components)} / uniforms.norm_size;\n    let inv_std_dev = inverseSqrt(${sumVector('mean_square_vector', components)} / uniforms.norm_size ${\n      simplified ? '' : '- mean * mean'\n    } + uniforms.epsilon);\n\n    for (var j: u32 = 0; j < uniforms.norm_size_vectorized; j++) {\n      let f32input = ${castToF32(dataType, components, 'x[j + offset]')};\n      let f32scale = ${castToF32(dataType, components, 'scale[j]')};\n      output[j + offset] = ${variables[0].type.value}((f32input ${simplified ? '' : '- mean'}) * inv_std_dev * f32scale\n        ${bias ? `+ ${castToF32(dataType, components, 'bias[j]')}` : ''}\n      );\n    }\n\n    ${hasMeanDataOutput ? 'mean_data_output[global_idx] = mean' : ''};\n    ${hasInvStdOutput ? 'inv_std_output[global_idx] = inv_std_dev' : ''};\n  }`;\n  };\n  const outputs = [{ dims: outputShape, dataType: inputs[0].dataType }];\n  if (hasMeanDataOutput) {\n    outputs.push({ dims: meanInvStdDevDim, dataType: DataType.float });\n  }\n  if (hasInvStdOutput) {\n    outputs.push({ dims: meanInvStdDevDim, dataType: DataType.float });\n  }\n\n  return {\n    name: 'LayerNormalization',\n    shaderCache: { hint: `${components};${outputCount};${simplified}`, inputDependencies },\n    getRunData: () => ({\n      outputs,\n      dispatchGroup: { x: Math.ceil(normCount / 64 /* workgroup size */) },\n      programUniforms,\n    }),\n    getShaderSource,\n  };\n};\n\nexport const layerNorm = (context: ComputeContext, attributes: LayerNormAttributes): void => {\n  validateInputs(context.inputs);\n  context.compute(createLayerNormProgramInfo(context.inputs, attributes, context.outputCount));\n};\n","// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport { TensorView } from '../../tensor-view';\nimport { BroadcastUtil, ShapeUtil } from '../../util';\nimport { ComputeContext } from '../types';\n\nimport { createNaiveMatmulProgramInfo } from './matmul-shaders';\nimport { createMatmulProgramInfo } from './3rd-party/matmul_packed_webgpu';\n\nconst validateInputs = (inputs: readonly TensorView[]): void => {\n  if (!inputs || inputs.length !== 2) {\n    throw new Error('MatMul requires 2 inputs.');\n  }\n\n  if (inputs[0].dims[inputs[0].dims.length - 1] !== inputs[1].dims[inputs[1].dims.length - 2]) {\n    throw new Error('shared dimension does not match.');\n  }\n};\n\nexport const matMul = (context: ComputeContext): void => {\n  validateInputs(context.inputs);\n  const outputShape = BroadcastUtil.calcShape(context.inputs[0].dims, context.inputs[1].dims, true);\n  if (!outputShape) {\n    throw new Error(\"Can't use matmul on the given tensors\");\n  }\n  const N = outputShape[outputShape.length - 1];\n  const K = context.inputs[0].dims[context.inputs[0].dims.length - 1];\n  if (N < 8 && K < 8) {\n    context.compute(createNaiveMatmulProgramInfo(context.inputs, { activation: '' }, outputShape));\n  } else {\n    const M = outputShape[outputShape.length - 2];\n    const batchA = ShapeUtil.size(context.inputs[0].dims.slice(0, -2));\n    const batchB = ShapeUtil.size(context.inputs[1].dims.slice(0, -2));\n    if (batchA !== 1 && M === 1 && batchB === 1) {\n      // Optimization for batched vec-mat-mul\n      const reshapedA = context.inputs[0].reshape([1, batchA, K]);\n      const reshapedB = context.inputs[1].reshape([1, K, N]);\n      const matmulOutputShape = [1, batchA, N];\n      const matmulInputs = [reshapedA, reshapedB];\n      context.compute(createMatmulProgramInfo(matmulInputs, { activation: '' }, outputShape, matmulOutputShape), {\n        inputs: matmulInputs,\n      });\n    } else {\n      context.compute(createMatmulProgramInfo(context.inputs, { activation: '' }, outputShape));\n    }\n  }\n};\n","// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport { DataType } from '../../../wasm-common';\nimport { TensorView } from '../../tensor-view';\nimport { ShapeUtil } from '../../util';\nimport { AttributeWithCacheKey, createAttributeWithCacheKey } from '../attribute-with-cache-key';\nimport { ComputeContext, ProgramInfo, ProgramUniform } from '../types';\n\nimport {\n  createTensorShapeVariables,\n  getMaxComponents,\n  inputVariable,\n  outputVariable,\n  ShaderHelper,\n  tensorTypeToWsglStorageType,\n} from './common';\n\n//  TODO support quantization bits not equal to 4\nexport interface MatMulNBitsAttributes extends AttributeWithCacheKey {\n  k: number;\n  n: number;\n  accuracyLevel: number;\n  bits: number;\n  blockSize: number;\n}\n\nconst validateInputs = (inputs: readonly TensorView[], attributes: MatMulNBitsAttributes): void => {\n  if (inputs.length < 3 || inputs.length > 4) {\n    throw new Error('MatMulNBits requires 3 or 4 inputs');\n  }\n  const a = inputs[0];\n  const aRank = a.dims.length;\n  if (a.dims[aRank - 1] !== attributes.k) {\n    throw new Error('The last dim of input shape does not match the k value');\n  }\n  const nBlocksPerCol = Math.floor((attributes.k + attributes.blockSize - 1) / attributes.blockSize);\n  const blobSize = (attributes.blockSize / 8) * attributes.bits;\n  const b = inputs[1];\n  if (!ShapeUtil.areEqual(b.dims, [attributes.n, nBlocksPerCol, blobSize])) {\n    throw new Error('The second inputs must be 3D tensor with shape N X nBlocksPerCol X blobSize');\n  }\n  const scales = inputs[2];\n  const scalesShape = scales.dims;\n  if (ShapeUtil.size(scalesShape) !== attributes.n * nBlocksPerCol) {\n    throw new Error('scales input size error.');\n  }\n  if (inputs.length === 4) {\n    const zeroPoints = inputs[3];\n    const zeroPointsShape = zeroPoints.dims;\n    const expectedZeroPointsSize =\n      attributes.bits > 4 ? attributes.n * nBlocksPerCol : attributes.n * Math.floor((nBlocksPerCol + 1) / 2);\n    if (ShapeUtil.size(zeroPointsShape) !== expectedZeroPointsSize) {\n      throw new Error('zeroPoints input size error.');\n    }\n  }\n};\n\nexport const createMatMulNBitsProgramInfo = (\n  inputs: readonly TensorView[],\n  attributes: MatMulNBitsAttributes,\n): ProgramInfo => {\n  const inputShape = inputs[0].dims;\n  const aRank = inputShape.length;\n  const dimAOuter = inputShape[aRank - 2];\n  const dimInner = attributes.k;\n  const dimBOuter = attributes.n;\n  const batchDims = inputShape.slice(0, aRank - 2);\n  const batchSize = ShapeUtil.size(batchDims);\n  const blobSize = inputs[1].dims[2];\n  const blobSizeInWords = blobSize / 4;\n  const dataType = inputs[0].dataType;\n  const aComponents = getMaxComponents(attributes.k);\n  const bComponents = getMaxComponents(blobSizeInWords);\n  const components = getMaxComponents(dimBOuter);\n  const outputShape = batchDims.concat([dimAOuter, dimBOuter]);\n  const outputNumber = dimAOuter > 1 && (dimBOuter / components) % 2 === 0 ? 2 : 1;\n  const dispatchSize = ShapeUtil.size(outputShape) / components / outputNumber;\n\n  const workgroupSize = 64;\n\n  const programUniforms: ProgramUniform[] = [];\n  const inputShapeTemp = [batchSize, dimAOuter, dimInner / aComponents];\n  const bShape = ShapeUtil.convertShape(inputs[1].dims).slice();\n  bShape.splice(-1, 1, blobSizeInWords / bComponents);\n  programUniforms.push(...createTensorShapeVariables(inputShapeTemp));\n  programUniforms.push(...createTensorShapeVariables(bShape));\n  programUniforms.push(...createTensorShapeVariables(inputs[2].dims));\n  if (inputs.length === 4) {\n    programUniforms.push(...createTensorShapeVariables(ShapeUtil.convertShape(inputs[3].dims)));\n  }\n  const outputShapeTemp = [batchSize, dimAOuter, dimBOuter / components];\n  programUniforms.push(...createTensorShapeVariables(outputShapeTemp));\n\n  const getShaderSource = (shaderHelper: ShaderHelper) => {\n    const inputRank = inputShapeTemp.length;\n    const a = inputVariable('a', inputs[0].dataType, inputRank, aComponents);\n    const b = inputVariable('b', DataType.uint32, bShape.length, bComponents);\n    const scales = inputVariable('scales', inputs[2].dataType, inputs[2].dims.length);\n    const inputVariables = [a, b, scales];\n    const zeroPoints =\n      inputs.length === 4 ? inputVariable('zero_points', DataType.uint32, inputs[3].dims.length) : undefined;\n    if (zeroPoints) {\n      inputVariables.push(zeroPoints);\n    }\n    const outputRank = outputShapeTemp.length;\n    const output = outputVariable('output', inputs[0].dataType, outputRank, components);\n    const dataType = tensorTypeToWsglStorageType(inputs[0].dataType);\n\n    const qDqDataType = (() => {\n      switch (aComponents) {\n        case 1:\n          return `array<${dataType}, 8>`;\n        case 2:\n          return `mat4x2<${dataType}>`;\n        case 4:\n          return `mat2x4<${dataType}>`;\n        default:\n          throw new Error(`${aComponents}-component is not supported.`);\n      }\n    })();\n\n    const processOneWord = (): string => {\n      let calcStr = `\n          // reuse a data\n            var input_offset = ${a.indicesToOffset(`${a.type.indices}(batch, row, word_offset)`)};\n            var a_data: ${qDqDataType};\n            for (var j: u32 = 0; j < ${8 / aComponents}; j++) {\n              a_data[j] = ${a.getByOffset('input_offset')};\n              input_offset++;\n            }\n          `;\n      for (let c = 0; c < components * outputNumber; c++) {\n        calcStr += `\n            b_value = ${bComponents === 1 ? `b${c}_data` : `b${c}_data[i]`};\n            b_value_lower = unpack4xU8(b_value & b_mask);\n            b_value_upper = unpack4xU8((b_value >> 4) & b_mask);\n            b_quantized_values = ${qDqDataType}(${Array.from(\n              { length: 4 },\n              (_, i) => `${dataType}(b_value_lower[${i}]), ${dataType}(b_value_upper[${i}])`,\n            ).join(', ')});\n            b_dequantized_values = ${(() => {\n              if (aComponents === 1) {\n                return `${qDqDataType}(${Array.from(\n                  { length: 8 },\n                  (_, i) => `(b_quantized_values[${i}] - ${zeroPoints ? `zero_point${c}` : 'zero_point'}) * scale${c}`,\n                ).join(', ')});`;\n              } else {\n                return `(b_quantized_values - ${qDqDataType}(${Array(8)\n                  .fill(`${zeroPoints ? `zero_point${c}` : 'zero_point'}`)\n                  .join(',')})) * scale${c};`;\n              }\n            })()};\n            workgroup_shared[local_id.x * ${outputNumber} + ${Math.floor(c / components)}]${components > 1 ? `[${c % components}]` : ''} += ${Array.from(\n              { length: 8 / aComponents },\n              (_, i) =>\n                `${\n                  aComponents === 1\n                    ? `a_data[${i}] * b_dequantized_values[${i}]`\n                    : `dot(a_data[${i}], b_dequantized_values[${i}])`\n                }`,\n            ).join(' + ')};\n          `;\n      }\n      return calcStr;\n    };\n    const prepareScaleAndZeroPoint = (): string => {\n      let calcStr = `\n            var col_index = col * ${components};\n            ${\n              zeroPoints\n                ? `\n            let zero_point_bytes_per_col = (nBlocksPerCol + 1) / 2;\n            var zero_point_byte_count: u32;\n            var zero_point_word_index: u32;\n            var zero_point_byte_offset: u32;\n            let zero_point_nibble_offset: u32 = block & 0x1u;\n            var zero_point_bits_offset: u32;\n            var zero_point_word: u32;`\n                : `\n            // The default zero point is 8 for unsigned 4-bit quantization.\n            let zero_point = ${dataType}(${8.0});`\n            }\n            `;\n      for (let c = 0; c < components * outputNumber; c++) {\n        calcStr += `\n            let scale${c} = ${scales.getByOffset(`col_index * nBlocksPerCol + block`)};\n            ${\n              zeroPoints\n                ? `\n            zero_point_byte_count = col_index * zero_point_bytes_per_col + (block >> 0x1u);\n            zero_point_word_index = zero_point_byte_count >> 0x2u;\n            zero_point_byte_offset = zero_point_byte_count & 0x3u;\n            zero_point_bits_offset = (zero_point_byte_offset << 3) + (zero_point_nibble_offset << 2);\n            zero_point_word = ${zeroPoints.getByOffset('zero_point_word_index')} >> zero_point_bits_offset;\n            let zero_point${c} = ${dataType}((zero_point_word) & 0xFu);`\n                : ''\n            }\n            col_index += 1;`;\n      }\n      return calcStr;\n    };\n    const prepareBData = (): string => {\n      let calcStr = `col_index = col * ${components};`;\n      for (let c = 0; c < components * outputNumber; c++) {\n        calcStr += `\n            let b${c}_data = ${b.getByIndices(`${b.type.indices}(col_index, block, word)`)};\n            col_index += 1;`;\n      }\n      calcStr += `\n            var b_value: u32;\n            let b_mask: u32 = 0x0F0F0F0Fu;\n            var b_value_lower: vec4<u32>;\n            var b_value_upper: vec4<u32>;\n            var b_quantized_values: ${qDqDataType};\n            var b_dequantized_values: ${qDqDataType};`;\n      return calcStr;\n    };\n    return `\n        var<workgroup> workgroup_shared: array<${output.type.value}, ${outputNumber * workgroupSize}>;\n        ${shaderHelper.declareVariables(...inputVariables, output)}\n        ${shaderHelper.mainStart([workgroupSize, 1, 1])}\n          let output_indices = ${output.offsetToIndices(`(global_idx / ${workgroupSize}) * ${outputNumber}`)};\n          let col = output_indices[2];\n          let row = output_indices[1];\n          let batch = output_indices[0];\n          let nBlocksPerCol = uniforms.b_shape[1];\n\n          for (var block = local_id.x; block < nBlocksPerCol; block += ${workgroupSize}) {\n            //process one block\n            var word_offset: u32 = block * ${attributes.blockSize / aComponents};\n            ${prepareScaleAndZeroPoint()}\n            for (var word: u32 = 0; word < ${blobSizeInWords}; word += ${bComponents}) {\n              ${prepareBData()}\n              for (var i: u32 = 0; i < ${bComponents}; i++) {\n                ${processOneWord()}\n                word_offset += ${8 / aComponents};\n              }\n            }\n          }\n          workgroupBarrier();\n\n          if (local_id.x < ${outputNumber}) {\n            var output_value: ${output.type.value} = ${output.type.value}(0);\n            var workgroup_shared_offset: u32 = local_id.x;\n            for (var b: u32 = 0u; b < ${workgroupSize}u; b++) {\n              output_value += workgroup_shared[workgroup_shared_offset];\n              workgroup_shared_offset += ${outputNumber};\n            }\n            ${output.setByIndices(`${output.type.indices}(batch, row, col + local_id.x)`, 'output_value')};\n          }\n        }`;\n  };\n  return {\n    name: 'MatMulNBits',\n    shaderCache: {\n      hint: `${attributes.blockSize};${attributes.bits};${aComponents};${bComponents};${components};${outputNumber};${workgroupSize}`,\n      inputDependencies: Array(inputs.length).fill('rank'),\n    },\n    getRunData: () => ({\n      outputs: [{ dims: outputShape, dataType }],\n      dispatchGroup: { x: dispatchSize },\n      programUniforms,\n    }),\n    getShaderSource,\n  };\n};\n\n// Currently, only support blockSize = 32.\nexport const createMatMulNBitsBlockSize32ProgramInfo = (\n  inputs: readonly TensorView[],\n  attributes: MatMulNBitsAttributes,\n): ProgramInfo => {\n  const inputShape = inputs[0].dims;\n  const aRank = inputShape.length;\n  const dimAOuter = inputShape[aRank - 2];\n  const dimInner = attributes.k;\n  const dimBOuter = attributes.n;\n  const batchDims = inputShape.slice(0, aRank - 2);\n  const batchSize = ShapeUtil.size(batchDims);\n  const blobSize = inputs[1].dims[2];\n  const blobSizeInWords = blobSize / 4;\n  const dataType = inputs[0].dataType;\n  const aComponents = getMaxComponents(attributes.k);\n  const bComponents = getMaxComponents(blobSizeInWords);\n  const outputShape = batchDims.concat([dimAOuter, dimBOuter]);\n\n  const workgroupSize = 128;\n  const workgroupY = dimBOuter % 8 === 0 ? 8 : dimBOuter % 4 === 0 ? 4 : 1;\n  const workgroupX = workgroupSize / workgroupY;\n  const tileSize = workgroupX * bComponents * 8; // each uint32 has 8 data.\n  const aLengthPerTile = tileSize / aComponents;\n  const blocksPerTile = tileSize / attributes.blockSize;\n  const dispatchSize = ShapeUtil.size(outputShape) / workgroupY;\n\n  const programUniforms: ProgramUniform[] = [];\n  const inputShapeTemp = [batchSize, dimAOuter, dimInner / aComponents];\n  const bShape = ShapeUtil.convertShape(inputs[1].dims).slice();\n  bShape.splice(-1, 1, blobSizeInWords / bComponents);\n  programUniforms.push(...createTensorShapeVariables(inputShapeTemp));\n  programUniforms.push(...createTensorShapeVariables(bShape));\n  programUniforms.push(...createTensorShapeVariables(inputs[2].dims));\n  if (inputs.length === 4) {\n    programUniforms.push(...createTensorShapeVariables(ShapeUtil.convertShape(inputs[3].dims)));\n  }\n  const outputShapeTemp = [batchSize, dimAOuter, dimBOuter];\n  programUniforms.push(...createTensorShapeVariables(outputShapeTemp));\n\n  const getShaderSource = (shaderHelper: ShaderHelper) => {\n    const inputRank = inputShapeTemp.length;\n    const a = inputVariable('a', inputs[0].dataType, inputRank, aComponents);\n    const b = inputVariable('b', DataType.uint32, bShape.length, bComponents);\n    const scales = inputVariable('scales', inputs[2].dataType, inputs[2].dims.length);\n    const inputVariables = [a, b, scales];\n    const zeroPoints =\n      inputs.length === 4 ? inputVariable('zero_points', DataType.uint32, inputs[3].dims.length) : undefined;\n    if (zeroPoints) {\n      inputVariables.push(zeroPoints);\n    }\n    const outputRank = outputShapeTemp.length;\n    const output = outputVariable('output', inputs[0].dataType, outputRank);\n    const dataType = tensorTypeToWsglStorageType(inputs[0].dataType);\n    const readA = () => {\n      switch (aComponents) {\n        case 1:\n          return `\n          let a_data0 = vec4<${dataType}>(sub_a[word_offset], sub_a[word_offset + 1], sub_a[word_offset + 2], sub_a[word_offset + 3]);\n          let a_data1 = vec4<${dataType}>(sub_a[word_offset + 4], sub_a[word_offset + 5], sub_a[word_offset + 6], sub_a[word_offset + 7]);`;\n        case 2:\n          return `\n          let a_data0 = vec4<${dataType}>(sub_a[word_offset], sub_a[word_offset + 1]);\n          let a_data1 = vec4<${dataType}>(sub_a[word_offset + 2], sub_a[word_offset + 3]);`;\n        case 4:\n          return `\n          let a_data0 = sub_a[word_offset];\n          let a_data1 = sub_a[word_offset + 1];`;\n        default:\n          throw new Error(`${aComponents}-component is not supported.`);\n      }\n    };\n\n    return `\n        var<workgroup> sub_a: array<${a.type.value}, ${aLengthPerTile}>;\n        var<workgroup> inter_results: array<array<${output.type.value}, ${workgroupX}>, ${workgroupY}>;\n        ${shaderHelper.declareVariables(...inputVariables, output)}\n        ${shaderHelper.mainStart([workgroupX, workgroupY, 1])}\n          let output_indices = ${output.offsetToIndices(`workgroup_index * ${workgroupY}`)};\n          let col = output_indices[2];\n          let row = output_indices[1];\n          let batch = output_indices[0];\n          let n_blocks_per_col = uniforms.b_shape[1];\n          let num_tiles =  (n_blocks_per_col - 1) / ${blocksPerTile} + 1;\n\n          // Loop over shared dimension.\n          for (var tile: u32 = 0; tile < num_tiles; tile += 1) {\n            let a_col_start = tile * ${aLengthPerTile};\n            // load one tile A data into shared memory.\n            for (var a_offset = local_idx; a_offset < ${aLengthPerTile}; a_offset += ${workgroupSize})\n            {\n              let a_col = a_col_start + a_offset;\n              if (a_col < uniforms.a_shape[2])\n              {\n                sub_a[a_offset] = ${a.getByIndices(`${a.type.indices}(batch, row, a_col)`)};\n              } else {\n                sub_a[a_offset] = ${a.type.value}(0);\n              }\n            }\n            workgroupBarrier();\n\n            // each thread process one block\n            let b_row = col + local_id.y;\n            let block = tile * ${blocksPerTile} + local_id.x;\n            ${\n              zeroPoints\n                ? `\n            let zero_point_bytes_per_col = (n_blocks_per_col + 1) / 2;\n            let zero_point_byte_count = b_row * zero_point_bytes_per_col + (block >> 0x1u);\n            let zero_point_word_index = zero_point_byte_count >> 0x2u;\n            let zero_point_byte_offset = zero_point_byte_count & 0x3u;\n            let zero_point_nibble_offset: u32 = block & 0x1u;\n            let zero_point_bits_offset = (zero_point_byte_offset << 3) + (zero_point_nibble_offset << 2);\n            let zero_point_word = ${zeroPoints.getByOffset('zero_point_word_index')} >> zero_point_bits_offset;\n            let zero_point = ${dataType}((zero_point_word) & 0xFu);`\n                : `\n            // The default zero point is 8 for unsigned 4-bit quantization.\n            let zero_point = ${dataType}(${8.0});`\n            }\n            let scale = ${scales.getByOffset(`b_row * n_blocks_per_col + block`)};\n            let b_data = ${b.getByIndices(`${b.type.indices}(b_row, block, 0)`)};\n            var word_offset = local_id.x * ${attributes.blockSize / aComponents};\n            for (var i: u32 = 0; i < ${bComponents}; i++) {\n              ${readA()}\n              let b_value = ${bComponents === 1 ? `b_data` : `b_data[i]`};\n              let b_value_lower = unpack4xU8(b_value & 0x0F0F0F0Fu);\n              let b_value_upper = unpack4xU8((b_value >> 4) & 0x0F0F0F0Fu);\n              let b_quantized_values = mat2x4<${dataType}>(${Array.from(\n                { length: 4 },\n                (_, i) => `${dataType}(b_value_lower[${i}]), ${dataType}(b_value_upper[${i}])`,\n              ).join(', ')});\n              let b_dequantized_values = (b_quantized_values - mat2x4<${dataType}>(${Array(8).fill('zero_point').join(',')})) * scale;\n              inter_results[local_id.y][local_id.x] += ${Array.from(\n                { length: 2 },\n                (_, i) => `${`dot(a_data${i}, b_dequantized_values[${i}])`}`,\n              ).join(' + ')};\n              word_offset += ${8 / aComponents};\n            }\n            workgroupBarrier();\n          }\n\n          if (local_idx < ${workgroupY}) {\n            var output_value: ${output.type.value} = ${output.type.value}(0);\n            for (var b = 0u; b < ${workgroupX}; b++) {\n              output_value += inter_results[local_idx][b];\n            }\n            if (col + local_idx < uniforms.output_shape[2])\n            {\n              ${output.setByIndices(`${output.type.indices}(batch, row, col + local_idx)`, 'output_value')}\n            }\n          }\n        }`;\n  };\n  return {\n    name: 'BlockwiseMatMulNBits32',\n    shaderCache: {\n      hint: `${attributes.blockSize};${aComponents};${bComponents};${workgroupX};${workgroupY}`,\n      inputDependencies: Array(inputs.length).fill('rank'),\n    },\n    getRunData: () => ({\n      outputs: [{ dims: outputShape, dataType }],\n      dispatchGroup: { x: dispatchSize },\n      programUniforms,\n    }),\n    getShaderSource,\n  };\n};\n\nexport const matMulNBits = (context: ComputeContext, attributes: MatMulNBitsAttributes): void => {\n  validateInputs(context.inputs, attributes);\n  if (\n    attributes.blockSize === 32 &&\n    context.adapterInfo.isVendor('intel') &&\n    context.adapterInfo.isArchitecture('gen-12lp')\n  ) {\n    context.compute(createMatMulNBitsBlockSize32ProgramInfo(context.inputs, attributes));\n  } else {\n    context.compute(createMatMulNBitsProgramInfo(context.inputs, attributes));\n  }\n};\n\nexport const parseMatMulNBitsAttributes = (attributes: Record<string, unknown>): MatMulNBitsAttributes =>\n  createAttributeWithCacheKey(attributes as Omit<MatMulNBitsAttributes, keyof AttributeWithCacheKey>);\n","// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport { DataType } from '../../../wasm-common';\nimport { TensorView } from '../../tensor-view';\nimport { ShapeUtil } from '../../util';\nimport { ComputeContext, ProgramInfo, ProgramInputTensorInfoDependency, ProgramUniform } from '../types';\n\nimport {\n  createTensorShapeVariables,\n  getElementAt,\n  IndicesHelper,\n  inputVariable,\n  outputVariable,\n  ShaderHelper,\n  UniformDataElementType,\n  UniformsArrayType,\n} from './common';\n\ninterface PadAttributes {\n  // 0-constant, 1-reflect, 2-edge, 3-wrap\n  readonly mode: number;\n  readonly value: number;\n  readonly pads: number[];\n}\n\nconst validateInputs = (inputs: readonly TensorView[]): void => {\n  if (!inputs || inputs.length < 1) {\n    throw new Error('Too few inputs');\n  }\n  if (inputs[0].dataType !== DataType.float && inputs[0].dataType !== DataType.float16) {\n    throw new Error('Input type must be float or float16.');\n  }\n\n  if (inputs.length >= 2) {\n    let validPads = inputs[0].dims.length * 2 === inputs[1].dims[0];\n    if (inputs.length === 4) {\n      validPads = inputs[3].dims[0] * 2 === inputs[1].dims[0];\n    }\n    if (!validPads) {\n      throw new Error('The pads should be a 1D tensor of shape [2 * input_rank] or [2 * num_axes].');\n    }\n  }\n};\n\nconst getPadConstant = (output: IndicesHelper, inputRank: number, padsLength: number): string => {\n  let block = '';\n  for (let i = inputRank - 1; i >= 0; --i) {\n    block += `\n            k = i32(${output.indicesGet('indices', i)}) - ${getElementAt('uniforms.pads', i, padsLength)};\n            if (k < 0) {\n              break;\n            }\n            if (k >= i32(${getElementAt('uniforms.x_shape', i, inputRank)})) {\n              break;\n            }\n            offset += k * i32(${getElementAt('uniforms.x_strides', i, inputRank)});\n        `;\n  }\n\n  return `\n          value = ${output.type.value}(uniforms.constant_value);\n          for (var i = 0; i < 1; i++) {\n            var offset = 0;\n            var k = 0;\n            ${block}\n            value = x[offset];\n          }\n      `;\n};\n\nconst getPadReflect = (output: IndicesHelper, inputRank: number, padsLength: number): string => {\n  let block = '';\n  for (let i = inputRank - 1; i >= 0; --i) {\n    block += `\n                k = i32(${output.indicesGet('indices', i)}) - ${getElementAt('uniforms.pads', i, padsLength)};\n                if (k < 0) {\n                  k = -k;\n                }\n                {\n                  let _2n_1 = 2 * (i32(${getElementAt('uniforms.x_shape', i, inputRank)}) - 1);\n                  k = k % _2n_1;\n                  if(k >= i32(${getElementAt('uniforms.x_shape', i, inputRank)})) {\n                    k = _2n_1 - k;\n                  }\n                }\n                offset += k * i32(${getElementAt('uniforms.x_strides', i, inputRank)});\n            `;\n  }\n\n  return `\n              var offset = 0;\n              var k = 0;\n              ${block}\n              value = x[offset];\n          `;\n};\n\nconst getPadEdge = (output: IndicesHelper, inputRank: number, padsLength: number): string => {\n  let block = '';\n  for (let i = inputRank - 1; i >= 0; --i) {\n    block += `\n                k = i32(${output.indicesGet('indices', i)}) - ${getElementAt('uniforms.pads', i, padsLength)};\n                if (k < 0) {\n                  k = 0;\n                }\n                if (k >= i32(${getElementAt('uniforms.x_shape', i, inputRank)})) {\n                  k = i32(${getElementAt('uniforms.x_shape', i, inputRank)}) - 1;\n                }\n                offset += k * i32(${getElementAt('uniforms.x_strides', i, inputRank)});\n            `;\n  }\n\n  return `\n              var offset = 0;\n              var k = 0;\n              ${block}\n              value = x[offset];\n          `;\n};\n\nconst getPadWrap = (output: IndicesHelper, inputRank: number, padsLength: number): string => {\n  let block = '';\n  for (let i = inputRank - 1; i >= 0; --i) {\n    block += `\n                k = i32(${output.indicesGet('indices', i)}) - ${getElementAt('uniforms.pads', i, padsLength)};\n                if (k < 0)  {\n                  k += i32(${getElementAt('uniforms.x_shape', i, inputRank)}]);\n                }\n                if (k >= i32(${getElementAt('uniforms.x_shape', i, inputRank)})) {\n                  k -= i32(${getElementAt('uniforms.x_shape', i, inputRank)});\n                }\n                offset += k * i32(${getElementAt('uniforms.x_strides', i, inputRank)});\n            `;\n  }\n\n  return `\n              var offset = 0;\n              var k = 0;\n              ${block}\n              value = x[offset];\n          `;\n};\n\nconst getPadSnippet = (output: IndicesHelper, inputRank: number, attributes: PadAttributes): string => {\n  switch (attributes.mode) {\n    case 0:\n      return getPadConstant(output, inputRank, attributes.pads.length);\n    case 1:\n      return getPadReflect(output, inputRank, attributes.pads.length);\n    case 2:\n      return getPadEdge(output, inputRank, attributes.pads.length);\n    case 3:\n      return getPadWrap(output, inputRank, attributes.pads.length);\n    default:\n      throw new Error('Invalid mode');\n  }\n};\n\nconst createPadProgramInfo = (inputs: readonly TensorView[], attributes: PadAttributes): ProgramInfo => {\n  const outputShape = ShapeUtil.padShape(inputs[0].dims.slice(), attributes.pads);\n  const inputDims = inputs[0].dims;\n  const outputSize = ShapeUtil.size(outputShape);\n  const programUniforms: ProgramUniform[] = [\n    { type: DataType.uint32, data: outputSize },\n    { type: DataType.int32, data: attributes.pads },\n  ];\n\n  const isValueFromInput = inputs.length >= 3 && inputs[2].data;\n  if (attributes.mode === 0) {\n    programUniforms.push({ type: isValueFromInput ? inputs[2].dataType : DataType.float, data: attributes.value });\n  }\n\n  programUniforms.push(...createTensorShapeVariables(inputs[0].dims, outputShape));\n  const inputDependencies: ProgramInputTensorInfoDependency[] = ['rank'];\n\n  const getShaderSource = (shaderHelper: ShaderHelper) => {\n    const output = outputVariable('output', inputs[0].dataType, outputShape.length);\n    const input = inputVariable('x', inputs[0].dataType, inputDims.length);\n    const dataType = input.type.value;\n    const padSnippet = getPadSnippet(output, inputDims.length, attributes);\n    const uniforms: UniformsArrayType = [\n      { name: 'output_size', type: 'u32' },\n      { name: 'pads', type: 'i32', length: attributes.pads.length },\n    ];\n    if (attributes.mode === 0) {\n      uniforms.push({ name: 'constant_value', type: (isValueFromInput ? dataType : 'f32') as UniformDataElementType });\n    }\n\n    return `\n            ${shaderHelper.registerUniforms(uniforms).declareVariables(input, output)}\n            ${shaderHelper.mainStart()}\n            ${shaderHelper.guardAgainstOutOfBoundsWorkgroupSizes('uniforms.output_size')}\n\n            let indices = ${output.offsetToIndices('global_idx')};\n\n            var value = ${dataType}(0);\n            ${padSnippet}\n            output[global_idx] = value;\n        }`;\n  };\n\n  return {\n    name: 'Pad',\n    shaderCache: { hint: `${attributes.mode}${isValueFromInput}`, inputDependencies },\n    getRunData: () => ({\n      outputs: [{ dims: outputShape, dataType: inputs[0].dataType }],\n      dispatchGroup: { x: Math.ceil(ShapeUtil.size(outputShape) / 64 /* workgroup size */) },\n      programUniforms,\n    }),\n    getShaderSource,\n  };\n};\n\nconst createPadAttributesFromInputs = (inputs: readonly TensorView[], attributes: PadAttributes): PadAttributes => {\n  if (inputs.length > 1) {\n    const bigInt64Pads = inputs[1].getBigInt64Array();\n    const value =\n      inputs.length >= 3 && inputs[2].data\n        ? inputs[2].dataType === DataType.float16\n          ? inputs[2].getUint16Array()[0]\n          : inputs[2].getFloat32Array()[0]\n        : 0.0;\n\n    const inputRank = inputs[0].dims.length;\n    const updatePads = new Int32Array(2 * inputRank).fill(0);\n    if (inputs.length >= 4) {\n      const axes = inputs[3].getBigInt64Array();\n      for (let i = 0; i < axes.length; i++) {\n        updatePads[Number(axes[i])] = Number(bigInt64Pads[i]);\n        updatePads[Number(axes[i]) + inputRank] = Number(bigInt64Pads[i + axes.length]);\n      }\n    } else {\n      bigInt64Pads.forEach((v, i) => (updatePads[Number(i)] = Number(v)));\n    }\n\n    const pads: number[] = [];\n    updatePads.forEach((v) => pads.push(v));\n\n    return { mode: attributes.mode, value, pads };\n  } else {\n    return attributes;\n  }\n};\n\nexport const pad = (context: ComputeContext, attributes: PadAttributes): void => {\n  validateInputs(context.inputs);\n  const updatedAttributes = createPadAttributesFromInputs(context.inputs, attributes);\n  context.compute(createPadProgramInfo(context.inputs, updatedAttributes), { inputs: [0] });\n};\n","// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport { env } from 'onnxruntime-common';\n\nimport { DataType } from '../../../wasm-common';\nimport { TensorView } from '../../tensor-view';\nimport { PoolConvUtil, ShapeUtil } from '../../util';\nimport { AttributeWithCacheKey } from '../attribute-with-cache-key';\nimport { ComputeContext, ProgramInfo, ProgramInputTensorInfoDependency, ProgramUniform } from '../types';\n\nimport {\n  createTensorShapeVariables,\n  getElementAt,\n  IndicesHelper,\n  inputVariable,\n  outputVariable,\n  ShaderHelper,\n  UniformsArrayType,\n} from './common';\n\n// TODO: support:\n// - ceil_mode                 \"test_maxpool_2d_ceil\"\n// - storage_order             \"test_maxpool_with_argmax_2d_precomputed_strides\"\n// - [MaxPool] dilations       \"test_maxpool_2d_dilations\"\n// - [MaxPool] output[1]       \"test_maxpool_with_argmax_2d_precomputed_pads\"\n\nconst validateInputs = (inputs: readonly TensorView[]): void => {\n  if (env.webgpu.validateInputContent && (!inputs || inputs.length !== 1)) {\n    throw new Error('Pool ops requires 1 input.');\n  }\n};\n\nconst getAdjustedPoolAttributesAndOutputShape = <AttributeType extends AveragePoolAttributes | MaxPoolAttributes>(\n  input: TensorView,\n  attributes: AttributeType,\n  isGlobalOperator: boolean,\n): [AttributeType, number[]] => {\n  const isChannelsLast = attributes.format === 'NHWC';\n  const inputShapeAsChannelFirst = input.dims.slice();\n  if (isChannelsLast) {\n    inputShapeAsChannelFirst.splice(1, 0, inputShapeAsChannelFirst.pop()!); // Move channel to the second position.\n  }\n  const hasDilations = Object.hasOwnProperty.call(attributes, 'dilations');\n  const kernelShape = attributes.kernelShape.slice();\n  const strides = attributes.strides.slice();\n  const dilations: number[] = hasDilations ? (attributes as MaxPoolAttributes).dilations.slice() : [];\n  const pads = attributes.pads.slice();\n  PoolConvUtil.adjustPoolAttributes(isGlobalOperator, inputShapeAsChannelFirst, kernelShape, strides, dilations, pads);\n\n  const outputShapeAsChannelFirst = PoolConvUtil.computePoolOutputShape(\n    isGlobalOperator,\n    inputShapeAsChannelFirst,\n    strides,\n    dilations,\n    kernelShape,\n    pads,\n    attributes.autoPad,\n  );\n\n  const newAttributes = Object.assign({}, attributes);\n  if (hasDilations) {\n    Object.assign(newAttributes, { kernelShape, strides, pads, dilations, cacheKey: attributes.cacheKey });\n  } else {\n    Object.assign(newAttributes, { kernelShape, strides, pads, cacheKey: attributes.cacheKey });\n  }\n  const outputShapeAsChannelLast = outputShapeAsChannelFirst.slice();\n  outputShapeAsChannelLast.push(outputShapeAsChannelLast.splice(1, 1)[0]);\n  return [newAttributes, isChannelsLast ? outputShapeAsChannelLast : outputShapeAsChannelFirst];\n};\n\nconst getUniformAndPadInfo = <AttributeType extends AveragePoolAttributes | MaxPoolAttributes>(\n  outputShape: readonly number[],\n  attributes: AttributeType,\n): [ProgramUniform[], UniformsArrayType, boolean, boolean, boolean] => {\n  const isChannelsLast = attributes.format === 'NHWC';\n  const outputSize = ShapeUtil.size(outputShape);\n  const kernelSize = ShapeUtil.size(attributes.kernelShape);\n  const programUniforms: ProgramUniform[] = [\n    { type: DataType.uint32, data: outputSize },\n    { type: DataType.uint32, data: kernelSize },\n  ];\n  const uniforms: UniformsArrayType = [\n    { name: 'outputSize', type: 'u32' },\n    { name: 'kernelSize', type: 'u32' },\n  ];\n  if (attributes.kernelShape.length <= 2) {\n    const kw = attributes.kernelShape[attributes.kernelShape.length - 1];\n    const sw = attributes.strides[attributes.strides.length - 1];\n    const pwStart = attributes.pads[attributes.pads.length / 2 - 1];\n    const pwEnd = attributes.pads[attributes.pads.length - 1];\n    const pwStartEndNotZero = !!(pwStart + pwEnd);\n    programUniforms.push(\n      { type: DataType.uint32, data: kw },\n      { type: DataType.uint32, data: sw },\n      { type: DataType.uint32, data: pwStart },\n      { type: DataType.uint32, data: pwEnd },\n    );\n    uniforms.push(\n      { name: 'kw', type: 'u32' },\n      { name: 'sw', type: 'u32' },\n      { name: 'pwStart', type: 'u32' },\n      { name: 'pwEnd', type: 'u32' },\n    );\n\n    let phStartEndNotZero = false;\n    if (attributes.kernelShape.length === 2) {\n      const kh = attributes.kernelShape[attributes.kernelShape.length - 2];\n      const sh = attributes.strides[attributes.strides.length - 2];\n      const phStart = attributes.pads[attributes.pads.length / 2 - 2];\n      const phEnd = attributes.pads[attributes.pads.length - 2];\n      phStartEndNotZero = !!(phStart + phEnd);\n      programUniforms.push(\n        { type: DataType.uint32, data: kh },\n        { type: DataType.uint32, data: sh },\n        { type: DataType.uint32, data: phStart },\n        { type: DataType.uint32, data: phEnd },\n      );\n\n      uniforms.push(\n        { name: 'kh', type: 'u32' },\n        { name: 'sh', type: 'u32' },\n        { name: 'phStart', type: 'u32' },\n        { name: 'phEnd', type: 'u32' },\n      );\n    }\n    return [programUniforms, uniforms, true, pwStartEndNotZero, phStartEndNotZero];\n  } else {\n    if (isChannelsLast) {\n      throw new Error('Pooling with kernelShape.length > 2 is not supported for NHWC format.');\n    }\n    const kernelStrides = ShapeUtil.computeStrides(attributes.kernelShape);\n    programUniforms.push(\n      { type: DataType.uint32, data: kernelStrides },\n      { type: DataType.uint32, data: attributes.pads },\n      { type: DataType.uint32, data: attributes.strides },\n    );\n    uniforms.push(\n      { name: 'kernelStrides', type: 'u32', length: kernelStrides.length },\n      { name: 'pads', type: 'u32', length: attributes.pads.length },\n      { name: 'strides', type: 'u32', length: attributes.strides.length },\n    );\n\n    const hasPads = attributes.pads.reduce((sum, cur) => sum + cur);\n    return [programUniforms, uniforms, !!hasPads, false, false];\n  }\n};\n\nconst generatePoolingCode = <AttributeType extends AveragePoolAttributes | MaxPoolAttributes>(\n  shaderHelper: ShaderHelper,\n  x: IndicesHelper,\n  rank: number,\n  outputShapeRank: number,\n  attributes: AttributeType,\n  op1: string,\n  op2: string,\n  start: number,\n  uniforms: UniformsArrayType,\n  hasPads: boolean,\n  pwStartEndNotZero: boolean,\n  phStartEndNotZero: boolean,\n): string => {\n  const isChannelsLast = attributes.format === 'NHWC';\n  const dataType = x.type.value;\n  const output = outputVariable('output', x.type.tensor, outputShapeRank);\n\n  if (attributes.kernelShape.length <= 2) {\n    let codeW = '';\n    let codeH = '';\n    let codeHEnd = '';\n    const dimIdxW = rank - (isChannelsLast ? 2 : 1);\n    if (pwStartEndNotZero) {\n      codeW = `\n                for (var i: u32 = 0u; i < uniforms.kw; i++) {\n                  xIndices[${dimIdxW}] = indices[${dimIdxW}] * uniforms.sw - uniforms.pwStart + i;\n                  if (xIndices[${dimIdxW}] < 0 || xIndices[${dimIdxW}]\n                      >= uniforms.x_shape[${dimIdxW}]) {\n                    pad++;\n                    continue;\n                  }\n                  let x_val = x[${x.indicesToOffset('xIndices')}];\n                  ${op1}\n                }`;\n    } else {\n      codeW = `\n                for (var i: u32 = 0u; i < uniforms.kw; i++) {\n                  xIndices[${dimIdxW}] = indices[${dimIdxW}] * uniforms.sw - uniforms.pwStart + i;\n                  let x_val = x[${x.indicesToOffset('xIndices')}];\n                  ${op1}\n                }`;\n    }\n\n    if (attributes.kernelShape.length === 2) {\n      const dimIdxH = rank - (isChannelsLast ? 3 : 2);\n      if (phStartEndNotZero) {\n        codeH = `\n                for (var j: u32 = 0u; j < uniforms.kh; j++) {\n                  xIndices[${dimIdxH}] = indices[${dimIdxH}] * uniforms.sh - uniforms.phStart + j;\n                  if (xIndices[${dimIdxH}] < 0 || xIndices[${dimIdxH}] >= uniforms.x_shape[${dimIdxH}]) {\n                    pad += i32(uniforms.kw);\n                    continue;\n                  }\n              `;\n      } else {\n        codeH = `\n                for (var j: u32 = 0u; j < uniforms.kh; j++) {\n                  xIndices[${dimIdxH}] = indices[${dimIdxH}] * uniforms.sh - uniforms.phStart + j;\n                `;\n      }\n      codeHEnd = `\n              }\n            `;\n    }\n\n    const poolingCode = `\n            ${shaderHelper.registerUniforms(uniforms).declareVariables(x, output)}\n\n            ${shaderHelper.mainStart()}\n              ${shaderHelper.guardAgainstOutOfBoundsWorkgroupSizes('uniforms.outputSize')}\n\n              let indices = ${output.offsetToIndices('global_idx')};\n              var xIndices = ${output.offsetToIndices('global_idx')};\n\n              var value = ${dataType}(${start});\n              var pad = 0;\n              ${codeH}\n              ${codeW}\n              ${codeHEnd}\n              ${op2}\n\n              output[global_idx] = value;\n            }`;\n    return poolingCode;\n  } else {\n    if (isChannelsLast) {\n      throw new Error('Pooling with kernelShape.length > 2 is not supported for NHWC format.');\n    }\n    const stridesRank = attributes.kernelShape.length;\n    const padsRank = attributes.pads.length;\n    let padCode = '';\n    if (hasPads) {\n      padCode = `\n                if (xIndices[j] >= uniforms.x_shape[j]) {\n                  pad++;\n                  isPad = true;\n                  break;\n                }\n              }\n              if (!isPad) {\n                let x_val = x[${x.indicesToOffset('xIndices')}];\n                ${op1}\n              }`;\n    } else {\n      padCode = `\n              }\n              let x_val = x[${x.indicesToOffset('xIndices')}];\n              ${op1}\n            `;\n    }\n    const poolingCode = `\n            ${shaderHelper.registerUniforms(uniforms).declareVariables(x, output)}\n\n            ${shaderHelper.mainStart()}\n              ${shaderHelper.guardAgainstOutOfBoundsWorkgroupSizes('uniforms.outputSize')}\n              let indices = ${output.offsetToIndices('global_idx')};\n              var xIndices = ${output.offsetToIndices('global_idx')};\n\n              var offsets: array<u32, ${stridesRank}>;\n\n              var value = ${dataType}(${start});\n              var pad = 0;\n              var isPad = false;\n\n              for (var i: u32 = 0u; i < uniforms.kernelSize; i++) {\n                var offset = i;\n                for (var j = 0u; j < ${stridesRank - 1}u; j++) {\n                  offsets[j] = offset / ${getElementAt('uniforms.kernelStrides', 'j', stridesRank)};\n                  offset -= offsets[j] * ${getElementAt('uniforms.kernelStrides', 'j', stridesRank)};\n                }\n                offsets[${stridesRank - 1}] = offset;\n\n                isPad = false;\n                for (var j = ${rank - stridesRank}u; j < ${rank}u; j++) {\n                  xIndices[j] = indices[j] * ${getElementAt(\n                    'uniforms.strides',\n                    `j - ${rank - stridesRank}u`,\n                    stridesRank,\n                  )}\n                    + offsets[j - ${rank - stridesRank}u] - ${getElementAt('uniforms.pads', 'j - 2u', padsRank)};\n                  ${padCode}\n              }\n              ${op2}\n\n              output[global_idx] = value;\n            }`;\n    return poolingCode;\n  }\n};\n\nexport interface FormatAttributes {\n  readonly format: 'NHWC' | 'NCHW';\n}\n\nexport interface PoolCommonAttributes extends FormatAttributes {\n  readonly autoPad: string;\n  readonly ceilMode: number;\n  readonly kernelShape: readonly number[];\n  readonly strides: readonly number[];\n  readonly pads: readonly number[];\n}\n\nconst createShaderKeyFromAttributes = (attributes: PoolCommonAttributes): string =>\n  `${attributes.format};${attributes.ceilMode};${attributes.autoPad};${attributes.kernelShape.length}`;\n\nconst createAveragePoolShaderKeyFromAttributes = (attributes: AveragePoolAttributes): string =>\n  `${createShaderKeyFromAttributes(attributes)};${attributes.countIncludePad}`;\n\nconst createMaxPoolShaderKeyFromAttributes = (attributes: MaxPoolAttributes): string =>\n  `${createShaderKeyFromAttributes(attributes)};${attributes.storageOrder};${attributes.dilations}`;\n\nconst parsePoolCommonAttributes = (attributes: Record<string, unknown>): PoolCommonAttributes => ({\n  format: attributes.format as FormatAttributes['format'],\n  autoPad: ['NOTSET', 'VALID', 'SAME_UPPER', 'SAME_LOWER'][attributes.auto_pad as number],\n  ceilMode: attributes.ceil_mode as number,\n  kernelShape: attributes.kernel_shape as [number, number],\n  strides: attributes.strides as [number, number],\n  pads: attributes.pads as [number, number, number, number],\n});\n\nexport interface AveragePoolAttributes extends PoolCommonAttributes, AttributeWithCacheKey {\n  readonly countIncludePad: boolean;\n}\n\nconst createAveragePoolProgramInfo = (\n  name: string,\n  input: TensorView,\n  isGlobalOperator: boolean,\n  attributes: AveragePoolAttributes,\n): ProgramInfo => {\n  const [adjustedAttributes, outputShape] = getAdjustedPoolAttributesAndOutputShape(\n    input,\n    attributes,\n    isGlobalOperator,\n  );\n  const x = inputVariable('x', input.dataType, input.dims.length);\n  const dataType = x.type.value;\n\n  const op1 = 'value += x_val;';\n  let op2 = '';\n  if (adjustedAttributes.countIncludePad) {\n    op2 += `value /= ${dataType}(uniforms.kernelSize);`;\n  } else {\n    op2 += `value /= ${dataType}(i32(uniforms.kernelSize) - pad);`;\n  }\n  const [programUniforms, uniforms, hasPads, pwStartEndNotZero, phStartEndNotZero] = getUniformAndPadInfo(\n    outputShape,\n    adjustedAttributes,\n  );\n  programUniforms.push(...createTensorShapeVariables(input.dims, outputShape));\n  const inputDependencies: ProgramInputTensorInfoDependency[] = ['rank'];\n  return {\n    name,\n    shaderCache: {\n      hint: `${attributes.cacheKey};${hasPads};${pwStartEndNotZero};${phStartEndNotZero}`,\n      inputDependencies,\n    },\n    getRunData: () => ({\n      outputs: [{ dims: outputShape, dataType: input.dataType }],\n      dispatchGroup: { x: Math.ceil(ShapeUtil.size(outputShape) / 64 /* workgroup size */) },\n      programUniforms,\n    }),\n    getShaderSource: (shaderHelper) =>\n      generatePoolingCode(\n        shaderHelper,\n        x,\n        input.dims.length,\n        outputShape.length,\n        adjustedAttributes,\n        op1,\n        op2,\n        0.0,\n        uniforms,\n        hasPads,\n        pwStartEndNotZero,\n        phStartEndNotZero,\n      ),\n  };\n};\n\nexport const parseAveragePoolAttributes = (attributes: Record<string, unknown>): AveragePoolAttributes => {\n  const countIncludePad = (attributes.count_include_pad as number) === 0 ? false : true;\n\n  const attr = parsePoolCommonAttributes(attributes);\n  // TODO: support attribute 'ceil_mode'\n  if (attr.ceilMode !== 0) {\n    throw new Error('using ceil() in shape computation is not yet supported for AveragePool');\n  }\n  const averagePoolAttributes = { countIncludePad, ...attr, cacheKey: '' };\n  return { ...averagePoolAttributes, cacheKey: createAveragePoolShaderKeyFromAttributes(averagePoolAttributes) };\n};\n\nexport const averagePool = (context: ComputeContext, attributes: AveragePoolAttributes): void => {\n  validateInputs(context.inputs);\n  context.compute(createAveragePoolProgramInfo('AveragePool', context.inputs[0], false, attributes));\n};\n\nconst globalPoolAttributes = {\n  autoPad: '',\n  ceilMode: 0,\n  countIncludePad: false,\n  kernelShape: [],\n  strides: [],\n  pads: [],\n  storageOrder: 0,\n  dilations: [],\n};\n\nexport const parseGlobalAveragePoolAttributes = (attributes: Record<string, unknown>): AveragePoolAttributes => {\n  const format = attributes.format as FormatAttributes['format'];\n  return { format, ...globalPoolAttributes, cacheKey: format };\n};\n\nexport const globalAveragePool = (context: ComputeContext, attributes: AveragePoolAttributes): void => {\n  validateInputs(context.inputs);\n  context.compute(createAveragePoolProgramInfo('GlobalAveragePool', context.inputs[0], true, attributes));\n};\n\nexport interface MaxPoolAttributes extends PoolCommonAttributes, AttributeWithCacheKey {\n  readonly storageOrder: number;\n  readonly dilations: number[];\n}\n\nconst createMaxPoolProgramInfo = (\n  name: string,\n  input: TensorView,\n  isGlobalOperator: boolean,\n  attributes: MaxPoolAttributes,\n): ProgramInfo => {\n  const [adjustedAttributes, outputShape] = getAdjustedPoolAttributesAndOutputShape(\n    input,\n    attributes,\n    isGlobalOperator,\n  );\n  const op1 = `\n      value = max(x_val, value);\n    `;\n  const op2 = '';\n  const x = inputVariable('x', input.dataType, input.dims.length);\n  const inputDependencies: ProgramInputTensorInfoDependency[] = ['rank'];\n  const [programUniforms, uniforms, hasPads, pwStartEndNotZero, phStartEndNotZero] = getUniformAndPadInfo(\n    outputShape,\n    adjustedAttributes,\n  );\n  programUniforms.push(...createTensorShapeVariables(input.dims, outputShape));\n  return {\n    name,\n    shaderCache: {\n      hint: `${attributes.cacheKey};${hasPads};${pwStartEndNotZero};${phStartEndNotZero}`,\n      inputDependencies,\n    },\n    getRunData: () => ({\n      outputs: [{ dims: outputShape, dataType: input.dataType }],\n      dispatchGroup: { x: Math.ceil(ShapeUtil.size(outputShape) / 64 /* workgroup size */) },\n      programUniforms,\n    }),\n    getShaderSource: (shaderHelper) =>\n      generatePoolingCode(\n        shaderHelper,\n        x,\n        input.dims.length,\n        outputShape.length,\n        adjustedAttributes,\n        op1,\n        op2,\n        input.dataType === DataType.float16 ? -65504 : -1e5,\n        uniforms,\n        hasPads,\n        pwStartEndNotZero,\n        phStartEndNotZero,\n      ),\n  };\n};\n\nexport const maxPool = (context: ComputeContext, attributes: MaxPoolAttributes): void => {\n  validateInputs(context.inputs);\n  context.compute(createMaxPoolProgramInfo('MaxPool', context.inputs[0], false, attributes));\n};\n\nexport const parseMaxPoolAttributes = (attributes: Record<string, unknown>): MaxPoolAttributes => {\n  const storageOrder = attributes.storage_order as number;\n  const dilations = attributes.dilations as [number, number];\n\n  const attr = parsePoolCommonAttributes(attributes);\n  // TODO: support attribute 'ceil_mode' and 'storage_order'\n  if (storageOrder !== 0) {\n    throw new Error('column major storage order is not yet supported for MaxPool');\n  }\n  if (attr.ceilMode !== 0) {\n    throw new Error('using ceil() in shape computation is not yet supported for MaxPool');\n  }\n  const maxPoolAttributes = { storageOrder, dilations, ...attr, cacheKey: '' };\n  return { ...maxPoolAttributes, cacheKey: createMaxPoolShaderKeyFromAttributes(maxPoolAttributes) };\n};\n\nexport const parseGlobalMaxPoolAttributes = (attributes: Record<string, unknown>): MaxPoolAttributes => {\n  const format = attributes.format as FormatAttributes['format'];\n  return { format, ...globalPoolAttributes, cacheKey: format };\n};\n\nexport const globalMaxPool = (context: ComputeContext, attributes: MaxPoolAttributes): void => {\n  validateInputs(context.inputs);\n  context.compute(createMaxPoolProgramInfo('GlobalMaxPool', context.inputs[0], true, attributes));\n};\n","// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport { DataType } from '../../../wasm-common';\nimport { TensorView } from '../../tensor-view';\nimport { ShapeUtil } from '../../util';\nimport { AttributeWithCacheKey, createAttributeWithCacheKey } from '../attribute-with-cache-key';\nimport { ComputeContext, ProgramInfo, ProgramUniform } from '../types';\n\nimport {\n  createTensorShapeVariables,\n  getMaxComponents,\n  inputVariable,\n  outputVariable,\n  ShaderHelper,\n  UniformsArrayType,\n} from './common';\n\nexport interface DequantizeLinerAttributes extends AttributeWithCacheKey {\n  axis: number;\n  blockSize: number;\n}\n\nconst validateInputs = (inputs: readonly TensorView[], attributes: DequantizeLinerAttributes): void => {\n  if (inputs.length < 2 || inputs.length > 3) {\n    throw new Error('DequantizeLinear requires 2 or 3 inputs.');\n  }\n  if (inputs.length === 3 && inputs[1].dims === inputs[2].dims) {\n    throw new Error('x-scale and x-zero-point must have the same shape.');\n  }\n  if (inputs.length === 3 && inputs[0].dataType !== inputs[2].dataType) {\n    throw new Error('x and x-zero-point must have the same data type.');\n  }\n  if (inputs[0].dataType === DataType.int32 && inputs.length > 2) {\n    throw new Error('In the case of dequantizing int32 there is no zero point.');\n  }\n  if (inputs[1].dims.length !== 0 && inputs[1].dims.length !== 1 && inputs[1].dims.length !== inputs[0].dims.length) {\n    throw new Error('scale input must be a scalar, a 1D tensor, or have the same rank as the input tensor.');\n  }\n  // validate scale and zero-point input shapes\n  if (inputs.length > 2) {\n    // zero-point input type should be the same as input data type.\n    if (inputs[0].dataType !== inputs[2].dataType) {\n      throw new Error('x and x-zero-point must have the same data type.');\n    }\n    // Scale and zero-point inputs must have the same shape\n    if (inputs[1].dims.length !== inputs[2].dims.length) {\n      throw new Error('scale and zero-point inputs must have the same rank.');\n    }\n    if (!inputs[1].dims.map((d, i) => d === inputs[2].dims[i]).reduce((a, b) => a && b, true)) {\n      throw new Error('scale and zero-point inputs must have the same shape.');\n    }\n  }\n  // Validate blockSize\n  if (attributes.blockSize > 0) {\n    // Block qunatization\n    if (inputs[1].dims.length === 0 || (inputs[1].dims.length === 1 && inputs[1].dims[0] === 1)) {\n      throw new Error('blockSize must be set only for block quantization.');\n    }\n    if (\n      !inputs[1].dims.map((d, i) => i === attributes.axis || d === inputs[0].dims[i]).reduce((a, b) => a && b, true)\n    ) {\n      throw new Error('For block qunatization, scale input shape to match the input shape except for the axis');\n    }\n    // Scale input rank should be same as the input rank\n    if (inputs[1].dims.length !== inputs[0].dims.length) {\n      throw new Error('For block qunatization the scale input rank must be the same as the x rank.');\n    }\n    const dI = inputs[0].dims[attributes.axis];\n    const si = inputs[1].dims[attributes.axis];\n    if (attributes.blockSize < Math.ceil(dI / si) || attributes.blockSize > Math.ceil(dI / (si - 1) - 1)) {\n      throw new Error('blockSize must be with in the range [ceil(dI / Si), ceil(dI / (Si - 1) - 1)].');\n    }\n  }\n};\n\nconst createDequantizeLinearProgramInfo = (\n  inputs: readonly TensorView[],\n  attributes: DequantizeLinerAttributes,\n): ProgramInfo => {\n  const axis = ShapeUtil.normalizeAxis(attributes.axis, inputs[0].dims.length);\n  const inputType = inputs[0].dataType;\n  const isSigned = inputType === DataType.int8;\n  const outputShape = inputs[0].dims; // output shape is same as the input shape\n  const dataType = inputs[1].dataType; // output type is same as the the scale input type\n  const outputSize = ShapeUtil.size(outputShape);\n  const isPacked = inputType === DataType.int8 || inputType === DataType.uint8;\n  const inputShape = isPacked ? [Math.ceil(ShapeUtil.size(inputs[0].dims) / 4)] : inputs[0].dims;\n  const scaleShape = inputs[1].dims;\n  const zeroPointInput = inputs.length > 2 ? inputs[2] : undefined;\n  const zeroPointShape = zeroPointInput\n    ? isPacked\n      ? [Math.ceil(ShapeUtil.size(zeroPointInput.dims) / 4)]\n      : zeroPointInput.dims\n    : undefined;\n  // Scales input is a scaler for per-tensor/per-layer quantization, 1-D tensor for per-axis quantization\n  // or tensor with same rank as input for blocked quantization.\n  const perLayerQuantization = scaleShape.length === 0 || (scaleShape.length === 1 && scaleShape[0] === 1);\n  const perAxisQuantization = perLayerQuantization === false && scaleShape.length === 1;\n  // Left unnecessary commented-out assignment for documentation\n  // const blockQuantization = perLayerQuantization === false && perAxisQuantization === false;\n  const maxComponents = getMaxComponents(outputSize);\n  const useComponents = perLayerQuantization && (!isPacked || maxComponents === 4);\n  const components = useComponents ? maxComponents : 1;\n  const inputComponent = useComponents && !isPacked ? maxComponents : 1;\n  const input = inputVariable('input', isPacked ? DataType.uint32 : inputType, inputShape.length, inputComponent);\n  const scale = inputVariable('scale', dataType, scaleShape.length);\n  const zeroPoint = zeroPointInput\n    ? inputVariable('zero_point', isPacked ? DataType.uint32 : inputType, zeroPointShape!.length)\n    : undefined;\n  const output = outputVariable('output', dataType, outputShape.length, components);\n  const inputVariables = [input, scale];\n  if (zeroPoint) {\n    inputVariables.push(zeroPoint);\n  }\n  const inputShapes = [inputShape, scaleShape];\n  if (zeroPointInput) {\n    inputShapes.push(zeroPointShape!);\n  }\n  const programUniforms: ProgramUniform[] = [\n    { type: DataType.uint32, data: outputSize / components },\n    { type: DataType.uint32, data: axis },\n    { type: DataType.uint32, data: attributes.blockSize },\n    ...createTensorShapeVariables(...inputShapes, outputShape),\n  ];\n  const getShaderSource = (shaderHelper: ShaderHelper) => {\n    const uniforms: UniformsArrayType = [\n      { name: 'output_size', type: 'u32' },\n      { name: 'axis', type: 'u32' },\n      { name: 'block_size', type: 'u32' },\n    ];\n    return `\n      ${shaderHelper.registerUniforms(uniforms).declareVariables(...inputVariables, output)}\n      ${shaderHelper.mainStart()}\n          ${shaderHelper.guardAgainstOutOfBoundsWorkgroupSizes('uniforms.output_size')}\n          let output_indices = ${output.offsetToIndices('global_idx')};\n\n          // Set input x\n          ${(() => {\n            if (isPacked) {\n              return `\n            let input = ${input.getByOffset('global_idx / 4')};\n            let x_vec = ${isSigned ? 'unpack4xI8(input)' : 'unpack4xU8(input)'};\n            let x_value = ${components === 1 ? 'x_vec[global_idx % 4]' : 'x_vec'};`;\n            } else {\n              return `let x_value = ${input.getByOffset('global_idx')};`;\n            }\n          })()};\n\n          // Set scale input\n          ${(() => {\n            if (perLayerQuantization) {\n              // scale input is a scalar ()\n              return `let scale_value= ${scale.getByOffset('0')}`;\n            } else if (perAxisQuantization) {\n              // scale input is a 1D tensor\n              return `\n            let scale_index = ${output.indicesGet('output_indices', 'uniforms.axis')};\n            let scale_value= ${scale.getByOffset('scale_index')};`;\n            } else {\n              // Block quantization. Scale input rank is same as input/output rank.\n              return `\n            var scale_indices: ${scale.type.indices} = output_indices;\n            let index = ${scale.indicesGet('scale_indices', 'uniforms.axis')} / uniforms.block_size;\n            ${scale.indicesSet('scale_indices', 'uniforms.axis', 'index')};\n            let scale_value= ${scale.getByIndices('scale_indices')};`;\n            }\n          })()};\n\n          // Set zero-point input\n          ${(() => {\n            if (zeroPoint) {\n              if (perLayerQuantization) {\n                // zero-point input is a scalar\n                if (isPacked) {\n                  return `\n                let zero_point_input = ${zeroPoint.getByOffset('0')};\n                let zero_point_vec =  ${isSigned ? 'unpack4xI8(zero_point_input)' : 'unpack4xU8(zero_point_input)'};\n                let zero_point_value= zero_point_vec[0]`;\n                } else {\n                  return `let zero_point_value = ${zeroPoint.getByOffset('0')}`;\n                }\n              } else if (perAxisQuantization) {\n                // zero-point input is a 1D tensor\n                if (isPacked) {\n                  return `\n                let zero_point_index = ${output.indicesGet('output_indices', 'uniforms.axis')};\n                let zero_point_input = ${zeroPoint.getByOffset('zero_point_index / 4')};\n                let zero_point_vec =  ${isSigned ? 'unpack4xI8(zero_point_input)' : 'unpack4xU8(zero_point_input)'};\n                let zero_point_value = zero_point_vec[zero_point_index % 4]`;\n                } else {\n                  return `\n                let zero_point_index = ${output.indicesGet('output_indices', 'uniforms.axis')};\n                let zero_point_value = ${zeroPoint.getByOffset('zero_point_index')};`;\n                }\n              } else {\n                // BlockedQuantization. The zero-point input shape is same as the input shape except along axis.\n                if (isPacked) {\n                  return `\n                let zero_point_offset = ${scale.indicesToOffset('scale_indices')};\n                let zero_point_input = ${zeroPoint.getByOffset('zero_point_offset / 4')};\n                let zero_point_vec = ${isSigned ? 'unpack4xI8(zero_point_input)' : 'unpack4xU8(zero_point_input)'};\n                let zero_point_value = zero_point_vec[zero_point_offset % 4];`;\n                } else {\n                  return `let zero_point_value = ${zeroPoint.getByIndices('scale_indices')};`;\n                }\n              }\n            } else {\n              return `let zero_point_value = ${isPacked ? (isSigned ? 'i32' : 'u32') : input.type.value}(0);`;\n            }\n          })()};\n      // Compute and write output\n      ${output.setByOffset('global_idx', `${output.type.value}(x_value - zero_point_value) * scale_value`)};\n      }`;\n  };\n  return {\n    name: 'DequantizeLinear',\n    shaderCache: {\n      hint: attributes.cacheKey,\n      inputDependencies: zeroPoint ? ['rank', 'rank', 'rank'] : ['rank', 'rank'],\n    },\n    getShaderSource,\n    getRunData: () => ({\n      outputs: [{ dims: outputShape, dataType }],\n      dispatchGroup: { x: Math.ceil(outputSize / components / 64), y: 1, z: 1 },\n      programUniforms,\n    }),\n  };\n};\n\nexport const dequantizeLinear = (context: ComputeContext, attributes: DequantizeLinerAttributes): void => {\n  validateInputs(context.inputs, attributes);\n  context.compute(createDequantizeLinearProgramInfo(context.inputs, attributes));\n};\n\nexport const parseDequantizeLinearAttributes = (attributes: Record<string, unknown>): DequantizeLinerAttributes =>\n  createAttributeWithCacheKey({ axis: attributes.axis as number, blockSize: attributes.blockSize as number });\n","// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport { env } from 'onnxruntime-common';\n\nimport { DataType } from '../../../wasm-common';\nimport { ComputeContext, ProgramInfo, ProgramUniform } from '../types';\n\nimport {\n  createTensorShapeVariables,\n  outputVariable,\n  ShaderHelper,\n  UniformDataElementType,\n  UniformsArrayType,\n} from './common';\n\nconst validateInputsContent = (start: number, limit: number, delta: number): void => {\n  const sameStartLimit = start === limit;\n  const increasingRangeNegativeStep = start < limit && delta < 0;\n  const decreasingRangePositiveStep = start > limit && delta > 0;\n\n  if (sameStartLimit || increasingRangeNegativeStep || decreasingRangePositiveStep) {\n    throw new Error(\"Range these inputs' contents are invalid.\");\n  }\n};\n\nconst createRangeProgramInfo = (start: number, limit: number, delta: number, dataType: DataType): ProgramInfo => {\n  const numElements = Math.abs(Math.ceil((limit - start) / delta));\n  const outputShape: number[] = [numElements];\n  const outputSize = numElements;\n  const programUniforms: ProgramUniform[] = [\n    { type: DataType.uint32, data: outputSize },\n    { type: dataType, data: start },\n    { type: dataType, data: delta },\n    ...createTensorShapeVariables(outputShape),\n  ];\n\n  const getShaderSource = (shaderHelper: ShaderHelper) => {\n    const output = outputVariable('output', dataType, outputShape.length);\n    const wgslType = output.type.value;\n    const uniforms: UniformsArrayType = [\n      { name: 'outputSize', type: 'u32' },\n      { name: 'start', type: wgslType as UniformDataElementType },\n      { name: 'delta', type: wgslType as UniformDataElementType },\n    ];\n    return `\n        ${shaderHelper.registerUniforms(uniforms).declareVariables(output)}\n        ${shaderHelper.mainStart()}\n        ${shaderHelper.guardAgainstOutOfBoundsWorkgroupSizes('uniforms.outputSize')}\n        output[global_idx] = uniforms.start + ${wgslType}(global_idx) * uniforms.delta;\n      }`;\n  };\n\n  return {\n    name: 'Range',\n    shaderCache: { hint: `${dataType}` },\n    getShaderSource,\n    getRunData: () => ({\n      outputs: [{ dims: outputShape, dataType }],\n      dispatchGroup: { x: Math.ceil(outputSize / 64 /* workgroup size */) },\n      programUniforms,\n    }),\n  };\n};\n\nexport const range = (context: ComputeContext): void => {\n  let start = 0;\n  let limit = 0;\n  let delta = 0;\n  if (context.inputs[0].dataType === DataType.int32) {\n    start = context.inputs[0].getInt32Array()[0];\n    limit = context.inputs[1].getInt32Array()[0];\n    delta = context.inputs[2].getInt32Array()[0];\n  } else if (context.inputs[0].dataType === DataType.float) {\n    start = context.inputs[0].getFloat32Array()[0];\n    limit = context.inputs[1].getFloat32Array()[0];\n    delta = context.inputs[2].getFloat32Array()[0];\n  }\n  if (env.webgpu.validateInputContent) {\n    validateInputsContent(start, limit, delta);\n  }\n\n  context.compute(createRangeProgramInfo(start, limit, delta, context.inputs[0].dataType), { inputs: [] });\n};\n","// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport { DataType } from '../../../wasm-common';\nimport { TensorView } from '../../tensor-view';\nimport { ShapeUtil } from '../../util';\nimport { AttributeWithCacheKey, createAttributeWithCacheKey } from '../attribute-with-cache-key';\nimport { ComputeContext, ProgramInfo, ProgramUniform } from '../types';\n\nimport {\n  atomicOutputVariable,\n  createTensorShapeVariables,\n  inputVariable,\n  outputVariable,\n  ShaderHelper,\n} from './common';\n\nexport interface ScatterNDAttributes extends AttributeWithCacheKey {\n  reduction: string;\n}\n\ntype ReductionType = 'i32' | 'u32' | 'f32';\n\nconst atomicReductionSnippet = (reduction: string, ptr: string, v: string, type: ReductionType) => {\n  if (reduction !== 'none' && type !== 'i32' && type !== 'u32' && type !== 'f32') {\n    throw new Error(`Input ${type} is not supported with reduction ${reduction}.`);\n  }\n\n  const floatStart = `{\n                var oldValue = 0;\n                loop {\n                  let newValueF32 =`;\n  const floatEnd = `;\n                  let newValue = bitcast<i32>(newValueF32);\n                  let res = atomicCompareExchangeWeak(&${ptr}, oldValue, newValue);\n                  if res.exchanged {\n                    break;\n                  }\n                  oldValue = res.old_value;\n                }\n              }`;\n\n  switch (reduction) {\n    case 'none':\n      return `${ptr}=${v};`;\n    case 'add':\n      if (type === 'i32' || type === 'u32') {\n        return `atomicAdd(&${ptr}, bitcast<${type}>(${v}));`;\n      } else {\n        // atomicAdd only supports uint/int type. For float, we use\n        // atomicCompareExchangeWeak to simulate.\n        return `\n              ${floatStart}bitcast<${type}>(oldValue) + (${v})${floatEnd}`;\n      }\n    case 'max':\n      if (type === 'i32' || type === 'u32') {\n        return `atomicMax(&${ptr}, bitcast<${type}>(${v}));`;\n      } else {\n        // atomicMax only supports uint/int type. For float, we use\n        // atomicCompareExchangeWeak to simulate.\n        return `\n                ${floatStart}max(bitcast<f32>(oldValue), (${v}))${floatEnd}`;\n      }\n    case 'min':\n      if (type === 'i32' || type === 'u32') {\n        return `atomicMin(&${ptr}, bitcast<${type}>(${v}));`;\n      } else {\n        // atomicMin only supports uint/int type. For float, we use\n        // atomicCompareExchangeWeak to simulate.\n        return `${floatStart}min(bitcast<${type}>(oldValue), (${v}))${floatEnd}`;\n      }\n    case 'mul':\n      // atomicMul is not supported, we use atomicCompareExchangeWeak to simulate.\n      return `${floatStart}(bitcast<${type}>(oldValue) * (${v}))${floatEnd}`;\n\n    default:\n      throw new Error(`Reduction ${reduction} is not supported.`);\n  }\n};\n\nconst createScatterNDProgramInfo = (inputs: readonly TensorView[], attributes: ScatterNDAttributes): ProgramInfo => {\n  const inputShape = inputs[0].dims;\n  const indicesShape = inputs[1].dims;\n  const outputShape = inputShape;\n  // TODO: support bool with components 4.\n  const components = 1;\n  const outputSize = Math.ceil(ShapeUtil.size(indicesShape) / components);\n  const lastIndexDimension = indicesShape[indicesShape.length - 1];\n  const numUpdatesElements = ShapeUtil.sizeFromDimension(inputShape, lastIndexDimension);\n\n  const programUniforms: ProgramUniform[] = [\n    { type: DataType.uint32, data: outputSize },\n    { type: DataType.uint32, data: lastIndexDimension },\n    { type: DataType.uint32, data: numUpdatesElements },\n    ...createTensorShapeVariables(inputs[1].dims, inputs[2].dims, outputShape),\n  ];\n\n  const getShaderSource = (shaderHelper: ShaderHelper) => {\n    const indices = inputVariable('indices', inputs[1].dataType, inputs[1].dims.length);\n    const updates = inputVariable('updates', inputs[2].dataType, inputs[2].dims.length, components);\n    const output =\n      attributes.reduction !== 'none' && attributes.reduction !== ''\n        ? atomicOutputVariable('output', inputs[0].dataType, outputShape.length)\n        : outputVariable('output', inputs[0].dataType, outputShape.length, components);\n\n    return `\n      ${shaderHelper\n        .registerUniform('output_size', 'u32')\n        .registerUniform('last_index_dimension', 'u32')\n        .registerUniform('num_updates_elements', 'u32')\n        .declareVariables(indices, updates, output)}\n      ${shaderHelper.mainStart()}\n        ${shaderHelper.guardAgainstOutOfBoundsWorkgroupSizes('uniforms.output_size')}\n  var hasDuplicates = false;\n  if (${attributes.reduction === 'none'}) {\n    let n = ${ShapeUtil.size(indicesShape)};\n    for (var i = 0; i < n; i = i + 1) {\n      for (var j = i + 1; j < n; j = j + 1) {\n        var index_i = i32(indices[i].x);\n        var index_j = i32(indices[j].x);\n        if (index_i == index_j) {\n          hasDuplicates = true;\n          break;\n        }\n      }\n      if (hasDuplicates) {\n        break;\n      }\n    }\n  }\n\n  var data_offset = 0u;\n  var indices_start = uniforms.last_index_dimension * global_idx;\n  if (${attributes.reduction === 'none'} && hasDuplicates) {\n    if (global_idx != 0u) {\n      return;\n    }\n    indices_start = 0u;\n  }\n  let indices_end = indices_start + uniforms.last_index_dimension;\n  for (var i = indices_start; i < indices_end; i++) {\n    var index = i32(indices[i].x);\n    ${\n      inputs[0].dims.length === 1\n        ? `\n    let element_count_dim = uniforms.output_strides;\n    let dim_value = uniforms.output_shape;`\n        : `\n    let element_count_dim = uniforms.output_strides[i - indices_start];\n    let dim_value = uniforms.output_shape[i - indices_start + uniforms.last_index_dimension];`\n    }\n    if (index >= 0) {\n      if (index >= i32(dim_value)) {\n        index = i32(dim_value - 1);\n      }\n    } else {\n      if (index < -i32(dim_value)) {\n        index = 0;\n      } else {\n        index += i32(dim_value);\n      }\n    }\n    data_offset += u32((u32(index) * element_count_dim));\n  }\n\n  for (var i = 0u; i < uniforms.num_updates_elements; i++) {\n    let value = updates[uniforms.num_updates_elements * global_idx + i];\n    ${atomicReductionSnippet(\n      attributes.reduction,\n      'output[data_offset + i]',\n      'value',\n      output.type.value as ReductionType,\n    )}\n  }\n\n      }`;\n  };\n  return {\n    name: 'ScatterND',\n    shaderCache: {\n      hint: `${attributes.cacheKey}_${attributes.reduction}`,\n      inputDependencies: ['rank', 'rank'],\n    },\n    getRunData: () => ({\n      outputs: [{ dims: outputShape, dataType: inputs[0].dataType }],\n      dispatchGroup: { x: Math.ceil(outputSize / 64 /* workgroup size */) },\n      programUniforms,\n    }),\n    getShaderSource,\n  };\n};\n\nexport const parseScatterNDAttributes = (attributes: Record<string, unknown>): ScatterNDAttributes =>\n  createAttributeWithCacheKey({ reduction: attributes.reduction as string });\n\nexport const scatterND = (context: ComputeContext, attributes: ScatterNDAttributes): void => {\n  context.compute(createScatterNDProgramInfo(context.inputs, attributes), {\n    inputs: [context.inputs[1], context.inputs[2]],\n    outputs: [],\n  });\n};\n","// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport { DataType } from '../../../wasm-common';\nimport { TensorView } from '../../tensor-view';\nimport { ShapeUtil } from '../../util';\nimport { AttributeWithCacheKey, createAttributeWithCacheKey } from '../attribute-with-cache-key';\nimport { ComputeContext, ProgramInfo } from '../types';\n\nimport {\n  createTensorShapeVariables,\n  getElementAt,\n  IndicesHelper,\n  inputVariable,\n  outputVariable,\n  ShaderHelper,\n} from './common';\n\ntype CoordinateTransformMode =\n  | 'half_pixel'\n  | 'asymmetric'\n  | 'pytorch_half_pixel'\n  | 'tf_half_pixel_for_nn'\n  | 'align_corners'\n  | 'tf_crop_and_resize'\n  | 'half_pixel_symmetric';\n\ntype KeepAspectRatioPolicy = 'stretch' | 'not_smaller' | 'not_larger';\n\ntype Mode = 'nearest' | 'linear' | 'cubic';\n\ntype NearestMode = 'round_prefer_floor' | 'round_prefer_ceil' | 'floor' | 'ceil' | 'simple';\n\nexport interface ResizeAttributes extends AttributeWithCacheKey {\n  antialias: number;\n  axes: number[];\n  coordinateTransformMode: CoordinateTransformMode;\n  cubicCoeffA: number;\n  excludeOutside: boolean;\n  extrapolationValue: number;\n  keepAspectRatioPolicy: KeepAspectRatioPolicy;\n  mode: Mode;\n  nearestMode: NearestMode;\n}\n\nconst validateScales = (scales: number[], attributes: ResizeAttributes): void => {\n  scales.every(\n    (value) =>\n      value > 0 ||\n      (() => {\n        throw new Error('Resize requires scales input values to be positive');\n      }),\n  );\n  // Check scales dims based on mode: LINEAR, CUBIC\n  if (scales.length > 0) {\n    if (attributes.mode === 'linear') {\n      if (\n        !(\n          scales.length === 2 ||\n          scales.length === 3 ||\n          (scales.length === 4 && scales[0] === 1 && scales[1] === 1) ||\n          (scales.length === 4 && scales[0] === 1 && scales[3] === 1) ||\n          (scales.length === 5 && scales[0] === 1 && scales[1] === 1)\n        )\n      ) {\n        throw new Error(\n          `For linear mode, Resize requires scales to be 2D, 3D, 4D with either two outermost or one innermost and\n            one outermost scale values equal to 1, or 5D with two outermost scale values equal to 1`,\n        );\n      }\n    } else if (attributes.mode === 'cubic') {\n      if (\n        !(\n          scales.length === 2 ||\n          (scales.length === 4 && scales[0] === 1 && scales[1] === 1) ||\n          (scales.length === 4 && scales[0] === 1 && scales[3] === 1)\n        )\n      ) {\n        throw new Error('Resize requires scales input size to be 2 or 4 for cubic mode');\n      }\n    }\n  }\n};\n\nconst updateScales = (scales: readonly number[], axes: readonly number[], rank: number): number[] => {\n  axes.every(\n    (value) =>\n      (value >= 0 && value < rank) ||\n      (() => {\n        throw new Error('Resize requires axes input values to be positive and less than rank');\n      }),\n  );\n  const newScales = new Array(rank).fill(1.0);\n  axes.forEach((value, index) => (newScales[value] = scales[index]));\n  return newScales;\n};\n\nconst validateInputs = (\n  inputs: readonly TensorView[],\n  attributes: ResizeAttributes,\n  opsetVersion: number,\n  scales: number[],\n  sizes: number[],\n  roi: number[],\n): void => {\n  const [roiInputIndex, scalesInputIndex, sizesInputIndex] =\n    opsetVersion > 10 ? [1, 2, 3] : [-1, inputs.length > 1 ? 1 : -1, -1];\n  const rank = inputs[0].dims.length;\n  if (roiInputIndex > 0 && inputs.length > roiInputIndex && inputs[roiInputIndex].dims.length > 0) {\n    inputs[roiInputIndex].getFloat32Array().forEach((value) => roi.push(value));\n  } else if (attributes.coordinateTransformMode === 'tf_crop_and_resize') {\n    throw new Error('Resize requires RoI input to be specified when coordinateTransformMode is tfCropAndResize');\n  }\n\n  if (\n    scalesInputIndex > 0 &&\n    inputs.length > scalesInputIndex &&\n    inputs[scalesInputIndex].dims.length === 1 &&\n    inputs[scalesInputIndex].dims[0] > 0\n  ) {\n    inputs[scalesInputIndex].getFloat32Array().forEach((value) => scales.push(value));\n    if (\n      scales.length !== 0 &&\n      scales.length !== rank &&\n      opsetVersion >= 18 &&\n      scales.length !== attributes.axes.length\n    ) {\n      throw new Error('Resize requires scales input size to be same as input rank or axes size for opset 18 and up');\n    }\n    validateScales(scales, attributes);\n    if (attributes.axes.length > 0) {\n      updateScales(scales, attributes.axes, rank).forEach((value, index) => (scales[index] = value));\n    }\n  }\n  if (\n    sizesInputIndex > 0 &&\n    inputs.length > sizesInputIndex &&\n    inputs[sizesInputIndex].dims.length === 1 &&\n    inputs[sizesInputIndex].dims[0] > 0\n  ) {\n    inputs[sizesInputIndex].getBigInt64Array().forEach((value) => sizes.push(Number(value)));\n    if (sizes.length !== 0 && sizes.length !== rank && opsetVersion >= 18 && sizes.length !== attributes.axes.length) {\n      throw new Error('Resize requires sizes input size to be same as input rank or axes size for opset 18 and up');\n    }\n  }\n\n  if (attributes.axes.length > 0) {\n    if (scales.length !== 0 && scales.length !== attributes.axes.length) {\n      throw new Error('Resize requires \"scales\" input size to be of axes rank when axes attributes is specified');\n    }\n    if (sizes.length !== 0 && sizes.length !== attributes.axes.length) {\n      throw new Error('Resize requires \"sizes\" input size to be of rank axes rank when axes attributes is specified');\n    }\n  }\n  if (typeof scales !== 'undefined' && typeof sizes !== 'undefined' && scales.length > 0 && sizes.length > rank) {\n    throw new Error('Resize requires only of scales or sizes to be specified');\n  }\n};\n\nconst getSafeIntegerDivision = (a: string, b: string, c: string, dType: string): string => `\n  // The whole part and the fractional part are calculated separately due to inaccuracy of floating\n  // point division. As an example, f32(21) / f32(7) may evaluate to 2.99... instead of 3, causing an\n  // offset-by-one error later in floor().\n  let big = (${a}) * (${b});\n  let whole = ${dType}(big / (${c}));\n  let fract = ${dType}(big % (${c})) / ${dType}(${c});\n  return whole + fract;\n`;\n\nconst getOriginalCoordinateFromResizedCoordinate = (\n  coordinateTransferMode: CoordinateTransformMode,\n  dType: string,\n): string =>\n  `fn getOriginalCoordinateFromResizedCoordinate(xResized: u32, xScale: f32, lengthResized: u32,\n     lengthOriginal: u32, roiStart: f32, roiEnd: f32) -> ${dType} { ` +\n  (() => {\n    switch (coordinateTransferMode) {\n      case 'asymmetric':\n        return `\n          if (xScale < 1.0 || floor(xScale) != xScale) {\n            return ${dType}(xResized) / ${dType}(xScale);\n          } else {\n            ${getSafeIntegerDivision('xResized', 'lengthOriginal', 'lengthResized', dType)}\n          }\n        `;\n      case 'pytorch_half_pixel':\n        return `if (lengthResized > 1) {\n                    return (${dType}(xResized) + 0.5) / ${dType}(xScale) - 0.5;\n                  } else {\n                    return 0.0;\n                  }`;\n      case 'tf_half_pixel_for_nn':\n        return `return (${dType}(xResized) + 0.5) / ${dType}(xScale);`;\n      case 'align_corners':\n        return `if (lengthResized == 1) {\n                    return 0.0;\n                  } else {\n                    ${getSafeIntegerDivision('xResized', 'lengthOriginal - 1', 'lengthResized - 1', dType)}\n                  }`;\n      case 'tf_crop_and_resize':\n        return `if (lengthResized > 1) {\n                    return ${dType}(roiStart) * ${dType}(lengthOriginal - 1) +\n                        (${dType}(xResized) * ${dType}(roiEnd - roiStart) * ${dType}(lengthOriginal - 1)) /\n                        ${dType}(lengthResized - 1);\n                  } else {\n                    return 0.5 * ${dType}(roiStart + roiEnd) * ${dType}(lengthOriginal - 1);\n                  }`;\n      case 'half_pixel_symmetric':\n        return `const outputWidth = ${dType}xScale * ${dType}(lengthResized);\n                  const adjustment = ${dType}(lengthResized) / outputWidth;\n                  const center = ${dType}(lengthOriginal) / 2;\n                  const offset = center * (1 - adjustment);\n                  return offset + ((${dType}(xResized) + 0.5) / ${dType}(xScale)) - 0.5;`;\n      case 'half_pixel':\n        return `return ((${dType}(xResized) + 0.5) / ${dType}(xScale)) - 0.5;`;\n      default:\n        throw new Error(`Coordinate transform mode ${coordinateTransferMode} is not supported`);\n    }\n  })() +\n  '}';\n\nconst getNearestPixelFromOriginal = (nearestMode: NearestMode, opsetVersion: number, dType: string): string =>\n  `fn getNearestPixelFromOriginal(xOriginal: ${dType}, isDownSample: bool) -> ${dType} {` +\n  (() => {\n    switch (nearestMode) {\n      case 'round_prefer_ceil':\n        return 'if (fract(xOriginal) == 0.5) { \\\n            return ceil(xOriginal); \\\n          } else { \\\n            return round(xOriginal); \\\n          }';\n      case 'floor':\n        return 'return floor(xOriginal);';\n      case 'ceil':\n        return 'return ceil(xOriginal);';\n      case 'round_prefer_floor':\n        return 'if (fract(xOriginal) == 0.5) { \\\n                    return floor(xOriginal); \\\n                  } else { \\\n                    return round(xOriginal); \\\n                  }';\n      case 'simple':\n      default:\n        if (opsetVersion < 11) {\n          return 'if (isDownSample) \\\n                    { \\\n                      return ceil(xOriginal); \\\n                    } else { \\\n                      return xOriginal; \\\n                    }';\n        }\n        throw new Error(`Nearest mode ${nearestMode} is not supported`);\n    }\n  })() +\n  '}';\n\nconst updateRoI = (roi: readonly number[], axes: readonly number[], rank: number): number[] => {\n  const roiTmp = new Array(rank).fill(0).concat(new Array(rank).fill(1));\n  const roiLocal = roi.length === 0 ? roiTmp : roi.slice();\n  if (axes.length > 0) {\n    axes.forEach((v, i) => {\n      roiTmp[v] = roiLocal[i];\n      roiTmp[i + rank] = roiLocal[axes.length + i];\n    });\n    return roiTmp;\n  }\n  return roiLocal;\n};\n\nconst initOutputShape = (\n  inputShape: readonly number[],\n  scales: readonly number[],\n  sizes: readonly number[],\n  axes: readonly number[],\n): number[] => {\n  let outputShape: number[] = [];\n  if (sizes.length > 0) {\n    if (axes.length > 0) {\n      inputShape.forEach((v) => outputShape.push(v));\n      if (Math.max(...axes) > inputShape.length) {\n        throw new Error('axes is out of bound');\n      }\n      axes.forEach((v, i) => (outputShape[v] = sizes[i]));\n    } else {\n      sizes.forEach((v) => outputShape.push(v));\n    }\n  } else {\n    if (scales.length === 0) {\n      throw new Error('Resize requires either scales or sizes.');\n    } else {\n      outputShape = inputShape.map((value, index) => Math.round(value * scales[index]));\n    }\n  }\n  return outputShape;\n};\n\nconst adjustOutputShape = (inputShape: readonly number[], scales: number[], attributes: ResizeAttributes) => {\n  const scaleInPolicy = (() => {\n    switch (attributes.keepAspectRatioPolicy) {\n      case 'not_larger':\n        return attributes.axes.length > 0\n          ? Math.min(...attributes.axes.map((i) => scales[i]), Number.MAX_VALUE)\n          : Math.min(...scales, Number.MAX_VALUE);\n      case 'not_smaller':\n        return attributes.axes.length > 0\n          ? Math.max(...attributes.axes.map((i) => scales[i]), Number.MIN_VALUE)\n          : Math.max(...scales, Number.MIN_VALUE);\n      default:\n        throw new Error(`Keep aspect ratio policy ${attributes.keepAspectRatioPolicy} is not supported`);\n    }\n  })();\n  scales.fill(1.0, 0, scales.length);\n  const adjustedOutputShape = inputShape.slice();\n  if (attributes.axes.length > 0) {\n    attributes.axes.forEach((v) => (scales[v] = scaleInPolicy));\n    attributes.axes.forEach((v) => (adjustedOutputShape[v] = Math.round(inputShape[v] * scales[v])));\n  } else {\n    scales.fill(scaleInPolicy, 0, scales.length);\n    adjustedOutputShape.forEach((v, i) => (adjustedOutputShape[i] = Math.round(v * scales[i])));\n  }\n  return adjustedOutputShape;\n};\n\nconst calculateOriginalIndicesFromOutputIndices = (\n  output: IndicesHelper,\n  inputShape: readonly number[],\n  outputShape: readonly number[],\n  scalesLength: number,\n  roiLength: number,\n): string => `\n    fn calculateOriginalIndicesFromOutputIndices(output_indices: ${output.type.indices}) -> array<${\n      output.type.value\n    }, ${outputShape.length}> {\n      var original_indices: array<${output.type.value}, ${outputShape.length}>;\n      for (var i:u32 = 0; i < ${outputShape.length}; i++) {\n        var output_index = ${output.indicesGet('output_indices', 'i')};\n        var scale = ${getElementAt('uniforms.scales', 'i', scalesLength)};\n        var roi_low = ${getElementAt('uniforms.roi', 'i', roiLength)};\n        var roi_hi = ${getElementAt('uniforms.roi', `i + ${inputShape.length}`, roiLength)};\n        if (scale == 1.0) {\n          original_indices[i] = ${output.type.value}(output_index);\n        } else {\n          var input_shape_i = ${getElementAt('uniforms.input_shape', 'i', inputShape.length)};\n          var output_shape_i = ${getElementAt('uniforms.output_shape', 'i', outputShape.length)};\n          original_indices[i] = getOriginalCoordinateFromResizedCoordinate(output_index, scale, output_shape_i,\n                                                                           input_shape_i, roi_low, roi_hi);\n        }\n      }\n      return original_indices;\n    }`;\n\nconst calculateInputIndicesFromOutputIndices = (\n  input: IndicesHelper,\n  output: IndicesHelper,\n  inputShape: readonly number[],\n  outputShape: readonly number[],\n  scalesLength: number,\n  roiLength: number,\n  useExtrapolation: boolean,\n): string => `\n    fn calculateInputIndicesFromOutputIndices(output_indices: ${output.type.indices}) -> ${input.type.indices} {\n      var input_indices: ${input.type.indices};\n      for (var i:u32 = 0; i < ${outputShape.length}; i++) {\n        var output_index = ${output.indicesGet('output_indices', 'i')};\n        var input_index: u32;\n        var scale = ${getElementAt('uniforms.scales', 'i', scalesLength)};\n        if (scale == 1.0) {\n          input_index = output_index;\n        } else {\n          var roi_low = ${getElementAt('uniforms.roi', 'i', roiLength)};\n          var roi_hi = ${getElementAt('uniforms.roi', `i + ${inputShape.length}`, roiLength)};\n          var input_shape_i = ${getElementAt('uniforms.input_shape', 'i', inputShape.length)};\n          var output_shape_i = ${getElementAt('uniforms.output_shape', 'i', outputShape.length)};\n          var original_idx = getOriginalCoordinateFromResizedCoordinate(output_index, scale, output_shape_i,\n                                                                        input_shape_i, roi_low, roi_hi);\n          if (!${useExtrapolation} || (original_idx >= 0 && original_idx < ${output.type.value}(input_shape_i))) {\n            if (original_idx < 0) {\n              input_index = 0;\n            } else if (original_idx > ${output.type.value}(input_shape_i - 1)) {\n              input_index = input_shape_i - 1;\n            } else {\n              input_index = u32(getNearestPixelFromOriginal(original_idx, scale < 1));\n            }\n          } else {\n            input_index = u32(original_idx);\n          }\n        }\n        ${input.indicesSet('input_indices', 'i', 'input_index')}\n      }\n      return input_indices;\n    }`;\nconst checkInputIndices = (input: IndicesHelper, inputShape: readonly number[]): string => `\n    fn checkInputIndices(input_indices: ${input.type.indices}) -> bool {\n      for (var i:u32 = 0; i < ${inputShape.length}; i++) {\n        var input_index = ${input.indicesGet('input_indices', 'i')};\n        if (input_index < 0 || input_index >= ${getElementAt('uniforms.input_shape', 'i', inputShape.length)}) {\n          return false;\n        }\n      }\n      return true;\n    }`;\n\nconst setChannelAndBatchIndices = (\n  input: IndicesHelper,\n  channelIdx: number,\n  batchIdx: number,\n  spacialDims: number,\n): string =>\n  input.rank > spacialDims\n    ? `\n    ${input.indicesSet('input_indices', channelIdx, 'channel')};\n    ${input.indicesSet('input_indices', batchIdx, 'batch')};\n`\n    : '';\n\nconst bilinearInterpolation = (\n  input: IndicesHelper,\n  output: IndicesHelper,\n  inputShape: readonly number[],\n  useExtrapolation: boolean,\n  extrapolationValue: number,\n): string => {\n  const isNchw = true;\n  const [batchIdx, heightIdx, widthIdx, channelIdx] =\n    inputShape.length === 2 ? [-1, 0, 1, -1] : isNchw ? [0, 2, 3, 1] : [0, 1, 2, 3];\n  const dType = input.type.value;\n  return `\n    fn getInputValue(batch: u32, channel: u32, row: u32, col: u32) -> ${dType} {\n      var input_indices: ${input.type.indices};\n      ${input.indicesSet('input_indices', heightIdx, `max(0, min(row, ${inputShape[heightIdx]} - 1))`)};\n      ${input.indicesSet('input_indices', widthIdx, `max(0, min(col, ${inputShape[widthIdx]} - 1))`)};\n      ${setChannelAndBatchIndices(input, channelIdx, batchIdx, 2)}\n      return ${input.getByIndices('input_indices')};\n    }\n\n    fn bilinearInterpolation(output_indices: ${output.type.indices}) -> ${dType} {\n      var originalIndices = calculateOriginalIndicesFromOutputIndices(output_indices);\n      var row:${dType} = originalIndices[${heightIdx}];\n      var col:${dType} = originalIndices[${widthIdx}];\n      ${\n        useExtrapolation\n          ? `if (row < 0 || row > (${inputShape[heightIdx]} - 1) || col < 0 || col > (${inputShape[widthIdx]} - 1)) {\n        return ${extrapolationValue};\n      }`\n          : ''\n      };\n      row = max(0, min(row, ${inputShape[heightIdx]} - 1));\n      col = max(0, min(col, ${inputShape[widthIdx]} - 1));\n      var row1: u32 = u32(row);\n      var col1: u32 = u32(col);\n      var row2: u32 = u32(row + 1);\n      var col2: u32 = u32(col + 1);\n      var channel: u32 = ${inputShape.length > 2 ? `u32(originalIndices[${channelIdx}])` : '0'};\n      var batch: u32 =  ${inputShape.length > 2 ? `u32(originalIndices[${batchIdx}])` : '0'};\n      var x11: ${dType} = getInputValue(batch, channel, row1, col1);\n      var x12: ${dType} = getInputValue(batch, channel, row1, col2);\n      var x21: ${dType} = getInputValue(batch, channel, row2, col1);\n      var x22: ${dType} = getInputValue(batch, channel, row2, col2);\n      var dx1: ${dType} = abs(row - ${dType}(row1));\n      var dx2: ${dType} = abs(${dType}(row2) - row);\n      var dy1: ${dType} = abs(col - ${dType}(col1));\n      var dy2: ${dType} = abs(${dType}(col2) - col);\n      if (row1 == row2) {\n        dx1 = 0.5;\n        dx2 = 0.5;\n      }\n      if (col1 == col2) {\n        dy1 = 0.5;\n        dy2 = 0.5;\n      }\n      return (x11 * dx2 * dy2 + x12 * dx2 * dy1 + x21 * dx1 * dy2 + x22 * dx1 * dy1);\n    }`;\n};\n\nconst bicubicInterpolation = (\n  input: IndicesHelper,\n  output: IndicesHelper,\n  inputShape: readonly number[],\n  outputShape: readonly number[],\n  scales: readonly number[],\n  roi: readonly number[],\n  cubicCoeffA: number,\n  useExtrapolation: boolean,\n  extrapolationValue: number,\n  excludeOutside: boolean,\n): string => {\n  const is2D = inputShape.length === 2;\n  const isNchw = true;\n  const [heightIdx, widthIdx] = is2D ? [0, 1] : isNchw ? [2, 3] : [1, 2];\n  const dType = input.type.value;\n  const createCubicInterpolationFunction = (idx: number): string => {\n    const direction = idx === heightIdx ? 'row' : 'col';\n    return `\n      fn ${direction}CubicInterpolation(input_indices: ${input.type.indices}, output_indices: ${\n        output.type.indices\n      }) -> ${dType} {\n        var output_index = ${output.indicesGet('output_indices', idx)};\n        var originalIdx: ${dType} = getOriginalCoordinateFromResizedCoordinate(output_index, ${scales[idx]},\n        ${outputShape[idx]}, ${inputShape[idx]}, ${roi[idx]}, ${roi[idx]} + ${inputShape.length});\n        var fractOriginalIdx: ${dType} = originalIdx - floor(originalIdx);\n        var coefs = getCubicInterpolationCoefs(fractOriginalIdx);\n\n        if (${useExtrapolation} && (originalIdx < 0 || originalIdx > (${inputShape[idx]} - 1))) {\n          return ${extrapolationValue};\n        }\n        var data: array<${dType}, 4> = array<${dType}, 4>(0.0, 0.0, 0.0, 0.0);\n        for (var i: i32 = -1; i < 3; i++) {\n          var ${direction}: ${dType} = originalIdx + ${dType}(i);\n          if (${direction} < 0 || ${direction} >= ${inputShape[idx]}) {\n            ${(() => {\n              if (excludeOutside) {\n                return `coefs[i + 1] = 0.0;\n                        continue;`;\n              } else if (useExtrapolation) {\n                return `return ${extrapolationValue};`;\n              } else {\n                return `${direction} = max(0, min(${direction}, ${inputShape[idx]} - 1));`;\n              }\n            })()};\n          }\n        var input_indices_copy: ${input.type.indices} = input_indices;\n          ${input.indicesSet('input_indices_copy', idx, `u32(${direction})`)};\n          data[i + 1] = ${\n            idx === heightIdx\n              ? input.getByIndices('input_indices_copy')\n              : 'rowCubicInterpolation(input_indices_copy, output_indices)'\n          };\n        }\n        return cubicInterpolation1D(data, coefs);\n      }`;\n  };\n\n  return `\n    ${createCubicInterpolationFunction(heightIdx)};\n    ${createCubicInterpolationFunction(widthIdx)};\n  fn getCubicInterpolationCoefs(s: ${dType}) -> array<${dType}, 4> {\n    var absS = abs(s);\n    var coeffs: array<${dType}, 4> = array<${dType}, 4>(0.0, 0.0, 0.0, 0.0);\n    var oneMinusAbsS: ${dType} = 1.0 - absS;\n    var twoMinusAbsS: ${dType} = 2.0 - absS;\n    var onePlusAbsS: ${dType} = 1.0 + absS;\n    coeffs[0] = ((${cubicCoeffA} * onePlusAbsS - 5 * ${cubicCoeffA}) * onePlusAbsS + 8 * ${\n      cubicCoeffA\n    }) * onePlusAbsS - 4 * ${cubicCoeffA};\n    coeffs[1] = ((${cubicCoeffA} + 2) * absS - (${cubicCoeffA} + 3)) * absS * absS + 1;\n    coeffs[2] = ((${cubicCoeffA} + 2) * oneMinusAbsS - (${cubicCoeffA} + 3)) * oneMinusAbsS * oneMinusAbsS + 1;\n    coeffs[3] = ((${cubicCoeffA} * twoMinusAbsS - 5 * ${cubicCoeffA}) * twoMinusAbsS + 8 * ${\n      cubicCoeffA\n    }) * twoMinusAbsS - 4 * ${cubicCoeffA};\n    return coeffs;\n  }\n\n  fn cubicInterpolation1D(x: array<${dType}, 4>, coefs: array<${dType}, 4>) -> ${dType} {\n    var coefsSum: ${dType} = coefs[0] + coefs[1] + coefs[2] + coefs[3];\n    return (x[0] * coefs[0] + x[1] * coefs[1]+ x[2] * coefs[2]+ x[3] * coefs[3]) / coefsSum;\n  }\n\n  fn bicubicInterpolation(output_indices: ${output.type.indices}) -> ${dType} {\n    var input_indices: ${input.type.indices} = output_indices;\n    return colCubicInterpolation(input_indices, output_indices);\n  }\n    `;\n};\n\nconst trilinearInterpolation = (\n  input: IndicesHelper,\n  output: IndicesHelper,\n  inputShape: readonly number[],\n  useExtrapolation: boolean,\n  extrapolationValue: number,\n): string => {\n  const isNchw = true;\n  const [batchIdx, depthIdx, heightIdx, widthIdx, channelIdx] =\n    inputShape.length === 3 ? [-1, 0, 1, 2, -1] : isNchw ? [0, 2, 3, 4, 1] : [0, 1, 2, 3, 4];\n  const dType = input.type.value;\n  return `\n    fn getInputValue(batch: u32, channel: u32, depth:u32, height: u32, width: u32) -> ${dType} {\n      var input_indices: ${input.type.indices};\n      ${input.indicesSet('input_indices', depthIdx, `max(0, min(depth, ${inputShape[depthIdx]} - 1))`)};\n      ${input.indicesSet('input_indices', heightIdx, `max(0, min(height, ${inputShape[heightIdx]} - 1))`)};\n      ${input.indicesSet('input_indices', widthIdx, `max(0, min(width, ${inputShape[widthIdx]} - 1))`)};\n      ${setChannelAndBatchIndices(input, channelIdx, batchIdx, 3)}\n      return ${input.getByIndices('input_indices')};\n    }\n\n    fn trilinearInterpolation(output_indices: ${output.type.indices}) -> ${dType} {\n      var originalIndices = calculateOriginalIndicesFromOutputIndices(output_indices);\n      var depth:${dType} = originalIndices[${depthIdx}];\n      var height:${dType} = originalIndices[${heightIdx}];\n      var width:${dType} = originalIndices[${widthIdx}];\n      ${\n        useExtrapolation\n          ? `if (depth < 0 || depth > (${inputShape[depthIdx]} - 1) || height < 0 || height > (${\n              inputShape[heightIdx]\n            } - 1) || width < 0 || (width > ${inputShape[widthIdx]} - 1)) {\n      return ${extrapolationValue};\n        }`\n          : ''\n      };\n\n    depth = max(0, min(depth, ${inputShape[depthIdx]} - 1));\n      height = max(0, min(height, ${inputShape[heightIdx]} - 1));\n      width = max(0, min(width, ${inputShape[widthIdx]} - 1));\n      var depth1: u32 = u32(depth);\n      var height1: u32 = u32(height);\n      var width1: u32 = u32(width);\n      var depth2: u32 = u32(depth + 1);\n      var height2: u32 = u32(height + 1);\n      var width2: u32 = u32(width + 1);\n      var channel: u32 = ${inputShape.length > 3 ? `u32(originalIndices[${channelIdx}])` : '0'};\n      var batch: u32 =  ${inputShape.length > 3 ? `u32(originalIndices[${batchIdx}])` : '0'};\n\n      var x111: ${dType} = getInputValue(batch, channel, depth1, height1, width1);\n      var x112: ${dType} = getInputValue(batch, channel, depth1, height1, width2);\n      var x121: ${dType} = getInputValue(batch, channel, depth1, height2, width1);\n      var x122: ${dType} = getInputValue(batch, channel, depth1, height2, width2);\n      var x211: ${dType} = getInputValue(batch, channel, depth2, height1, width1);\n      var x212: ${dType} = getInputValue(batch, channel, depth2, height1, width2);\n      var x221: ${dType} = getInputValue(batch, channel, depth2, height2, width1);\n      var x222: ${dType} = getInputValue(batch, channel, depth2, height2, width2);\n      var dx1: ${dType} = abs(depth - ${dType}(depth1));\n      var dx2: ${dType} = abs(${dType}(depth2) - depth);\n      var dy1: ${dType} = abs(height - ${dType}(height1));\n      var dy2: ${dType} = abs(${dType}(height2) - height);\n      var dz1: ${dType} = abs(width - ${dType}(width1));\n      var dz2: ${dType} = abs(${dType}(width2) - width);\n      if (depth1 == depth2) {\n        dx1 = 0.5;\n        dx2 = 0.5;\n      }\n      if (height1 == height2) {\n        dy1 = 0.5;\n        dy2 = 0.5;\n      }\n      if (width1 == width2) {\n        dz1 = 0.5;\n        dz2 = 0.5;\n      }\n      return (x111 * dx2 * dy2 * dz2 + x112 * dx2 * dy2 * dz1 + x121 * dx2 * dy1 *dz2 + x122 * dx2 * dy1 * dz1 +\n              x211 * dx1 * dy2 * dz2 + x212 * dx1 * dy2 * dz1 + x221 * dx1 * dy1 *dz2 + x222 * dx1 * dy1 * dz1);\n    }`;\n};\n\nconst createResizeProgramInfo = (\n  inputTensor: TensorView,\n  attributes: ResizeAttributes,\n  opsetVersion: number,\n  scalesInput: readonly number[],\n  sizes: readonly number[],\n  roiInput: readonly number[],\n): ProgramInfo => {\n  const inputShape = inputTensor.dims;\n  const roi = updateRoI(roiInput, attributes.axes, inputShape.length);\n\n  let outputShape = initOutputShape(inputShape, scalesInput, sizes, attributes.axes);\n  let scales = scalesInput.slice();\n  if (scalesInput.length === 0) {\n    scales = inputShape.map((value, index) => (value === 0 ? 1.0 : outputShape[index] / value));\n    if (attributes.keepAspectRatioPolicy !== 'stretch') {\n      outputShape = adjustOutputShape(inputShape, scales, attributes);\n    }\n  }\n  const output = outputVariable('output', inputTensor.dataType, outputShape.length);\n  const input = inputVariable('input', inputTensor.dataType, inputShape.length);\n  const outputSize = ShapeUtil.size(outputShape);\n  const noScale = inputShape.length === outputShape.length && inputShape.every((d, i) => d === outputShape[i]);\n  const useExtrapolation = attributes.coordinateTransformMode === 'tf_crop_and_resize';\n  const extrapolationValue = attributes.extrapolationValue;\n  const dataType = input.type.value;\n  const getShaderSource = (shaderHelper: ShaderHelper) => `\n      ${\n        noScale\n          ? ''\n          : `\n      ${getOriginalCoordinateFromResizedCoordinate(attributes.coordinateTransformMode, dataType)};\n      ${(() => {\n        switch (attributes.mode) {\n          case 'nearest':\n            return `\n              ${checkInputIndices(input, inputShape)};\n              ${getNearestPixelFromOriginal(attributes.nearestMode, opsetVersion, dataType)};\n              ${calculateInputIndicesFromOutputIndices(\n                input,\n                output,\n                inputShape,\n                outputShape,\n                scales.length,\n                roi.length,\n                useExtrapolation,\n              )};\n              `;\n          case 'linear':\n            return `\n              ${calculateOriginalIndicesFromOutputIndices(output, inputShape, outputShape, scales.length, roi.length)};\n              ${(() => {\n                if (inputShape.length === 2 || inputShape.length === 4) {\n                  return `${bilinearInterpolation(input, output, inputShape, useExtrapolation, extrapolationValue)}`;\n                } else if (inputShape.length === 3 || inputShape.length === 5) {\n                  return `${trilinearInterpolation(input, output, inputShape, useExtrapolation, extrapolationValue)}`;\n                } else {\n                  throw Error('Linear mode only supports input dims 2, 3, 4 and 5 are supported in linear mode.');\n                }\n              })()};\n            `;\n          case 'cubic':\n            return `\n            ${(() => {\n              if (inputShape.length === 2 || inputShape.length === 4) {\n                return `${bicubicInterpolation(\n                  input,\n                  output,\n                  inputShape,\n                  outputShape,\n                  scales,\n                  roi,\n                  attributes.cubicCoeffA,\n                  useExtrapolation,\n                  attributes.extrapolationValue,\n                  attributes.excludeOutside,\n                )}`;\n              } else {\n                throw Error('Cubic mode only supports input dims 2 and 4 are supported in linear mode.');\n              }\n            })()};\n            `;\n          default:\n            throw Error('Invalid resize mode');\n        }\n      })()};\n      `\n      }\n      ${shaderHelper\n        .registerUniform('output_size', 'u32')\n        .registerUniform('scales', 'f32', scales.length)\n        .registerUniform('roi', 'f32', roi.length)\n        .declareVariables(input, output)}\n      ${shaderHelper.mainStart()}\n        ${shaderHelper.guardAgainstOutOfBoundsWorkgroupSizes('uniforms.output_size')}\n        ${\n          noScale\n            ? 'output[global_idx] = input[global_idx];'\n            : `\n        let output_indices = ${output.offsetToIndices('global_idx')};\n        var input_indices: ${input.type.indices};\n        ${(() => {\n          switch (attributes.mode) {\n            case 'nearest':\n              return `input_indices = calculateInputIndicesFromOutputIndices(output_indices);\n                if (checkInputIndices(input_indices)) {\n                  output[global_idx] = ${input.getByIndices('input_indices')};\n                } else {\n                  output[global_idx] = ${attributes.extrapolationValue};\n                }`;\n            case 'linear':\n              return `output[global_idx] = ${\n                inputShape.length === 2 || inputShape.length === 4 ? 'bilinearInterpolation' : 'trilinearInterpolation'\n              }(output_indices);`;\n            case 'cubic':\n              return 'output[global_idx] = bicubicInterpolation(output_indices);';\n            default:\n              throw Error(`Unsupported resize mode: ${attributes.mode}`);\n          }\n        })()};\n`\n        }\n      }`;\n\n  return {\n    name: 'Resize',\n    shaderCache: {\n      hint: `${attributes.cacheKey}|${opsetVersion}|${\n        scales.length > 0 ? (attributes.mode === 'cubic' ? scales : scales.length) : ''\n      }|${sizes.length > 0 ? sizes : ''}|${roi.length > 0 ? roi : ''}|${noScale}|${\n        attributes.mode === 'nearest' ? inputShape.length : inputShape\n      }`,\n      inputDependencies: ['rank'],\n    },\n    getShaderSource,\n    getRunData: () => ({\n      outputs: [{ dims: outputShape, dataType: inputTensor.dataType }],\n      dispatchGroup: { x: Math.ceil(outputSize / 64 /* workgroup size */) },\n      programUniforms: [\n        { type: DataType.uint32, data: outputSize },\n        { type: DataType.float, data: scales },\n        { type: DataType.float, data: roi },\n        ...createTensorShapeVariables(inputShape, outputShape),\n      ],\n    }),\n  };\n};\n\nconst getOpsetVersionFromCustomDataBuffer = (context: ComputeContext): number => {\n  const customDataBuffer = context.customDataBuffer;\n  const customDataBuffer32 = new Uint32Array(customDataBuffer, customDataBuffer.byteOffset, 1);\n  const opsetVersion = customDataBuffer32[0];\n  return opsetVersion;\n};\n\nexport const resize = (context: ComputeContext, attributes: ResizeAttributes): void => {\n  const scales: number[] = [];\n  const sizes: number[] = [];\n  const roi: number[] = [];\n\n  // Note that scales in resize are always f32. roi can be f32 or f16.\n  // TODO: Currently this code does not support f16 for roi when passed as optional input.\n\n  const opsetVersion = getOpsetVersionFromCustomDataBuffer(context);\n  if (attributes.antialias !== 0) {\n    throw Error('Only default value (0) for Antialias attribute is supported');\n  }\n  validateInputs(context.inputs, attributes, opsetVersion, scales, sizes, roi);\n  context.compute(createResizeProgramInfo(context.inputs[0], attributes, opsetVersion, scales, sizes, roi), {\n    inputs: [0],\n  });\n};\n\nexport const parseResizeAttributes = (attributes: Record<string, unknown>): ResizeAttributes => {\n  const antialias = attributes.antialias as number;\n  const axes = attributes.axes as number[];\n  const coordinateTransformMode: CoordinateTransformMode =\n    attributes.coordinateTransformMode as CoordinateTransformMode;\n  const cubicCoeffA = attributes.cubicCoeffA as number;\n  const excludeOutside = (attributes.excludeOutside as number) !== 0;\n  const extrapolationValue = attributes.extrapolationValue as number;\n  const keepAspectRatioPolicy: KeepAspectRatioPolicy = attributes.keepAspectRatioPolicy as KeepAspectRatioPolicy;\n  const mode: Mode = attributes.mode as Mode;\n  // If nearestMode is not specified, use simple mode.\n  const nearestMode: NearestMode = (attributes.nearestMode === '' ? 'simple' : attributes.nearestMode) as NearestMode;\n  return createAttributeWithCacheKey({\n    antialias,\n    axes,\n    coordinateTransformMode,\n    cubicCoeffA,\n    excludeOutside,\n    extrapolationValue,\n    keepAspectRatioPolicy,\n    mode,\n    nearestMode,\n  });\n};\n","// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport { DataType } from '../../../wasm-common';\nimport { TensorView } from '../../tensor-view';\nimport { ShapeUtil } from '../../util';\nimport { createAttributeWithCacheKey } from '../attribute-with-cache-key';\nimport { ComputeContext, ProgramInfo, ProgramUniform } from '../types';\n\nimport { createTensorShapeVariables, inputVariable, outputVariable, ShaderHelper, WORKGROUP_SIZE } from './common';\n\nexport interface RotaryEmbeddingAttributes {\n  readonly interleaved: boolean;\n  readonly numHeads: number;\n  readonly rotaryEmbeddingDim: number;\n  readonly scale: number;\n}\n\nconst validateInputs = (inputs: readonly TensorView[], attributes: RotaryEmbeddingAttributes): void => {\n  const [input, positionIds, cosCache, sinCache] = inputs;\n  const { numHeads, rotaryEmbeddingDim } = attributes;\n\n  if (input.dims.length !== 3 && input.dims.length !== 4) {\n    throw new Error(`Input 'x' is expected to have 3 or 4 dimensions, got ${input.dims.length}`);\n  }\n  if (\n    !ShapeUtil.areEqual(positionIds.dims, []) &&\n    !ShapeUtil.areEqual(positionIds.dims, [1]) &&\n    positionIds.dims.length !== 2\n  ) {\n    throw new Error(`Input 'position_ids' is expected to have 0, 1, or 2 dimensions, got ${positionIds.dims.length}`);\n  }\n  if (cosCache.dims.length !== 2) {\n    throw new Error(`Input 'cos_cache' is expected to have 2 dimensions, got ${cosCache.dims.length}`);\n  }\n  if (sinCache.dims.length !== 2) {\n    throw new Error(`Input 'sin_cache' is expected to have 2 dimensions, got ${sinCache.dims.length}`);\n  }\n  if (!ShapeUtil.areEqual(cosCache.dims, sinCache.dims)) {\n    throw new Error(\"Inputs 'cos_cache' and 'sin_cache' are expected to have the same shape\");\n  }\n\n  if (rotaryEmbeddingDim > 0 && numHeads === 0) {\n    throw new Error('num_heads must be provided if rotary_embedding_dim is specified');\n  }\n\n  const batchSize = input.dims[0];\n  const sequenceLength = input.dims[input.dims.length - 2];\n  const maxSequenceLength = cosCache.dims[0];\n  const hiddenSize = ShapeUtil.sizeFromDimension(input.dims, 1) / sequenceLength;\n  const headSize = rotaryEmbeddingDim === 0 ? cosCache.dims[1] * 2 : hiddenSize / numHeads;\n  if (rotaryEmbeddingDim > headSize) {\n    throw new Error('rotary_embedding_dim must be less than or equal to head_size');\n  }\n\n  if (positionIds.dims.length === 2) {\n    if (batchSize !== positionIds.dims[0]) {\n      throw new Error(`Input 'position_ids' dimension 0 should be of size batch_size, got ${positionIds.dims[0]}`);\n    }\n    if (sequenceLength !== positionIds.dims[1]) {\n      throw new Error(`Input 'position_ids' dimension 1 should be of size sequence_length, got ${positionIds.dims[1]}`);\n    }\n  }\n\n  if (headSize / 2 !== cosCache.dims[1] && rotaryEmbeddingDim / 2 !== cosCache.dims[1]) {\n    throw new Error(\n      `Input 'cos_cache' dimension 1 should be same as head_size / 2 or rotary_embedding_dim / 2, got ${\n        cosCache.dims[1]\n      }`,\n    );\n  }\n\n  if (sequenceLength > maxSequenceLength) {\n    throw new Error('Updating cos_cache and sin_cache in RotaryEmbedding is not currently supported');\n  }\n};\n\nconst createRotaryEmbeddingProgramInfo = (\n  inputs: readonly TensorView[],\n  attributes: RotaryEmbeddingAttributes,\n): ProgramInfo => {\n  const { interleaved, numHeads, rotaryEmbeddingDim, scale } = attributes;\n  const batchSize = inputs[0].dims[0];\n  const batchStride = ShapeUtil.sizeFromDimension(inputs[0].dims, 1);\n  const sequenceLength = inputs[0].dims[inputs[0].dims.length - 2];\n  const hiddenSize = batchStride / sequenceLength;\n  const halfRotaryEmbeddingDim = inputs[2].dims[1];\n  const headSize = rotaryEmbeddingDim === 0 ? halfRotaryEmbeddingDim * 2 : hiddenSize / numHeads;\n\n  // Rotary embeddings will be calculated in a pair-wise fashion. In accordance, use the shape\n  // [batch size, sequence length, num of heads, num of pairs to rotate + num of dims to copy]\n  // to unfold the global index in shader.\n  const globalShape = new Array<number>(\n    batchSize,\n    sequenceLength,\n    hiddenSize / headSize,\n    headSize - halfRotaryEmbeddingDim,\n  );\n  const globalStrides = ShapeUtil.computeStrides(globalShape);\n\n  const programUniforms: ProgramUniform[] = [\n    { type: DataType.float, data: scale },\n    { type: DataType.uint32, data: globalShape },\n    { type: DataType.uint32, data: globalStrides },\n\n    // strides for addressing the input/output tensor, in permutated order to align with the unfolded global index,\n    // i.e. BSNH\n    ...(inputs[0].dims.length === 3\n      ? new Array<ProgramUniform>({ type: DataType.uint32, data: [batchStride, hiddenSize, headSize, 1] })\n      : []),\n    ...(inputs[0].dims.length === 4\n      ? new Array<ProgramUniform>({\n          type: DataType.uint32,\n          data: [batchStride, headSize, sequenceLength * headSize, 1],\n        })\n      : []),\n\n    ...createTensorShapeVariables(inputs[0].dims, inputs[1].dims, inputs[2].dims, inputs[3].dims, inputs[0].dims),\n  ];\n\n  const getShaderSource = (shaderHelper: ShaderHelper) => {\n    const input = inputVariable('input', inputs[0].dataType, inputs[0].dims.length);\n    const positionIds = inputVariable('position_ids', inputs[1].dataType, inputs[1].dims.length);\n    const cosCache = inputVariable('cos_cache', inputs[2].dataType, inputs[2].dims.length);\n    const sinCache = inputVariable('sin_cache', inputs[3].dataType, inputs[3].dims.length);\n    const output = outputVariable('output', inputs[0].dataType, inputs[0].dims.length);\n\n    shaderHelper.registerUniforms([\n      { name: 'scale', type: 'f32' },\n      { name: 'global_shape', type: 'u32', length: globalShape.length },\n      { name: 'global_strides', type: 'u32', length: globalStrides.length },\n      { name: 'input_output_strides', type: 'u32', length: globalStrides.length },\n    ]);\n\n    return `\n        ${shaderHelper.declareVariables(input, positionIds, cosCache, sinCache, output)}\n\n        ${shaderHelper.mainStart(WORKGROUP_SIZE)}\n          let half_rotary_emb_dim = uniforms.${cosCache.name}_shape[1];\n          let bsnh = global_idx / uniforms.global_strides % uniforms.global_shape;\n          let size = uniforms.global_shape[0] * uniforms.global_strides[0];\n          ${shaderHelper.guardAgainstOutOfBoundsWorkgroupSizes('size')}\n\n          if (bsnh[3] < half_rotary_emb_dim) {\n            let position_ids_idx =\n                ${positionIds.broadcastedIndicesToOffset('bsnh.xy', outputVariable('', positionIds.type.tensor, 2))};\n            let position_id =\n                u32(${positionIds.getByOffset('position_ids_idx')}) + select(0, bsnh[1], position_ids_idx == 0);\n            let i = dot(bsnh, uniforms.input_output_strides) + select(0, bsnh[3], ${interleaved});\n            let j = i + select(half_rotary_emb_dim, 1, ${interleaved});\n            let re = ${input.getByOffset('i')} * ${cosCache.get('position_id', 'bsnh[3]')} -\n                ${input.getByOffset('j')} * ${sinCache.get('position_id', 'bsnh[3]')};\n            ${output.setByOffset('i', 're')}\n            let im = ${input.getByOffset('i')} * ${sinCache.get('position_id', 'bsnh[3]')} +\n                ${input.getByOffset('j')} * ${cosCache.get('position_id', 'bsnh[3]')};\n            ${output.setByOffset('j', 'im')}\n          } else {\n            let k = dot(bsnh, uniforms.input_output_strides) + half_rotary_emb_dim;\n            ${output.setByOffset('k', input.getByOffset('k'))}\n          }\n        }`;\n  };\n\n  return {\n    name: 'RotaryEmbedding',\n    shaderCache: {\n      hint: createAttributeWithCacheKey({\n        interleaved,\n      }).cacheKey,\n      inputDependencies: ['rank', 'rank', 'rank', 'rank'],\n    },\n    getShaderSource,\n    getRunData: () => ({\n      outputs: [{ dims: inputs[0].dims, dataType: inputs[0].dataType }],\n      dispatchGroup: { x: Math.ceil(ShapeUtil.size(globalShape) / WORKGROUP_SIZE) },\n      programUniforms,\n    }),\n  };\n};\n\nexport const rotaryEmbedding = (context: ComputeContext, attributes: RotaryEmbeddingAttributes): void => {\n  validateInputs(context.inputs, attributes);\n  context.compute(createRotaryEmbeddingProgramInfo(context.inputs, attributes));\n};\n","// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport { DataType } from '../../../wasm-common';\nimport { TensorView } from '../../tensor-view';\nimport { ShapeUtil } from '../../util';\nimport { ComputeContext, ProgramInfo, ProgramUniform } from '../types';\n\nimport {\n  castToF32,\n  getMaxComponents,\n  inputVariable,\n  outputVariable,\n  ShaderHelper,\n  sumVector,\n  tensorTypeToWsglStorageType,\n  UniformsArrayType,\n} from './common';\n\nexport interface SkipLayerNormAttributes {\n  simplified: boolean;\n  epsilon: number;\n}\n\nconst validateInputs = (inputs: readonly TensorView[]): void => {\n  if (!inputs || inputs.length < 3) {\n    throw new Error('layerNorm requires at least 3 inputs.');\n  }\n\n  const input: TensorView = inputs[0];\n  const skip: TensorView = inputs[1];\n  const gamma: TensorView = inputs[2];\n\n  if (input.dataType !== skip.dataType || input.dataType !== gamma.dataType) {\n    throw new Error('All inputs must have the same data type');\n  }\n\n  if (input.dims.length !== 3 && input.dims.length !== 2) {\n    throw new Error('Input must be 2D or 3D');\n  }\n\n  if (skip.dims.length !== 3 && skip.dims.length !== 2) {\n    throw new Error('Skip must be 2D or 3D');\n  }\n\n  const hiddenSize = input.dims[input.dims.length - 1];\n  const sequenceLength = input.dims[input.dims.length - 2];\n  if (skip.dims[skip.dims.length - 1] !== hiddenSize) {\n    throw new Error('Skip must have the same hidden size as input');\n  }\n  if (skip.dims[skip.dims.length - 2] !== sequenceLength) {\n    throw new Error('Skip must have the same sequence length as input');\n  }\n\n  if (gamma.dims.length !== 1) {\n    throw new Error('Gamma must be 1D');\n  }\n  if (gamma.dims[gamma.dims.length - 1] !== hiddenSize) {\n    throw new Error('Gamma must have the same hidden size as input');\n  }\n  if (inputs.length > 3) {\n    const beta: TensorView = inputs[3];\n    if (beta.dims.length !== 1) {\n      throw new Error('Beta must be 1D');\n    }\n    if (beta.dims[beta.dims.length - 1] !== hiddenSize) {\n      throw new Error('Beta must have the same hidden size as input');\n    }\n  }\n  if (inputs.length > 4) {\n    const bias: TensorView = inputs[4];\n    if (bias.dims.length !== 1) {\n      throw new Error('Bias must be 1D');\n    }\n    if (bias.dims[bias.dims.length - 1] !== hiddenSize) {\n      throw new Error('Bias must have the same hidden size as input');\n    }\n  }\n};\n\nconst createSkipLayerNormProgramInfo = (\n  inputs: readonly TensorView[],\n  attributes: SkipLayerNormAttributes,\n  outputCount: number,\n  isTraining: boolean,\n): ProgramInfo => {\n  const simplified = attributes.simplified;\n\n  const inputShape = inputs[0].dims;\n  const inputSize = ShapeUtil.size(inputShape);\n  const outputShape = inputShape;\n  const outputSize = inputSize;\n  const hiddenSize = inputShape.slice(-1)[0];\n  const meanInvStdDevDim = isTraining ? inputShape.slice(0, -1).concat(1) : [];\n  const hasBetaInput = !simplified && inputs.length > 3;\n  const hasBiasInput = inputs.length > 4;\n  const hasMeanOutput = isTraining && outputCount > 1;\n  const hasInvStdDevOutput = isTraining && outputCount > 2;\n  const hasInputSkipBiasSumOutput = outputCount > 3;\n  const workgroupSize = 64;\n\n  const components = getMaxComponents(hiddenSize);\n\n  const programUniforms: ProgramUniform[] = [\n    { type: DataType.uint32, data: outputSize },\n    { type: DataType.uint32, data: components },\n    { type: DataType.uint32, data: hiddenSize },\n    { type: DataType.float, data: attributes.epsilon },\n  ];\n  const getShaderSource = (shaderHelper: ShaderHelper) => {\n    const uniformsArray: UniformsArrayType = [\n      { name: 'output_size', type: 'u32' },\n      { name: 'components', type: 'u32' },\n      { name: 'hidden_size', type: 'u32' },\n      { name: 'epsilon', type: 'f32' },\n    ];\n    const variables = [\n      inputVariable('x', inputs[0].dataType, inputs[0].dims, components),\n      inputVariable('skip', inputs[1].dataType, inputs[1].dims, components),\n      inputVariable('gamma', inputs[2].dataType, inputs[2].dims, components),\n    ];\n    if (hasBetaInput) {\n      variables.push(inputVariable('beta', inputs[3].dataType, inputs[3].dims, components));\n    }\n    if (hasBiasInput) {\n      variables.push(inputVariable('bias', inputs[4].dataType, inputs[4].dims, components));\n    }\n    variables.push(outputVariable('output', inputs[0].dataType, outputShape, components));\n    if (hasMeanOutput) {\n      variables.push(outputVariable('mean_output', DataType.float, meanInvStdDevDim));\n    }\n    if (hasInvStdDevOutput) {\n      variables.push(outputVariable('inv_std_output', DataType.float, meanInvStdDevDim));\n    }\n    if (hasInputSkipBiasSumOutput) {\n      variables.push(outputVariable('input_skip_bias_sum', inputs[0].dataType, outputShape, components));\n    }\n    const dataType = tensorTypeToWsglStorageType(inputs[0].dataType);\n    const vecDataType = tensorTypeToWsglStorageType(DataType.float, components);\n    return `\n\n      ${shaderHelper.registerUniforms(uniformsArray).declareVariables(...variables)}\n      var<workgroup> sum_shared : array<${vecDataType}, ${workgroupSize}>;\n      var<workgroup> sum_squared_shared : array<${vecDataType}, ${workgroupSize}>;\n\n      ${shaderHelper.mainStart([workgroupSize, 1, 1])}\n        let ix = local_id.x;\n        let iy = global_id.x / ${workgroupSize};\n\n        let hidden_size_vectorized: u32 = uniforms.hidden_size / uniforms.components;\n        var stride = hidden_size_vectorized / ${workgroupSize};\n        let offset = ix * stride + iy * hidden_size_vectorized;\n        let offset1d = stride * ix;\n        if (ix == ${workgroupSize - 1}) {\n          stride = hidden_size_vectorized - stride * ix;\n        }\n        for (var i: u32 = 0; i < stride; i++) {\n          let skip_value = skip[offset + i];\n          let bias_value = ${hasBiasInput ? 'bias[offset1d + i]' : dataType + '(0.0)'};\n          let input_value = x[offset + i];\n          let value = input_value + skip_value + bias_value;\n          ${hasInputSkipBiasSumOutput ? 'input_skip_bias_sum[offset + i] = value;' : ''}\n          output[offset + i] = value;\n          let f32_value = ${castToF32(dataType, components, 'value')};\n          sum_shared[ix] += f32_value;\n          sum_squared_shared[ix] += f32_value * f32_value;\n        }\n        workgroupBarrier();\n\n        var reduce_size : u32 = ${workgroupSize};\n        for (var curr_size = reduce_size >> 1;  curr_size > 0; curr_size = reduce_size >> 1) {\n          reduce_size = curr_size + (reduce_size & 1);\n          if (ix < curr_size) {\n            sum_shared[ix] += sum_shared[ix + reduce_size];\n            sum_squared_shared[ix] += sum_squared_shared[ix + reduce_size];\n          }\n          workgroupBarrier();\n        }\n\n        let sum = sum_shared[0];\n        let square_sum = sum_squared_shared[0];\n        let mean = ${sumVector('sum', components)} / f32(uniforms.hidden_size);\n        let inv_std_dev = inverseSqrt(${sumVector('square_sum', components)} / f32(uniforms.hidden_size) ${\n          simplified ? '' : '- mean * mean'\n        } + uniforms.epsilon);\n        ${hasMeanOutput ? 'mean_output[global_idx] = mean;' : ''}\n        ${hasInvStdDevOutput ? 'inv_std_output[global_idx] = inv_std_dev;' : ''}\n\n        for (var i: u32 = 0; i < stride; i++) {\n          output[offset + i] = (output[offset + i] ${simplified ? '' : `- ${dataType}(mean)`}) *\n            ${dataType}(inv_std_dev) * gamma[offset1d + i]\n            ${hasBetaInput ? '+ beta[offset1d + i]' : ''};\n        }\n      }`;\n  };\n  const outputs = [{ dims: outputShape, dataType: inputs[0].dataType }];\n  if (outputCount > 1) {\n    outputs.push({ dims: meanInvStdDevDim, dataType: DataType.float });\n  }\n  if (outputCount > 2) {\n    outputs.push({ dims: meanInvStdDevDim, dataType: DataType.float });\n  }\n  if (outputCount > 3) {\n    outputs.push({ dims: inputShape, dataType: inputs[0].dataType });\n  }\n  return {\n    name: 'SkipLayerNormalization',\n    shaderCache: {\n      hint: `${components};${hasMeanOutput};${hasInvStdDevOutput};${hasInputSkipBiasSumOutput}`,\n      inputDependencies: inputs.map((_input, _index) => 'type'),\n    },\n    getShaderSource,\n    getRunData: () => ({\n      outputs,\n      dispatchGroup: {\n        x: Math.ceil(outputSize / hiddenSize),\n      },\n      programUniforms,\n    }),\n  };\n};\n\nexport const skipLayerNorm = (context: ComputeContext, attributes: SkipLayerNormAttributes): void => {\n  // TODO: initialize isTraining from ComputeContext\n  const isTraining = false;\n  validateInputs(context.inputs);\n  // Mean and InvStdDev are only used in training mode and are not required for inference.\n  // They are added here for completeness only.\n  const outputs = [0];\n  if (context.outputCount > 1) {\n    outputs.push(isTraining ? 1 : -3);\n  }\n  if (context.outputCount > 2) {\n    outputs.push(isTraining ? 2 : -3);\n  }\n  if (context.outputCount > 3) {\n    outputs.push(3);\n  }\n  context.compute(createSkipLayerNormProgramInfo(context.inputs, attributes, context.outputCount, isTraining), {\n    outputs,\n  });\n};\n","// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport { DataType } from '../../../wasm-common';\nimport { TensorView } from '../../tensor-view';\nimport { ShapeUtil } from '../../util';\nimport { AttributeWithCacheKey, createAttributeWithCacheKey } from '../attribute-with-cache-key';\nimport { ComputeContext, ProgramInfo, ProgramUniform, TensorInfo } from '../types';\n\nimport {\n  createTensorShapeVariables,\n  getElementAt,\n  IndicesHelper,\n  inputVariable,\n  outputVariable,\n  ShaderHelper,\n  UniformsArrayType,\n} from './common';\n\nexport interface SliceAttributes extends AttributeWithCacheKey {\n  readonly starts: number[];\n  readonly ends: number[];\n  readonly axes: number[];\n}\n\nconst validateInputs = (inputs: readonly TensorView[], attributes: SliceAttributes): void => {\n  if (!inputs || inputs.length < 1) {\n    throw new Error('too few inputs');\n  }\n  if (attributes.axes.length !== 0) {\n    if (attributes.axes.length !== attributes.starts.length || attributes.axes.length !== attributes.ends.length) {\n      throw new Error('axes, starts and ends must have the same length');\n    }\n  } else if (attributes.starts.length !== attributes.ends.length) {\n    throw new Error('starts and ends must have the same length');\n  }\n  inputs.slice(1).forEach((_, idx) => {\n    if (inputs[idx + 1].dataType !== DataType.int32 && inputs[idx + 1].dataType !== DataType.int64) {\n      throw new Error(`Input ${idx} must be an array of int32 or int64`);\n    }\n  });\n};\n\nconst readInput = (inputs: readonly TensorView[], idx: number): number[] => {\n  const input: number[] = [];\n  if (inputs.length > idx) {\n    if (inputs[idx].dataType === DataType.int64) {\n      inputs[idx].getBigInt64Array().forEach((v) => input.push(Number(v)));\n    } else if (inputs[idx].dataType === DataType.int32) {\n      inputs[idx].getInt32Array().forEach((v) => input.push(Number(v)));\n    } else {\n      throw new Error(`Input ${idx} must be an array of int32 or int64`);\n    }\n  }\n  return input;\n};\n\nconst createSliceAttributesFromInputs = (\n  inputs: readonly TensorView[],\n  attributes: SliceAttributes,\n): SliceAttributes => {\n  if (inputs.length > 1) {\n    const starts: number[] = readInput(inputs, 1);\n    const ends: number[] = readInput(inputs, 2);\n    let axes: number[] = readInput(inputs, 3);\n    if (axes.length === 0) {\n      axes = [...Array(inputs[0].dims.length).keys()];\n    }\n    return createAttributeWithCacheKey({ starts, ends, axes });\n  } else {\n    return attributes;\n  }\n};\n\nconst fixStartEndValues = (\n  value: number,\n  index: number,\n  inputShape: readonly number[],\n  axes: readonly number[],\n  steps: readonly number[],\n): number => {\n  let newValue = value;\n  if (value < 0) {\n    newValue += inputShape[axes[index]];\n  }\n  if (steps[index] < 0) {\n    return Math.max(0, Math.min(newValue, inputShape[axes[index]] - 1));\n  } else {\n    return Math.max(0, Math.min(newValue, inputShape[axes[index]]));\n  }\n};\n\nconst calculateInputIndicesImpl = (\n  input: IndicesHelper,\n  output: IndicesHelper,\n  inputShape: readonly number[],\n): string =>\n  `fn calculateInputIndices(output_indices: ${output.type.indices}) -> ${input.type.indices} {\n          var input_indices: ${input.type.indices};\n          var carry = 0u;\n          for (var i = ${inputShape.length}; i >= 0; i--) {\n            let input_shape_i = ${getElementAt('uniforms.input_shape', 'i', inputShape.length)};\n            let steps_i = ${getElementAt('uniforms.steps', 'i', inputShape.length)};\n            let signs_i = ${getElementAt('uniforms.signs', 'i', inputShape.length)};\n            let starts_i = ${getElementAt('uniforms.starts', 'i', inputShape.length)};\n            var output_index = ${output.indicesGet('output_indices', 'i')};\n            var input_index = output_index * steps_i + starts_i + carry;\n            carry = input_index / input_shape_i;\n            input_index = input_index % input_shape_i;\n            if (signs_i < 0) {\n              input_index = input_shape_i - input_index - 1u + starts_i;\n            }\n            ${input.indicesSet('input_indices', 'i', 'input_index')};\n          }\n          return input_indices;\n      }`;\n\nconst createSliceProgramInfo = (inputs: readonly TensorView[], attributes: SliceAttributes): ProgramInfo => {\n  const inputShape = inputs[0].dims;\n  const inputSize = ShapeUtil.size(inputShape);\n  const axes =\n    attributes.axes.length > 0\n      ? ShapeUtil.normalizeAxes(attributes.axes, inputShape.length)\n      : [...Array(inputShape.length).keys()];\n  let steps = readInput(inputs, 4);\n  steps.forEach(\n    (step) =>\n      step !== 0 ||\n      (() => {\n        throw new Error('step cannot be 0');\n      }),\n  );\n  if (steps.length === 0) {\n    steps = Array(axes.length).fill(1);\n  }\n  const starts = attributes.starts.map((start, i) => fixStartEndValues(start, i, inputShape, axes, steps));\n\n  const ends = attributes.ends.map((end, i) => fixStartEndValues(end, i, inputShape, axes, steps));\n\n  if (axes.length !== starts.length || axes.length !== ends.length) {\n    throw new Error('start, ends and axes should have the same number of elements');\n  }\n\n  if (axes.length !== inputShape.length) {\n    for (let i = 0; i < inputShape.length; ++i) {\n      if (!axes.includes(i)) {\n        starts.splice(i, 0, 0);\n        ends.splice(i, 0, inputShape[i]);\n        steps.splice(i, 0, 1);\n      }\n    }\n  }\n  const signs = steps.map((step) => Math.sign(step));\n  // Convert negative steps to positive steps and reverse starts and ends\n  steps.forEach((step, i, array) => {\n    if (step < 0) {\n      const numSteps = (ends[i] - starts[i]) / step;\n      const newEnd = starts[i];\n      const newStart = newEnd + numSteps * steps[i];\n      starts[i] = newStart;\n      ends[i] = newEnd;\n      array[i] = -step;\n    }\n  });\n  // Output rank is expected to be less than or equal to the input rank.\n  const outputShape = inputShape.slice(0);\n  axes.forEach((axis, _) => {\n    outputShape[axis] = Math.ceil((ends[axis] - starts[axis]) / steps[axis]);\n  });\n  const outputTensorInfo: TensorInfo = { dims: outputShape, dataType: inputs[0].dataType };\n\n  const output = outputVariable('output', inputs[0].dataType, outputShape.length);\n  const input = inputVariable('input', inputs[0].dataType, inputs[0].dims.length);\n  const outputSize = ShapeUtil.size(outputShape);\n  const uniforms: UniformsArrayType = [\n    { name: 'outputSize', type: 'u32' },\n    { name: 'starts', type: 'u32', length: starts.length },\n    { name: 'signs', type: 'i32', length: signs.length },\n    { name: 'steps', type: 'u32', length: steps.length },\n  ];\n\n  const programUniforms: ProgramUniform[] = [\n    { type: DataType.uint32, data: outputSize },\n    { type: DataType.uint32, data: starts },\n    { type: DataType.int32, data: signs },\n    { type: DataType.uint32, data: steps },\n    ...createTensorShapeVariables(inputs[0].dims, outputShape),\n  ];\n\n  const getShaderSource = (shaderHelper: ShaderHelper) => `\n      ${shaderHelper.registerUniforms(uniforms).declareVariables(input, output)}\n        ${calculateInputIndicesImpl(input, output, inputShape)}\n        ${shaderHelper.mainStart()}\n          ${shaderHelper.guardAgainstOutOfBoundsWorkgroupSizes('uniforms.outputSize')}\n          let output_indices = ${output.offsetToIndices('global_idx')};\n          let input_indices = calculateInputIndices(output_indices);\n          ${output.setByOffset('global_idx', input.getByIndices('input_indices'))}\n      }`;\n  return {\n    name: 'Slice',\n    shaderCache: { hint: `${signs.length}_${starts.length}_${steps.length}`, inputDependencies: ['rank'] },\n    getShaderSource,\n    getRunData: () => ({\n      outputs: [outputTensorInfo],\n      dispatchGroup: { x: Math.ceil(inputSize / 64 /* workgroup size */) },\n      programUniforms,\n    }),\n  };\n};\n\nexport const slice = (context: ComputeContext, attributes: SliceAttributes): void => {\n  validateInputs(context.inputs, attributes);\n  const updatedAttributes = createSliceAttributesFromInputs(context.inputs, attributes);\n  context.compute(createSliceProgramInfo(context.inputs, updatedAttributes), { inputs: [0] });\n  // if (ShapeUtil.size(program.outputs[0].dims) > 0) {\n  //   context.compute(programInfoLoader, {inputs: [0]});\n  // } else {\n  //   // TODO: support empty output\n  //   throw new Error('slice: output size is 0');\n  // }\n};\n\nexport const parseSliceAttributes = (attributes: Record<string, unknown>): SliceAttributes => {\n  const starts = attributes.starts as number[];\n  const ends = attributes.ends as number[];\n  const axes = attributes.axes as number[];\n  return createAttributeWithCacheKey({ starts, ends, axes });\n};\n","// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\n// TODO: this is the same naive implementation we use for reduce that has\n// performance limitations when the reduced axis is long. Need to add\n// a optimized codepath for this.\n\nimport { DataType } from '../../../wasm-common';\nimport { TensorView } from '../../tensor-view';\nimport { ShapeUtil } from '../../util';\nimport { AttributeWithCacheKey, createAttributeWithCacheKey } from '../attribute-with-cache-key';\nimport { ComputeContext } from '../types';\nimport { createTransposeProgramInfo } from './transpose';\n\nimport {\n  getMaxComponents,\n  inputVariable,\n  outputVariable,\n  ShaderHelper,\n  sumVector,\n  tensorTypeToWsglStorageType,\n} from './common';\n\nconst validateInputs = (inputs: readonly TensorView[]): void => {\n  if (!inputs || inputs.length !== 1) {\n    throw new Error('Softmax op requires 1 input.');\n  }\n};\n\nexport interface SoftmaxAttributes extends AttributeWithCacheKey {\n  readonly axis: number;\n}\n\nconst createSoftmaxProgramInfo = (context: ComputeContext, attributes: SoftmaxAttributes) => {\n  const input = context.inputs[0];\n  const inputShape = input.dims;\n  const outputSize = ShapeUtil.size(inputShape);\n  const inputRank = inputShape.length;\n  const axis = ShapeUtil.normalizeAxis(attributes.axis, inputRank);\n  const isTransposeRequired = axis < inputShape.length - 1;\n  let transposedInput: TensorView;\n  let perm: number[] = [];\n\n  if (isTransposeRequired) {\n    perm = Array.from({ length: inputRank }, (_, i) => i);\n    perm[axis] = inputRank - 1;\n    perm[inputRank - 1] = axis;\n\n    transposedInput = context.compute(createTransposeProgramInfo(input, perm), {\n      inputs: [input],\n      outputs: [-1],\n    })[0];\n  } else {\n    transposedInput = input;\n  }\n\n  const transposedInputShape = transposedInput.dims;\n  const cols = transposedInputShape[inputRank - 1];\n  const rows = outputSize / cols;\n  const components = getMaxComponents(cols);\n  const packedCols = cols / components;\n  let WG = 64;\n  // If only one workgroup is dispatched, increase workgroupSize to improve parallelism.\n  if (rows === 1) {\n    WG = 256;\n  }\n  const maxVector = (name: string, components: number) => {\n    if (components === 4) {\n      return `max(max(${name}.x, ${name}.y), max(${name}.z, ${name}.w))`;\n    } else if (components === 2) {\n      return `max(${name}.x, ${name}.y)`;\n    } else if (components === 3) {\n      return `max(max(${name}.x, ${name}.y), ${name}.z)`;\n    }\n\n    return name;\n  };\n  const x = inputVariable('x', transposedInput.dataType, transposedInput.dims, components);\n  const output = outputVariable('result', transposedInput.dataType, transposedInput.dims, components);\n  const valueType = x.type.value;\n  // 6.2.4 in wgsl spec\n  const threadMaxDecl =\n    tensorTypeToWsglStorageType(transposedInput.dataType) === 'f32'\n      ? `var threadMax = ${valueType}(-3.402823e+38f);`\n      : `var threadMax = ${valueType}(-65504.0h);`;\n  const getShaderSource = (shaderHelper: ShaderHelper) => `\n      var<workgroup> rowMaxShared : ${valueType};\n      var<workgroup> rowSumShared : ${valueType};\n      var<workgroup> threadShared : array<${valueType}, ${WG}>;\n\n      fn getValue(row: i32, col: i32, row_stride: i32) -> ${valueType} {\n        let index = row * row_stride + col;\n        return x[index];\n      }\n\n      fn setValue(row: i32, col: i32, row_stride: i32, value: ${valueType}) {\n        let index = row * row_stride + col;\n        result[index] = value;\n      }\n      ${shaderHelper.registerUniform('packedCols', 'i32').declareVariables(x, output)}\n      ${shaderHelper.mainStart(WG)}\n        let gindex = i32(global_idx);\n        let lindex = i32(local_idx);\n        const wg = ${WG};\n        let row = gindex / wg;\n        let cols = uniforms.packedCols;\n        let row_stride : i32 = uniforms.packedCols;\n\n        // find the rows max\n        ${threadMaxDecl}\n        for (var col = lindex; col < cols; col += wg) {\n          let value = getValue(row, col, row_stride);\n          threadMax = max(threadMax, value);\n        }\n        if (lindex < cols) {\n          threadShared[lindex] = threadMax;\n        }\n        workgroupBarrier();\n\n        var reduceSize = min(cols, wg);\n        for (var currSize = reduceSize >> 1;  currSize > 0; currSize = reduceSize >> 1) {\n          reduceSize = currSize + (reduceSize & 1);\n          if (lindex < currSize) {\n            threadShared[lindex] = max(threadShared[lindex], threadShared[lindex + reduceSize]);\n          }\n          workgroupBarrier();\n        }\n        if (lindex == 0) {\n          rowMaxShared = ${valueType}(${maxVector('threadShared[0]', components)});\n        }\n        workgroupBarrier();\n\n        // find the rows sum\n        var threadSum = ${valueType}(0.0);\n        for (var col = lindex; col < cols; col += wg) {\n          let subExp = exp(getValue(row, col, row_stride) - rowMaxShared);\n          threadSum += subExp;\n        }\n        threadShared[lindex] = threadSum;\n        workgroupBarrier();\n\n        for (var currSize = wg >> 1;  currSize > 0; currSize = currSize >> 1) {\n          if (lindex < currSize) {\n            threadShared[lindex] = threadShared[lindex] + threadShared[lindex + currSize];\n          }\n          workgroupBarrier();\n        }\n        if (lindex == 0) {\n          rowSumShared = ${valueType}(${sumVector('threadShared[0]', components)});\n        }\n        workgroupBarrier();\n\n        // calculate final value for each element in the row\n        for (var col = lindex; col < cols; col += wg) {\n          let value = exp(getValue(row, col, row_stride) - rowMaxShared) / rowSumShared;\n          setValue(row, col, row_stride, value);\n        }\n      }`;\n  const result = context.compute(\n    {\n      name: 'Softmax',\n      // Note that in JSEP, WG size is not included in cache by default, but WebGPU EP it is.\n      shaderCache: { hint: `${components};${WG}`, inputDependencies: ['type'] },\n      getRunData: () => ({\n        outputs: [{ dims: transposedInputShape, dataType: transposedInput.dataType }],\n        dispatchGroup: { x: rows },\n        programUniforms: [{ type: DataType.int32, data: packedCols }],\n      }),\n      getShaderSource,\n    },\n    {\n      inputs: [transposedInput],\n      outputs: [isTransposeRequired ? -1 : 0],\n    },\n  )[0];\n\n  if (isTransposeRequired) {\n    context.compute(createTransposeProgramInfo(result, perm), {\n      inputs: [result],\n    });\n  }\n};\n\nexport const softmax = (context: ComputeContext, attributes: SoftmaxAttributes): void => {\n  validateInputs(context.inputs);\n  createSoftmaxProgramInfo(context, attributes);\n};\n\nexport const parseSoftmaxAttributes = (attributes: Record<string, unknown>): SoftmaxAttributes =>\n  createAttributeWithCacheKey({ axis: attributes.axis as number });\n","// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport { DataType } from '../../../wasm-common';\nimport { TensorView } from '../../tensor-view';\nimport { ShapeUtil } from '../../util';\nimport { ComputeContext, ProgramInfo } from '../types';\n\nimport { createTensorShapeVariables, inputVariable, outputVariable, ShaderHelper } from './common';\n\nconst getRepeats = (repeatsTensorView: TensorView): readonly number[] =>\n  Array.from(repeatsTensorView.getBigInt64Array(), Number);\n\nconst validateInputs = (inputs: readonly TensorView[]): void => {\n  if (!inputs || inputs.length !== 2) {\n    throw new Error('Tile requires 2 inputs.');\n  }\n\n  if (\n    inputs[0].dataType !== DataType.float &&\n    inputs[0].dataType !== DataType.float16 &&\n    inputs[0].dataType !== DataType.int32 &&\n    inputs[0].dataType !== DataType.uint32\n  ) {\n    throw new Error('Tile only support float, float16, int32, and uint32 data types');\n  }\n\n  if (inputs[1].dataType !== DataType.int64) {\n    throw new Error('Tile `repeats` input should be of int64 data type');\n  }\n\n  if (inputs[1].dims.length !== 1) {\n    throw new Error('Tile `repeats` input should be 1-D');\n  }\n\n  const repeats: readonly number[] = getRepeats(inputs[1]);\n\n  if (repeats.length !== inputs[0].dims.length) {\n    throw new Error('Tile `repeats` input should have same number of elements as rank of input data tensor');\n  }\n};\n\nconst getOutputShape = (inputShape: readonly number[], repeats: readonly number[]): readonly number[] => {\n  const outputShape: number[] = [];\n\n  for (let i = 0; i < inputShape.length; ++i) {\n    outputShape.push(inputShape[i] * repeats[i]);\n  }\n\n  return outputShape;\n};\n\nexport const createTileProgramInfo = (inputs: readonly TensorView[], shape?: number[]): ProgramInfo => {\n  const inputShape = inputs[0].dims;\n  const repeats: readonly number[] = shape == null ? getRepeats(inputs[1]) : shape;\n  const outputShape = getOutputShape(inputShape, repeats);\n  const outputSize = ShapeUtil.size(outputShape);\n\n  const dataType = inputs[0].dataType;\n  const input = inputVariable('input', dataType, inputShape.length);\n  const output = outputVariable('output', dataType, outputShape.length);\n\n  const getShaderSource = (shaderHelper: ShaderHelper) => `\n      const inputShape = ${input.indices(...inputShape)};\n      ${shaderHelper.registerUniform('output_size', 'u32').declareVariables(input, output)}\n      ${shaderHelper.mainStart()}\n      ${shaderHelper.guardAgainstOutOfBoundsWorkgroupSizes('uniforms.output_size')}\n      let output_indices = ${output.offsetToIndices('global_idx')};\n      var input_indices: ${input.type.indices};\n      for (var i = 0; i < ${inputShape.length}; i++) {\n        let input_dim_i = ${input.indicesGet('uniforms.input_shape', 'i')};\n        let input_dim_value = ${output.indicesGet('output_indices', 'i')}  % input_dim_i;\n\n        ${input.indicesSet('input_indices', 'i', 'input_dim_value')}\n      }\n      ${output.setByOffset('global_idx', input.getByIndices('input_indices'))}\n    }`;\n\n  return {\n    name: 'Tile',\n    shaderCache: { hint: `${repeats}`, inputDependencies: ['rank'] },\n    getRunData: () => ({\n      outputs: [{ dims: outputShape, dataType: inputs[0].dataType }],\n      dispatchGroup: { x: Math.ceil(outputSize / 64 /* workgroup size */) },\n      programUniforms: [\n        { type: DataType.uint32, data: outputSize },\n        ...createTensorShapeVariables(inputs[0].dims, outputShape),\n      ],\n    }),\n    getShaderSource,\n  };\n};\n\nexport const tile = (context: ComputeContext): void => {\n  validateInputs(context.inputs);\n  context.compute(createTileProgramInfo(context.inputs), { inputs: [0] });\n};\n","// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport { DataType } from '../../../wasm-common';\nimport { TensorView } from '../../tensor-view';\nimport { BroadcastUtil, ShapeUtil } from '../../util';\nimport { ComputeContext, ProgramInfo } from '../types';\n\nimport { createTensorShapeVariables, inputVariable, outputVariable, ShaderHelper } from './common';\n\nconst createWhereOpProgramShader = (\n  shaderHelper: ShaderHelper,\n  inputs: readonly TensorView[],\n  dimsOutput: readonly number[],\n  isBroadcast: boolean,\n  typeOutput: number,\n) => {\n  const output = outputVariable('output_data', typeOutput, dimsOutput.length, 4);\n  const a = inputVariable('a_data', inputs[1].dataType, inputs[1].dims.length, 4);\n  const b = inputVariable('b_data', inputs[2].dataType, inputs[2].dims.length, 4);\n  const c = inputVariable('c_data', inputs[0].dataType, inputs[0].dims.length, 4);\n\n  let assignment: string;\n  const expression = (a: string, b: string, c: string) => `select(${b}, ${a}, ${c})`;\n  if (!isBroadcast) {\n    assignment = output.setByOffset(\n      'global_idx',\n      expression(a.getByOffset('global_idx'), b.getByOffset('global_idx'), c.getByOffset('global_idx')),\n    );\n  } else {\n    const singleAssignment = (resStr: string, x: number, typeCast = '') => {\n      const expressionA = `a_data[index_a${x}][component_a${x}]`;\n      const expressionB = `b_data[index_b${x}][component_b${x}]`;\n      // eslint-disable-next-line no-bitwise\n      const expressionC = `bool(c_data[index_c${x}] & (0xffu << (component_c${x} * 8)))`;\n      return `\n            let output_indices${x} = ${output.offsetToIndices(`global_idx * 4u + ${x}u`)};\n            let offset_a${x} = ${a.broadcastedIndicesToOffset(`output_indices${x}`, output)};\n            let offset_b${x} = ${b.broadcastedIndicesToOffset(`output_indices${x}`, output)};\n            let offset_c${x} = ${c.broadcastedIndicesToOffset(`output_indices${x}`, output)};\n            let index_a${x} = offset_a${x} / 4u;\n            let index_b${x} = offset_b${x} / 4u;\n            let index_c${x} = offset_c${x} / 4u;\n            let component_a${x} = offset_a${x} % 4u;\n            let component_b${x} = offset_b${x} % 4u;\n            let component_c${x} = offset_c${x} % 4u;\n            ${resStr}[${x}] = ${typeCast}(${expression(expressionA, expressionB, expressionC)});\n          `;\n    };\n    if (typeOutput === DataType.bool) {\n      assignment = `\n            var data = vec4<u32>(0);\n            ${singleAssignment('data', 0, 'u32')}\n            ${singleAssignment('data', 1, 'u32')}\n            ${singleAssignment('data', 2, 'u32')}\n            ${singleAssignment('data', 3, 'u32')}\n            output_data[global_idx] = dot(vec4<u32>(0x1, 0x100, 0x10000, 0x1000000), vec4<u32>(data));`;\n    } else {\n      assignment = `\n            ${singleAssignment('output_data[global_idx]', 0)}\n            ${singleAssignment('output_data[global_idx]', 1)}\n            ${singleAssignment('output_data[global_idx]', 2)}\n            ${singleAssignment('output_data[global_idx]', 3)}\n          `;\n    }\n  }\n\n  return `\n        ${shaderHelper.registerUniform('vec_size', 'u32').declareVariables(c, a, b, output)}\n        ${shaderHelper.mainStart()}\n        ${shaderHelper.guardAgainstOutOfBoundsWorkgroupSizes('uniforms.vec_size')}\n        ${assignment}\n      }`;\n};\n\nconst createWhereOpProgramInfo = (inputs: readonly TensorView[]): ProgramInfo => {\n  const dimsA = inputs[1].dims;\n  const dimsB = inputs[2].dims;\n  const dimsC = inputs[0].dims;\n  const outputDataType = inputs[1].dataType;\n\n  const isBroadcast = !(ShapeUtil.areEqual(dimsA, dimsB) && ShapeUtil.areEqual(dimsB, dimsC));\n  let outputShape = dimsA;\n  let outputSize = ShapeUtil.size(dimsA);\n  // TODO: deal with zero-sized tensors (eg. dims=[1,0])\n\n  if (isBroadcast) {\n    const calculatedShape = BroadcastUtil.calcShape(BroadcastUtil.calcShape(dimsA, dimsB, false)!, dimsC, false);\n    if (!calculatedShape) {\n      throw new Error(\"Can't perform where op on the given tensors\");\n    }\n    outputShape = calculatedShape;\n    outputSize = ShapeUtil.size(outputShape);\n  }\n\n  const vecSize = Math.ceil(outputSize / 4);\n\n  return {\n    name: 'Where',\n    shaderCache: { inputDependencies: ['rank', 'rank', 'rank'] },\n    getShaderSource: (shaderHelper) =>\n      createWhereOpProgramShader(shaderHelper, inputs, outputShape, isBroadcast, outputDataType),\n    getRunData: () => ({\n      outputs: [{ dims: outputShape, dataType: outputDataType }],\n      dispatchGroup: { x: Math.ceil(outputSize / 64 /* workgroup size */ / 4 /* vec size */) },\n      programUniforms: [\n        { type: DataType.uint32, data: vecSize },\n        ...createTensorShapeVariables(dimsC, dimsA, dimsB, outputShape),\n      ],\n    }),\n  };\n};\n\nexport const where = (context: ComputeContext): void => {\n  context.compute(createWhereOpProgramInfo(context.inputs));\n};\n","// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport { argMax, argMin, parseArgMinMaxAttributes } from './ops/argminmax';\nimport { attention } from './ops/attention';\nimport { batchNorm } from './ops/batch-norm';\nimport { biasAdd } from './ops/bias-add';\nimport { biasSplitGelu } from './ops/bias-split-gelu';\nimport * as binaryOps from './ops/binary-op';\nimport { concat, parseConcatAttributes } from './ops/concat';\nimport { conv, parseConvAttributes } from './ops/conv';\nimport { convTranspose, parseConvTransposeAttributes } from './ops/conv-transpose';\nimport { cumsum, parseCumSumAttributes } from './ops/cumsum';\nimport { depthToSpace, parseDepthToSpaceAttributes } from './ops/depth-to-space';\nimport { einsum, parseEinsumAttributes } from './ops/einsum';\nimport { expand } from './ops/expand';\nimport { fastGelu } from './ops/fast-gelu';\nimport { gather, parseGatherAttributes } from './ops/gather';\nimport { gatherND, parseGatherNDAttributes } from './ops/gather-nd';\nimport { gatherBlockQuantized, parseGatherBlockQuantizedAttributes } from './ops/gather-block-quantized';\nimport { gatherElements, parseGatherElementsAttributes } from './ops/gather-elements';\nimport { gemm, parseGemmAttributes } from './ops/gemm';\nimport { gridSample, parseGridSampleAttributes } from './ops/grid-sample';\nimport { groupQueryAttention } from './ops/group-query-attention';\nimport { instanceNorm } from './ops/instance-norm';\nimport { layerNorm } from './ops/layer-norm';\nimport { matMul } from './ops/matmul';\nimport { matMulNBits, parseMatMulNBitsAttributes } from './ops/matmulnbits';\nimport { multiHeadAttention, parseMultiHeadAttentionAttributes } from './ops/multihead-attention';\nimport { pad } from './ops/pad';\nimport * as pool from './ops/pool';\nimport { dequantizeLinear, parseDequantizeLinearAttributes } from './ops/quantize-linear';\nimport { range } from './ops/range';\nimport { scatterND, parseScatterNDAttributes } from './ops/scatter-nd';\nimport {\n  reduceL1,\n  reduceL2,\n  reduceLogSum,\n  reduceLogSumExp,\n  reduceMax,\n  reduceMean,\n  reduceMin,\n  reduceProd,\n  reduceSum,\n  reduceSumSquare,\n} from './ops/reduce';\nimport { parseResizeAttributes, resize } from './ops/resize';\nimport { rotaryEmbedding } from './ops/rotary-embedding';\nimport { skipLayerNorm } from './ops/skip-layer-norm';\nimport { parseSliceAttributes, slice } from './ops/slice';\nimport { parseSoftmaxAttributes, softmax } from './ops/softmax';\nimport { parseSplitAttributes, split } from './ops/split';\nimport { tile } from './ops/tile';\nimport { parseTransposeAttributes, transpose } from './ops/transpose';\nimport * as unaryOps from './ops/unary-op';\nimport { where } from './ops/where';\nimport { ComputeContext } from './types';\n\nexport type RunFunction = (context: ComputeContext, attribute?: unknown) => void;\nexport type ParseAttributeFunction = (attributeRaw: unknown) => unknown;\nexport type OperatorImplementation = [RunFunction] | [RunFunction, ParseAttributeFunction];\n\nexport const WEBGPU_OP_RESOLVE_RULES: Map<string, OperatorImplementation> = new Map([\n  ['Abs', [unaryOps.abs]],\n  ['Acos', [unaryOps.acos]],\n  ['Acosh', [unaryOps.acosh]],\n  ['Add', [binaryOps.add]],\n  ['ArgMax', [argMax, parseArgMinMaxAttributes]],\n  ['ArgMin', [argMin, parseArgMinMaxAttributes]],\n  ['Asin', [unaryOps.asin]],\n  ['Asinh', [unaryOps.asinh]],\n  ['Atan', [unaryOps.atan]],\n  ['Atanh', [unaryOps.atanh]],\n  ['Attention', [attention]],\n  // TODO: support new attributes for AveragePool-10\n  ['AveragePool', [pool.averagePool, pool.parseAveragePoolAttributes]],\n  ['BatchNormalization', [batchNorm]],\n  ['BiasAdd', [biasAdd]],\n  ['BiasSplitGelu', [biasSplitGelu]],\n  ['Cast', [unaryOps.cast, unaryOps.parseCastAttributes]],\n  ['Ceil', [unaryOps.ceil]],\n  ['Clip', [unaryOps.clip]],\n  ['Concat', [concat, parseConcatAttributes]],\n  ['Conv', [conv, parseConvAttributes]],\n  ['ConvTranspose', [convTranspose, parseConvTransposeAttributes]],\n  ['Cos', [unaryOps.cos]],\n  ['Cosh', [unaryOps.cosh]],\n  ['CumSum', [cumsum, parseCumSumAttributes]],\n  ['DepthToSpace', [depthToSpace, parseDepthToSpaceAttributes]],\n  ['DequantizeLinear', [dequantizeLinear, parseDequantizeLinearAttributes]],\n  ['Div', [binaryOps.div]],\n  ['Einsum', [einsum, parseEinsumAttributes]],\n  ['Elu', [unaryOps.elu, unaryOps.parseAlphaAttributes]],\n  ['Equal', [binaryOps.equal]],\n  ['Erf', [unaryOps.erf]],\n  ['Exp', [unaryOps.exp]],\n  ['Expand', [expand]],\n  ['FastGelu', [fastGelu]],\n  ['Floor', [unaryOps.floor]],\n  ['FusedConv', [conv, parseConvAttributes]],\n  ['Gather', [gather, parseGatherAttributes]],\n  ['GatherElements', [gatherElements, parseGatherElementsAttributes]],\n  ['GatherBlockQuantized', [gatherBlockQuantized, parseGatherBlockQuantizedAttributes]],\n  ['GatherND', [gatherND, parseGatherNDAttributes]],\n  ['Gelu', [unaryOps.gelu]],\n  ['Gemm', [gemm, parseGemmAttributes]],\n  ['GlobalAveragePool', [pool.globalAveragePool, pool.parseGlobalAveragePoolAttributes]],\n  ['GlobalMaxPool', [pool.globalMaxPool, pool.parseGlobalMaxPoolAttributes]],\n  ['Greater', [binaryOps.greater]],\n  ['GreaterOrEqual', [binaryOps.greaterOrEqual]],\n  ['GridSample', [gridSample, parseGridSampleAttributes]],\n  ['GroupQueryAttention', [groupQueryAttention]],\n  ['HardSigmoid', [unaryOps.hardSigmoid, unaryOps.parseHardSigmoidAttributes]],\n  ['InstanceNormalization', [instanceNorm]],\n  ['LayerNormalization', [layerNorm]],\n  ['LeakyRelu', [unaryOps.leakyRelu, unaryOps.parseAlphaAttributes]],\n  ['Less', [binaryOps.less]],\n  ['LessOrEqual', [binaryOps.lessOrEqual]],\n  ['Log', [unaryOps.log]],\n  ['MatMul', [matMul]],\n  ['MatMulNBits', [matMulNBits, parseMatMulNBitsAttributes]],\n  // TODO: support new attributes for MaxPool-8 and MaxPool-10\n  ['MaxPool', [pool.maxPool, pool.parseMaxPoolAttributes]],\n  ['Mul', [binaryOps.mul]],\n  ['MultiHeadAttention', [multiHeadAttention, parseMultiHeadAttentionAttributes]],\n  ['Neg', [unaryOps.neg]],\n  ['Not', [unaryOps.not]],\n  ['Pad', [pad]],\n  ['Pow', [binaryOps.pow]],\n  ['QuickGelu', [unaryOps.quickgelu, unaryOps.parseAlphaAttributes]],\n  ['Range', [range]],\n  ['Reciprocal', [unaryOps.reciprocal]],\n  ['ReduceMin', [reduceMin]],\n  ['ReduceMean', [reduceMean]],\n  ['ReduceMax', [reduceMax]],\n  ['ReduceSum', [reduceSum]],\n  ['ReduceProd', [reduceProd]],\n  ['ReduceL1', [reduceL1]],\n  ['ReduceL2', [reduceL2]],\n  ['ReduceLogSum', [reduceLogSum]],\n  ['ReduceLogSumExp', [reduceLogSumExp]],\n  ['ReduceSumSquare', [reduceSumSquare]],\n  ['Relu', [unaryOps.relu]],\n  ['Resize', [resize, parseResizeAttributes]],\n  ['RotaryEmbedding', [rotaryEmbedding]],\n  ['ScatterND', [scatterND, parseScatterNDAttributes]],\n  ['Sigmoid', [unaryOps.sigmoid]],\n  ['Sin', [unaryOps.sin]],\n  ['Sinh', [unaryOps.sinh]],\n  ['Slice', [slice, parseSliceAttributes]],\n  ['SkipLayerNormalization', [skipLayerNorm]],\n  ['Split', [split, parseSplitAttributes]],\n  ['Sqrt', [unaryOps.sqrt]],\n  ['Softmax', [softmax, parseSoftmaxAttributes]],\n  ['Sub', [binaryOps.sub]],\n  ['Tan', [unaryOps.tan]],\n  ['Tanh', [unaryOps.tanh]],\n  ['ThresholdedRelu', [unaryOps.thresholdedRelu, unaryOps.parseAlphaAttributes]],\n  ['Tile', [tile]],\n  ['Transpose', [transpose, parseTransposeAttributes]],\n  ['Where', [where]],\n]);\n","// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport { TRACE_FUNC_BEGIN, TRACE_FUNC_END } from 'onnxruntime-common';\n\nimport { WebGpuBackend } from '../backend-webgpu';\nimport { LOG_DEBUG } from '../log';\n\nimport { createShaderHelper } from './ops/common';\nimport { Artifact, GpuData, ProgramInfo } from './types';\n\n/**\n * ProgramManager is the main class behind running computations\n * It builds ProgramInfo's into Artifacts\n * It compiles given ProgramInfo's into WebGL Prorams (cached as Artifacts)\n * Uses the artifact to run the computation by calling Draw on\n * the WebGL drawing buffer\n * ProgramManager automatically maps (binds) input variables to their\n * corresponding Location's in the binary program\n */\nexport class ProgramManager {\n  repo: Map<unknown, Artifact>; // this should be per-session object\n  attributesBound: boolean;\n\n  constructor(private backend: WebGpuBackend) {\n    this.repo = new Map();\n    this.attributesBound = false;\n  }\n  getArtifact(key: unknown): Artifact | undefined {\n    return this.repo.get(key);\n  }\n  setArtifact(key: unknown, artifact: Artifact): void {\n    this.repo.set(key, artifact);\n  }\n  run(\n    buildArtifact: Artifact,\n    inputs: GpuData[],\n    outputs: GpuData[],\n    dispatchGroup: [number, number, number],\n    uniformBufferBinding: GPUBindingResource | undefined,\n  ): void {\n    TRACE_FUNC_BEGIN(buildArtifact.programInfo.name);\n    const device = this.backend.device;\n    const computePassEncoder = this.backend.getComputePassEncoder();\n    this.backend.writeTimestamp(this.backend.pendingDispatchNumber * 2);\n    const entries = [];\n    for (const input of inputs) {\n      entries.push({ binding: entries.length, resource: { buffer: input.buffer } });\n    }\n    for (const output of outputs) {\n      entries.push({ binding: entries.length, resource: { buffer: output.buffer } });\n    }\n    if (uniformBufferBinding) {\n      entries.push({ binding: entries.length, resource: uniformBufferBinding });\n    }\n    const bindGroup = device.createBindGroup({\n      layout: buildArtifact.computePipeline.getBindGroupLayout(0),\n      entries,\n      label: buildArtifact.programInfo.name,\n    });\n\n    if (this.backend.sessionStatus === 'capturing') {\n      const commandInfo = {\n        kernelId: this.backend.currentKernelId!,\n        computePipeline: buildArtifact.computePipeline,\n        bindGroup,\n        dispatchGroup,\n      };\n      const sessionCommandList = this.backend.capturedCommandList.get(this.backend.currentSessionId!);\n      sessionCommandList!.push(commandInfo);\n    }\n\n    computePassEncoder.setPipeline(buildArtifact.computePipeline);\n    computePassEncoder.setBindGroup(0, bindGroup);\n    computePassEncoder.dispatchWorkgroups(...dispatchGroup);\n    this.backend.writeTimestamp(this.backend.pendingDispatchNumber * 2 + 1);\n    this.backend.pendingDispatchNumber++;\n\n    if (\n      this.backend.pendingDispatchNumber >= this.backend.maxDispatchNumber ||\n      this.backend.queryType === 'at-passes'\n    ) {\n      this.backend.endComputePass();\n    }\n    if (this.backend.pendingDispatchNumber >= this.backend.maxDispatchNumber) {\n      this.backend.flush();\n    }\n    TRACE_FUNC_END(buildArtifact.programInfo.name);\n  }\n  dispose(): void {\n    // this.repo.forEach(a => this.glContext.deleteProgram(a.program));\n  }\n  build(programInfo: ProgramInfo, normalizedDispatchGroupSize: [number, number, number]): Artifact {\n    TRACE_FUNC_BEGIN(programInfo.name);\n    const device = this.backend.device;\n    const enableDirectives: string[] = [];\n\n    // Enable WGSL extensions based on available WebGPU features\n    const extensionsInfo: Array<{ feature: GPUFeatureName; extension: string }> = [\n      { feature: 'shader-f16', extension: 'f16' },\n      { feature: 'subgroups' as GPUFeatureName, extension: 'subgroups' },\n    ];\n    extensionsInfo.forEach((info) => {\n      if (device.features.has(info.feature)) {\n        enableDirectives.push(`enable ${info.extension};`);\n      }\n    });\n\n    const shaderHelper = createShaderHelper(normalizedDispatchGroupSize, this.backend.device.limits);\n    const userCode = programInfo.getShaderSource(shaderHelper);\n    const code = `${enableDirectives.join('\\n')}\\n${shaderHelper.additionalImplementations}\\n${userCode}`;\n    const shaderModule = device.createShaderModule({ code, label: programInfo.name });\n    LOG_DEBUG('verbose', () => `[WebGPU] ${programInfo.name} shader code: ${code}`);\n\n    const computePipeline = device.createComputePipeline({\n      compute: { module: shaderModule, entryPoint: 'main' },\n      layout: 'auto',\n      label: programInfo.name,\n    });\n\n    TRACE_FUNC_END(programInfo.name);\n    return { programInfo, computePipeline, uniformVariablesInfo: shaderHelper.variablesInfo };\n  }\n\n  normalizeDispatchGroupSize(\n    dispatchGroup: ReturnType<ProgramInfo['getRunData']>['dispatchGroup'],\n  ): [number, number, number] {\n    const x = typeof dispatchGroup === 'number' ? dispatchGroup : dispatchGroup.x;\n    const y = typeof dispatchGroup === 'number' ? 1 : dispatchGroup.y || 1;\n    const z = typeof dispatchGroup === 'number' ? 1 : dispatchGroup.z || 1;\n    const limitPerDimension = this.backend.device.limits.maxComputeWorkgroupsPerDimension;\n    if (x <= limitPerDimension && y <= limitPerDimension && z <= limitPerDimension) {\n      return [x, y, z];\n    }\n    const size = x * y * z;\n    let dispatchAverage = Math.ceil(Math.sqrt(size));\n    if (dispatchAverage > limitPerDimension) {\n      dispatchAverage = Math.ceil(Math.cbrt(size));\n      if (dispatchAverage > limitPerDimension) {\n        throw new Error('Total dispatch size exceeds WebGPU maximum.');\n      }\n      return [dispatchAverage, dispatchAverage, dispatchAverage];\n    } else {\n      return [dispatchAverage, dispatchAverage, 1];\n    }\n  }\n}\n","// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport { Env, Tensor, TRACE, TRACE_FUNC_BEGIN, TRACE_FUNC_END } from 'onnxruntime-common';\n\nimport { DataType, tensorDataTypeEnumToString } from '../wasm-common';\n\nimport { configureLogger, LOG_DEBUG } from './log';\nimport { createView, TensorView } from './tensor-view';\nimport { createGpuDataManager, downloadGpuData, GpuDataManager } from './webgpu/gpu-data-manager';\nimport { RunFunction, WEBGPU_OP_RESOLVE_RULES } from './webgpu/op-resolve-rules';\nimport { ProgramManager } from './webgpu/program-manager';\nimport {\n  AdapterInfo,\n  ComputeContext,\n  GpuArchitecture,\n  GpuData,\n  GpuVendor,\n  ProgramInfo,\n  ProgramInputTensorInfoDependency,\n  SessionState,\n  TimestampQuery,\n} from './webgpu/types';\n\ninterface CommandInfo {\n  readonly kernelId: number;\n  readonly computePipeline: GPUComputePipeline;\n  readonly bindGroup: GPUBindGroup;\n  readonly dispatchGroup: [number, number, number];\n}\n\ninterface KernelInfo {\n  readonly kernelType: string;\n  readonly kernelName: string;\n  readonly kernelEntry: RunFunction;\n  readonly attributes: [((attribute: unknown) => unknown) | undefined, unknown];\n}\n\ninterface PendingKernelInfo {\n  readonly kernelId: number;\n  readonly programName: string;\n  readonly inputTensorViews: readonly TensorView[];\n  readonly outputTensorViews: readonly TensorView[];\n}\n\nconst getProgramInputTensorInfoDependencyKey = (\n  inputTensors: readonly TensorView[],\n  inputDependencies: readonly ProgramInputTensorInfoDependency[],\n): string => {\n  if (inputDependencies.length !== inputTensors.length) {\n    throw new Error(\n      `inputDependencies length ${inputDependencies.length} is not equal to inputTensors length ${\n        inputTensors.length\n      }.`,\n    );\n  }\n\n  const inputInfos: string[] = [];\n  for (let i = 0; i < inputTensors.length; ++i) {\n    const type = inputTensors[i].dataType;\n    switch (inputDependencies[i]) {\n      case 'none': {\n        inputInfos.push('');\n        break;\n      }\n      case 'type': {\n        inputInfos.push(`${type}`);\n        break;\n      }\n      case 'rank': {\n        const rank = inputTensors[i].dims.length;\n        inputInfos.push(`${type};${rank}`);\n        break;\n      }\n      case 'dims': {\n        const dims = inputTensors[i].dims.join(',');\n        inputInfos.push(`${type};${dims}`);\n        break;\n      }\n      default:\n        throw new Error(`unsupported input dependency: ${inputDependencies[i]}`);\n    }\n  }\n\n  return inputInfos.join('|');\n};\n\n/**\n * get a unique key representing the program from the program info, input shapes and types.\n *\n * @returns a unique key is a shorter string than the shader source, which contains all the information to identify a\n * program. if the key is the same, the program shader source should be the same, so we can reuse the program.\n *\n */\nconst getProgramInfoUniqueKey = (\n  programInfo: ProgramInfo,\n  inputTensors: readonly TensorView[],\n  is1DimensionDispatch: boolean,\n): string => {\n  // final key format:\n  // <PROGRAM_NAME>[<PROGRAM_CUSTOM_CACHE_HINT>]:is1DimensionDispatch:<INPUTS_INFO_0>|<INPUTS_INFO_1>|...\n  let key = programInfo.name;\n  if (programInfo.shaderCache?.hint) {\n    key += '[' + programInfo.shaderCache.hint + ']';\n  }\n  key +=\n    ':' +\n    is1DimensionDispatch +\n    `:${getProgramInputTensorInfoDependencyKey(\n      inputTensors,\n      programInfo.shaderCache?.inputDependencies ??\n        new Array<ProgramInputTensorInfoDependency>(inputTensors.length).fill('dims'),\n    )}`;\n  return key;\n};\n\nclass AdapterInfoImpl implements AdapterInfo {\n  readonly architecture?: string;\n  readonly vendor?: string;\n\n  constructor(adapterInfo: GPUAdapterInfo) {\n    if (adapterInfo) {\n      this.architecture = adapterInfo.architecture;\n      this.vendor = adapterInfo.vendor;\n    }\n  }\n\n  isArchitecture(architecture: GpuArchitecture): boolean {\n    return this.architecture === architecture;\n  }\n\n  isVendor(vendor: GpuVendor): boolean {\n    return this.vendor === vendor;\n  }\n}\n\n/**\n * this class is designed to store status and being used as a singleton for JSEP. It will be passed to jsepInit() as\n * the first parameter so that it is stored for future use.\n */\nexport class WebGpuBackend {\n  adapterInfo: AdapterInfoImpl;\n  device: GPUDevice;\n  /**\n   * an instance of GpuDataManager to manage a GpuDataId -> GpuBuffer mapping\n   */\n  gpuDataManager: GpuDataManager;\n  /**\n   * an instance of ProgramManager to build and run WebGPU compute shader program, and manage a ProgramKey -> Program\n   * artifacts mapping\n   */\n  programManager: ProgramManager;\n\n  /**\n   * representing the session ID of which is currently being run.\n   * `null` means no session is being run.\n   * only valid when session.run is executed.\n   */\n  currentSessionId: number | null = null;\n\n  /**\n   * representing the kernel ID of which is currently being computed (CPU code perspective).\n   * `null` means no kernel is being computed.\n   * only one kernel can be computed at a moment.\n   */\n  currentKernelId: number | null = null;\n  /**\n   * a list of temporary GPU data for the current kernel. should release when the kernel done computation.\n   */\n  private temporaryData: GpuData[];\n  /**\n   * a KernelID -> a GPU data list, which stores persistent GPU data owned by the specific kernel.\n   */\n  private kernelPersistentData: Map<number, GpuData[]>;\n  /**\n   * a KernelID -> a custom data, which stores custom data owned by the specific kernel.\n   */\n  private kernelCustomData: Map<number, { [key: string]: unknown }>;\n  /**\n   * get the custom data of the current kernel\n   */\n  get currentKernelCustomData(): { [key: string]: unknown } {\n    if (this.currentKernelId === null) {\n      throw new Error('currentKernelCustomData(): currentKernelId is null. (should not happen)');\n    }\n\n    let data = this.kernelCustomData.get(this.currentKernelId);\n    if (!data) {\n      data = {};\n      this.kernelCustomData.set(this.currentKernelId, data);\n    }\n\n    return data;\n  }\n\n  // KernelID -> kernelInfo mapping\n  kernels: Map<number, KernelInfo>;\n  private commandEncoder: GPUCommandEncoder | null = null;\n  private computePassEncoder: GPUComputePassEncoder | null = null;\n  maxDispatchNumber = 16;\n  pendingDispatchNumber = 0;\n\n  // info of kernels pending submission for a single batch\n  private pendingKernels: PendingKernelInfo[] = [];\n  // queryReadBuffer -> pendingKernels mapping for all the batches\n  private pendingQueries: Map<GPUBuffer, PendingKernelInfo[]> = new Map();\n  private queryResolveBuffer?: GPUBuffer;\n  private querySet?: GPUQuerySet;\n  private queryTimeBase?: bigint;\n  queryType: TimestampQuery;\n\n  env: Env;\n  sessionStatus: SessionState = 'default';\n  /**\n   * a SessionID -> CommandInfo[] mapping. It's used to record all GPU commands for corresponding session.\n   */\n  capturedCommandList: Map<number, CommandInfo[]> = new Map();\n\n  /**\n   * a SessionID -> PendingKernelInfo[] mapping for profiling.\n   */\n  private capturedPendingKernels: Map<number, PendingKernelInfo[]> = new Map();\n\n  /**\n   * a SessionID -> a Map of (InputOutputIndex -> [ID, GPUBuffer]) mapping.\n   */\n  sessionExternalDataMapping: Map<number, Map<number, [number, GPUBuffer]>> = new Map();\n\n  async initialize(env: Env, adapter: GPUAdapter): Promise<void> {\n    this.env = env;\n    const requiredFeatures: GPUFeatureName[] = [];\n    const deviceDescriptor: GPUDeviceDescriptor = {\n      requiredLimits: {\n        maxComputeWorkgroupStorageSize: adapter.limits.maxComputeWorkgroupStorageSize,\n        maxComputeWorkgroupsPerDimension: adapter.limits.maxComputeWorkgroupsPerDimension,\n        maxStorageBufferBindingSize: adapter.limits.maxStorageBufferBindingSize,\n        maxBufferSize: adapter.limits.maxBufferSize,\n        maxComputeInvocationsPerWorkgroup: adapter.limits.maxComputeInvocationsPerWorkgroup,\n        maxComputeWorkgroupSizeX: adapter.limits.maxComputeWorkgroupSizeX,\n        maxComputeWorkgroupSizeY: adapter.limits.maxComputeWorkgroupSizeY,\n        maxComputeWorkgroupSizeZ: adapter.limits.maxComputeWorkgroupSizeZ,\n      },\n      requiredFeatures,\n    };\n\n    // Try requiring WebGPU features\n    const requireFeatureIfAvailable = (feature: GPUFeatureName) =>\n      adapter.features.has(feature) && requiredFeatures.push(feature) && true;\n    // Try chromium-experimental-timestamp-query-inside-passes and fallback to timestamp-query\n    if (!requireFeatureIfAvailable('chromium-experimental-timestamp-query-inside-passes' as GPUFeatureName)) {\n      requireFeatureIfAvailable('timestamp-query');\n    }\n    requireFeatureIfAvailable('shader-f16');\n    // Try subgroups\n    requireFeatureIfAvailable('subgroups' as GPUFeatureName);\n\n    this.device = await adapter.requestDevice(deviceDescriptor);\n    this.adapterInfo = new AdapterInfoImpl(adapter.info || (await adapter.requestAdapterInfo()));\n    this.gpuDataManager = createGpuDataManager(this);\n    this.programManager = new ProgramManager(this);\n    this.kernels = new Map();\n    this.kernelPersistentData = new Map();\n    this.kernelCustomData = new Map();\n\n    // set up flags for logger\n    configureLogger(env.logLevel!, !!env.debug);\n\n    // TODO: set up flags\n\n    this.device.onuncapturederror = (ev) => {\n      if (ev.error instanceof GPUValidationError) {\n        // eslint-disable-next-line no-console\n        console.error(`An uncaught WebGPU validation error was raised: ${ev.error.message}`);\n      }\n    };\n\n    Object.defineProperty(this.env.webgpu, 'device', {\n      value: this.device,\n      writable: false,\n      enumerable: true,\n      configurable: false,\n    });\n    Object.defineProperty(this.env.webgpu, 'adapter', {\n      value: adapter,\n      writable: false,\n      enumerable: true,\n      configurable: false,\n    });\n\n    // init queryType, which is necessary for InferenceSession.create\n    this.setQueryType();\n  }\n\n  dispose(): void {\n    if (typeof this.querySet !== 'undefined') {\n      this.querySet.destroy();\n    }\n    this.gpuDataManager.dispose();\n  }\n\n  getCommandEncoder(): GPUCommandEncoder {\n    if (!this.commandEncoder) {\n      this.commandEncoder = this.device.createCommandEncoder();\n    }\n    return this.commandEncoder;\n  }\n\n  getComputePassEncoder(): GPUComputePassEncoder {\n    if (!this.computePassEncoder) {\n      const commandEncoder = this.getCommandEncoder();\n      const computePassDescriptor: GPUComputePassDescriptor = {};\n\n      if (this.queryType === 'at-passes') {\n        computePassDescriptor.timestampWrites = {\n          querySet: this.querySet!,\n          beginningOfPassWriteIndex: this.pendingDispatchNumber * 2,\n          endOfPassWriteIndex: this.pendingDispatchNumber * 2 + 1,\n        };\n      }\n\n      this.computePassEncoder = commandEncoder.beginComputePass(computePassDescriptor);\n    }\n    return this.computePassEncoder;\n  }\n\n  endComputePass(): void {\n    if (this.computePassEncoder) {\n      this.computePassEncoder.end();\n      this.computePassEncoder = null;\n    }\n  }\n\n  flush(): void {\n    if (!this.commandEncoder) {\n      return;\n    }\n\n    TRACE_FUNC_BEGIN();\n\n    this.endComputePass();\n    let queryReadBuffer: GPUBuffer;\n    if (this.queryType !== 'none') {\n      this.commandEncoder.resolveQuerySet(\n        this.querySet!,\n        0,\n        this.pendingDispatchNumber * 2,\n        this.queryResolveBuffer!,\n        0,\n      );\n\n      queryReadBuffer = this.device.createBuffer(\n        // eslint-disable-next-line no-bitwise\n        { size: this.pendingDispatchNumber * 2 * 8, usage: GPUBufferUsage.MAP_READ | GPUBufferUsage.COPY_DST },\n      );\n\n      this.pendingQueries.set(queryReadBuffer, this.pendingKernels);\n      this.pendingKernels = [];\n      this.commandEncoder.copyBufferToBuffer(\n        this.queryResolveBuffer!,\n        0,\n        queryReadBuffer,\n        0,\n        this.pendingDispatchNumber * 2 * 8,\n      );\n    }\n\n    this.device.queue.submit([this.commandEncoder.finish()]);\n    this.gpuDataManager.refreshPendingBuffers();\n    this.commandEncoder = null;\n    this.pendingDispatchNumber = 0;\n\n    if (this.queryType !== 'none') {\n      void queryReadBuffer!.mapAsync(GPUMapMode.READ).then(() => {\n        const mappedData = new BigUint64Array(queryReadBuffer.getMappedRange());\n        const pendingKernels = this.pendingQueries.get(queryReadBuffer)!;\n        for (let i = 0; i < mappedData.length / 2; i++) {\n          const pendingKernelInfo = pendingKernels[i];\n          const kernelId = pendingKernelInfo.kernelId;\n          const kernelInfo = this.kernels.get(kernelId)!;\n          const kernelType = kernelInfo.kernelType;\n          const kernelName = kernelInfo.kernelName;\n          const programName = pendingKernelInfo.programName;\n          const inputTensorViews = pendingKernelInfo.inputTensorViews;\n          const outputTensorViews = pendingKernelInfo.outputTensorViews;\n          const startTimeU64 = mappedData[i * 2];\n          const endTimeU64 = mappedData[i * 2 + 1];\n\n          if (typeof this.queryTimeBase === 'undefined') {\n            this.queryTimeBase = startTimeU64;\n          }\n\n          const startTime = Number(startTimeU64 - this.queryTimeBase);\n          const endTime = Number(endTimeU64 - this.queryTimeBase);\n\n          if (!Number.isSafeInteger(startTime) || !Number.isSafeInteger(endTime)) {\n            throw new RangeError('incorrect timestamp range');\n          }\n\n          if (this.env.webgpu.profiling?.ondata) {\n            this.env.webgpu.profiling.ondata({\n              version: 1,\n              inputsMetadata: inputTensorViews.map((value) => ({\n                dims: value.dims,\n                dataType: tensorDataTypeEnumToString(value.dataType),\n              })),\n              outputsMetadata: outputTensorViews.map((value) => ({\n                dims: value.dims,\n                dataType: tensorDataTypeEnumToString(value.dataType),\n              })),\n              kernelId,\n              kernelType,\n              kernelName,\n              programName,\n              startTime,\n              endTime,\n            });\n          } else {\n            // if no callback is provided, print the profiling message to console\n            let inputShapes = '';\n            inputTensorViews.forEach((value, i) => {\n              inputShapes += `input[${i}]: [${value.dims}] | ${tensorDataTypeEnumToString(value.dataType)}, `;\n            });\n            let outputShapes = '';\n            outputTensorViews.forEach((value, i) => {\n              outputShapes += `output[${i}]: [${value.dims}] | ${tensorDataTypeEnumToString(value.dataType)}, `;\n            });\n            // eslint-disable-next-line no-console\n            console.log(\n              `[profiling] kernel \"${kernelId}|${kernelType}|${kernelName}|${programName}\" ${inputShapes}${\n                outputShapes\n              }execution time: ${endTime - startTime} ns`,\n            );\n          }\n          TRACE('GPU', `${programName}::${startTimeU64}::${endTimeU64}`);\n        }\n        queryReadBuffer.unmap();\n        this.pendingQueries.delete(queryReadBuffer);\n      });\n    }\n    TRACE_FUNC_END();\n  }\n\n  /**\n   * run a WebGPU program.\n   * @param program a ProgramInfo instance\n   * @param inputTensorViews a TensorView array. each element represents a value already exists in GPU.\n   * @param outputIndices an indices array. each element can be either -1 (temporary data), -2 (persistent data) or an\n   * index to the kernel's output.\n   * @param createKernelOutput a callback function that create a value to kernel's output with the given index\n   * @param createIntermediateOutput a callback function that create a value as a intermediate value, either temporary\n   * or persistent (owned by the current kernel)\n   * @returns a TensorView array representing the result.\n   */\n  run(\n    program: ProgramInfo,\n    inputTensorViews: readonly TensorView[],\n    outputIndices: readonly number[],\n    createKernelOutput: (index: number, dataType: number, dims: readonly number[]) => TensorView,\n    createIntermediateOutput: (dataType: number, dims: readonly number[]) => TensorView,\n    outputCount: number,\n  ): TensorView[] {\n    TRACE_FUNC_BEGIN(program.name);\n    // create info for inputs\n    const inputDatas: GpuData[] = [];\n    for (let i = 0; i < inputTensorViews.length; ++i) {\n      const data = inputTensorViews[i].data;\n      // if tensor view data is 0, it means the output is zero-sized tensor, and there is no GPU data for it.\n      if (data === 0) {\n        continue;\n      }\n      const gpuData = this.gpuDataManager.get(data);\n      if (!gpuData) {\n        throw new Error(`no GPU data for input: ${data}`);\n      }\n      inputDatas.push(gpuData);\n    }\n\n    const { outputs, dispatchGroup, programUniforms } = program.getRunData(inputTensorViews);\n\n    // check output indices\n    const validatedOutputIndices = outputIndices.length === 0 ? outputs.map((_, i) => i) : outputIndices;\n    if (validatedOutputIndices.length !== outputs.length) {\n      throw new Error(`Output size ${validatedOutputIndices.length} must be equal to ${outputs.length}.`);\n    }\n\n    // create info for outputs\n    const outputTensorViews: TensorView[] = [];\n    const outputDatas: GpuData[] = [];\n    for (let i = 0; i < outputs.length; ++i) {\n      // value -1 and -2 are used for creating temporary and persistent outputs.\n      // value -3 is used for placeholder output. So -3, -2, -1 and 0, 1, 2, ... are valid\n      // output indices. see type definition of ComputeContextInputsOutputsMapping for more details.\n      if (\n        !Number.isInteger(validatedOutputIndices[i]) ||\n        validatedOutputIndices[i] < -3 ||\n        validatedOutputIndices[i] >= outputCount\n      ) {\n        throw new Error(`Invalid output index: ${validatedOutputIndices[i]}`);\n      }\n      if (validatedOutputIndices[i] === -3) {\n        continue;\n      }\n      const isTemporary = validatedOutputIndices[i] === -1;\n      const isPersistent = validatedOutputIndices[i] === -2;\n      const tensorView =\n        isTemporary || isPersistent\n          ? createIntermediateOutput(outputs[i].dataType, outputs[i].dims)\n          : createKernelOutput(validatedOutputIndices[i], outputs[i].dataType, outputs[i].dims);\n      outputTensorViews.push(tensorView);\n      // if tensor view data is 0, it means the output is zero-sized tensor, and there is no GPU data for it.\n      if (tensorView.data === 0) {\n        continue;\n      }\n      const gpuData = this.gpuDataManager.get(tensorView.data);\n      if (!gpuData) {\n        throw new Error(`no GPU data for output: ${tensorView.data}`);\n      }\n      if (isTemporary) {\n        this.temporaryData.push(gpuData);\n      }\n      if (isPersistent) {\n        let persistentData = this.kernelPersistentData.get(this.currentKernelId!);\n        if (!persistentData) {\n          persistentData = [];\n          this.kernelPersistentData.set(this.currentKernelId!, persistentData);\n        }\n        persistentData.push(gpuData);\n      }\n      outputDatas.push(gpuData);\n    }\n\n    // when there are any zero-sized tensor in the inputs or outputs, we should report error unless all outputs are\n    // zero-sized tensors.\n    if (inputDatas.length !== inputTensorViews.length || outputDatas.length !== outputTensorViews.length) {\n      // if all outputs are zero-sized tensors, there is no need to run the program.\n      if (outputDatas.length === 0) {\n        TRACE_FUNC_END(program.name);\n        return outputTensorViews;\n      }\n      // if some outputs are zero-sized tensors, report an error.\n      //\n      // TODO: so far we don't see any use case that outputs include both zero-sized tensors and non-zero-sized tensors.\n      // If we see such use case, we need to make a change here to support it.\n      throw new Error(\n        `Program ${program.name} has zero-sized tensor(s) in inputs or outputs. This is not supported now.`,\n      );\n    }\n\n    // load uniforms\n    // TODO: add cache for uniform (is it necessary?)\n    //\n    let uniformBufferBinding: GPUBindingResource | undefined;\n    if (programUniforms) {\n      let currentOffset = 0;\n      const offsets: number[] = [];\n\n      programUniforms.forEach((v) => {\n        const data = typeof v.data === 'number' ? [v.data] : v.data;\n        if (data.length === 0) {\n          return;\n        }\n        // https://www.w3.org/TR/WGSL/#alignof\n        const sizeOfElement = v.type === DataType.float16 ? 2 : 4;\n        let sizeOfVecOrMat;\n        let baseAlignment;\n        if (v.type === DataType.float16) {\n          baseAlignment = data.length > 4 ? 16 : data.length > 2 ? 8 : data.length * sizeOfElement;\n          sizeOfVecOrMat = data.length > 4 ? 16 : sizeOfElement * data.length;\n        } else {\n          baseAlignment = data.length <= 2 ? data.length * sizeOfElement : 16;\n          sizeOfVecOrMat = 16;\n        }\n        currentOffset = Math.ceil(currentOffset / baseAlignment) * baseAlignment;\n        offsets.push(currentOffset);\n        // For non-float16 type, when data.length > 4, the uniform variable is of type array<vec4<i32|u32|f32>,N>, where\n        // N = Math.ceil(data.length / 4) and SizeOf(vec4<i32|u32|f32>) = 16. The total byte length is N *\n        // SizeOf(vec4<i32|u32|f32>). For float16 type, when data.length > 4, the uniform variable is of type\n        // array<mat2x4<f16>,N>, where N = Math.ceil(data.length / 8) and SizeOf(mat2x4<f16>) = 16. The total byte\n        // length is N * SizeOf(mat2x4<f16>).\n        const elementPerVecOrMat = v.type === DataType.float16 ? 8 : 4;\n        currentOffset +=\n          data.length > 4 ? Math.ceil(data.length / elementPerVecOrMat) * sizeOfVecOrMat : data.length * sizeOfElement;\n      });\n\n      // Meet alignment of struct here: https://www.w3.org/TR/WGSL/#alignment-and-size. For simplicity, set\n      // maxAlignmentOfField to 16 since the underlying buffer has been rounded up to 16.\n      const maxAlignmentOfField = 16;\n      currentOffset = Math.ceil(currentOffset / maxAlignmentOfField) * maxAlignmentOfField;\n      const arrayBuffer = new ArrayBuffer(currentOffset);\n      programUniforms.forEach((v, i) => {\n        const offset = offsets[i];\n        const data = typeof v.data === 'number' ? [v.data] : v.data;\n        if (v.type === DataType.int32) {\n          new Int32Array(arrayBuffer, offset, data.length).set(data);\n        } else if (v.type === DataType.uint32) {\n          new Uint32Array(arrayBuffer, offset, data.length).set(data);\n        } else if (v.type === DataType.float16) {\n          new Uint16Array(arrayBuffer, offset, data.length).set(data);\n        } else if (v.type === DataType.float) {\n          new Float32Array(arrayBuffer, offset, data.length).set(data);\n        } else {\n          throw new Error(`Unsupported uniform type: ${tensorDataTypeEnumToString(v.type)}`);\n        }\n      });\n\n      const uniformBufferData =\n        // eslint-disable-next-line no-bitwise\n        this.gpuDataManager.create(currentOffset, GPUBufferUsage.COPY_DST | GPUBufferUsage.UNIFORM);\n      this.device.queue.writeBuffer(uniformBufferData.buffer, 0, arrayBuffer, 0, currentOffset);\n      this.gpuDataManager.release(uniformBufferData.id);\n      uniformBufferBinding = { offset: 0, size: currentOffset, buffer: uniformBufferData.buffer };\n    }\n\n    const normalizedDispatchGroup = this.programManager.normalizeDispatchGroupSize(dispatchGroup);\n    const is1DimensionDispatch = normalizedDispatchGroup[1] === 1 && normalizedDispatchGroup[2] === 1;\n    // get program info\n    const key = getProgramInfoUniqueKey(program, inputTensorViews, is1DimensionDispatch);\n    let artifact = this.programManager.getArtifact(key);\n    if (!artifact) {\n      artifact = this.programManager.build(program, normalizedDispatchGroup);\n      this.programManager.setArtifact(key, artifact);\n      LOG_DEBUG('info', () => `[artifact] key: ${key}, programName: ${program.name}`);\n    }\n\n    // validate uniform variables\n    if (programUniforms && artifact.uniformVariablesInfo) {\n      if (programUniforms.length !== artifact.uniformVariablesInfo.length) {\n        throw new Error(\n          `Uniform variables count mismatch: expect ${artifact.uniformVariablesInfo.length}, got ${\n            programUniforms.length\n          } in program \"${artifact.programInfo.name}\".`,\n        );\n      }\n      for (let i = 0; i < programUniforms.length; i++) {\n        const uniform = programUniforms[i];\n        const actualType = uniform.type;\n        const actualLength = typeof uniform.data === 'number' ? 1 : uniform.data.length;\n        const [type, length] = artifact.uniformVariablesInfo[i];\n        if (actualType !== type || actualLength !== length) {\n          throw new Error(\n            `Uniform variable ${i} mismatch: expect type ${type} with size ${length}, got type ${\n              actualType\n            } with size ${actualLength} in program \"${artifact.programInfo.name}\".`,\n          );\n        }\n      }\n    }\n\n    LOG_DEBUG(\n      'info',\n      () =>\n        `[ProgramManager] run \"${program.name}\" (key=${key}) with ${normalizedDispatchGroup[0]}x${\n          normalizedDispatchGroup[1]\n        }x${normalizedDispatchGroup[2]}`,\n    );\n\n    if (this.queryType !== 'none' || this.sessionStatus === 'capturing') {\n      const pendingKernelInfo: PendingKernelInfo = {\n        kernelId: this.currentKernelId!,\n        programName: artifact.programInfo.name,\n        inputTensorViews,\n        outputTensorViews,\n      };\n      this.pendingKernels.push(pendingKernelInfo);\n\n      if (this.sessionStatus === 'capturing') {\n        const sessionPendingKernels = this.capturedPendingKernels.get(this.currentSessionId!);\n        sessionPendingKernels!.push(pendingKernelInfo);\n      }\n    }\n\n    this.programManager.run(artifact, inputDatas, outputDatas, normalizedDispatchGroup, uniformBufferBinding);\n\n    TRACE_FUNC_END(program.name);\n    return outputTensorViews;\n  }\n\n  upload(gpuDataId: number, data: Uint8Array): void {\n    this.gpuDataManager.upload(gpuDataId, data);\n  }\n\n  memcpy(src: number, dst: number): void {\n    this.gpuDataManager.memcpy(src, dst);\n  }\n\n  async download(gpuDataId: number, getTargetBuffer: () => Uint8Array): Promise<void> {\n    // the underlying buffer may be changed after the async function is called. so we use a getter function to make sure\n    // the buffer is up-to-date.\n    await this.gpuDataManager.download(gpuDataId, getTargetBuffer);\n  }\n\n  alloc(size: number): number {\n    return this.gpuDataManager.create(size).id;\n  }\n\n  free(ptr: number): number {\n    return this.gpuDataManager.release(ptr);\n  }\n\n  createKernel(kernelType: string, kernelId: number, attribute: unknown, kernelName: string): void {\n    const op = WEBGPU_OP_RESOLVE_RULES.get(kernelType);\n    if (!op) {\n      throw new Error(`kernel not implemented: ${kernelType}`);\n    }\n\n    const kernelInfo: KernelInfo = {\n      kernelType,\n      kernelName,\n      kernelEntry: op[0],\n      attributes: [op[1], attribute],\n    };\n    this.kernels.set(kernelId, kernelInfo);\n  }\n\n  releaseKernel(kernelId: number): void {\n    const persistentData = this.kernelPersistentData.get(kernelId);\n    if (persistentData) {\n      for (const data of persistentData) {\n        this.gpuDataManager.release(data.id);\n      }\n      this.kernelPersistentData.delete(kernelId);\n    }\n\n    this.kernelCustomData.delete(kernelId);\n    this.kernels.delete(kernelId);\n  }\n\n  computeKernel(kernelId: number, context: ComputeContext, errors: Array<Promise<string | null>>): number {\n    const kernel = this.kernels.get(kernelId);\n    if (!kernel) {\n      throw new Error(`kernel not created: ${kernelId}`);\n    }\n    const kernelType = kernel.kernelType;\n    const kernelName = kernel.kernelName;\n    const kernelEntry = kernel.kernelEntry;\n    const attributes = kernel.attributes;\n    if (this.currentKernelId !== null) {\n      throw new Error(`kernel \"[${kernelType}] ${kernelName}\" is not allowed to be called recursively`);\n    }\n    this.currentKernelId = kernelId;\n\n    // parse attributes if necessary\n    if (attributes[0]) {\n      attributes[1] = attributes[0](attributes[1]);\n      attributes[0] = undefined;\n    }\n\n    LOG_DEBUG('info', () => `[WebGPU] Start to run kernel \"[${kernelType}] ${kernelName}\"...`);\n\n    const useErrorScope = this.env.debug;\n\n    this.temporaryData = [];\n    try {\n      if (useErrorScope) {\n        this.device.pushErrorScope('validation');\n      }\n\n      kernelEntry(context, attributes[1]);\n      return 0; // ORT_OK\n    } catch (e) {\n      errors.push(Promise.resolve(`[WebGPU] Kernel \"[${kernelType}] ${kernelName}\" failed. ${e}`));\n      return 1; // ORT_FAIL\n    } finally {\n      if (useErrorScope) {\n        errors.push(\n          this.device\n            .popErrorScope()\n            .then((err) =>\n              err ? `GPU validation error for kernel \"[${kernelType}] ${kernelName}\": ${err.message}` : null,\n            ),\n        );\n      }\n\n      for (const data of this.temporaryData) {\n        this.gpuDataManager.release(data.id);\n      }\n      this.temporaryData = [];\n      this.currentKernelId = null;\n    }\n  }\n\n  // #region external buffer\n  registerBuffer(sessionId: number, index: number, buffer: GPUBuffer, size: number): number {\n    let sessionInputOutputMapping = this.sessionExternalDataMapping.get(sessionId);\n    if (!sessionInputOutputMapping) {\n      sessionInputOutputMapping = new Map();\n      this.sessionExternalDataMapping.set(sessionId, sessionInputOutputMapping);\n    }\n\n    // the buffer may be user created, or managed by GPU data manager.\n    // The GPU data manager will not manage these buffers. we register them as external buffers.\n    //\n    // The map `sessionInputOutputMapping` is used to store the data ID and buffer for each input/output. Once a\n    // specific input/output is registered, the data ID will not change.\n    const previousBuffer = sessionInputOutputMapping.get(index);\n    const id = this.gpuDataManager.registerExternalBuffer(buffer, size, previousBuffer);\n    sessionInputOutputMapping.set(index, [id, buffer]);\n    return id;\n  }\n  unregisterBuffers(sessionId: number): void {\n    const sessionInputOutputMapping = this.sessionExternalDataMapping.get(sessionId);\n    if (sessionInputOutputMapping) {\n      sessionInputOutputMapping.forEach((bufferInfo) => this.gpuDataManager.unregisterExternalBuffer(bufferInfo[0]));\n      this.sessionExternalDataMapping.delete(sessionId);\n    }\n  }\n  getBuffer(gpuDataId: number): GPUBuffer {\n    const gpuData = this.gpuDataManager.get(gpuDataId);\n    if (!gpuData) {\n      throw new Error(`no GPU data for buffer: ${gpuDataId}`);\n    }\n    return gpuData.buffer;\n  }\n  createDownloader(\n    gpuBuffer: GPUBuffer,\n    size: number,\n    type: Tensor.GpuBufferDataTypes,\n  ): () => Promise<Tensor.DataType> {\n    return async () => {\n      const data = await downloadGpuData(this, gpuBuffer, size);\n      return createView(data.buffer, type);\n    };\n  }\n  // #endregion\n  writeTimestamp(index: number): void {\n    if (this.queryType !== 'inside-passes') {\n      return;\n    }\n\n    // eslint-disable-next-line @typescript-eslint/no-explicit-any\n    (this.computePassEncoder as any).writeTimestamp(this.querySet, index);\n  }\n  setQueryType(): void {\n    this.queryType = 'none';\n    if (\n      this.env.webgpu.profiling?.mode === 'default' ||\n      (typeof this.env.trace === 'undefined' ? this.env.wasm.trace : this.env.trace)\n    ) {\n      if (this.device.features.has('chromium-experimental-timestamp-query-inside-passes')) {\n        this.queryType = 'inside-passes';\n      } else if (this.device.features.has('timestamp-query')) {\n        this.queryType = 'at-passes';\n      }\n\n      if (this.queryType !== 'none' && typeof this.querySet === 'undefined') {\n        this.querySet = this.device.createQuerySet({\n          type: 'timestamp',\n          count: this.maxDispatchNumber * 2,\n        });\n        this.queryResolveBuffer = this.device.createBuffer(\n          // eslint-disable-next-line no-bitwise\n          { size: this.maxDispatchNumber * 2 * 8, usage: GPUBufferUsage.COPY_SRC | GPUBufferUsage.QUERY_RESOLVE },\n        );\n      }\n    }\n  }\n\n  captureBegin(): void {\n    LOG_DEBUG('info', 'captureBegin');\n    if (!this.capturedCommandList.get(this.currentSessionId!)) {\n      this.capturedCommandList.set(this.currentSessionId!, []);\n    }\n    if (!this.capturedPendingKernels.get(this.currentSessionId!)) {\n      this.capturedPendingKernels.set(this.currentSessionId!, []);\n    }\n    // flush the left commands before we change the status.\n    this.flush();\n    this.sessionStatus = 'capturing';\n  }\n  captureEnd(): void {\n    LOG_DEBUG('info', 'captureEnd');\n    // flush the left commands before we change the status.\n    this.flush();\n    this.sessionStatus = 'default';\n  }\n  replay(): void {\n    LOG_DEBUG('info', 'replay');\n    this.sessionStatus = 'replaying';\n    const sessionCommandList = this.capturedCommandList.get(this.currentSessionId!);\n    const sessionPendingKernels = this.capturedPendingKernels.get(this.currentSessionId!);\n    const length = sessionCommandList!.length;\n    this.pendingKernels = [];\n    for (let i = 0; i < length; i++) {\n      const computePassEncoder = this.getComputePassEncoder();\n      const command = sessionCommandList![i];\n      this.writeTimestamp(this.pendingDispatchNumber * 2);\n      computePassEncoder.setPipeline(command.computePipeline);\n      computePassEncoder.setBindGroup(0, command.bindGroup);\n      computePassEncoder.dispatchWorkgroups(...command.dispatchGroup);\n      this.writeTimestamp(this.pendingDispatchNumber * 2 + 1);\n      this.pendingDispatchNumber++;\n      if (this.queryType !== 'none') {\n        this.pendingKernels.push(sessionPendingKernels![i]);\n      }\n      if (this.pendingDispatchNumber >= this.maxDispatchNumber || this.queryType === 'at-passes') {\n        this.endComputePass();\n      }\n      if (this.pendingDispatchNumber >= this.maxDispatchNumber) {\n        this.flush();\n      }\n    }\n    // flush the left commands before we change the status.\n    this.flush();\n    this.sessionStatus = 'default';\n  }\n\n  onCreateSession(): void {\n    this.gpuDataManager.onCreateSession();\n  }\n\n  onReleaseSession(sessionId: number): void {\n    this.unregisterBuffers(sessionId);\n    if (this.capturedCommandList.has(sessionId)) {\n      this.capturedCommandList.delete(sessionId);\n    }\n    if (this.capturedPendingKernels.has(sessionId)) {\n      this.capturedPendingKernels.delete(sessionId);\n    }\n    this.gpuDataManager.onReleaseSession(sessionId);\n  }\n\n  onRunStart(sessionId: number): void {\n    this.currentSessionId = sessionId;\n    this.setQueryType();\n  }\n}\n","// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport type { Env } from 'onnxruntime-common';\n\nimport { calculateTensorSizeInBytes, DataType } from '../wasm-common';\n\nimport type { OrtWasmModule } from '../wasm-types';\n\nimport type { WebGpuBackend } from './backend-webgpu';\nimport { LOG_DEBUG } from './log';\nimport type { TensorView } from './tensor-view';\nimport { ShapeUtil } from './util';\nimport type { AdapterInfo, ComputeContext, ComputeContextInputsOutputsMapping, ProgramInfo } from './webgpu/types';\nimport { WebNNBackend } from './backend-webnn';\n\n/* eslint-disable no-bitwise */\n\nclass TensorViewImpl implements TensorView {\n  constructor(\n    private module: OrtWasmModule,\n    public readonly dataType: number,\n    public readonly data: number,\n    public readonly dims: readonly number[],\n  ) {}\n\n  getFloat32Array(): Float32Array {\n    if (this.dataType !== DataType.float) {\n      throw new Error('Invalid data type');\n    }\n    const elementCount = ShapeUtil.size(this.dims);\n    return elementCount === 0\n      ? new Float32Array()\n      : new Float32Array(this.module.HEAP8.buffer, this.data, elementCount);\n  }\n\n  getBigInt64Array(): BigInt64Array {\n    if (this.dataType !== DataType.int64) {\n      throw new Error('Invalid data type');\n    }\n    const elementCount = ShapeUtil.size(this.dims);\n    return elementCount === 0\n      ? new BigInt64Array()\n      : new BigInt64Array(this.module.HEAP8.buffer, this.data, elementCount);\n  }\n\n  getInt32Array(): Int32Array {\n    if (this.dataType !== DataType.int32) {\n      throw new Error('Invalid data type');\n    }\n    const elementCount = ShapeUtil.size(this.dims);\n    return elementCount === 0 ? new Int32Array() : new Int32Array(this.module.HEAP8.buffer, this.data, elementCount);\n  }\n\n  getUint16Array(): Uint16Array {\n    if (this.dataType !== DataType.float16 && this.dataType !== DataType.uint16) {\n      throw new Error('Invalid data type');\n    }\n    const elementCount = ShapeUtil.size(this.dims);\n    return elementCount === 0 ? new Uint16Array() : new Uint16Array(this.module.HEAP8.buffer, this.data, elementCount);\n  }\n\n  reshape(newDims: readonly number[]): TensorView {\n    if (ShapeUtil.size(newDims) !== ShapeUtil.size(this.dims)) {\n      throw new Error('Invalid new shape');\n    }\n    return new TensorViewImpl(this.module, this.dataType, this.data, newDims);\n  }\n}\n\nclass ComputeContextImpl implements ComputeContext {\n  readonly adapterInfo: AdapterInfo;\n  readonly opKernelContext: number;\n  readonly inputs: readonly TensorView[];\n  readonly outputCount: number;\n  get kernelCustomData(): { [key: string]: unknown } {\n    return this.backend.currentKernelCustomData;\n  }\n  get customDataBuffer(): Uint8Array {\n    return this.module.HEAPU8.subarray(this.customDataOffset, this.customDataOffset + this.customDataSize);\n  }\n  private customDataOffset = 0;\n  private customDataSize = 0;\n  constructor(\n    private module: OrtWasmModule,\n    private backend: WebGpuBackend,\n    contextDataOffset: number,\n  ) {\n    this.adapterInfo = backend.adapterInfo;\n\n    // extract context data\n    const ptrSize = module.PTR_SIZE;\n    let dataIndex = contextDataOffset / module.PTR_SIZE;\n    const type = ptrSize === 4 ? 'i32' : 'i64';\n    this.opKernelContext = Number(module.getValue(ptrSize * dataIndex++, type));\n    const inputCount = Number(module.getValue(ptrSize * dataIndex++, type));\n    this.outputCount = Number(module.getValue(ptrSize * dataIndex++, type));\n    this.customDataOffset = Number(module.getValue(ptrSize * dataIndex++, '*'));\n    this.customDataSize = Number(module.getValue(ptrSize * dataIndex++, type));\n\n    const inputs: TensorView[] = [];\n    for (let i = 0; i < inputCount; i++) {\n      const dataType = Number(module.getValue(ptrSize * dataIndex++, type));\n      const data = Number(module.getValue(ptrSize * dataIndex++, '*'));\n      const dim = Number(module.getValue(ptrSize * dataIndex++, type));\n      const dims: number[] = [];\n      for (let d = 0; d < dim; d++) {\n        dims.push(Number(module.getValue(ptrSize * dataIndex++, type)));\n      }\n      inputs.push(new TensorViewImpl(module, dataType, data, dims));\n    }\n    this.inputs = inputs;\n  }\n\n  compute(program: ProgramInfo, inputsOutputsMapping?: ComputeContextInputsOutputsMapping): TensorView[] {\n    // prepare inputs. inputs should always be valid data.\n    const mappedInputs =\n      inputsOutputsMapping?.inputs?.map((i) => (typeof i === 'number' ? this.inputs[i] : i)) ?? this.inputs;\n    // prepare outputs.\n    const outputIndices = inputsOutputsMapping?.outputs ?? [];\n    const createKernelOutput = (index: number, dataType: number, dims: readonly number[]): TensorView =>\n      new TensorViewImpl(this.module, dataType, this.output(index, dims), dims);\n    const createTemporaryOutput = (dataType: number, dims: readonly number[]): TensorView => {\n      const bufferSize = calculateTensorSizeInBytes(dataType, dims);\n      if (!bufferSize) {\n        throw new Error(`Unsupported data type: ${dataType}`);\n      }\n      const gpuDataId = bufferSize > 0 ? this.backend.gpuDataManager.create(bufferSize).id : 0;\n      return new TensorViewImpl(this.module, dataType, gpuDataId, dims);\n    };\n    return this.backend.run(\n      program,\n      mappedInputs,\n      outputIndices,\n      createKernelOutput,\n      createTemporaryOutput,\n      this.outputCount,\n    );\n  }\n\n  output(index: number, dims: readonly number[]): number {\n    const stack = this.module.stackSave();\n    try {\n      const ptrSize = this.module.PTR_SIZE;\n      const type = ptrSize === 4 ? 'i32' : 'i64';\n      const data = this.module.stackAlloc((1 + dims.length) * ptrSize /* sizeof(size_t) */);\n      this.module.setValue(data, dims.length, type);\n      for (let i = 0; i < dims.length; i++) {\n        this.module.setValue(data + ptrSize * (i + 1), dims[i], type);\n      }\n      return this.module._JsepOutput!(this.opKernelContext, index, data);\n    } catch (e) {\n      throw new Error(\n        `Failed to generate kernel's output[${index}] with dims [${dims}]. ` +\n          'If you are running with pre-allocated output, please make sure the output type/dims are correct. ' +\n          `Error: ${e}`,\n      );\n    } finally {\n      this.module.stackRestore(stack);\n    }\n  }\n}\n\n/**\n * Initialize JSEP with WebGPU backend.\n *\n * This function will be called after the WebAssembly module is loaded and initialized (\"_OrtInit\" is called), once for\n * each of the following EPs if they are specified:\n * - \"webgpu\"\n * - \"webnn\"\n *\n * For WebGPU, this function expects:\n *  - WebGPU is enabled in build (BUILD_DEFS.DISABLE_JSEP === false).\n *  - WebGPU is available in current environment. (a valid GPUAdapter is passed in)\n *\n * For WebNN, this function expects:\n * - WebNN is enabled in build (BUILD_DEFS.DISABLE_JSEP === false).\n * - WebNN is available in current environment. (navigator.ml is not undefined)\n *\n * If the WebAssembly module is not built with JSEP support, this function will throw an error. This will invalidate\n * 'webgpu'/'webnn' backend.\n *\n * @param name - the name of the EP, either \"webgpu\" or \"webnn\"\n * @param module - the ORT WebAssembly module\n * @param env - the ORT environment variable (ort.env)\n * @param gpuAdapter - the pre-created GPU adapter\n */\nexport const init = async (\n  name: 'webgpu' | 'webnn',\n  module: OrtWasmModule,\n  env: Env,\n  gpuAdapter?: GPUAdapter,\n): Promise<void> => {\n  const jsepInit = module.jsepInit;\n  if (!jsepInit) {\n    throw new Error('Failed to initialize JSEP. The WebAssembly module is not built with JSEP support.');\n  }\n\n  if (name === 'webgpu') {\n    if (!BUILD_DEFS.USE_WEBGPU_EP) {\n      // eslint-disable-next-line @typescript-eslint/no-require-imports, @typescript-eslint/no-var-requires\n      const webGpuBackendImpl = require('./backend-webgpu').WebGpuBackend;\n      const backend = new webGpuBackendImpl();\n      await backend.initialize(env, gpuAdapter!);\n\n      jsepInit('webgpu', [\n        // backend\n        backend,\n\n        // jsepAlloc()\n        (size: number) => backend.alloc(Number(size)),\n\n        // jsepFree()\n        (ptr: number) => backend.free(ptr),\n\n        // jsepCopy(src, dst, size, isSourceGpu)\n        (src: number, dst: number, size: number, isSourceGpu = false) => {\n          if (isSourceGpu) {\n            LOG_DEBUG(\n              'verbose',\n              () => `[WebGPU] jsepCopyGpuToGpu: src=${Number(src)}, dst=${Number(dst)}, size=${Number(size)}`,\n            );\n            backend.memcpy(Number(src), Number(dst));\n          } else {\n            LOG_DEBUG(\n              'verbose',\n              () =>\n                `[WebGPU] jsepCopyCpuToGpu: dataOffset=${Number(src)}, gpuDataId=${Number(dst)}, size=${Number(size)}`,\n            );\n            const data = module.HEAPU8.subarray(Number(src >>> 0), Number(src >>> 0) + Number(size));\n            backend.upload(Number(dst), data);\n          }\n        },\n\n        // jsepCopyAsync(src, dst, size)\n        async (gpuDataId: number, dataOffset: number, size: number): Promise<void> => {\n          LOG_DEBUG(\n            'verbose',\n            () => `[WebGPU] jsepCopyGpuToCpu: gpuDataId=${gpuDataId}, dataOffset=${dataOffset}, size=${size}`,\n          );\n\n          await backend.download(Number(gpuDataId), () =>\n            module.HEAPU8.subarray(Number(dataOffset) >>> 0, Number(dataOffset + size) >>> 0),\n          );\n        },\n\n        // jsepCreateKernel\n        (kernelType: string, kernelId: number, attribute: unknown) =>\n          backend.createKernel(\n            kernelType,\n            Number(kernelId),\n            attribute,\n            module.UTF8ToString(module._JsepGetNodeName!(Number(kernelId))),\n          ),\n\n        // jsepReleaseKernel\n        (kernel: number) => backend.releaseKernel(kernel),\n\n        // jsepRun\n        (kernel: number, contextDataOffset: number, sessionHandle: number, errors: Array<Promise<string | null>>) => {\n          LOG_DEBUG(\n            'verbose',\n            () =>\n              `[WebGPU] jsepRun: sessionHandle=${sessionHandle}, kernel=${kernel}, contextDataOffset=${contextDataOffset}`,\n          );\n          const context = new ComputeContextImpl(module, backend, Number(contextDataOffset));\n          return backend.computeKernel(Number(kernel), context, errors);\n        },\n        // jsepCaptureBegin\n        () => backend.captureBegin(),\n        // jsepCaptureEnd\n        () => backend.captureEnd(),\n        // jsepReplay\n        () => backend.replay(),\n      ]);\n    }\n  } else {\n    const backend = new WebNNBackend(env);\n    jsepInit('webnn', [\n      backend,\n      // jsepReserveTensorId\n      () => backend.reserveTensorId(),\n      // jsepReleaseTensorId,\n      (tensorId: number) => backend.releaseTensorId(tensorId),\n      // jsepEnsureTensor\n      async (sessionId: number | undefined, tensorId: number, onnxDataType: number, shape: number[], copyOld) =>\n        backend.ensureTensor(sessionId, tensorId, onnxDataType, shape, copyOld),\n      // jsepUploadTensor\n      (tensorId: number, data: Uint8Array) => {\n        backend.uploadTensor(tensorId, data);\n      },\n      // jsepDownloadTensor\n      async (tensorId: number, dstBuffer: ArrayBufferView | ArrayBuffer) => backend.downloadTensor(tensorId, dstBuffer),\n    ]);\n  }\n};\n","// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\n// WebNN API currently does not have a TypeScript definition file. This file is a workaround with types generated from\n// WebNN API specification.\n// https://github.com/webmachinelearning/webnn/issues/677\n/// <reference path=\"jsep/webnn/webnn.d.ts\" />\n\nimport { Env, InferenceSession, Tensor } from 'onnxruntime-common';\n\nimport {\n  SerializableInternalBuffer,\n  SerializableSessionMetadata,\n  SerializableTensorMetadata,\n  TensorMetadata,\n} from './proxy-messages';\nimport { setRunOptions } from './run-options';\nimport { setSessionOptions } from './session-options';\nimport {\n  calculateTensorSizeInBytes,\n  dataLocationStringToEnum,\n  isGpuBufferSupportedType,\n  isMLTensorSupportedType,\n  logLevelStringToEnum,\n  tensorDataTypeEnumToString,\n  tensorDataTypeStringToEnum,\n  tensorTypeToTypedArrayConstructor,\n} from './wasm-common';\nimport { getInstance } from './wasm-factory';\nimport { allocWasmString, checkLastError } from './wasm-utils';\nimport { loadFile } from './wasm-utils-load-file';\n\n// #region Initializations\n\n/**\n * There are 4 different \"initialization\" steps for ORT. They happen in different places and different time.\n *\n * 1. JavaScript initialization for onnxruntime-common and onnxruntime-web.\n *    This is the first initialization step. In this step, onnxruntime-web calls onnxruntime-common's registerBackend()\n * function multiple times to register all the available backends. The backend registration is very fast. It only\n * registers the backend name with the uninitialized backend object. No heavy initialization is done in this step.\n *    Refer to web/lib/index.ts for the backend registration.\n *\n * 2. WebAssembly artifact initialization.\n *    This happens when any registered wasm backend is used for the first time (ie. `ort.InferenceSession.create()` is\n * called). In this step, onnxruntime-web does the followings:\n *     - create a proxy worker and make sure the proxy worker is ready to receive messages, if proxy is enabled.\n *     - perform feature detection, locate correct WebAssembly artifact path and call the Emscripten generated\n * JavaScript code to initialize the WebAssembly runtime.\n *         - if proxy is enabled, this step happens in the proxy worker using message 'init-wasm'.\n *         - downloading the 'ort-wasm{...}.wasm' file is done in this step.\n *         - if multi-thread is enabled, one or more webworker will be created to initialize the PThread threadpool.\n *\n * 3. ORT environment initialization.\n *    This happens after step 2. In this step, onnxruntime-web performs ONNX Runtime environment initialization.\n * Function `_OrtInit()` is called in this step.\n *     - if proxy is enabled, this step happens in the proxy worker using message 'init-ort'.\n *     - logging level (ort.env.logLevel) and thread number (ort.env.wasm.numThreads) are set in this step.\n *\n * 4. Session initialization.\n *    This happens when `ort.InferenceSession.create()` is called. Unlike the first 3 steps (they only called once),\n * this step will be done for each session. In this step, onnxruntime-web does the followings:\n *    If the parameter is a URL:\n *    - download the model data from the URL.\n *    - copy the model data to the WASM heap. (proxy: 'copy-from')\n *    - dereference the model buffer. This step allows the original ArrayBuffer to be garbage collected.\n *    - call `_OrtCreateSession()` to create the session. (proxy: 'create')\n *\n *    If the parameter is a Uint8Array object:\n *    - copy the model data to the WASM heap. (proxy: 'copy-from')\n *    - call `_OrtCreateSession()` to create the session. (proxy: 'create')\n *\n *\n */\n\n/**\n * initialize ORT environment.\n *\n * @param numThreads SetGlobalIntraOpNumThreads(numThreads)\n * @param loggingLevel CreateEnv(static_cast<OrtLoggingLevel>(logging_level))\n */\nconst initOrt = (numThreads: number, loggingLevel: number): void => {\n  const errorCode = getInstance()._OrtInit(numThreads, loggingLevel);\n  if (errorCode !== 0) {\n    checkLastError(\"Can't initialize onnxruntime.\");\n  }\n};\n\n/**\n * initialize runtime environment.\n * @param env passed in the environment config object.\n */\nexport const initRuntime = async (env: Env): Promise<void> => {\n  // init ORT\n  initOrt(env.wasm.numThreads!, logLevelStringToEnum(env.logLevel));\n};\n\n/**\n * perform EP specific initialization.\n *\n * @param env\n * @param epName\n */\nexport const initEp = async (env: Env, epName: string): Promise<void> => {\n  // initialize ASYNCIFY support\n  getInstance().asyncInit?.();\n\n  if (epName === 'webgpu' && BUILD_DEFS.USE_WEBGPU_EP) {\n    getInstance().webgpuInit!((device) => {\n      env.webgpu.device = device;\n    });\n  }\n\n  if (!BUILD_DEFS.DISABLE_JSEP) {\n    // eslint-disable-next-line @typescript-eslint/no-require-imports, @typescript-eslint/no-var-requires\n    const initJsep = require('./jsep/init').init;\n\n    if (epName === 'webgpu' && !BUILD_DEFS.USE_WEBGPU_EP) {\n      // perform WebGPU availability check\n      if (typeof navigator === 'undefined' || !navigator.gpu) {\n        throw new Error('WebGPU is not supported in current environment');\n      }\n\n      let adapter = env.webgpu.adapter as GPUAdapter | null;\n      if (!adapter) {\n        // if adapter is not set, request a new adapter.\n        const powerPreference = env.webgpu.powerPreference;\n        if (\n          powerPreference !== undefined &&\n          powerPreference !== 'low-power' &&\n          powerPreference !== 'high-performance'\n        ) {\n          throw new Error(`Invalid powerPreference setting: \"${powerPreference}\"`);\n        }\n        const forceFallbackAdapter = env.webgpu.forceFallbackAdapter;\n        if (forceFallbackAdapter !== undefined && typeof forceFallbackAdapter !== 'boolean') {\n          throw new Error(`Invalid forceFallbackAdapter setting: \"${forceFallbackAdapter}\"`);\n        }\n        adapter = await navigator.gpu.requestAdapter({ powerPreference, forceFallbackAdapter });\n        if (!adapter) {\n          throw new Error(\n            'Failed to get GPU adapter. ' +\n              'You may need to enable flag \"--enable-unsafe-webgpu\" if you are using Chrome.',\n          );\n        }\n      } else {\n        // if adapter is set, validate it.\n        if (\n          typeof adapter.limits !== 'object' ||\n          typeof adapter.features !== 'object' ||\n          typeof adapter.requestDevice !== 'function'\n        ) {\n          throw new Error('Invalid GPU adapter set in `env.webgpu.adapter`. It must be a GPUAdapter object.');\n        }\n      }\n\n      await initJsep('webgpu', getInstance(), env, adapter);\n    }\n    if (epName === 'webnn') {\n      // perform WebNN availability check\n      if (typeof navigator === 'undefined' || !(navigator as unknown as { ml: unknown }).ml) {\n        throw new Error('WebNN is not supported in current environment');\n      }\n\n      await initJsep('webnn', getInstance(), env);\n    }\n  }\n};\n\n// #endregion Initializations\n\n/**\n * valid data locations for input/output tensors.\n */\ntype SupportedTensorDataLocationForInputOutput = 'cpu' | 'cpu-pinned' | 'gpu-buffer' | 'ml-tensor';\n\ntype IOBindingState = {\n  /**\n   * the handle of IO binding.\n   */\n  readonly handle: number;\n\n  /**\n   * the preferred location for each output tensor.\n   *\n   * value is one of 'cpu', 'cpu-pinned', 'gpu-buffer', 'ml-tensor'.\n   */\n  readonly outputPreferredLocations: readonly SupportedTensorDataLocationForInputOutput[];\n\n  /**\n   * enum value of the preferred location for each output tensor.\n   */\n  readonly outputPreferredLocationsEncoded: readonly number[];\n};\n\n/**\n *  tuple elements are: InferenceSession ID; inputNamesUTF8Encoded; outputNamesUTF8Encoded; bindingState\n */\ntype SessionMetadata = [\n  inferenceSessionId: number,\n  inputNamesUTF8Encoded: number[],\n  outputNamesUTF8Encoded: number[],\n  bindingState: IOBindingState | null,\n  enableGraphCapture: boolean,\n  inputOutputBound: boolean,\n];\n\nconst activeSessions = new Map<number, SessionMetadata>();\n\n/**\n * get the input/output count of the session.\n * @param sessionHandle the handle representing the session. should be non-zero.\n * @returns a tuple including 2 numbers, representing the input count and output count.\n */\nconst getSessionInputOutputCount = (sessionHandle: number): [number, number] => {\n  const wasm = getInstance();\n  const stack = wasm.stackSave();\n  try {\n    const ptrSize = wasm.PTR_SIZE;\n    const dataOffset = wasm.stackAlloc(2 * ptrSize);\n    const errorCode = wasm._OrtGetInputOutputCount(sessionHandle, dataOffset, dataOffset + ptrSize);\n    if (errorCode !== 0) {\n      checkLastError(\"Can't get session input/output count.\");\n    }\n    const type = ptrSize === 4 ? 'i32' : 'i64';\n    return [Number(wasm.getValue(dataOffset, type)), Number(wasm.getValue(dataOffset + ptrSize, type))];\n  } finally {\n    wasm.stackRestore(stack);\n  }\n};\n\n/**\n * allocate the memory and memcpy the external buffer.\n *\n * @param model - the external buffer containing the model data. Must not be the same buffer as the WASM heap.\n * @returns a 2-elements tuple - the pointer and size of the allocated buffer\n */\nexport const copyFromExternalBuffer = (model: Uint8Array): [number, number] => {\n  const wasm = getInstance();\n  const modelDataOffset = wasm._malloc(model.byteLength);\n  if (modelDataOffset === 0) {\n    throw new Error(`Can't create a session. failed to allocate a buffer of size ${model.byteLength}.`);\n  }\n  wasm.HEAPU8.set(model, modelDataOffset);\n  return [modelDataOffset, model.byteLength];\n};\n\n/**\n * create an inference session from a model data buffer.\n *\n * @param modelData - either a Uint8Array object representing the model data, or a 2-elements tuple containing the\n *     pointer and size of the model data buffer.\n * @param options an optional session options object.\n * @returns a 3-elements tuple containing [session handle, input names, output names]\n */\nexport const createSession = async (\n  modelData: Uint8Array | SerializableInternalBuffer,\n  options?: InferenceSession.SessionOptions,\n): Promise<SerializableSessionMetadata> => {\n  let modelDataOffset: number, modelDataLength: number;\n  const wasm = getInstance();\n\n  if (Array.isArray(modelData)) {\n    // if model data is an array, it must be a 2-elements tuple containing the pointer and size of the model data\n    [modelDataOffset, modelDataLength] = modelData;\n  } else if (modelData.buffer === wasm.HEAPU8.buffer) {\n    // if model data uses the same buffer as the WASM heap, we don't need to copy it.\n    [modelDataOffset, modelDataLength] = [modelData.byteOffset, modelData.byteLength];\n  } else {\n    // otherwise, copy the model data to the WASM heap.\n    [modelDataOffset, modelDataLength] = copyFromExternalBuffer(modelData);\n  }\n\n  let sessionHandle = 0;\n  let sessionOptionsHandle = 0;\n  let ioBindingHandle = 0;\n  let allocs: number[] = [];\n  const inputNamesUTF8Encoded = [];\n  const outputNamesUTF8Encoded = [];\n\n  try {\n    [sessionOptionsHandle, allocs] = await setSessionOptions(options);\n\n    if (options?.externalData && wasm.mountExternalData) {\n      const loadingPromises = [];\n      for (const file of options.externalData) {\n        const path = typeof file === 'string' ? file : file.path;\n        loadingPromises.push(\n          loadFile(typeof file === 'string' ? file : file.data).then((data) => {\n            wasm.mountExternalData(path, data);\n          }),\n        );\n      }\n\n      // wait for all external data files to be loaded\n      await Promise.all(loadingPromises);\n    }\n\n    for (const provider of options?.executionProviders ?? []) {\n      const providerName = typeof provider === 'string' ? provider : provider.name;\n      if (providerName === 'webnn') {\n        wasm.shouldTransferToMLTensor = false;\n        if (typeof provider !== 'string') {\n          const webnnOptions = provider as InferenceSession.WebNNExecutionProviderOption;\n          const context = (webnnOptions as InferenceSession.WebNNOptionsWithMLContext)?.context;\n          const gpuDevice = (webnnOptions as InferenceSession.WebNNOptionsWebGpu)?.gpuDevice;\n          const deviceType = (webnnOptions as InferenceSession.WebNNContextOptions)?.deviceType;\n          const powerPreference = (webnnOptions as InferenceSession.WebNNContextOptions)?.powerPreference;\n          if (context) {\n            wasm.currentContext = context as MLContext;\n          } else if (gpuDevice) {\n            wasm.currentContext = await wasm.jsepCreateMLContext!(gpuDevice);\n          } else {\n            wasm.currentContext = await wasm.jsepCreateMLContext!({ deviceType, powerPreference });\n          }\n        } else {\n          wasm.currentContext = await wasm.jsepCreateMLContext!();\n        }\n        break;\n      }\n    }\n\n    sessionHandle = await wasm._OrtCreateSession(modelDataOffset, modelDataLength, sessionOptionsHandle);\n    wasm.webgpuOnCreateSession?.(sessionHandle);\n    if (sessionHandle === 0) {\n      checkLastError(\"Can't create a session.\");\n    }\n\n    wasm.jsepOnCreateSession?.();\n\n    // clear current MLContext after session creation\n    if (wasm.currentContext) {\n      wasm.jsepRegisterMLContext!(sessionHandle, wasm.currentContext);\n      wasm.currentContext = undefined;\n      wasm.shouldTransferToMLTensor = true;\n    }\n\n    const [inputCount, outputCount] = getSessionInputOutputCount(sessionHandle);\n\n    const enableGraphCapture = !!options?.enableGraphCapture;\n\n    const inputNames = [];\n    const outputNames = [];\n    const outputPreferredLocations: SupportedTensorDataLocationForInputOutput[] = [];\n    for (let i = 0; i < inputCount; i++) {\n      const name = wasm._OrtGetInputName(sessionHandle, i);\n      if (name === 0) {\n        checkLastError(\"Can't get an input name.\");\n      }\n      inputNamesUTF8Encoded.push(name);\n      inputNames.push(wasm.UTF8ToString(name));\n    }\n    for (let i = 0; i < outputCount; i++) {\n      const name = wasm._OrtGetOutputName(sessionHandle, i);\n      if (name === 0) {\n        checkLastError(\"Can't get an output name.\");\n      }\n      outputNamesUTF8Encoded.push(name);\n      const nameString = wasm.UTF8ToString(name);\n      outputNames.push(nameString);\n\n      if (!BUILD_DEFS.DISABLE_JSEP) {\n        if (enableGraphCapture && options?.preferredOutputLocation === undefined) {\n          outputPreferredLocations.push('gpu-buffer');\n          continue;\n        }\n        const location =\n          typeof options?.preferredOutputLocation === 'string'\n            ? options.preferredOutputLocation\n            : (options?.preferredOutputLocation?.[nameString] ?? 'cpu');\n        if (location !== 'cpu' && location !== 'cpu-pinned' && location !== 'gpu-buffer' && location !== 'ml-tensor') {\n          throw new Error(`Not supported preferred output location: ${location}.`);\n        }\n        if (enableGraphCapture && location !== 'gpu-buffer') {\n          throw new Error(\n            `Not supported preferred output location: ${location}. Only 'gpu-buffer' location is supported when enableGraphCapture is true.`,\n          );\n        }\n        outputPreferredLocations.push(location);\n      }\n    }\n\n    // use IO binding only when at least one output is preferred to be on GPU.\n    let bindingState: IOBindingState | null = null;\n    if (!BUILD_DEFS.DISABLE_JSEP && outputPreferredLocations.some((l) => l === 'gpu-buffer' || l === 'ml-tensor')) {\n      ioBindingHandle = wasm._OrtCreateBinding(sessionHandle);\n      if (ioBindingHandle === 0) {\n        checkLastError(\"Can't create IO binding.\");\n      }\n\n      bindingState = {\n        handle: ioBindingHandle,\n        outputPreferredLocations,\n        outputPreferredLocationsEncoded: outputPreferredLocations.map((l) => dataLocationStringToEnum(l)),\n      };\n    }\n\n    activeSessions.set(sessionHandle, [\n      sessionHandle,\n      inputNamesUTF8Encoded,\n      outputNamesUTF8Encoded,\n      bindingState,\n      enableGraphCapture,\n      false,\n    ]);\n    return [sessionHandle, inputNames, outputNames];\n  } catch (e) {\n    inputNamesUTF8Encoded.forEach((buf) => wasm._OrtFree(buf));\n    outputNamesUTF8Encoded.forEach((buf) => wasm._OrtFree(buf));\n\n    if (ioBindingHandle !== 0) {\n      if (wasm._OrtReleaseBinding(ioBindingHandle) !== 0) {\n        checkLastError(\"Can't release IO binding.\");\n      }\n    }\n\n    if (sessionHandle !== 0) {\n      if (wasm._OrtReleaseSession(sessionHandle) !== 0) {\n        checkLastError(\"Can't release session.\");\n      }\n    }\n    throw e;\n  } finally {\n    wasm._free(modelDataOffset);\n    if (sessionOptionsHandle !== 0) {\n      if (wasm._OrtReleaseSessionOptions(sessionOptionsHandle) !== 0) {\n        checkLastError(\"Can't release session options.\");\n      }\n    }\n    allocs.forEach((alloc) => wasm._free(alloc));\n\n    // unmount external data if necessary\n    wasm.unmountExternalData?.();\n  }\n};\n\nexport const releaseSession = (sessionId: number): void => {\n  const wasm = getInstance();\n  const session = activeSessions.get(sessionId);\n  if (!session) {\n    throw new Error(`cannot release session. invalid session id: ${sessionId}`);\n  }\n  const [sessionHandle, inputNamesUTF8Encoded, outputNamesUTF8Encoded, ioBindingState, enableGraphCapture] = session;\n\n  if (ioBindingState) {\n    if (enableGraphCapture) {\n      if (wasm._OrtClearBoundOutputs(ioBindingState.handle) !== 0) {\n        checkLastError(\"Can't clear bound outputs.\");\n      }\n    }\n    if (wasm._OrtReleaseBinding(ioBindingState.handle) !== 0) {\n      checkLastError(\"Can't release IO binding.\");\n    }\n  }\n\n  wasm.jsepOnReleaseSession?.(sessionId);\n  wasm.webgpuOnReleaseSession?.(sessionId);\n\n  inputNamesUTF8Encoded.forEach((buf) => wasm._OrtFree(buf));\n  outputNamesUTF8Encoded.forEach((buf) => wasm._OrtFree(buf));\n  if (wasm._OrtReleaseSession(sessionHandle) !== 0) {\n    checkLastError(\"Can't release session.\");\n  }\n  activeSessions.delete(sessionId);\n};\n\nexport const prepareInputOutputTensor = async (\n  tensor: TensorMetadata | null,\n  tensorHandles: number[],\n  allocs: number[],\n  sessionId: number,\n  index: number,\n  enableGraphCapture = false,\n): Promise<void> => {\n  if (!tensor) {\n    tensorHandles.push(0);\n    return;\n  }\n\n  const wasm = getInstance();\n  const ptrSize = wasm.PTR_SIZE;\n\n  const dataType = tensor[0];\n  const dims = tensor[1];\n  const location = tensor[3];\n  let actualLocation = location;\n\n  let rawData: number;\n  let dataByteLength: number;\n\n  if (dataType === 'string' && (location === 'gpu-buffer' || location === 'ml-tensor')) {\n    throw new Error('String tensor is not supported on GPU.');\n  }\n\n  if (enableGraphCapture && location !== 'gpu-buffer') {\n    throw new Error(\n      `External buffer must be provided for input/output index ${index} when enableGraphCapture is true.`,\n    );\n  }\n\n  if (location === 'gpu-buffer') {\n    const gpuBuffer = tensor[2].gpuBuffer;\n    dataByteLength = calculateTensorSizeInBytes(tensorDataTypeStringToEnum(dataType), dims)!;\n\n    if (BUILD_DEFS.USE_WEBGPU_EP) {\n      const registerBuffer = wasm.webgpuRegisterBuffer;\n      if (!registerBuffer) {\n        throw new Error('Tensor location \"gpu-buffer\" is not supported without using WebGPU.');\n      }\n\n      rawData = registerBuffer(gpuBuffer, sessionId);\n    } else {\n      const registerBuffer = wasm.jsepRegisterBuffer;\n      if (!registerBuffer) {\n        throw new Error('Tensor location \"gpu-buffer\" is not supported without using WebGPU.');\n      }\n      rawData = registerBuffer(sessionId, index, gpuBuffer, dataByteLength);\n    }\n  } else if (location === 'ml-tensor') {\n    const mlTensor = tensor[2].mlTensor as MLTensor;\n    dataByteLength = calculateTensorSizeInBytes(tensorDataTypeStringToEnum(dataType), dims)!;\n\n    const registerMLTensor = wasm.jsepRegisterMLTensor;\n    if (!registerMLTensor) {\n      throw new Error('Tensor location \"ml-tensor\" is not supported without using WebNN.');\n    }\n    rawData = registerMLTensor(sessionId, mlTensor, tensorDataTypeStringToEnum(dataType), dims);\n  } else {\n    const data = tensor[2];\n\n    if (Array.isArray(data)) {\n      // string tensor\n      dataByteLength = ptrSize * data.length;\n      rawData = wasm._malloc(dataByteLength);\n      allocs.push(rawData);\n      for (let i = 0; i < data.length; i++) {\n        if (typeof data[i] !== 'string') {\n          throw new TypeError(`tensor data at index ${i} is not a string`);\n        }\n        wasm.setValue(rawData + i * ptrSize, allocWasmString(data[i], allocs), '*');\n      }\n    } else {\n      const isGraphInput = wasm.jsepIsGraphInput;\n      if (dataType !== 'string' && isGraphInput) {\n        const tensorNameUTF8 = wasm._OrtGetInputName(sessionId, index);\n        const tensorName = wasm.UTF8ToString(tensorNameUTF8);\n        // Promote the tensor to 'ml-tensor' if it is a graph input.\n        if (isGraphInput(sessionId, tensorName)) {\n          const dataTypeEnum = tensorDataTypeStringToEnum(dataType);\n          dataByteLength = calculateTensorSizeInBytes(dataTypeEnum, dims)!;\n          actualLocation = 'ml-tensor';\n          const createTemporaryTensor = wasm.jsepCreateTemporaryTensor;\n          const uploadTensor = wasm.jsepUploadTensor;\n          if (!createTemporaryTensor || !uploadTensor) {\n            throw new Error('Tensor location \"ml-tensor\" is not supported without using WebNN.');\n          }\n          const tensorId = await createTemporaryTensor(sessionId, dataTypeEnum, dims as number[]);\n          uploadTensor(tensorId, new Uint8Array(data.buffer, data.byteOffset, data.byteLength));\n          rawData = tensorId;\n        } else {\n          dataByteLength = data.byteLength;\n          rawData = wasm._malloc(dataByteLength);\n          allocs.push(rawData);\n          wasm.HEAPU8.set(new Uint8Array(data.buffer, data.byteOffset, dataByteLength), rawData);\n        }\n      } else {\n        dataByteLength = data.byteLength;\n        rawData = wasm._malloc(dataByteLength);\n        allocs.push(rawData);\n        wasm.HEAPU8.set(new Uint8Array(data.buffer, data.byteOffset, dataByteLength), rawData);\n      }\n    }\n  }\n\n  const stack = wasm.stackSave();\n  const dimsOffset = wasm.stackAlloc(4 * dims.length);\n  try {\n    dims.forEach((d, index) => wasm.setValue(dimsOffset + index * ptrSize, d, ptrSize === 4 ? 'i32' : 'i64'));\n    const tensor = wasm._OrtCreateTensor(\n      tensorDataTypeStringToEnum(dataType),\n      rawData,\n      dataByteLength,\n      dimsOffset,\n      dims.length,\n      dataLocationStringToEnum(actualLocation),\n    );\n    if (tensor === 0) {\n      checkLastError(`Can't create tensor for input/output. session=${sessionId}, index=${index}.`);\n    }\n    tensorHandles.push(tensor);\n  } finally {\n    wasm.stackRestore(stack);\n  }\n};\n\n/**\n * perform inference run\n */\nexport const run = async (\n  sessionId: number,\n  inputIndices: number[],\n  inputTensors: TensorMetadata[],\n  outputIndices: number[],\n  outputTensors: Array<TensorMetadata | null>,\n  options: InferenceSession.RunOptions,\n): Promise<TensorMetadata[]> => {\n  const wasm = getInstance();\n  const ptrSize = wasm.PTR_SIZE;\n  const session = activeSessions.get(sessionId);\n  if (!session) {\n    throw new Error(`cannot run inference. invalid session id: ${sessionId}`);\n  }\n  const sessionHandle = session[0];\n  const inputNamesUTF8Encoded = session[1];\n  const outputNamesUTF8Encoded = session[2];\n  const ioBindingState = session[3];\n  const enableGraphCapture = session[4];\n  const inputOutputBound = session[5];\n\n  const inputCount = inputIndices.length;\n  const outputCount = outputIndices.length;\n\n  let runOptionsHandle = 0;\n  let runOptionsAllocs: number[] = [];\n\n  const inputTensorHandles: number[] = [];\n  const outputTensorHandles: number[] = [];\n  const inputOutputAllocs: number[] = [];\n\n  const beforeRunStack = wasm.stackSave();\n  const inputValuesOffset = wasm.stackAlloc(inputCount * ptrSize);\n  const inputNamesOffset = wasm.stackAlloc(inputCount * ptrSize);\n  const outputValuesOffset = wasm.stackAlloc(outputCount * ptrSize);\n  const outputNamesOffset = wasm.stackAlloc(outputCount * ptrSize);\n\n  try {\n    [runOptionsHandle, runOptionsAllocs] = setRunOptions(options);\n\n    // create input tensors\n    for (let i = 0; i < inputCount; i++) {\n      await prepareInputOutputTensor(\n        inputTensors[i],\n        inputTensorHandles,\n        inputOutputAllocs,\n        sessionId,\n        inputIndices[i],\n        enableGraphCapture,\n      );\n    }\n\n    // create output tensors\n    for (let i = 0; i < outputCount; i++) {\n      await prepareInputOutputTensor(\n        outputTensors[i],\n        outputTensorHandles,\n        inputOutputAllocs,\n        sessionId,\n        inputCount + outputIndices[i],\n        enableGraphCapture,\n      );\n    }\n\n    for (let i = 0; i < inputCount; i++) {\n      wasm.setValue(inputValuesOffset + i * ptrSize, inputTensorHandles[i], '*');\n      wasm.setValue(inputNamesOffset + i * ptrSize, inputNamesUTF8Encoded[inputIndices[i]], '*');\n    }\n    for (let i = 0; i < outputCount; i++) {\n      wasm.setValue(outputValuesOffset + i * ptrSize, outputTensorHandles[i], '*');\n      wasm.setValue(outputNamesOffset + i * ptrSize, outputNamesUTF8Encoded[outputIndices[i]], '*');\n    }\n\n    if (!BUILD_DEFS.DISABLE_JSEP && ioBindingState && !inputOutputBound) {\n      const { handle, outputPreferredLocations, outputPreferredLocationsEncoded } = ioBindingState;\n\n      if (inputNamesUTF8Encoded.length !== inputCount) {\n        throw new Error(\n          `input count from feeds (${inputCount}) is expected to be always equal to model's input count (${inputNamesUTF8Encoded.length}).`,\n        );\n      }\n\n      // process inputs\n      for (let i = 0; i < inputCount; i++) {\n        const index = inputIndices[i];\n        const errorCode = await wasm._OrtBindInput(handle, inputNamesUTF8Encoded[index], inputTensorHandles[i]);\n        if (errorCode !== 0) {\n          checkLastError(`Can't bind input[${i}] for session=${sessionId}.`);\n        }\n      }\n\n      // process pre-allocated outputs\n      for (let i = 0; i < outputCount; i++) {\n        const index = outputIndices[i];\n        const location = outputTensors[i]?.[3]; // undefined means output is not pre-allocated.\n\n        if (location) {\n          // output is pre-allocated. bind the tensor.\n          const errorCode = wasm._OrtBindOutput(handle, outputNamesUTF8Encoded[index], outputTensorHandles[i], 0);\n          if (errorCode !== 0) {\n            checkLastError(`Can't bind pre-allocated output[${i}] for session=${sessionId}.`);\n          }\n        } else {\n          // output is not pre-allocated. reset preferred location.\n          const errorCode = wasm._OrtBindOutput(\n            handle,\n            outputNamesUTF8Encoded[index],\n            0,\n            outputPreferredLocationsEncoded[index],\n          );\n          if (errorCode !== 0) {\n            checkLastError(`Can't bind output[${i}] to ${outputPreferredLocations[i]} for session=${sessionId}.`);\n          }\n        }\n      }\n      activeSessions.set(sessionId, [\n        sessionHandle,\n        inputNamesUTF8Encoded,\n        outputNamesUTF8Encoded,\n        ioBindingState,\n        enableGraphCapture,\n        true,\n      ]);\n    }\n\n    wasm.jsepOnRunStart?.(sessionHandle);\n\n    let errorCode: number;\n    if (!BUILD_DEFS.DISABLE_JSEP && ioBindingState) {\n      errorCode = await wasm._OrtRunWithBinding(\n        sessionHandle,\n        ioBindingState.handle,\n        outputCount,\n        outputValuesOffset,\n        runOptionsHandle,\n      );\n    } else {\n      errorCode = await wasm._OrtRun(\n        sessionHandle,\n        inputNamesOffset,\n        inputValuesOffset,\n        inputCount,\n        outputNamesOffset,\n        outputCount,\n        outputValuesOffset,\n        runOptionsHandle,\n      );\n    }\n\n    if (errorCode !== 0) {\n      checkLastError('failed to call OrtRun().');\n    }\n\n    const output: TensorMetadata[] = [];\n\n    for (let i = 0; i < outputCount; i++) {\n      const tensor = Number(wasm.getValue(outputValuesOffset + i * ptrSize, '*'));\n      if (tensor === outputTensorHandles[i]) {\n        // output tensor is pre-allocated. no need to copy data.\n        output.push(outputTensors[i]!);\n        continue;\n      }\n\n      const beforeGetTensorDataStack = wasm.stackSave();\n      // stack allocate 4 pointer value\n      const tensorDataOffset = wasm.stackAlloc(4 * ptrSize);\n\n      let keepOutputTensor = false;\n      let type: Tensor.Type | undefined,\n        dataOffset = 0;\n      try {\n        const errorCode = wasm._OrtGetTensorData(\n          tensor,\n          tensorDataOffset,\n          tensorDataOffset + ptrSize,\n          tensorDataOffset + 2 * ptrSize,\n\n          tensorDataOffset + 3 * ptrSize,\n        );\n        if (errorCode !== 0) {\n          checkLastError(`Can't access output tensor data on index ${i}.`);\n        }\n        const valueType = ptrSize === 4 ? 'i32' : 'i64';\n        const dataType = Number(wasm.getValue(tensorDataOffset, valueType));\n        dataOffset = wasm.getValue(tensorDataOffset + ptrSize, '*');\n        const dimsOffset = wasm.getValue(tensorDataOffset + ptrSize * 2, '*');\n        const dimsLength = Number(wasm.getValue(tensorDataOffset + ptrSize * 3, valueType));\n        const dims = [];\n        for (let i = 0; i < dimsLength; i++) {\n          dims.push(Number(wasm.getValue(dimsOffset + i * ptrSize, valueType)));\n        }\n        if (wasm._OrtFree(dimsOffset) !== 0) {\n          checkLastError(\"Can't free memory for tensor dims.\");\n        }\n        const size = dims.reduce((a, b) => a * b, 1);\n        type = tensorDataTypeEnumToString(dataType);\n\n        const preferredLocation = ioBindingState?.outputPreferredLocations[outputIndices[i]];\n\n        if (type === 'string') {\n          if (preferredLocation === 'gpu-buffer' || preferredLocation === 'ml-tensor') {\n            throw new Error('String tensor is not supported on GPU.');\n          }\n          const stringData: string[] = [];\n          for (let i = 0; i < size; i++) {\n            const offset = wasm.getValue(dataOffset + i * ptrSize, '*');\n            const nextOffset = wasm.getValue(dataOffset + (i + 1) * ptrSize, '*');\n            const maxBytesToRead = i === size - 1 ? undefined : nextOffset - offset;\n            stringData.push(wasm.UTF8ToString(offset, maxBytesToRead));\n          }\n          output.push([type, dims, stringData, 'cpu']);\n        } else {\n          // If a certain output's preferred location is GPU but the tensor is empty, we still need to create a CPU\n          // tensor for it. There is no mapping GPU buffer for an empty tensor.\n          if (preferredLocation === 'gpu-buffer' && size > 0) {\n            const getBuffer = BUILD_DEFS.USE_WEBGPU_EP ? wasm.webgpuGetBuffer : wasm.jsepGetBuffer;\n            if (!getBuffer) {\n              throw new Error('preferredLocation \"gpu-buffer\" is not supported without using WebGPU.');\n            }\n            const gpuBuffer = getBuffer(dataOffset);\n            const bufferSize = calculateTensorSizeInBytes(dataType, size);\n            if (bufferSize === undefined || !isGpuBufferSupportedType(type)) {\n              throw new Error(`Unsupported data type: ${type}`);\n            }\n\n            // do not release the tensor right now. it will be released when user calls tensor.dispose().\n            keepOutputTensor = true;\n\n            if (BUILD_DEFS.USE_WEBGPU_EP) {\n              wasm.webgpuRegisterBuffer!(gpuBuffer, sessionId, dataOffset);\n              const downloadDataFunction = wasm.webgpuCreateDownloader!(gpuBuffer, bufferSize, sessionId);\n              output.push([\n                type,\n                dims,\n                {\n                  gpuBuffer,\n                  download: async () => {\n                    const arrayBuffer = await downloadDataFunction();\n                    const data = new (tensorTypeToTypedArrayConstructor(type!))(arrayBuffer);\n                    return data as Tensor.DataTypeMap[Tensor.GpuBufferDataTypes];\n                  },\n                  dispose: () => {\n                    if (wasm._OrtReleaseTensor(tensor) !== 0) {\n                      checkLastError(\"Can't release tensor.\");\n                    }\n                  },\n                },\n                'gpu-buffer',\n              ]);\n            } else {\n              output.push([\n                type,\n                dims,\n                {\n                  gpuBuffer,\n                  download: wasm.jsepCreateDownloader!(gpuBuffer, bufferSize, type),\n                  dispose: () => {\n                    if (wasm._OrtReleaseTensor(tensor) !== 0) {\n                      checkLastError(\"Can't release tensor.\");\n                    }\n                  },\n                },\n                'gpu-buffer',\n              ]);\n            }\n          } else if (preferredLocation === 'ml-tensor' && size > 0) {\n            const ensureTensor = wasm.jsepEnsureTensor;\n            const isInt64Supported = wasm.jsepIsInt64Supported;\n            if (!ensureTensor || !isInt64Supported) {\n              throw new Error('preferredLocation \"ml-tensor\" is not supported without using WebNN.');\n            }\n            const tensorSize = calculateTensorSizeInBytes(dataType, size);\n            if (tensorSize === undefined || !isMLTensorSupportedType(type)) {\n              throw new Error(`Unsupported data type: ${type}`);\n            }\n            if (type === 'int64' && !isInt64Supported(sessionId)) {\n              throw new Error(\n                `preferredLocation \"ml-tensor\" for int64 output is not supported by current WebNN Context.`,\n              );\n            }\n\n            // If the graph has been partitioned, the output tensor may have not been created. For this reason, we use\n            // ensureTensor to get/create the MLTensor. In which case, we don't need to copy the data if a new tensor\n            // has been created.\n            const mlTensor = await ensureTensor(sessionId, dataOffset, dataType, dims, false);\n\n            // do not release the tensor right now. it will be released when user calls tensor.dispose().\n            keepOutputTensor = true;\n\n            output.push([\n              type,\n              dims,\n              {\n                mlTensor,\n                download: wasm.jsepCreateMLTensorDownloader!(dataOffset, type),\n                dispose: () => {\n                  wasm.jsepReleaseTensorId!(dataOffset);\n                  wasm._OrtReleaseTensor(tensor);\n                },\n              },\n              'ml-tensor',\n            ]);\n          } else {\n            const typedArrayConstructor = tensorTypeToTypedArrayConstructor(type);\n            const data = new typedArrayConstructor(size);\n            new Uint8Array(data.buffer, data.byteOffset, data.byteLength).set(\n              wasm.HEAPU8.subarray(dataOffset, dataOffset + data.byteLength),\n            );\n            output.push([type, dims, data, 'cpu']);\n          }\n        }\n      } finally {\n        wasm.stackRestore(beforeGetTensorDataStack);\n        if (type === 'string' && dataOffset) {\n          wasm._free(dataOffset);\n        }\n        if (!keepOutputTensor) {\n          wasm._OrtReleaseTensor(tensor);\n        }\n        wasm.jsepOnRunEnd?.(sessionHandle);\n      }\n    }\n\n    if (ioBindingState && !enableGraphCapture) {\n      if (wasm._OrtClearBoundOutputs(ioBindingState.handle) !== 0) {\n        checkLastError(\"Can't clear bound outputs.\");\n      }\n      activeSessions.set(sessionId, [\n        sessionHandle,\n        inputNamesUTF8Encoded,\n        outputNamesUTF8Encoded,\n        ioBindingState,\n        enableGraphCapture,\n        false,\n      ]);\n    }\n    return output;\n  } finally {\n    wasm.stackRestore(beforeRunStack);\n\n    if (BUILD_DEFS.USE_WEBGPU_EP) {\n      inputTensors.forEach((t) => {\n        if (t && t[3] === 'gpu-buffer') {\n          wasm.webgpuUnregisterBuffer!(t[2].gpuBuffer);\n        }\n      });\n      outputTensors.forEach((t) => {\n        if (t && t[3] === 'gpu-buffer') {\n          wasm.webgpuUnregisterBuffer!(t[2].gpuBuffer);\n        }\n      });\n    }\n    inputTensorHandles.forEach((v) => wasm._OrtReleaseTensor(v));\n    outputTensorHandles.forEach((v) => wasm._OrtReleaseTensor(v));\n    inputOutputAllocs.forEach((p) => wasm._free(p));\n\n    if (runOptionsHandle !== 0) {\n      wasm._OrtReleaseRunOptions(runOptionsHandle);\n    }\n    runOptionsAllocs.forEach((p) => wasm._free(p));\n  }\n};\n\n/**\n * end profiling\n */\nexport const endProfiling = (sessionId: number): void => {\n  const wasm = getInstance();\n  const session = activeSessions.get(sessionId);\n  if (!session) {\n    throw new Error('invalid session id');\n  }\n  const sessionHandle = session[0];\n\n  // profile file name is not used yet, but it must be freed.\n  const profileFileName = wasm._OrtEndProfiling(sessionHandle);\n  if (profileFileName === 0) {\n    checkLastError(\"Can't get an profile file name.\");\n  }\n  wasm._OrtFree(profileFileName);\n};\n\nexport const extractTransferableBuffers = (tensors: readonly SerializableTensorMetadata[]): ArrayBufferLike[] => {\n  const buffers: ArrayBufferLike[] = [];\n  for (const tensor of tensors) {\n    const data = tensor[2];\n    if (!Array.isArray(data) && 'buffer' in data) {\n      buffers.push(data.buffer);\n    }\n  }\n  return buffers;\n};\n","// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport { env, InferenceSession } from 'onnxruntime-common';\n\nimport {\n  OrtWasmMessage,\n  SerializableInternalBuffer,\n  SerializableSessionMetadata,\n  SerializableTensorMetadata,\n  TensorMetadata,\n} from './proxy-messages';\nimport * as core from './wasm-core-impl';\nimport { initializeWebAssembly } from './wasm-factory';\nimport {\n  importProxyWorker,\n  inferWasmPathPrefixFromScriptSrc,\n  isEsmImportMetaUrlHardcodedAsFileUri,\n} from './wasm-utils-import';\n\nconst isProxy = (): boolean => !!env.wasm.proxy && typeof document !== 'undefined';\nlet proxyWorker: Worker | undefined;\nlet initializing = false;\nlet initialized = false;\nlet aborted = false;\nlet temporaryObjectUrl: string | undefined;\n\ntype PromiseCallbacks<T = void> = [resolve: (result: T) => void, reject: (reason: unknown) => void];\nlet initWasmCallbacks: PromiseCallbacks;\nconst queuedCallbacks: Map<OrtWasmMessage['type'], Array<PromiseCallbacks<unknown>>> = new Map();\n\nconst enqueueCallbacks = (type: OrtWasmMessage['type'], callbacks: PromiseCallbacks<unknown>): void => {\n  const queue = queuedCallbacks.get(type);\n  if (queue) {\n    queue.push(callbacks);\n  } else {\n    queuedCallbacks.set(type, [callbacks]);\n  }\n};\n\nconst ensureWorker = (): void => {\n  if (initializing || !initialized || aborted || !proxyWorker) {\n    throw new Error('worker not ready');\n  }\n};\n\nconst onProxyWorkerMessage = (ev: MessageEvent<OrtWasmMessage>): void => {\n  switch (ev.data.type) {\n    case 'init-wasm':\n      initializing = false;\n      if (ev.data.err) {\n        aborted = true;\n        initWasmCallbacks[1](ev.data.err);\n      } else {\n        initialized = true;\n        initWasmCallbacks[0]();\n      }\n      if (temporaryObjectUrl) {\n        URL.revokeObjectURL(temporaryObjectUrl);\n        temporaryObjectUrl = undefined;\n      }\n      break;\n    case 'init-ep':\n    case 'copy-from':\n    case 'create':\n    case 'release':\n    case 'run':\n    case 'end-profiling': {\n      const callbacks = queuedCallbacks.get(ev.data.type)!;\n      if (ev.data.err) {\n        callbacks.shift()![1](ev.data.err);\n      } else {\n        callbacks.shift()![0](ev.data.out!);\n      }\n      break;\n    }\n    default:\n  }\n};\n\nexport const initializeWebAssemblyAndOrtRuntime = async (): Promise<void> => {\n  if (initialized) {\n    return;\n  }\n  if (initializing) {\n    throw new Error(\"multiple calls to 'initWasm()' detected.\");\n  }\n  if (aborted) {\n    throw new Error(\"previous call to 'initWasm()' failed.\");\n  }\n\n  initializing = true;\n\n  if (!BUILD_DEFS.DISABLE_WASM_PROXY && isProxy()) {\n    return new Promise<void>((resolve, reject) => {\n      proxyWorker?.terminate();\n\n      void importProxyWorker().then(([objectUrl, worker]) => {\n        try {\n          proxyWorker = worker;\n          proxyWorker.onerror = (ev: ErrorEvent) => reject(ev);\n          proxyWorker.onmessage = onProxyWorkerMessage;\n          initWasmCallbacks = [resolve, reject];\n          const message: OrtWasmMessage = { type: 'init-wasm', in: env };\n\n          // if the proxy worker is loaded from a blob URL, we need to make sure the path information is not lost.\n          //\n          // when `env.wasm.wasmPaths` is not set, we need to pass the path information to the worker.\n          //\n          if (!BUILD_DEFS.ENABLE_BUNDLE_WASM_JS && !message.in!.wasm.wasmPaths && objectUrl) {\n            // for a build not bundled the wasm JS, we need to pass the path prefix to the worker.\n            // the path prefix will be used to resolve the path to both the wasm JS and the wasm file.\n            const inferredWasmPathPrefix = inferWasmPathPrefixFromScriptSrc();\n            if (inferredWasmPathPrefix) {\n              message.in!.wasm.wasmPaths = inferredWasmPathPrefix;\n            }\n          }\n\n          if (\n            BUILD_DEFS.IS_ESM &&\n            BUILD_DEFS.ENABLE_BUNDLE_WASM_JS &&\n            !message.in!.wasm.wasmPaths &&\n            (objectUrl || isEsmImportMetaUrlHardcodedAsFileUri)\n          ) {\n            // for a build bundled the wasm JS, if either of the following conditions is met:\n            // - the proxy worker is loaded from a blob URL\n            // - `import.meta.url` is a file URL, it means it is overwriten by the bundler.\n            //\n            // in either case, the path information is lost, we need to pass the path of the .wasm file to the worker.\n            // we need to use the bundler preferred URL format:\n            // new URL('filename', import.meta.url)\n            // so that the bundler can handle the file using corresponding loaders.\n            message.in!.wasm.wasmPaths = {\n              wasm: !BUILD_DEFS.DISABLE_JSEP\n                ? new URL('ort-wasm-simd-threaded.jsep.wasm', BUILD_DEFS.ESM_IMPORT_META_URL).href\n                : new URL('ort-wasm-simd-threaded.wasm', BUILD_DEFS.ESM_IMPORT_META_URL).href,\n            };\n          }\n          proxyWorker.postMessage(message);\n          temporaryObjectUrl = objectUrl;\n        } catch (e) {\n          reject(e);\n        }\n      }, reject);\n    });\n  } else {\n    try {\n      await initializeWebAssembly(env.wasm);\n      await core.initRuntime(env);\n      initialized = true;\n    } catch (e) {\n      aborted = true;\n      throw e;\n    } finally {\n      initializing = false;\n    }\n  }\n};\n\nexport const initializeOrtEp = async (epName: string): Promise<void> => {\n  if (!BUILD_DEFS.DISABLE_WASM_PROXY && isProxy()) {\n    ensureWorker();\n    return new Promise<void>((resolve, reject) => {\n      enqueueCallbacks('init-ep', [resolve, reject]);\n      const message: OrtWasmMessage = { type: 'init-ep', in: { epName, env } };\n      proxyWorker!.postMessage(message);\n    });\n  } else {\n    await core.initEp(env, epName);\n  }\n};\n\nexport const copyFromExternalBuffer = async (buffer: Uint8Array): Promise<SerializableInternalBuffer> => {\n  if (!BUILD_DEFS.DISABLE_WASM_PROXY && isProxy()) {\n    ensureWorker();\n    return new Promise<SerializableInternalBuffer>((resolve, reject) => {\n      enqueueCallbacks('copy-from', [resolve, reject]);\n      const message: OrtWasmMessage = { type: 'copy-from', in: { buffer } };\n      proxyWorker!.postMessage(message, [buffer.buffer]);\n    });\n  } else {\n    return core.copyFromExternalBuffer(buffer);\n  }\n};\n\nexport const createSession = async (\n  model: SerializableInternalBuffer | Uint8Array,\n  options?: InferenceSession.SessionOptions,\n): Promise<SerializableSessionMetadata> => {\n  if (!BUILD_DEFS.DISABLE_WASM_PROXY && isProxy()) {\n    // check unsupported options\n    if (options?.preferredOutputLocation) {\n      throw new Error('session option \"preferredOutputLocation\" is not supported for proxy.');\n    }\n    ensureWorker();\n    return new Promise<SerializableSessionMetadata>((resolve, reject) => {\n      enqueueCallbacks('create', [resolve, reject]);\n      const message: OrtWasmMessage = { type: 'create', in: { model, options: { ...options } } };\n      const transferable: Transferable[] = [];\n      if (model instanceof Uint8Array) {\n        transferable.push(model.buffer);\n      }\n      proxyWorker!.postMessage(message, transferable);\n    });\n  } else {\n    return core.createSession(model, options);\n  }\n};\n\nexport const releaseSession = async (sessionId: number): Promise<void> => {\n  if (!BUILD_DEFS.DISABLE_WASM_PROXY && isProxy()) {\n    ensureWorker();\n    return new Promise<void>((resolve, reject) => {\n      enqueueCallbacks('release', [resolve, reject]);\n      const message: OrtWasmMessage = { type: 'release', in: sessionId };\n      proxyWorker!.postMessage(message);\n    });\n  } else {\n    core.releaseSession(sessionId);\n  }\n};\n\nexport const run = async (\n  sessionId: number,\n  inputIndices: number[],\n  inputs: TensorMetadata[],\n  outputIndices: number[],\n  outputs: Array<TensorMetadata | null>,\n  options: InferenceSession.RunOptions,\n): Promise<TensorMetadata[]> => {\n  if (!BUILD_DEFS.DISABLE_WASM_PROXY && isProxy()) {\n    // check inputs location\n    if (inputs.some((t) => t[3] !== 'cpu')) {\n      throw new Error('input tensor on GPU is not supported for proxy.');\n    }\n    // check outputs location\n    if (outputs.some((t) => t)) {\n      throw new Error('pre-allocated output tensor is not supported for proxy.');\n    }\n    ensureWorker();\n    return new Promise<SerializableTensorMetadata[]>((resolve, reject) => {\n      enqueueCallbacks('run', [resolve, reject]);\n      const serializableInputs = inputs as SerializableTensorMetadata[]; // every input is on CPU.\n      const message: OrtWasmMessage = {\n        type: 'run',\n        in: { sessionId, inputIndices, inputs: serializableInputs, outputIndices, options },\n      };\n      proxyWorker!.postMessage(message, core.extractTransferableBuffers(serializableInputs));\n    });\n  } else {\n    return core.run(sessionId, inputIndices, inputs, outputIndices, outputs, options);\n  }\n};\n\nexport const endProfiling = async (sessionId: number): Promise<void> => {\n  if (!BUILD_DEFS.DISABLE_WASM_PROXY && isProxy()) {\n    ensureWorker();\n    return new Promise<void>((resolve, reject) => {\n      enqueueCallbacks('end-profiling', [resolve, reject]);\n      const message: OrtWasmMessage = { type: 'end-profiling', in: sessionId };\n      proxyWorker!.postMessage(message);\n    });\n  } else {\n    core.endProfiling(sessionId);\n  }\n};\n","// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {\n  InferenceSession,\n  InferenceSessionHandler,\n  SessionHandler,\n  Tensor,\n  TRACE_FUNC_BEGIN,\n  TRACE_FUNC_END,\n} from 'onnxruntime-common';\n\nimport { SerializableInternalBuffer, TensorMetadata } from './proxy-messages';\nimport { copyFromExternalBuffer, createSession, endProfiling, releaseSession, run } from './proxy-wrapper';\nimport { isGpuBufferSupportedType, isMLTensorSupportedType } from './wasm-common';\nimport { isNode } from './wasm-utils-env';\nimport { loadFile } from './wasm-utils-load-file';\n\nexport const encodeTensorMetadata = (tensor: Tensor, getName: () => string): TensorMetadata => {\n  switch (tensor.location) {\n    case 'cpu':\n      return [tensor.type, tensor.dims, tensor.data, 'cpu'];\n    case 'gpu-buffer':\n      return [tensor.type, tensor.dims, { gpuBuffer: tensor.gpuBuffer }, 'gpu-buffer'];\n    case 'ml-tensor':\n      return [tensor.type, tensor.dims, { mlTensor: tensor.mlTensor }, 'ml-tensor'];\n    default:\n      throw new Error(`invalid data location: ${tensor.location} for ${getName()}`);\n  }\n};\n\nexport const decodeTensorMetadata = (tensor: TensorMetadata): Tensor => {\n  switch (tensor[3]) {\n    case 'cpu':\n      return new Tensor(tensor[0], tensor[2], tensor[1]);\n    case 'gpu-buffer': {\n      const dataType = tensor[0];\n      if (!isGpuBufferSupportedType(dataType)) {\n        throw new Error(`not supported data type: ${dataType} for deserializing GPU tensor`);\n      }\n      const { gpuBuffer, download, dispose } = tensor[2];\n      return Tensor.fromGpuBuffer(gpuBuffer, { dataType, dims: tensor[1], download, dispose });\n    }\n    case 'ml-tensor': {\n      const dataType = tensor[0];\n      if (!isMLTensorSupportedType(dataType)) {\n        throw new Error(`not supported data type: ${dataType} for deserializing MLTensor tensor`);\n      }\n      const { mlTensor, download, dispose } = tensor[2];\n      return Tensor.fromMLTensor(mlTensor, { dataType, dims: tensor[1], download, dispose });\n    }\n    default:\n      throw new Error(`invalid data location: ${tensor[3]}`);\n  }\n};\n\nexport class OnnxruntimeWebAssemblySessionHandler implements InferenceSessionHandler {\n  private sessionId: number;\n\n  inputNames: string[];\n  outputNames: string[];\n\n  async fetchModelAndCopyToWasmMemory(path: string): Promise<SerializableInternalBuffer> {\n    // fetch model from url and move to wasm heap.\n    return copyFromExternalBuffer(await loadFile(path));\n  }\n\n  async loadModel(pathOrBuffer: string | Uint8Array, options?: InferenceSession.SessionOptions): Promise<void> {\n    TRACE_FUNC_BEGIN();\n    let model: Parameters<typeof createSession>[0];\n\n    if (typeof pathOrBuffer === 'string') {\n      if (isNode) {\n        // node\n        model = await loadFile(pathOrBuffer);\n      } else {\n        // browser\n        // fetch model and copy to wasm heap.\n        model = await this.fetchModelAndCopyToWasmMemory(pathOrBuffer);\n      }\n    } else {\n      model = pathOrBuffer;\n    }\n\n    [this.sessionId, this.inputNames, this.outputNames] = await createSession(model, options);\n    TRACE_FUNC_END();\n  }\n\n  async dispose(): Promise<void> {\n    return releaseSession(this.sessionId);\n  }\n\n  async run(\n    feeds: SessionHandler.FeedsType,\n    fetches: SessionHandler.FetchesType,\n    options: InferenceSession.RunOptions,\n  ): Promise<SessionHandler.ReturnType> {\n    TRACE_FUNC_BEGIN();\n    const inputArray: Tensor[] = [];\n    const inputIndices: number[] = [];\n    Object.entries(feeds).forEach((kvp) => {\n      const name = kvp[0];\n      const tensor = kvp[1];\n      const index = this.inputNames.indexOf(name);\n      if (index === -1) {\n        throw new Error(`invalid input '${name}'`);\n      }\n      inputArray.push(tensor);\n      inputIndices.push(index);\n    });\n\n    const outputArray: Array<Tensor | null> = [];\n    const outputIndices: number[] = [];\n    Object.entries(fetches).forEach((kvp) => {\n      const name = kvp[0];\n      const tensor = kvp[1];\n      const index = this.outputNames.indexOf(name);\n      if (index === -1) {\n        throw new Error(`invalid output '${name}'`);\n      }\n      outputArray.push(tensor);\n      outputIndices.push(index);\n    });\n\n    const inputs = inputArray.map((t, i) =>\n      encodeTensorMetadata(t, () => `input \"${this.inputNames[inputIndices[i]]}\"`),\n    );\n    const outputs = outputArray.map((t, i) =>\n      t ? encodeTensorMetadata(t, () => `output \"${this.outputNames[outputIndices[i]]}\"`) : null,\n    );\n\n    const results = await run(this.sessionId, inputIndices, inputs, outputIndices, outputs, options);\n\n    const resultMap: SessionHandler.ReturnType = {};\n    for (let i = 0; i < results.length; i++) {\n      resultMap[this.outputNames[outputIndices[i]]] = outputArray[i] ?? decodeTensorMetadata(results[i]);\n    }\n    TRACE_FUNC_END();\n    return resultMap;\n  }\n\n  startProfiling(): void {\n    // TODO: implement profiling\n  }\n\n  endProfiling(): void {\n    void endProfiling(this.sessionId);\n  }\n}\n","// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport { Backend, env, InferenceSession, InferenceSessionHandler } from 'onnxruntime-common';\n\nimport { initializeOrtEp, initializeWebAssemblyAndOrtRuntime } from './wasm/proxy-wrapper';\nimport { OnnxruntimeWebAssemblySessionHandler } from './wasm/session-handler-inference';\n\n/**\n * This function initializes all flags for WebAssembly.\n *\n * Those flags are accessible from `ort.env.wasm`. Users are allow to set those flags before the first inference session\n * being created, to override default value.\n */\nexport const initializeFlags = (): void => {\n  if (typeof env.wasm.initTimeout !== 'number' || env.wasm.initTimeout < 0) {\n    env.wasm.initTimeout = 0;\n  }\n\n  if (env.wasm.simd === false) {\n    // eslint-disable-next-line no-console\n    console.warn(\n      'Deprecated property \"env.wasm.simd\" is set to false. ' +\n        'non-SIMD build is no longer provided, and this setting will be ignored.',\n    );\n  }\n\n  if (typeof env.wasm.proxy !== 'boolean') {\n    env.wasm.proxy = false;\n  }\n\n  if (typeof env.wasm.trace !== 'boolean') {\n    env.wasm.trace = false;\n  }\n\n  if (typeof env.wasm.numThreads !== 'number' || !Number.isInteger(env.wasm.numThreads) || env.wasm.numThreads <= 0) {\n    // The following logic only applies when `ort.env.wasm.numThreads` is not set by user. We will always honor user's\n    // setting if it is provided.\n\n    // Browser: when crossOriginIsolated is false, SharedArrayBuffer is not available so WebAssembly threads will not\n    // work. In this case, we will set numThreads to 1.\n    //\n    // There is an exception: when the browser is configured to force-enable SharedArrayBuffer (e.g. Chromuim with\n    // --enable-features=SharedArrayBuffer), it is possible that `self.crossOriginIsolated` is false and\n    // SharedArrayBuffer is available at the same time. This is usually for testing. In this case,  we will still set\n    // numThreads to 1 here. If we want to enable multi-threading in test, we should set `ort.env.wasm.numThreads` to a\n    // value greater than 1.\n    if (typeof self !== 'undefined' && !self.crossOriginIsolated) {\n      env.wasm.numThreads = 1;\n    } else {\n      const numCpuLogicalCores =\n        typeof navigator === 'undefined' ? require('node:os').cpus().length : navigator.hardwareConcurrency;\n      env.wasm.numThreads = Math.min(4, Math.ceil((numCpuLogicalCores || 1) / 2));\n    }\n  }\n};\n\nexport class OnnxruntimeWebAssemblyBackend implements Backend {\n  /**\n   * This function initializes the WebAssembly backend.\n   *\n   * This function will be called only once for each backend name. It will be called the first time when\n   * `ort.InferenceSession.create()` is called with a registered backend name.\n   *\n   * @param backendName - the registered backend name.\n   */\n  async init(backendName: string): Promise<void> {\n    // populate wasm flags\n    initializeFlags();\n\n    // init wasm\n    await initializeWebAssemblyAndOrtRuntime();\n\n    // performe EP specific initialization\n    await initializeOrtEp(backendName);\n  }\n  createInferenceSessionHandler(\n    path: string,\n    options?: InferenceSession.SessionOptions,\n  ): Promise<InferenceSessionHandler>;\n  createInferenceSessionHandler(\n    buffer: Uint8Array,\n    options?: InferenceSession.SessionOptions,\n  ): Promise<InferenceSessionHandler>;\n  async createInferenceSessionHandler(\n    pathOrBuffer: string | Uint8Array,\n    options?: InferenceSession.SessionOptions,\n  ): Promise<InferenceSessionHandler> {\n    const handler = new OnnxruntimeWebAssemblySessionHandler();\n    await handler.loadModel(pathOrBuffer, options);\n    return Promise.resolve(handler);\n  }\n}\n\nexport const wasmBackend = new OnnxruntimeWebAssemblyBackend();\n","// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\n/* eslint-disable @typescript-eslint/no-var-requires, @typescript-eslint/no-require-imports */\n\n// We use \"require\" instead of \"import\" here because import statement must be put in top level. Our current code does\n// not allow bundler to tree-shaking code as expected because some codes are treated as having side effects.\n// So we import code inside the if-clause to allow bundler remove the code safely.\n\nexport * from 'onnxruntime-common';\nimport * as ort from 'onnxruntime-common';\nexport default ort;\n\nimport { registerBackend, env } from 'onnxruntime-common';\nimport { version } from './version';\n\nif (!BUILD_DEFS.DISABLE_WEBGL) {\n  const onnxjsBackend = require('./backend-onnxjs').onnxjsBackend;\n  registerBackend('webgl', onnxjsBackend, -10);\n}\n\nif (!BUILD_DEFS.DISABLE_WASM) {\n  const wasmBackend = require('./backend-wasm').wasmBackend;\n  if (!BUILD_DEFS.DISABLE_JSEP) {\n    registerBackend('webgpu', wasmBackend, 5);\n    registerBackend('webnn', wasmBackend, 5);\n  }\n  registerBackend('cpu', wasmBackend, 10);\n  registerBackend('wasm', wasmBackend, 10);\n}\n\nObject.defineProperty(env.versions, 'web', { value: version, enumerable: true });\n","// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\n// This file is generated by /js/scripts/update-version.ts\n// Do not modify file content manually.\n\nexport const version = '1.22.0';\n"]}